{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acad7b98",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-07T11:34:45.773552Z",
     "iopub.status.busy": "2024-04-07T11:34:45.773241Z",
     "iopub.status.idle": "2024-04-07T11:34:45.783907Z",
     "shell.execute_reply": "2024-04-07T11:34:45.783071Z"
    },
    "papermill": {
     "duration": 0.016317,
     "end_time": "2024-04-07T11:34:45.785865",
     "exception": false,
     "start_time": "2024-04-07T11:34:45.769548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('/kaggle/input/baid-model-test/baid-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa9ea0e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T11:34:45.790852Z",
     "iopub.status.busy": "2024-04-07T11:34:45.790561Z",
     "iopub.status.idle": "2024-04-07T18:08:07.932830Z",
     "shell.execute_reply": "2024-04-07T18:08:07.931494Z"
    },
    "papermill": {
     "duration": 23602.147507,
     "end_time": "2024-04-07T18:08:07.935480",
     "exception": false,
     "start_time": "2024-04-07T11:34:45.787973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 50731/50731 [00:00<00:00, 323717.17it/s]\r\n",
      "100%|███████████████████████████████████| 3199/3199 [00:00<00:00, 279195.52it/s]\r\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\r\n",
      "  warnings.warn(\r\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\r\n",
      "  warnings.warn(msg)\r\n",
      "Checkpoint keys: ['epoch', 'model_state_dict', 'optimizer_state_dict']\r\n",
      "Resuming from epoch 78\r\n",
      "78\r\n",
      "100%|█████████████████████████████████| 50731/50731 [00:00<00:00, 296571.61it/s]\r\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\r\n",
      "  warnings.warn(_create_warning_msg(\r\n",
      "100%|███████████████████████████████████| 3199/3199 [00:00<00:00, 253324.37it/s]\r\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\r\n",
      "  warnings.warn(_create_warning_msg(\r\n",
      "Epoch:  78 Step:     0 /   793 Train loss: 0.02467458\r\n",
      "Epoch:  78 Step:     1 /   793 Train loss: 0.02252991\r\n",
      "Epoch:  78 Step:     2 /   793 Train loss: 0.02828561\r\n",
      "Epoch:  78 Step:     3 /   793 Train loss: 0.02865759\r\n",
      "Epoch:  78 Step:     4 /   793 Train loss: 0.00827629\r\n",
      "Epoch:  78 Step:     5 /   793 Train loss: 0.01174787\r\n",
      "Epoch:  78 Step:     6 /   793 Train loss: 0.01941502\r\n",
      "Epoch:  78 Step:     7 /   793 Train loss: 0.02492953\r\n",
      "Epoch:  78 Step:     8 /   793 Train loss: 0.01801393\r\n",
      "Epoch:  78 Step:     9 /   793 Train loss: 0.01466898\r\n",
      "Epoch:  78 Step:    10 /   793 Train loss: 0.01907980\r\n",
      "Epoch:  78 Step:    11 /   793 Train loss: 0.01481916\r\n",
      "Epoch:  78 Step:    12 /   793 Train loss: 0.02606429\r\n",
      "Epoch:  78 Step:    13 /   793 Train loss: 0.02616175\r\n",
      "Epoch:  78 Step:    14 /   793 Train loss: 0.02492745\r\n",
      "Epoch:  78 Step:    15 /   793 Train loss: 0.01209474\r\n",
      "Epoch:  78 Step:    16 /   793 Train loss: 0.02755599\r\n",
      "Epoch:  78 Step:    17 /   793 Train loss: 0.01385238\r\n",
      "Epoch:  78 Step:    18 /   793 Train loss: 0.01821828\r\n",
      "Epoch:  78 Step:    19 /   793 Train loss: 0.02514118\r\n",
      "Epoch:  78 Step:    20 /   793 Train loss: 0.02840548\r\n",
      "Epoch:  78 Step:    21 /   793 Train loss: 0.01890963\r\n",
      "Epoch:  78 Step:    22 /   793 Train loss: 0.02081869\r\n",
      "Epoch:  78 Step:    23 /   793 Train loss: 0.00745791\r\n",
      "Epoch:  78 Step:    24 /   793 Train loss: 0.03667982\r\n",
      "Epoch:  78 Step:    25 /   793 Train loss: 0.01698530\r\n",
      "Epoch:  78 Step:    26 /   793 Train loss: 0.03049707\r\n",
      "Epoch:  78 Step:    27 /   793 Train loss: 0.02125138\r\n",
      "Epoch:  78 Step:    28 /   793 Train loss: 0.01367106\r\n",
      "Epoch:  78 Step:    29 /   793 Train loss: 0.03877172\r\n",
      "Epoch:  78 Step:    30 /   793 Train loss: 0.01413115\r\n",
      "Epoch:  78 Step:    31 /   793 Train loss: 0.02044337\r\n",
      "Epoch:  78 Step:    32 /   793 Train loss: 0.02152419\r\n",
      "Epoch:  78 Step:    33 /   793 Train loss: 0.02444812\r\n",
      "Epoch:  78 Step:    34 /   793 Train loss: 0.03025264\r\n",
      "Epoch:  78 Step:    35 /   793 Train loss: 0.02053700\r\n",
      "Epoch:  78 Step:    36 /   793 Train loss: 0.03668930\r\n",
      "Epoch:  78 Step:    37 /   793 Train loss: 0.02937461\r\n",
      "Epoch:  78 Step:    38 /   793 Train loss: 0.02370808\r\n",
      "Epoch:  78 Step:    39 /   793 Train loss: 0.02139157\r\n",
      "Epoch:  78 Step:    40 /   793 Train loss: 0.02549565\r\n",
      "Epoch:  78 Step:    41 /   793 Train loss: 0.01365961\r\n",
      "Epoch:  78 Step:    42 /   793 Train loss: 0.01686558\r\n",
      "Epoch:  78 Step:    43 /   793 Train loss: 0.02669878\r\n",
      "Epoch:  78 Step:    44 /   793 Train loss: 0.02672434\r\n",
      "Epoch:  78 Step:    45 /   793 Train loss: 0.02396157\r\n",
      "Epoch:  78 Step:    46 /   793 Train loss: 0.02257275\r\n",
      "Epoch:  78 Step:    47 /   793 Train loss: 0.02082419\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  78 Step:    48 /   793 Train loss: 0.03491363\r\n",
      "Epoch:  78 Step:    49 /   793 Train loss: 0.01988975\r\n",
      "Epoch:  78 Step:    50 /   793 Train loss: 0.02089050\r\n",
      "Epoch:  78 Step:    51 /   793 Train loss: 0.02599998\r\n",
      "Epoch:  78 Step:    52 /   793 Train loss: 0.02200416\r\n",
      "Epoch:  78 Step:    53 /   793 Train loss: 0.01901443\r\n",
      "Epoch:  78 Step:    54 /   793 Train loss: 0.02252792\r\n",
      "Epoch:  78 Step:    55 /   793 Train loss: 0.02688403\r\n",
      "Epoch:  78 Step:    56 /   793 Train loss: 0.02302107\r\n",
      "Epoch:  78 Step:    57 /   793 Train loss: 0.02033565\r\n",
      "Epoch:  78 Step:    58 /   793 Train loss: 0.01874400\r\n",
      "Epoch:  78 Step:    59 /   793 Train loss: 0.02545780\r\n",
      "Epoch:  78 Step:    60 /   793 Train loss: 0.02001565\r\n",
      "Epoch:  78 Step:    61 /   793 Train loss: 0.01410196\r\n",
      "Epoch:  78 Step:    62 /   793 Train loss: 0.02878511\r\n",
      "Epoch:  78 Step:    63 /   793 Train loss: 0.01201974\r\n",
      "Epoch:  78 Step:    64 /   793 Train loss: 0.02037863\r\n",
      "Epoch:  78 Step:    65 /   793 Train loss: 0.03320532\r\n",
      "Epoch:  78 Step:    66 /   793 Train loss: 0.01984405\r\n",
      "Epoch:  78 Step:    67 /   793 Train loss: 0.02535726\r\n",
      "Epoch:  78 Step:    68 /   793 Train loss: 0.03271460\r\n",
      "Epoch:  78 Step:    69 /   793 Train loss: 0.01871449\r\n",
      "Epoch:  78 Step:    70 /   793 Train loss: 0.02981827\r\n",
      "Epoch:  78 Step:    71 /   793 Train loss: 0.02285305\r\n",
      "Epoch:  78 Step:    72 /   793 Train loss: 0.02628792\r\n",
      "Epoch:  78 Step:    73 /   793 Train loss: 0.01737462\r\n",
      "Epoch:  78 Step:    74 /   793 Train loss: 0.01476838\r\n",
      "Epoch:  78 Step:    75 /   793 Train loss: 0.02807662\r\n",
      "Epoch:  78 Step:    76 /   793 Train loss: 0.02323877\r\n",
      "Epoch:  78 Step:    77 /   793 Train loss: 0.02735093\r\n",
      "Epoch:  78 Step:    78 /   793 Train loss: 0.04380573\r\n",
      "Epoch:  78 Step:    79 /   793 Train loss: 0.02797704\r\n",
      "Epoch:  78 Step:    80 /   793 Train loss: 0.02377454\r\n",
      "Epoch:  78 Step:    81 /   793 Train loss: 0.02418415\r\n",
      "Epoch:  78 Step:    82 /   793 Train loss: 0.02423157\r\n",
      "Epoch:  78 Step:    83 /   793 Train loss: 0.01797244\r\n",
      "Epoch:  78 Step:    84 /   793 Train loss: 0.02178994\r\n",
      "Epoch:  78 Step:    85 /   793 Train loss: 0.02477301\r\n",
      "Epoch:  78 Step:    86 /   793 Train loss: 0.02310991\r\n",
      "Epoch:  78 Step:    87 /   793 Train loss: 0.01961347\r\n",
      "Epoch:  78 Step:    88 /   793 Train loss: 0.02115643\r\n",
      "Epoch:  78 Step:    89 /   793 Train loss: 0.02110784\r\n",
      "Epoch:  78 Step:    90 /   793 Train loss: 0.03523276\r\n",
      "Epoch:  78 Step:    91 /   793 Train loss: 0.03340332\r\n",
      "Epoch:  78 Step:    92 /   793 Train loss: 0.02473098\r\n",
      "Epoch:  78 Step:    93 /   793 Train loss: 0.03412232\r\n",
      "Epoch:  78 Step:    94 /   793 Train loss: 0.02081305\r\n",
      "Epoch:  78 Step:    95 /   793 Train loss: 0.01954076\r\n",
      "Epoch:  78 Step:    96 /   793 Train loss: 0.02115004\r\n",
      "Epoch:  78 Step:    97 /   793 Train loss: 0.03191832\r\n",
      "Epoch:  78 Step:    98 /   793 Train loss: 0.03664260\r\n",
      "Epoch:  78 Step:    99 /   793 Train loss: 0.02225244\r\n",
      "Epoch:  78 Step:   100 /   793 Train loss: 0.02714999\r\n",
      "Epoch:  78 Step:   101 /   793 Train loss: 0.01499035\r\n",
      "Epoch:  78 Step:   102 /   793 Train loss: 0.02209143\r\n",
      "Epoch:  78 Step:   103 /   793 Train loss: 0.03605763\r\n",
      "Epoch:  78 Step:   104 /   793 Train loss: 0.02267659\r\n",
      "Epoch:  78 Step:   105 /   793 Train loss: 0.01781811\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  78 Step:   106 /   793 Train loss: 0.02846511\r\n",
      "Epoch:  78 Step:   107 /   793 Train loss: 0.02000616\r\n",
      "Epoch:  78 Step:   108 /   793 Train loss: 0.02649965\r\n",
      "Epoch:  78 Step:   109 /   793 Train loss: 0.03502161\r\n",
      "Epoch:  78 Step:   110 /   793 Train loss: 0.02218049\r\n",
      "Epoch:  78 Step:   111 /   793 Train loss: 0.02620088\r\n",
      "Epoch:  78 Step:   112 /   793 Train loss: 0.01475580\r\n",
      "Epoch:  78 Step:   113 /   793 Train loss: 0.02008420\r\n",
      "Epoch:  78 Step:   114 /   793 Train loss: 0.01847734\r\n",
      "Epoch:  78 Step:   115 /   793 Train loss: 0.02409792\r\n",
      "Epoch:  78 Step:   116 /   793 Train loss: 0.02802621\r\n",
      "Epoch:  78 Step:   117 /   793 Train loss: 0.03127154\r\n",
      "Epoch:  78 Step:   118 /   793 Train loss: 0.02274358\r\n",
      "Epoch:  78 Step:   119 /   793 Train loss: 0.01453376\r\n",
      "Epoch:  78 Step:   120 /   793 Train loss: 0.03269695\r\n",
      "Epoch:  78 Step:   121 /   793 Train loss: 0.01600899\r\n",
      "Epoch:  78 Step:   122 /   793 Train loss: 0.02361937\r\n",
      "Epoch:  78 Step:   123 /   793 Train loss: 0.02650174\r\n",
      "Epoch:  78 Step:   124 /   793 Train loss: 0.01807549\r\n",
      "Epoch:  78 Step:   125 /   793 Train loss: 0.02497842\r\n",
      "Epoch:  78 Step:   126 /   793 Train loss: 0.01134179\r\n",
      "Epoch:  78 Step:   127 /   793 Train loss: 0.02651890\r\n",
      "Epoch:  78 Step:   128 /   793 Train loss: 0.01985207\r\n",
      "Epoch:  78 Step:   129 /   793 Train loss: 0.02069776\r\n",
      "Epoch:  78 Step:   130 /   793 Train loss: 0.01870143\r\n",
      "Epoch:  78 Step:   131 /   793 Train loss: 0.02994440\r\n",
      "Epoch:  78 Step:   132 /   793 Train loss: 0.02831483\r\n",
      "Epoch:  78 Step:   133 /   793 Train loss: 0.01876765\r\n",
      "Epoch:  78 Step:   134 /   793 Train loss: 0.04024971\r\n",
      "Epoch:  78 Step:   135 /   793 Train loss: 0.02139773\r\n",
      "Epoch:  78 Step:   136 /   793 Train loss: 0.02760399\r\n",
      "Epoch:  78 Step:   137 /   793 Train loss: 0.02042430\r\n",
      "Epoch:  78 Step:   138 /   793 Train loss: 0.02280911\r\n",
      "Epoch:  78 Step:   139 /   793 Train loss: 0.02487426\r\n",
      "Epoch:  78 Step:   140 /   793 Train loss: 0.02439987\r\n",
      "Epoch:  78 Step:   141 /   793 Train loss: 0.02473588\r\n",
      "Epoch:  78 Step:   142 /   793 Train loss: 0.03008264\r\n",
      "Epoch:  78 Step:   143 /   793 Train loss: 0.02403351\r\n",
      "Epoch:  78 Step:   144 /   793 Train loss: 0.01709220\r\n",
      "Epoch:  78 Step:   145 /   793 Train loss: 0.01886504\r\n",
      "Epoch:  78 Step:   146 /   793 Train loss: 0.02828162\r\n",
      "Epoch:  78 Step:   147 /   793 Train loss: 0.01345629\r\n",
      "Epoch:  78 Step:   148 /   793 Train loss: 0.02577675\r\n",
      "Epoch:  78 Step:   149 /   793 Train loss: 0.03009094\r\n",
      "Epoch:  78 Step:   150 /   793 Train loss: 0.01772735\r\n",
      "Epoch:  78 Step:   151 /   793 Train loss: 0.02638871\r\n",
      "Epoch:  78 Step:   152 /   793 Train loss: 0.02389566\r\n",
      "Epoch:  78 Step:   153 /   793 Train loss: 0.01988460\r\n",
      "Epoch:  78 Step:   154 /   793 Train loss: 0.03995856\r\n",
      "Epoch:  78 Step:   155 /   793 Train loss: 0.00951557\r\n",
      "Epoch:  78 Step:   156 /   793 Train loss: 0.01200573\r\n",
      "Epoch:  78 Step:   157 /   793 Train loss: 0.02353776\r\n",
      "Epoch:  78 Step:   158 /   793 Train loss: 0.01759202\r\n",
      "Epoch:  78 Step:   159 /   793 Train loss: 0.01717040\r\n",
      "Epoch:  78 Step:   160 /   793 Train loss: 0.03118154\r\n",
      "Epoch:  78 Step:   161 /   793 Train loss: 0.02656032\r\n",
      "Epoch:  78 Step:   162 /   793 Train loss: 0.03288481\r\n",
      "Epoch:  78 Step:   163 /   793 Train loss: 0.02864407\r\n",
      "Epoch:  78 Step:   164 /   793 Train loss: 0.01682057\r\n",
      "Epoch:  78 Step:   165 /   793 Train loss: 0.02967359\r\n",
      "Epoch:  78 Step:   166 /   793 Train loss: 0.02674177\r\n",
      "Epoch:  78 Step:   167 /   793 Train loss: 0.02351100\r\n",
      "Epoch:  78 Step:   168 /   793 Train loss: 0.02436769\r\n",
      "Epoch:  78 Step:   169 /   793 Train loss: 0.03879148\r\n",
      "Epoch:  78 Step:   170 /   793 Train loss: 0.02264832\r\n",
      "Epoch:  78 Step:   171 /   793 Train loss: 0.02155770\r\n",
      "Epoch:  78 Step:   172 /   793 Train loss: 0.01735354\r\n",
      "Epoch:  78 Step:   173 /   793 Train loss: 0.02107405\r\n",
      "Epoch:  78 Step:   174 /   793 Train loss: 0.02563022\r\n",
      "Epoch:  78 Step:   175 /   793 Train loss: 0.01884099\r\n",
      "Epoch:  78 Step:   176 /   793 Train loss: 0.02821496\r\n",
      "Epoch:  78 Step:   177 /   793 Train loss: 0.00730118\r\n",
      "Epoch:  78 Step:   178 /   793 Train loss: 0.01628484\r\n",
      "Epoch:  78 Step:   179 /   793 Train loss: 0.02097123\r\n",
      "Epoch:  78 Step:   180 /   793 Train loss: 0.03719161\r\n",
      "Epoch:  78 Step:   181 /   793 Train loss: 0.02664535\r\n",
      "Epoch:  78 Step:   182 /   793 Train loss: 0.01706927\r\n",
      "Epoch:  78 Step:   183 /   793 Train loss: 0.02309463\r\n",
      "Epoch:  78 Step:   184 /   793 Train loss: 0.02733580\r\n",
      "Epoch:  78 Step:   185 /   793 Train loss: 0.03614553\r\n",
      "Epoch:  78 Step:   186 /   793 Train loss: 0.02306622\r\n",
      "Epoch:  78 Step:   187 /   793 Train loss: 0.02171516\r\n",
      "Epoch:  78 Step:   188 /   793 Train loss: 0.02401060\r\n",
      "Epoch:  78 Step:   189 /   793 Train loss: 0.01740987\r\n",
      "Epoch:  78 Step:   190 /   793 Train loss: 0.01386971\r\n",
      "Epoch:  78 Step:   191 /   793 Train loss: 0.02598085\r\n",
      "Epoch:  78 Step:   192 /   793 Train loss: 0.03056676\r\n",
      "Epoch:  78 Step:   193 /   793 Train loss: 0.01717458\r\n",
      "Epoch:  78 Step:   194 /   793 Train loss: 0.02159233\r\n",
      "Epoch:  78 Step:   195 /   793 Train loss: 0.01159391\r\n",
      "Epoch:  78 Step:   196 /   793 Train loss: 0.02677684\r\n",
      "Epoch:  78 Step:   197 /   793 Train loss: 0.00738901\r\n",
      "Epoch:  78 Step:   198 /   793 Train loss: 0.02633756\r\n",
      "Epoch:  78 Step:   199 /   793 Train loss: 0.02128848\r\n",
      "Epoch:  78 Step:   200 /   793 Train loss: 0.01640690\r\n",
      "Epoch:  78 Step:   201 /   793 Train loss: 0.01938000\r\n",
      "Epoch:  78 Step:   202 /   793 Train loss: 0.02429831\r\n",
      "Epoch:  78 Step:   203 /   793 Train loss: 0.03269980\r\n",
      "Epoch:  78 Step:   204 /   793 Train loss: 0.01858738\r\n",
      "Epoch:  78 Step:   205 /   793 Train loss: 0.02307857\r\n",
      "Epoch:  78 Step:   206 /   793 Train loss: 0.02449675\r\n",
      "Epoch:  78 Step:   207 /   793 Train loss: 0.01562956\r\n",
      "Epoch:  78 Step:   208 /   793 Train loss: 0.03613146\r\n",
      "Epoch:  78 Step:   209 /   793 Train loss: 0.03736285\r\n",
      "Epoch:  78 Step:   210 /   793 Train loss: 0.02213834\r\n",
      "Epoch:  78 Step:   211 /   793 Train loss: 0.01939090\r\n",
      "Epoch:  78 Step:   212 /   793 Train loss: 0.02901428\r\n",
      "Epoch:  78 Step:   213 /   793 Train loss: 0.01935904\r\n",
      "Epoch:  78 Step:   214 /   793 Train loss: 0.04163457\r\n",
      "Epoch:  78 Step:   215 /   793 Train loss: 0.03972223\r\n",
      "Epoch:  78 Step:   216 /   793 Train loss: 0.01581367\r\n",
      "Epoch:  78 Step:   217 /   793 Train loss: 0.01750357\r\n",
      "Epoch:  78 Step:   218 /   793 Train loss: 0.01894700\r\n",
      "Epoch:  78 Step:   219 /   793 Train loss: 0.03789626\r\n",
      "Epoch:  78 Step:   220 /   793 Train loss: 0.03459212\r\n",
      "Epoch:  78 Step:   221 /   793 Train loss: 0.02012586\r\n",
      "Epoch:  78 Step:   222 /   793 Train loss: 0.02063688\r\n",
      "Epoch:  78 Step:   223 /   793 Train loss: 0.02996271\r\n",
      "Epoch:  78 Step:   224 /   793 Train loss: 0.02221785\r\n",
      "Epoch:  78 Step:   225 /   793 Train loss: 0.01904879\r\n",
      "Epoch:  78 Step:   226 /   793 Train loss: 0.02681756\r\n",
      "Epoch:  78 Step:   227 /   793 Train loss: 0.02679229\r\n",
      "Epoch:  78 Step:   228 /   793 Train loss: 0.02963758\r\n",
      "Epoch:  78 Step:   229 /   793 Train loss: 0.01647357\r\n",
      "Epoch:  78 Step:   230 /   793 Train loss: 0.02073392\r\n",
      "Epoch:  78 Step:   231 /   793 Train loss: 0.02823116\r\n",
      "Epoch:  78 Step:   232 /   793 Train loss: 0.03562871\r\n",
      "Epoch:  78 Step:   233 /   793 Train loss: 0.01803900\r\n",
      "Epoch:  78 Step:   234 /   793 Train loss: 0.03418377\r\n",
      "Epoch:  78 Step:   235 /   793 Train loss: 0.02737870\r\n",
      "Epoch:  78 Step:   236 /   793 Train loss: 0.01793480\r\n",
      "Epoch:  78 Step:   237 /   793 Train loss: 0.02108306\r\n",
      "Epoch:  78 Step:   238 /   793 Train loss: 0.02241507\r\n",
      "Epoch:  78 Step:   239 /   793 Train loss: 0.02080027\r\n",
      "Epoch:  78 Step:   240 /   793 Train loss: 0.02685774\r\n",
      "Epoch:  78 Step:   241 /   793 Train loss: 0.02981282\r\n",
      "Epoch:  78 Step:   242 /   793 Train loss: 0.02269452\r\n",
      "Epoch:  78 Step:   243 /   793 Train loss: 0.03138696\r\n",
      "Epoch:  78 Step:   244 /   793 Train loss: 0.02815528\r\n",
      "Epoch:  78 Step:   245 /   793 Train loss: 0.02039927\r\n",
      "Epoch:  78 Step:   246 /   793 Train loss: 0.03050893\r\n",
      "Epoch:  78 Step:   247 /   793 Train loss: 0.03652778\r\n",
      "Epoch:  78 Step:   248 /   793 Train loss: 0.03371831\r\n",
      "Epoch:  78 Step:   249 /   793 Train loss: 0.02090719\r\n",
      "Epoch:  78 Step:   250 /   793 Train loss: 0.03228163\r\n",
      "Epoch:  78 Step:   251 /   793 Train loss: 0.02750444\r\n",
      "Epoch:  78 Step:   252 /   793 Train loss: 0.02389584\r\n",
      "Epoch:  78 Step:   253 /   793 Train loss: 0.03131186\r\n",
      "Epoch:  78 Step:   254 /   793 Train loss: 0.02189629\r\n",
      "Epoch:  78 Step:   255 /   793 Train loss: 0.03369545\r\n",
      "Epoch:  78 Step:   256 /   793 Train loss: 0.03766695\r\n",
      "Epoch:  78 Step:   257 /   793 Train loss: 0.02028030\r\n",
      "Epoch:  78 Step:   258 /   793 Train loss: 0.02438337\r\n",
      "Epoch:  78 Step:   259 /   793 Train loss: 0.01494309\r\n",
      "Epoch:  78 Step:   260 /   793 Train loss: 0.03225309\r\n",
      "Epoch:  78 Step:   261 /   793 Train loss: 0.02977562\r\n",
      "Epoch:  78 Step:   262 /   793 Train loss: 0.02959930\r\n",
      "Epoch:  78 Step:   263 /   793 Train loss: 0.03077104\r\n",
      "Epoch:  78 Step:   264 /   793 Train loss: 0.02741143\r\n",
      "Epoch:  78 Step:   265 /   793 Train loss: 0.02623741\r\n",
      "Epoch:  78 Step:   266 /   793 Train loss: 0.01795188\r\n",
      "Epoch:  78 Step:   267 /   793 Train loss: 0.03118516\r\n",
      "Epoch:  78 Step:   268 /   793 Train loss: 0.01406030\r\n",
      "Epoch:  78 Step:   269 /   793 Train loss: 0.01156792\r\n",
      "Epoch:  78 Step:   270 /   793 Train loss: 0.01609381\r\n",
      "Epoch:  78 Step:   271 /   793 Train loss: 0.01634368\r\n",
      "Epoch:  78 Step:   272 /   793 Train loss: 0.01322695\r\n",
      "Epoch:  78 Step:   273 /   793 Train loss: 0.02154634\r\n",
      "Epoch:  78 Step:   274 /   793 Train loss: 0.02341433\r\n",
      "Epoch:  78 Step:   275 /   793 Train loss: 0.02081468\r\n",
      "Epoch:  78 Step:   276 /   793 Train loss: 0.04543120\r\n",
      "Epoch:  78 Step:   277 /   793 Train loss: 0.01684168\r\n",
      "Epoch:  78 Step:   278 /   793 Train loss: 0.02964235\r\n",
      "Epoch:  78 Step:   279 /   793 Train loss: 0.01161808\r\n",
      "Epoch:  78 Step:   280 /   793 Train loss: 0.03346065\r\n",
      "Epoch:  78 Step:   281 /   793 Train loss: 0.04004732\r\n",
      "Epoch:  78 Step:   282 /   793 Train loss: 0.02174183\r\n",
      "Epoch:  78 Step:   283 /   793 Train loss: 0.02744781\r\n",
      "Epoch:  78 Step:   284 /   793 Train loss: 0.02606618\r\n",
      "Epoch:  78 Step:   285 /   793 Train loss: 0.03023359\r\n",
      "Epoch:  78 Step:   286 /   793 Train loss: 0.01444151\r\n",
      "Epoch:  78 Step:   287 /   793 Train loss: 0.02206463\r\n",
      "Epoch:  78 Step:   288 /   793 Train loss: 0.02742601\r\n",
      "Epoch:  78 Step:   289 /   793 Train loss: 0.01227499\r\n",
      "Epoch:  78 Step:   290 /   793 Train loss: 0.01987918\r\n",
      "Epoch:  78 Step:   291 /   793 Train loss: 0.02843717\r\n",
      "Epoch:  78 Step:   292 /   793 Train loss: 0.02625273\r\n",
      "Epoch:  78 Step:   293 /   793 Train loss: 0.02288482\r\n",
      "Epoch:  78 Step:   294 /   793 Train loss: 0.03658924\r\n",
      "Epoch:  78 Step:   295 /   793 Train loss: 0.01472734\r\n",
      "Epoch:  78 Step:   296 /   793 Train loss: 0.02264554\r\n",
      "Epoch:  78 Step:   297 /   793 Train loss: 0.02095788\r\n",
      "Epoch:  78 Step:   298 /   793 Train loss: 0.04008394\r\n",
      "Epoch:  78 Step:   299 /   793 Train loss: 0.02457297\r\n",
      "Epoch:  78 Step:   300 /   793 Train loss: 0.01919786\r\n",
      "Epoch:  78 Step:   301 /   793 Train loss: 0.02537448\r\n",
      "Epoch:  78 Step:   302 /   793 Train loss: 0.02324140\r\n",
      "Epoch:  78 Step:   303 /   793 Train loss: 0.02993234\r\n",
      "Epoch:  78 Step:   304 /   793 Train loss: 0.02678828\r\n",
      "Epoch:  78 Step:   305 /   793 Train loss: 0.03251802\r\n",
      "Epoch:  78 Step:   306 /   793 Train loss: 0.02291340\r\n",
      "Epoch:  78 Step:   307 /   793 Train loss: 0.02343447\r\n",
      "Epoch:  78 Step:   308 /   793 Train loss: 0.01766919\r\n",
      "Epoch:  78 Step:   309 /   793 Train loss: 0.02462817\r\n",
      "Epoch:  78 Step:   310 /   793 Train loss: 0.02196544\r\n",
      "Epoch:  78 Step:   311 /   793 Train loss: 0.02561755\r\n",
      "Epoch:  78 Step:   312 /   793 Train loss: 0.01681503\r\n",
      "Epoch:  78 Step:   313 /   793 Train loss: 0.01377430\r\n",
      "Epoch:  78 Step:   314 /   793 Train loss: 0.02078098\r\n",
      "Epoch:  78 Step:   315 /   793 Train loss: 0.02829673\r\n",
      "Epoch:  78 Step:   316 /   793 Train loss: 0.02558382\r\n",
      "Epoch:  78 Step:   317 /   793 Train loss: 0.02171480\r\n",
      "Epoch:  78 Step:   318 /   793 Train loss: 0.01949313\r\n",
      "Epoch:  78 Step:   319 /   793 Train loss: 0.02607299\r\n",
      "Epoch:  78 Step:   320 /   793 Train loss: 0.02193581\r\n",
      "Epoch:  78 Step:   321 /   793 Train loss: 0.01687142\r\n",
      "Epoch:  78 Step:   322 /   793 Train loss: 0.02418939\r\n",
      "Epoch:  78 Step:   323 /   793 Train loss: 0.02185982\r\n",
      "Epoch:  78 Step:   324 /   793 Train loss: 0.01221390\r\n",
      "Epoch:  78 Step:   325 /   793 Train loss: 0.02523763\r\n",
      "Epoch:  78 Step:   326 /   793 Train loss: 0.02325754\r\n",
      "Epoch:  78 Step:   327 /   793 Train loss: 0.02608335\r\n",
      "Epoch:  78 Step:   328 /   793 Train loss: 0.01227658\r\n",
      "Epoch:  78 Step:   329 /   793 Train loss: 0.01580161\r\n",
      "Epoch:  78 Step:   330 /   793 Train loss: 0.01513113\r\n",
      "Epoch:  78 Step:   331 /   793 Train loss: 0.02470676\r\n",
      "Epoch:  78 Step:   332 /   793 Train loss: 0.02493498\r\n",
      "Epoch:  78 Step:   333 /   793 Train loss: 0.02229451\r\n",
      "Epoch:  78 Step:   334 /   793 Train loss: 0.02108260\r\n",
      "Epoch:  78 Step:   335 /   793 Train loss: 0.02622161\r\n",
      "Epoch:  78 Step:   336 /   793 Train loss: 0.02556321\r\n",
      "Epoch:  78 Step:   337 /   793 Train loss: 0.02120292\r\n",
      "Epoch:  78 Step:   338 /   793 Train loss: 0.01689250\r\n",
      "Epoch:  78 Step:   339 /   793 Train loss: 0.01858916\r\n",
      "Epoch:  78 Step:   340 /   793 Train loss: 0.02540508\r\n",
      "Epoch:  78 Step:   341 /   793 Train loss: 0.02675418\r\n",
      "Epoch:  78 Step:   342 /   793 Train loss: 0.02006147\r\n",
      "Epoch:  78 Step:   343 /   793 Train loss: 0.02156136\r\n",
      "Epoch:  78 Step:   344 /   793 Train loss: 0.01104844\r\n",
      "Epoch:  78 Step:   345 /   793 Train loss: 0.02877090\r\n",
      "Epoch:  78 Step:   346 /   793 Train loss: 0.01526596\r\n",
      "Epoch:  78 Step:   347 /   793 Train loss: 0.03373887\r\n",
      "Epoch:  78 Step:   348 /   793 Train loss: 0.02129359\r\n",
      "Epoch:  78 Step:   349 /   793 Train loss: 0.02092473\r\n",
      "Epoch:  78 Step:   350 /   793 Train loss: 0.03476664\r\n",
      "Epoch:  78 Step:   351 /   793 Train loss: 0.02079909\r\n",
      "Epoch:  78 Step:   352 /   793 Train loss: 0.01878197\r\n",
      "Epoch:  78 Step:   353 /   793 Train loss: 0.02750011\r\n",
      "Epoch:  78 Step:   354 /   793 Train loss: 0.02315916\r\n",
      "Epoch:  78 Step:   355 /   793 Train loss: 0.01989162\r\n",
      "Epoch:  78 Step:   356 /   793 Train loss: 0.02055915\r\n",
      "Epoch:  78 Step:   357 /   793 Train loss: 0.02491905\r\n",
      "Epoch:  78 Step:   358 /   793 Train loss: 0.02428174\r\n",
      "Epoch:  78 Step:   359 /   793 Train loss: 0.02230707\r\n",
      "Epoch:  78 Step:   360 /   793 Train loss: 0.02302742\r\n",
      "Epoch:  78 Step:   361 /   793 Train loss: 0.02144177\r\n",
      "Epoch:  78 Step:   362 /   793 Train loss: 0.02585928\r\n",
      "Epoch:  78 Step:   363 /   793 Train loss: 0.02463112\r\n",
      "Epoch:  78 Step:   364 /   793 Train loss: 0.02426013\r\n",
      "Epoch:  78 Step:   365 /   793 Train loss: 0.02208241\r\n",
      "Epoch:  78 Step:   366 /   793 Train loss: 0.03176084\r\n",
      "Epoch:  78 Step:   367 /   793 Train loss: 0.01765683\r\n",
      "Epoch:  78 Step:   368 /   793 Train loss: 0.01226151\r\n",
      "Epoch:  78 Step:   369 /   793 Train loss: 0.01649290\r\n",
      "Epoch:  78 Step:   370 /   793 Train loss: 0.02435072\r\n",
      "Epoch:  78 Step:   371 /   793 Train loss: 0.02517414\r\n",
      "Epoch:  78 Step:   372 /   793 Train loss: 0.02525469\r\n",
      "Epoch:  78 Step:   373 /   793 Train loss: 0.03185370\r\n",
      "Epoch:  78 Step:   374 /   793 Train loss: 0.01656442\r\n",
      "Epoch:  78 Step:   375 /   793 Train loss: 0.03057258\r\n",
      "Epoch:  78 Step:   376 /   793 Train loss: 0.02511994\r\n",
      "Epoch:  78 Step:   377 /   793 Train loss: 0.02233846\r\n",
      "Epoch:  78 Step:   378 /   793 Train loss: 0.03380307\r\n",
      "Epoch:  78 Step:   379 /   793 Train loss: 0.02536581\r\n",
      "Epoch:  78 Step:   380 /   793 Train loss: 0.02575375\r\n",
      "Epoch:  78 Step:   381 /   793 Train loss: 0.01935221\r\n",
      "Epoch:  78 Step:   382 /   793 Train loss: 0.02663001\r\n",
      "Epoch:  78 Step:   383 /   793 Train loss: 0.01672410\r\n",
      "Epoch:  78 Step:   384 /   793 Train loss: 0.01384097\r\n",
      "Epoch:  78 Step:   385 /   793 Train loss: 0.02957907\r\n",
      "Epoch:  78 Step:   386 /   793 Train loss: 0.02462065\r\n",
      "Epoch:  78 Step:   387 /   793 Train loss: 0.02037767\r\n",
      "Epoch:  78 Step:   388 /   793 Train loss: 0.02774187\r\n",
      "Epoch:  78 Step:   389 /   793 Train loss: 0.03654055\r\n",
      "Epoch:  78 Step:   390 /   793 Train loss: 0.01515028\r\n",
      "Epoch:  78 Step:   391 /   793 Train loss: 0.02196971\r\n",
      "Epoch:  78 Step:   392 /   793 Train loss: 0.03399570\r\n",
      "Epoch:  78 Step:   393 /   793 Train loss: 0.03079807\r\n",
      "Epoch:  78 Step:   394 /   793 Train loss: 0.02194871\r\n",
      "Epoch:  78 Step:   395 /   793 Train loss: 0.02466083\r\n",
      "Epoch:  78 Step:   396 /   793 Train loss: 0.01699736\r\n",
      "Epoch:  78 Step:   397 /   793 Train loss: 0.03162829\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  78 Step:   398 /   793 Train loss: 0.03530681\r\n",
      "Epoch:  78 Step:   399 /   793 Train loss: 0.01903033\r\n",
      "Epoch:  78 Step:   400 /   793 Train loss: 0.02293651\r\n",
      "Epoch:  78 Step:   401 /   793 Train loss: 0.01638458\r\n",
      "Epoch:  78 Step:   402 /   793 Train loss: 0.03427386\r\n",
      "Epoch:  78 Step:   403 /   793 Train loss: 0.02799523\r\n",
      "Epoch:  78 Step:   404 /   793 Train loss: 0.03797349\r\n",
      "Epoch:  78 Step:   405 /   793 Train loss: 0.03173042\r\n",
      "Epoch:  78 Step:   406 /   793 Train loss: 0.01447822\r\n",
      "Epoch:  78 Step:   407 /   793 Train loss: 0.02214883\r\n",
      "Epoch:  78 Step:   408 /   793 Train loss: 0.02698196\r\n",
      "Epoch:  78 Step:   409 /   793 Train loss: 0.03433700\r\n",
      "Epoch:  78 Step:   410 /   793 Train loss: 0.03442679\r\n",
      "Epoch:  78 Step:   411 /   793 Train loss: 0.01346759\r\n",
      "Epoch:  78 Step:   412 /   793 Train loss: 0.02157120\r\n",
      "Epoch:  78 Step:   413 /   793 Train loss: 0.02446959\r\n",
      "Epoch:  78 Step:   414 /   793 Train loss: 0.02298966\r\n",
      "Epoch:  78 Step:   415 /   793 Train loss: 0.02054674\r\n",
      "Epoch:  78 Step:   416 /   793 Train loss: 0.02374173\r\n",
      "Epoch:  78 Step:   417 /   793 Train loss: 0.02098361\r\n",
      "Epoch:  78 Step:   418 /   793 Train loss: 0.02573854\r\n",
      "Epoch:  78 Step:   419 /   793 Train loss: 0.03674761\r\n",
      "Epoch:  78 Step:   420 /   793 Train loss: 0.03479363\r\n",
      "Epoch:  78 Step:   421 /   793 Train loss: 0.02334836\r\n",
      "Epoch:  78 Step:   422 /   793 Train loss: 0.02974427\r\n",
      "Epoch:  78 Step:   423 /   793 Train loss: 0.01888261\r\n",
      "Epoch:  78 Step:   424 /   793 Train loss: 0.02987335\r\n",
      "Epoch:  78 Step:   425 /   793 Train loss: 0.02637762\r\n",
      "Epoch:  78 Step:   426 /   793 Train loss: 0.02428922\r\n",
      "Epoch:  78 Step:   427 /   793 Train loss: 0.01741562\r\n",
      "Epoch:  78 Step:   428 /   793 Train loss: 0.01996012\r\n",
      "Epoch:  78 Step:   429 /   793 Train loss: 0.01053760\r\n",
      "Epoch:  78 Step:   430 /   793 Train loss: 0.01239205\r\n",
      "Epoch:  78 Step:   431 /   793 Train loss: 0.02679824\r\n",
      "Epoch:  78 Step:   432 /   793 Train loss: 0.01877923\r\n",
      "Epoch:  78 Step:   433 /   793 Train loss: 0.03248906\r\n",
      "Epoch:  78 Step:   434 /   793 Train loss: 0.03196955\r\n",
      "Epoch:  78 Step:   435 /   793 Train loss: 0.02909821\r\n",
      "Epoch:  78 Step:   436 /   793 Train loss: 0.01753447\r\n",
      "Epoch:  78 Step:   437 /   793 Train loss: 0.02029991\r\n",
      "Epoch:  78 Step:   438 /   793 Train loss: 0.02930113\r\n",
      "Epoch:  78 Step:   439 /   793 Train loss: 0.04277368\r\n",
      "Epoch:  78 Step:   440 /   793 Train loss: 0.01992488\r\n",
      "Epoch:  78 Step:   441 /   793 Train loss: 0.02869546\r\n",
      "Epoch:  78 Step:   442 /   793 Train loss: 0.02816229\r\n",
      "Epoch:  78 Step:   443 /   793 Train loss: 0.03205983\r\n",
      "Epoch:  78 Step:   444 /   793 Train loss: 0.01805539\r\n",
      "Epoch:  78 Step:   445 /   793 Train loss: 0.01440731\r\n",
      "Epoch:  78 Step:   446 /   793 Train loss: 0.02904966\r\n",
      "Epoch:  78 Step:   447 /   793 Train loss: 0.02171633\r\n",
      "Epoch:  78 Step:   448 /   793 Train loss: 0.02213345\r\n",
      "Epoch:  78 Step:   449 /   793 Train loss: 0.00908517\r\n",
      "Epoch:  78 Step:   450 /   793 Train loss: 0.03313685\r\n",
      "Epoch:  78 Step:   451 /   793 Train loss: 0.03093779\r\n",
      "Epoch:  78 Step:   452 /   793 Train loss: 0.03005389\r\n",
      "Epoch:  78 Step:   453 /   793 Train loss: 0.01687949\r\n",
      "Epoch:  78 Step:   454 /   793 Train loss: 0.02287272\r\n",
      "Epoch:  78 Step:   455 /   793 Train loss: 0.02059397\r\n",
      "Epoch:  78 Step:   456 /   793 Train loss: 0.02475901\r\n",
      "Epoch:  78 Step:   457 /   793 Train loss: 0.02476582\r\n",
      "Epoch:  78 Step:   458 /   793 Train loss: 0.03095444\r\n",
      "Epoch:  78 Step:   459 /   793 Train loss: 0.03001000\r\n",
      "Epoch:  78 Step:   460 /   793 Train loss: 0.03282702\r\n",
      "Epoch:  78 Step:   461 /   793 Train loss: 0.01491373\r\n",
      "Epoch:  78 Step:   462 /   793 Train loss: 0.03180583\r\n",
      "Epoch:  78 Step:   463 /   793 Train loss: 0.01442499\r\n",
      "Epoch:  78 Step:   464 /   793 Train loss: 0.02383009\r\n",
      "Epoch:  78 Step:   465 /   793 Train loss: 0.01880801\r\n",
      "Epoch:  78 Step:   466 /   793 Train loss: 0.01639485\r\n",
      "Epoch:  78 Step:   467 /   793 Train loss: 0.02181200\r\n",
      "Epoch:  78 Step:   468 /   793 Train loss: 0.02548063\r\n",
      "Epoch:  78 Step:   469 /   793 Train loss: 0.02575976\r\n",
      "Epoch:  78 Step:   470 /   793 Train loss: 0.01642713\r\n",
      "Epoch:  78 Step:   471 /   793 Train loss: 0.01725430\r\n",
      "Epoch:  78 Step:   472 /   793 Train loss: 0.01444424\r\n",
      "Epoch:  78 Step:   473 /   793 Train loss: 0.02886843\r\n",
      "Epoch:  78 Step:   474 /   793 Train loss: 0.01867967\r\n",
      "Epoch:  78 Step:   475 /   793 Train loss: 0.01439007\r\n",
      "Epoch:  78 Step:   476 /   793 Train loss: 0.02128965\r\n",
      "Epoch:  78 Step:   477 /   793 Train loss: 0.02994214\r\n",
      "Epoch:  78 Step:   478 /   793 Train loss: 0.01172335\r\n",
      "Epoch:  78 Step:   479 /   793 Train loss: 0.02776536\r\n",
      "Epoch:  78 Step:   480 /   793 Train loss: 0.01742726\r\n",
      "Epoch:  78 Step:   481 /   793 Train loss: 0.03400611\r\n",
      "Epoch:  78 Step:   482 /   793 Train loss: 0.01329980\r\n",
      "Epoch:  78 Step:   483 /   793 Train loss: 0.03263386\r\n",
      "Epoch:  78 Step:   484 /   793 Train loss: 0.01295909\r\n",
      "Epoch:  78 Step:   485 /   793 Train loss: 0.02701403\r\n",
      "Epoch:  78 Step:   486 /   793 Train loss: 0.02854348\r\n",
      "Epoch:  78 Step:   487 /   793 Train loss: 0.02327728\r\n",
      "Epoch:  78 Step:   488 /   793 Train loss: 0.02402622\r\n",
      "Epoch:  78 Step:   489 /   793 Train loss: 0.03246867\r\n",
      "Epoch:  78 Step:   490 /   793 Train loss: 0.03404972\r\n",
      "Epoch:  78 Step:   491 /   793 Train loss: 0.02791117\r\n",
      "Epoch:  78 Step:   492 /   793 Train loss: 0.01917483\r\n",
      "Epoch:  78 Step:   493 /   793 Train loss: 0.02834552\r\n",
      "Epoch:  78 Step:   494 /   793 Train loss: 0.02288236\r\n",
      "Epoch:  78 Step:   495 /   793 Train loss: 0.02289818\r\n",
      "Epoch:  78 Step:   496 /   793 Train loss: 0.01551107\r\n",
      "Epoch:  78 Step:   497 /   793 Train loss: 0.02521397\r\n",
      "Epoch:  78 Step:   498 /   793 Train loss: 0.02483128\r\n",
      "Epoch:  78 Step:   499 /   793 Train loss: 0.02073884\r\n",
      "Epoch:  78 Step:   500 /   793 Train loss: 0.01346938\r\n",
      "Epoch:  78 Step:   501 /   793 Train loss: 0.02167684\r\n",
      "Epoch:  78 Step:   502 /   793 Train loss: 0.01958433\r\n",
      "Epoch:  78 Step:   503 /   793 Train loss: 0.01907258\r\n",
      "Epoch:  78 Step:   504 /   793 Train loss: 0.03468054\r\n",
      "Epoch:  78 Step:   505 /   793 Train loss: 0.04816905\r\n",
      "Epoch:  78 Step:   506 /   793 Train loss: 0.02467465\r\n",
      "Epoch:  78 Step:   507 /   793 Train loss: 0.03421718\r\n",
      "Epoch:  78 Step:   508 /   793 Train loss: 0.02899631\r\n",
      "Epoch:  78 Step:   509 /   793 Train loss: 0.01912098\r\n",
      "Epoch:  78 Step:   510 /   793 Train loss: 0.03133420\r\n",
      "Epoch:  78 Step:   511 /   793 Train loss: 0.01891477\r\n",
      "Epoch:  78 Step:   512 /   793 Train loss: 0.02445842\r\n",
      "Epoch:  78 Step:   513 /   793 Train loss: 0.01648792\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  78 Step:   514 /   793 Train loss: 0.03962803\r\n",
      "Epoch:  78 Step:   515 /   793 Train loss: 0.02309948\r\n",
      "Epoch:  78 Step:   516 /   793 Train loss: 0.03085653\r\n",
      "Epoch:  78 Step:   517 /   793 Train loss: 0.04296055\r\n",
      "Epoch:  78 Step:   518 /   793 Train loss: 0.01478862\r\n",
      "Epoch:  78 Step:   519 /   793 Train loss: 0.02475265\r\n",
      "Epoch:  78 Step:   520 /   793 Train loss: 0.03547621\r\n",
      "Epoch:  78 Step:   521 /   793 Train loss: 0.01670931\r\n",
      "Epoch:  78 Step:   522 /   793 Train loss: 0.02061049\r\n",
      "Epoch:  78 Step:   523 /   793 Train loss: 0.03194407\r\n",
      "Epoch:  78 Step:   524 /   793 Train loss: 0.02520295\r\n",
      "Epoch:  78 Step:   525 /   793 Train loss: 0.03091577\r\n",
      "Epoch:  78 Step:   526 /   793 Train loss: 0.02227708\r\n",
      "Epoch:  78 Step:   527 /   793 Train loss: 0.02402584\r\n",
      "Epoch:  78 Step:   528 /   793 Train loss: 0.02475679\r\n",
      "Epoch:  78 Step:   529 /   793 Train loss: 0.02523948\r\n",
      "Epoch:  78 Step:   530 /   793 Train loss: 0.02260112\r\n",
      "Epoch:  78 Step:   531 /   793 Train loss: 0.02013883\r\n",
      "Epoch:  78 Step:   532 /   793 Train loss: 0.02716828\r\n",
      "Epoch:  78 Step:   533 /   793 Train loss: 0.01849806\r\n",
      "Epoch:  78 Step:   534 /   793 Train loss: 0.03087752\r\n",
      "Epoch:  78 Step:   535 /   793 Train loss: 0.02410677\r\n",
      "Epoch:  78 Step:   536 /   793 Train loss: 0.03355398\r\n",
      "Epoch:  78 Step:   537 /   793 Train loss: 0.01447775\r\n",
      "Epoch:  78 Step:   538 /   793 Train loss: 0.01363481\r\n",
      "Epoch:  78 Step:   539 /   793 Train loss: 0.04107755\r\n",
      "Epoch:  78 Step:   540 /   793 Train loss: 0.02576058\r\n",
      "Epoch:  78 Step:   541 /   793 Train loss: 0.02472085\r\n",
      "Epoch:  78 Step:   542 /   793 Train loss: 0.02354355\r\n",
      "Epoch:  78 Step:   543 /   793 Train loss: 0.02189797\r\n",
      "Epoch:  78 Step:   544 /   793 Train loss: 0.01425357\r\n",
      "Epoch:  78 Step:   545 /   793 Train loss: 0.02136202\r\n",
      "Epoch:  78 Step:   546 /   793 Train loss: 0.01717945\r\n",
      "Epoch:  78 Step:   547 /   793 Train loss: 0.01717729\r\n",
      "Epoch:  78 Step:   548 /   793 Train loss: 0.02461413\r\n",
      "Epoch:  78 Step:   549 /   793 Train loss: 0.03722133\r\n",
      "Epoch:  78 Step:   550 /   793 Train loss: 0.02963067\r\n",
      "Epoch:  78 Step:   551 /   793 Train loss: 0.03320684\r\n",
      "Epoch:  78 Step:   552 /   793 Train loss: 0.02429450\r\n",
      "Epoch:  78 Step:   553 /   793 Train loss: 0.02549873\r\n",
      "Epoch:  78 Step:   554 /   793 Train loss: 0.03158499\r\n",
      "Epoch:  78 Step:   555 /   793 Train loss: 0.02438595\r\n",
      "Epoch:  78 Step:   556 /   793 Train loss: 0.03866948\r\n",
      "Epoch:  78 Step:   557 /   793 Train loss: 0.03308465\r\n",
      "Epoch:  78 Step:   558 /   793 Train loss: 0.01470294\r\n",
      "Epoch:  78 Step:   559 /   793 Train loss: 0.02345676\r\n",
      "Epoch:  78 Step:   560 /   793 Train loss: 0.01089062\r\n",
      "Epoch:  78 Step:   561 /   793 Train loss: 0.03173691\r\n",
      "Epoch:  78 Step:   562 /   793 Train loss: 0.02864398\r\n",
      "Epoch:  78 Step:   563 /   793 Train loss: 0.02582508\r\n",
      "Epoch:  78 Step:   564 /   793 Train loss: 0.02530934\r\n",
      "Epoch:  78 Step:   565 /   793 Train loss: 0.02228867\r\n",
      "Epoch:  78 Step:   566 /   793 Train loss: 0.03661324\r\n",
      "Epoch:  78 Step:   567 /   793 Train loss: 0.01702744\r\n",
      "Epoch:  78 Step:   568 /   793 Train loss: 0.02201268\r\n",
      "Epoch:  78 Step:   569 /   793 Train loss: 0.02133083\r\n",
      "Epoch:  78 Step:   570 /   793 Train loss: 0.01963956\r\n",
      "Epoch:  78 Step:   571 /   793 Train loss: 0.02448910\r\n",
      "Epoch:  78 Step:   572 /   793 Train loss: 0.02806989\r\n",
      "Epoch:  78 Step:   573 /   793 Train loss: 0.01792616\r\n",
      "Epoch:  78 Step:   574 /   793 Train loss: 0.02682808\r\n",
      "Epoch:  78 Step:   575 /   793 Train loss: 0.02108431\r\n",
      "Epoch:  78 Step:   576 /   793 Train loss: 0.03153066\r\n",
      "Epoch:  78 Step:   577 /   793 Train loss: 0.01431618\r\n",
      "Epoch:  78 Step:   578 /   793 Train loss: 0.01844736\r\n",
      "Epoch:  78 Step:   579 /   793 Train loss: 0.03459678\r\n",
      "Epoch:  78 Step:   580 /   793 Train loss: 0.02249295\r\n",
      "Epoch:  78 Step:   581 /   793 Train loss: 0.01642876\r\n",
      "Epoch:  78 Step:   582 /   793 Train loss: 0.02396454\r\n",
      "Epoch:  78 Step:   583 /   793 Train loss: 0.01438780\r\n",
      "Epoch:  78 Step:   584 /   793 Train loss: 0.02448774\r\n",
      "Epoch:  78 Step:   585 /   793 Train loss: 0.02216002\r\n",
      "Epoch:  78 Step:   586 /   793 Train loss: 0.03779548\r\n",
      "Epoch:  78 Step:   587 /   793 Train loss: 0.02080329\r\n",
      "Epoch:  78 Step:   588 /   793 Train loss: 0.02157168\r\n",
      "Epoch:  78 Step:   589 /   793 Train loss: 0.01766778\r\n",
      "Epoch:  78 Step:   590 /   793 Train loss: 0.01319834\r\n",
      "Epoch:  78 Step:   591 /   793 Train loss: 0.02948708\r\n",
      "Epoch:  78 Step:   592 /   793 Train loss: 0.02554906\r\n",
      "Epoch:  78 Step:   593 /   793 Train loss: 0.02333897\r\n",
      "Epoch:  78 Step:   594 /   793 Train loss: 0.01545934\r\n",
      "Epoch:  78 Step:   595 /   793 Train loss: 0.02784656\r\n",
      "Epoch:  78 Step:   596 /   793 Train loss: 0.01891134\r\n",
      "Epoch:  78 Step:   597 /   793 Train loss: 0.02624482\r\n",
      "Epoch:  78 Step:   598 /   793 Train loss: 0.02074402\r\n",
      "Epoch:  78 Step:   599 /   793 Train loss: 0.02559486\r\n",
      "Epoch:  78 Step:   600 /   793 Train loss: 0.02842070\r\n",
      "Epoch:  78 Step:   601 /   793 Train loss: 0.03124280\r\n",
      "Epoch:  78 Step:   602 /   793 Train loss: 0.02850174\r\n",
      "Epoch:  78 Step:   603 /   793 Train loss: 0.02563121\r\n",
      "Epoch:  78 Step:   604 /   793 Train loss: 0.01717154\r\n",
      "Epoch:  78 Step:   605 /   793 Train loss: 0.02527496\r\n",
      "Epoch:  78 Step:   606 /   793 Train loss: 0.02218553\r\n",
      "Epoch:  78 Step:   607 /   793 Train loss: 0.03427407\r\n",
      "Epoch:  78 Step:   608 /   793 Train loss: 0.02641223\r\n",
      "Epoch:  78 Step:   609 /   793 Train loss: 0.02639611\r\n",
      "Epoch:  78 Step:   610 /   793 Train loss: 0.03404378\r\n",
      "Epoch:  78 Step:   611 /   793 Train loss: 0.01779410\r\n",
      "Epoch:  78 Step:   612 /   793 Train loss: 0.01594873\r\n",
      "Epoch:  78 Step:   613 /   793 Train loss: 0.02285639\r\n",
      "Epoch:  78 Step:   614 /   793 Train loss: 0.02193534\r\n",
      "Epoch:  78 Step:   615 /   793 Train loss: 0.02181185\r\n",
      "Epoch:  78 Step:   616 /   793 Train loss: 0.01842070\r\n",
      "Epoch:  78 Step:   617 /   793 Train loss: 0.02812421\r\n",
      "Epoch:  78 Step:   618 /   793 Train loss: 0.03010424\r\n",
      "Epoch:  78 Step:   619 /   793 Train loss: 0.00780667\r\n",
      "Epoch:  78 Step:   620 /   793 Train loss: 0.02616523\r\n",
      "Epoch:  78 Step:   621 /   793 Train loss: 0.02559096\r\n",
      "Epoch:  78 Step:   622 /   793 Train loss: 0.02512851\r\n",
      "Epoch:  78 Step:   623 /   793 Train loss: 0.02711042\r\n",
      "Epoch:  78 Step:   624 /   793 Train loss: 0.02890240\r\n",
      "Epoch:  78 Step:   625 /   793 Train loss: 0.03148751\r\n",
      "Epoch:  78 Step:   626 /   793 Train loss: 0.01920163\r\n",
      "Epoch:  78 Step:   627 /   793 Train loss: 0.02137389\r\n",
      "Epoch:  78 Step:   628 /   793 Train loss: 0.02821330\r\n",
      "Epoch:  78 Step:   629 /   793 Train loss: 0.03235469\r\n",
      "Epoch:  78 Step:   630 /   793 Train loss: 0.03159396\r\n",
      "Epoch:  78 Step:   631 /   793 Train loss: 0.02262329\r\n",
      "Epoch:  78 Step:   632 /   793 Train loss: 0.03554321\r\n",
      "Epoch:  78 Step:   633 /   793 Train loss: 0.02322606\r\n",
      "Epoch:  78 Step:   634 /   793 Train loss: 0.02189903\r\n",
      "Epoch:  78 Step:   635 /   793 Train loss: 0.03068786\r\n",
      "Epoch:  78 Step:   636 /   793 Train loss: 0.01763851\r\n",
      "Epoch:  78 Step:   637 /   793 Train loss: 0.01612286\r\n",
      "Epoch:  78 Step:   638 /   793 Train loss: 0.01993283\r\n",
      "Epoch:  78 Step:   639 /   793 Train loss: 0.02079385\r\n",
      "Epoch:  78 Step:   640 /   793 Train loss: 0.02146123\r\n",
      "Epoch:  78 Step:   641 /   793 Train loss: 0.02335433\r\n",
      "Epoch:  78 Step:   642 /   793 Train loss: 0.01870769\r\n",
      "Epoch:  78 Step:   643 /   793 Train loss: 0.02289233\r\n",
      "Epoch:  78 Step:   644 /   793 Train loss: 0.02164540\r\n",
      "Epoch:  78 Step:   645 /   793 Train loss: 0.02208010\r\n",
      "Epoch:  78 Step:   646 /   793 Train loss: 0.03360265\r\n",
      "Epoch:  78 Step:   647 /   793 Train loss: 0.01697537\r\n",
      "Epoch:  78 Step:   648 /   793 Train loss: 0.02034694\r\n",
      "Epoch:  78 Step:   649 /   793 Train loss: 0.01911073\r\n",
      "Epoch:  78 Step:   650 /   793 Train loss: 0.03632896\r\n",
      "Epoch:  78 Step:   651 /   793 Train loss: 0.02066563\r\n",
      "Epoch:  78 Step:   652 /   793 Train loss: 0.03170943\r\n",
      "Epoch:  78 Step:   653 /   793 Train loss: 0.01757078\r\n",
      "Epoch:  78 Step:   654 /   793 Train loss: 0.03099922\r\n",
      "Epoch:  78 Step:   655 /   793 Train loss: 0.03227118\r\n",
      "Epoch:  78 Step:   656 /   793 Train loss: 0.01996037\r\n",
      "Epoch:  78 Step:   657 /   793 Train loss: 0.02669268\r\n",
      "Epoch:  78 Step:   658 /   793 Train loss: 0.03148788\r\n",
      "Epoch:  78 Step:   659 /   793 Train loss: 0.02592606\r\n",
      "Epoch:  78 Step:   660 /   793 Train loss: 0.02809379\r\n",
      "Epoch:  78 Step:   661 /   793 Train loss: 0.02200211\r\n",
      "Epoch:  78 Step:   662 /   793 Train loss: 0.02534100\r\n",
      "Epoch:  78 Step:   663 /   793 Train loss: 0.02145149\r\n",
      "Epoch:  78 Step:   664 /   793 Train loss: 0.02823723\r\n",
      "Epoch:  78 Step:   665 /   793 Train loss: 0.02340185\r\n",
      "Epoch:  78 Step:   666 /   793 Train loss: 0.01539888\r\n",
      "Epoch:  78 Step:   667 /   793 Train loss: 0.02541842\r\n",
      "Epoch:  78 Step:   668 /   793 Train loss: 0.02204819\r\n",
      "Epoch:  78 Step:   669 /   793 Train loss: 0.02882895\r\n",
      "Epoch:  78 Step:   670 /   793 Train loss: 0.01703592\r\n",
      "Epoch:  78 Step:   671 /   793 Train loss: 0.02778284\r\n",
      "Epoch:  78 Step:   672 /   793 Train loss: 0.03096012\r\n",
      "Epoch:  78 Step:   673 /   793 Train loss: 0.01853327\r\n",
      "Epoch:  78 Step:   674 /   793 Train loss: 0.03329228\r\n",
      "Epoch:  78 Step:   675 /   793 Train loss: 0.01483941\r\n",
      "Epoch:  78 Step:   676 /   793 Train loss: 0.04214017\r\n",
      "Epoch:  78 Step:   677 /   793 Train loss: 0.01320666\r\n",
      "Epoch:  78 Step:   678 /   793 Train loss: 0.02273703\r\n",
      "Epoch:  78 Step:   679 /   793 Train loss: 0.02144967\r\n",
      "Epoch:  78 Step:   680 /   793 Train loss: 0.02444333\r\n",
      "Epoch:  78 Step:   681 /   793 Train loss: 0.02801914\r\n",
      "Epoch:  78 Step:   682 /   793 Train loss: 0.02082676\r\n",
      "Epoch:  78 Step:   683 /   793 Train loss: 0.00917867\r\n",
      "Epoch:  78 Step:   684 /   793 Train loss: 0.01155061\r\n",
      "Epoch:  78 Step:   685 /   793 Train loss: 0.02049097\r\n",
      "Epoch:  78 Step:   686 /   793 Train loss: 0.01926020\r\n",
      "Epoch:  78 Step:   687 /   793 Train loss: 0.01960636\r\n",
      "Epoch:  78 Step:   688 /   793 Train loss: 0.02941767\r\n",
      "Epoch:  78 Step:   689 /   793 Train loss: 0.02118448\r\n",
      "Epoch:  78 Step:   690 /   793 Train loss: 0.02557509\r\n",
      "Epoch:  78 Step:   691 /   793 Train loss: 0.02904146\r\n",
      "Epoch:  78 Step:   692 /   793 Train loss: 0.02930219\r\n",
      "Epoch:  78 Step:   693 /   793 Train loss: 0.02132033\r\n",
      "Epoch:  78 Step:   694 /   793 Train loss: 0.01460090\r\n",
      "Epoch:  78 Step:   695 /   793 Train loss: 0.02015362\r\n",
      "Epoch:  78 Step:   696 /   793 Train loss: 0.03323341\r\n",
      "Epoch:  78 Step:   697 /   793 Train loss: 0.05100127\r\n",
      "Epoch:  78 Step:   698 /   793 Train loss: 0.01842804\r\n",
      "Epoch:  78 Step:   699 /   793 Train loss: 0.01925633\r\n",
      "Epoch:  78 Step:   700 /   793 Train loss: 0.01375943\r\n",
      "Epoch:  78 Step:   701 /   793 Train loss: 0.04161817\r\n",
      "Epoch:  78 Step:   702 /   793 Train loss: 0.03040070\r\n",
      "Epoch:  78 Step:   703 /   793 Train loss: 0.03887092\r\n",
      "Epoch:  78 Step:   704 /   793 Train loss: 0.01665364\r\n",
      "Epoch:  78 Step:   705 /   793 Train loss: 0.03102366\r\n",
      "Epoch:  78 Step:   706 /   793 Train loss: 0.03510362\r\n",
      "Epoch:  78 Step:   707 /   793 Train loss: 0.01780820\r\n",
      "Epoch:  78 Step:   708 /   793 Train loss: 0.02165831\r\n",
      "Epoch:  78 Step:   709 /   793 Train loss: 0.04173253\r\n",
      "Epoch:  78 Step:   710 /   793 Train loss: 0.01630193\r\n",
      "Epoch:  78 Step:   711 /   793 Train loss: 0.01354353\r\n",
      "Epoch:  78 Step:   712 /   793 Train loss: 0.01020162\r\n",
      "Epoch:  78 Step:   713 /   793 Train loss: 0.01683352\r\n",
      "Epoch:  78 Step:   714 /   793 Train loss: 0.03100692\r\n",
      "Epoch:  78 Step:   715 /   793 Train loss: 0.03132992\r\n",
      "Epoch:  78 Step:   716 /   793 Train loss: 0.03271063\r\n",
      "Epoch:  78 Step:   717 /   793 Train loss: 0.01932843\r\n",
      "Epoch:  78 Step:   718 /   793 Train loss: 0.01841817\r\n",
      "Epoch:  78 Step:   719 /   793 Train loss: 0.01873093\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  78 Step:   720 /   793 Train loss: 0.02900708\r\n",
      "Epoch:  78 Step:   721 /   793 Train loss: 0.02920975\r\n",
      "Epoch:  78 Step:   722 /   793 Train loss: 0.01670181\r\n",
      "Epoch:  78 Step:   723 /   793 Train loss: 0.02969413\r\n",
      "Epoch:  78 Step:   724 /   793 Train loss: 0.03496878\r\n",
      "Epoch:  78 Step:   725 /   793 Train loss: 0.02146357\r\n",
      "Epoch:  78 Step:   726 /   793 Train loss: 0.03308824\r\n",
      "Epoch:  78 Step:   727 /   793 Train loss: 0.03256458\r\n",
      "Epoch:  78 Step:   728 /   793 Train loss: 0.02020478\r\n",
      "Epoch:  78 Step:   729 /   793 Train loss: 0.01994713\r\n",
      "Epoch:  78 Step:   730 /   793 Train loss: 0.01953945\r\n",
      "Epoch:  78 Step:   731 /   793 Train loss: 0.03284503\r\n",
      "Epoch:  78 Step:   732 /   793 Train loss: 0.03080465\r\n",
      "Epoch:  78 Step:   733 /   793 Train loss: 0.02728131\r\n",
      "Epoch:  78 Step:   734 /   793 Train loss: 0.02214336\r\n",
      "Epoch:  78 Step:   735 /   793 Train loss: 0.01387216\r\n",
      "Epoch:  78 Step:   736 /   793 Train loss: 0.01823536\r\n",
      "Epoch:  78 Step:   737 /   793 Train loss: 0.02037556\r\n",
      "Epoch:  78 Step:   738 /   793 Train loss: 0.02879968\r\n",
      "Epoch:  78 Step:   739 /   793 Train loss: 0.01281779\r\n",
      "Epoch:  78 Step:   740 /   793 Train loss: 0.02809679\r\n",
      "Epoch:  78 Step:   741 /   793 Train loss: 0.02108099\r\n",
      "Epoch:  78 Step:   742 /   793 Train loss: 0.01881341\r\n",
      "Epoch:  78 Step:   743 /   793 Train loss: 0.02721170\r\n",
      "Epoch:  78 Step:   744 /   793 Train loss: 0.03459539\r\n",
      "Epoch:  78 Step:   745 /   793 Train loss: 0.02273878\r\n",
      "Epoch:  78 Step:   746 /   793 Train loss: 0.02183450\r\n",
      "Epoch:  78 Step:   747 /   793 Train loss: 0.01505471\r\n",
      "Epoch:  78 Step:   748 /   793 Train loss: 0.02645116\r\n",
      "Epoch:  78 Step:   749 /   793 Train loss: 0.02646482\r\n",
      "Epoch:  78 Step:   750 /   793 Train loss: 0.02098563\r\n",
      "Epoch:  78 Step:   751 /   793 Train loss: 0.03210578\r\n",
      "Epoch:  78 Step:   752 /   793 Train loss: 0.00731328\r\n",
      "Epoch:  78 Step:   753 /   793 Train loss: 0.01813569\r\n",
      "Epoch:  78 Step:   754 /   793 Train loss: 0.02052879\r\n",
      "Epoch:  78 Step:   755 /   793 Train loss: 0.03188308\r\n",
      "Epoch:  78 Step:   756 /   793 Train loss: 0.03226110\r\n",
      "Epoch:  78 Step:   757 /   793 Train loss: 0.02435637\r\n",
      "Epoch:  78 Step:   758 /   793 Train loss: 0.02325478\r\n",
      "Epoch:  78 Step:   759 /   793 Train loss: 0.02258904\r\n",
      "Epoch:  78 Step:   760 /   793 Train loss: 0.01918328\r\n",
      "Epoch:  78 Step:   761 /   793 Train loss: 0.02414550\r\n",
      "Epoch:  78 Step:   762 /   793 Train loss: 0.01928077\r\n",
      "Epoch:  78 Step:   763 /   793 Train loss: 0.02649757\r\n",
      "Epoch:  78 Step:   764 /   793 Train loss: 0.02743933\r\n",
      "Epoch:  78 Step:   765 /   793 Train loss: 0.03744682\r\n",
      "Epoch:  78 Step:   766 /   793 Train loss: 0.02617660\r\n",
      "Epoch:  78 Step:   767 /   793 Train loss: 0.03716200\r\n",
      "Epoch:  78 Step:   768 /   793 Train loss: 0.02600726\r\n",
      "Epoch:  78 Step:   769 /   793 Train loss: 0.03209391\r\n",
      "Epoch:  78 Step:   770 /   793 Train loss: 0.02939317\r\n",
      "Epoch:  78 Step:   771 /   793 Train loss: 0.01537932\r\n",
      "Epoch:  78 Step:   772 /   793 Train loss: 0.02946744\r\n",
      "Epoch:  78 Step:   773 /   793 Train loss: 0.02803162\r\n",
      "Epoch:  78 Step:   774 /   793 Train loss: 0.02016873\r\n",
      "Epoch:  78 Step:   775 /   793 Train loss: 0.02491064\r\n",
      "Epoch:  78 Step:   776 /   793 Train loss: 0.03110663\r\n",
      "Epoch:  78 Step:   777 /   793 Train loss: 0.03133921\r\n",
      "Epoch:  78 Step:   778 /   793 Train loss: 0.04068159\r\n",
      "Epoch:  78 Step:   779 /   793 Train loss: 0.02399470\r\n",
      "Epoch:  78 Step:   780 /   793 Train loss: 0.02279527\r\n",
      "Epoch:  78 Step:   781 /   793 Train loss: 0.03445269\r\n",
      "Epoch:  78 Step:   782 /   793 Train loss: 0.02702759\r\n",
      "Epoch:  78 Step:   783 /   793 Train loss: 0.02849587\r\n",
      "Epoch:  78 Step:   784 /   793 Train loss: 0.02595621\r\n",
      "Epoch:  78 Step:   785 /   793 Train loss: 0.03006249\r\n",
      "Epoch:  78 Step:   786 /   793 Train loss: 0.03635798\r\n",
      "Epoch:  78 Step:   787 /   793 Train loss: 0.02247018\r\n",
      "Epoch:  78 Step:   788 /   793 Train loss: 0.01348621\r\n",
      "Epoch:  78 Step:   789 /   793 Train loss: 0.02279280\r\n",
      "Epoch:  78 Step:   790 /   793 Train loss: 0.01571435\r\n",
      "Epoch:  78 Step:   791 /   793 Train loss: 0.02201921\r\n",
      "Epoch:  78 Step:   792 /   793 Train loss: 0.01302597\r\n",
      "Epoch:  79 Step:     0 /   793 Train loss: 0.02346807\r\n",
      "Epoch:  79 Step:     1 /   793 Train loss: 0.02359692\r\n",
      "Epoch:  79 Step:     2 /   793 Train loss: 0.01793089\r\n",
      "Epoch:  79 Step:     3 /   793 Train loss: 0.03212371\r\n",
      "Epoch:  79 Step:     4 /   793 Train loss: 0.02484357\r\n",
      "Epoch:  79 Step:     5 /   793 Train loss: 0.00754160\r\n",
      "Epoch:  79 Step:     6 /   793 Train loss: 0.02540523\r\n",
      "Epoch:  79 Step:     7 /   793 Train loss: 0.02388098\r\n",
      "Epoch:  79 Step:     8 /   793 Train loss: 0.02472965\r\n",
      "Epoch:  79 Step:     9 /   793 Train loss: 0.01894656\r\n",
      "Epoch:  79 Step:    10 /   793 Train loss: 0.02412823\r\n",
      "Epoch:  79 Step:    11 /   793 Train loss: 0.02715801\r\n",
      "Epoch:  79 Step:    12 /   793 Train loss: 0.02580153\r\n",
      "Epoch:  79 Step:    13 /   793 Train loss: 0.02365072\r\n",
      "Epoch:  79 Step:    14 /   793 Train loss: 0.03051580\r\n",
      "Epoch:  79 Step:    15 /   793 Train loss: 0.03415343\r\n",
      "Epoch:  79 Step:    16 /   793 Train loss: 0.02844349\r\n",
      "Epoch:  79 Step:    17 /   793 Train loss: 0.02760661\r\n",
      "Epoch:  79 Step:    18 /   793 Train loss: 0.02801805\r\n",
      "Epoch:  79 Step:    19 /   793 Train loss: 0.02079561\r\n",
      "Epoch:  79 Step:    20 /   793 Train loss: 0.03159036\r\n",
      "Epoch:  79 Step:    21 /   793 Train loss: 0.01255256\r\n",
      "Epoch:  79 Step:    22 /   793 Train loss: 0.01913881\r\n",
      "Epoch:  79 Step:    23 /   793 Train loss: 0.01784174\r\n",
      "Epoch:  79 Step:    24 /   793 Train loss: 0.02355169\r\n",
      "Epoch:  79 Step:    25 /   793 Train loss: 0.01857335\r\n",
      "Epoch:  79 Step:    26 /   793 Train loss: 0.01695202\r\n",
      "Epoch:  79 Step:    27 /   793 Train loss: 0.03397073\r\n",
      "Epoch:  79 Step:    28 /   793 Train loss: 0.02044755\r\n",
      "Epoch:  79 Step:    29 /   793 Train loss: 0.01488360\r\n",
      "Epoch:  79 Step:    30 /   793 Train loss: 0.02958919\r\n",
      "Epoch:  79 Step:    31 /   793 Train loss: 0.02744356\r\n",
      "Epoch:  79 Step:    32 /   793 Train loss: 0.02073088\r\n",
      "Epoch:  79 Step:    33 /   793 Train loss: 0.02785282\r\n",
      "Epoch:  79 Step:    34 /   793 Train loss: 0.02339149\r\n",
      "Epoch:  79 Step:    35 /   793 Train loss: 0.02452397\r\n",
      "Epoch:  79 Step:    36 /   793 Train loss: 0.01428760\r\n",
      "Epoch:  79 Step:    37 /   793 Train loss: 0.01950607\r\n",
      "Epoch:  79 Step:    38 /   793 Train loss: 0.03043610\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  79 Step:    39 /   793 Train loss: 0.03673252\r\n",
      "Epoch:  79 Step:    40 /   793 Train loss: 0.01374244\r\n",
      "Epoch:  79 Step:    41 /   793 Train loss: 0.01658457\r\n",
      "Epoch:  79 Step:    42 /   793 Train loss: 0.03245419\r\n",
      "Epoch:  79 Step:    43 /   793 Train loss: 0.03006437\r\n",
      "Epoch:  79 Step:    44 /   793 Train loss: 0.02075510\r\n",
      "Epoch:  79 Step:    45 /   793 Train loss: 0.02675121\r\n",
      "Epoch:  79 Step:    46 /   793 Train loss: 0.01906616\r\n",
      "Epoch:  79 Step:    47 /   793 Train loss: 0.01618843\r\n",
      "Epoch:  79 Step:    48 /   793 Train loss: 0.02796563\r\n",
      "Epoch:  79 Step:    49 /   793 Train loss: 0.02155114\r\n",
      "Epoch:  79 Step:    50 /   793 Train loss: 0.01822451\r\n",
      "Epoch:  79 Step:    51 /   793 Train loss: 0.01409188\r\n",
      "Epoch:  79 Step:    52 /   793 Train loss: 0.02644184\r\n",
      "Epoch:  79 Step:    53 /   793 Train loss: 0.02536458\r\n",
      "Epoch:  79 Step:    54 /   793 Train loss: 0.02378311\r\n",
      "Epoch:  79 Step:    55 /   793 Train loss: 0.02275585\r\n",
      "Epoch:  79 Step:    56 /   793 Train loss: 0.01168154\r\n",
      "Epoch:  79 Step:    57 /   793 Train loss: 0.02543231\r\n",
      "Epoch:  79 Step:    58 /   793 Train loss: 0.02793176\r\n",
      "Epoch:  79 Step:    59 /   793 Train loss: 0.03027557\r\n",
      "Epoch:  79 Step:    60 /   793 Train loss: 0.02574638\r\n",
      "Epoch:  79 Step:    61 /   793 Train loss: 0.02478003\r\n",
      "Epoch:  79 Step:    62 /   793 Train loss: 0.03736384\r\n",
      "Epoch:  79 Step:    63 /   793 Train loss: 0.04277946\r\n",
      "Epoch:  79 Step:    64 /   793 Train loss: 0.02492692\r\n",
      "Epoch:  79 Step:    65 /   793 Train loss: 0.02801869\r\n",
      "Epoch:  79 Step:    66 /   793 Train loss: 0.01641537\r\n",
      "Epoch:  79 Step:    67 /   793 Train loss: 0.02141957\r\n",
      "Epoch:  79 Step:    68 /   793 Train loss: 0.02486252\r\n",
      "Epoch:  79 Step:    69 /   793 Train loss: 0.02113277\r\n",
      "Epoch:  79 Step:    70 /   793 Train loss: 0.02046708\r\n",
      "Epoch:  79 Step:    71 /   793 Train loss: 0.02859011\r\n",
      "Epoch:  79 Step:    72 /   793 Train loss: 0.02156493\r\n",
      "Epoch:  79 Step:    73 /   793 Train loss: 0.02746409\r\n",
      "Epoch:  79 Step:    74 /   793 Train loss: 0.02739470\r\n",
      "Epoch:  79 Step:    75 /   793 Train loss: 0.01119089\r\n",
      "Epoch:  79 Step:    76 /   793 Train loss: 0.02556029\r\n",
      "Epoch:  79 Step:    77 /   793 Train loss: 0.03281432\r\n",
      "Epoch:  79 Step:    78 /   793 Train loss: 0.01816279\r\n",
      "Epoch:  79 Step:    79 /   793 Train loss: 0.02464487\r\n",
      "Epoch:  79 Step:    80 /   793 Train loss: 0.02912198\r\n",
      "Epoch:  79 Step:    81 /   793 Train loss: 0.01403463\r\n",
      "Epoch:  79 Step:    82 /   793 Train loss: 0.03109126\r\n",
      "Epoch:  79 Step:    83 /   793 Train loss: 0.03256653\r\n",
      "Epoch:  79 Step:    84 /   793 Train loss: 0.02406415\r\n",
      "Epoch:  79 Step:    85 /   793 Train loss: 0.01297962\r\n",
      "Epoch:  79 Step:    86 /   793 Train loss: 0.01919761\r\n",
      "Epoch:  79 Step:    87 /   793 Train loss: 0.01980435\r\n",
      "Epoch:  79 Step:    88 /   793 Train loss: 0.02467643\r\n",
      "Epoch:  79 Step:    89 /   793 Train loss: 0.03070305\r\n",
      "Epoch:  79 Step:    90 /   793 Train loss: 0.02145151\r\n",
      "Epoch:  79 Step:    91 /   793 Train loss: 0.02127780\r\n",
      "Epoch:  79 Step:    92 /   793 Train loss: 0.01731944\r\n",
      "Epoch:  79 Step:    93 /   793 Train loss: 0.02115407\r\n",
      "Epoch:  79 Step:    94 /   793 Train loss: 0.01437719\r\n",
      "Epoch:  79 Step:    95 /   793 Train loss: 0.02609652\r\n",
      "Epoch:  79 Step:    96 /   793 Train loss: 0.01865250\r\n",
      "Epoch:  79 Step:    97 /   793 Train loss: 0.01289132\r\n",
      "Epoch:  79 Step:    98 /   793 Train loss: 0.02436654\r\n",
      "Epoch:  79 Step:    99 /   793 Train loss: 0.01840181\r\n",
      "Epoch:  79 Step:   100 /   793 Train loss: 0.03136824\r\n",
      "Epoch:  79 Step:   101 /   793 Train loss: 0.02041859\r\n",
      "Epoch:  79 Step:   102 /   793 Train loss: 0.02317780\r\n",
      "Epoch:  79 Step:   103 /   793 Train loss: 0.02944570\r\n",
      "Epoch:  79 Step:   104 /   793 Train loss: 0.01992894\r\n",
      "Epoch:  79 Step:   105 /   793 Train loss: 0.01801557\r\n",
      "Epoch:  79 Step:   106 /   793 Train loss: 0.03589894\r\n",
      "Epoch:  79 Step:   107 /   793 Train loss: 0.03025470\r\n",
      "Epoch:  79 Step:   108 /   793 Train loss: 0.02934804\r\n",
      "Epoch:  79 Step:   109 /   793 Train loss: 0.02896551\r\n",
      "Epoch:  79 Step:   110 /   793 Train loss: 0.03502797\r\n",
      "Epoch:  79 Step:   111 /   793 Train loss: 0.02688271\r\n",
      "Epoch:  79 Step:   112 /   793 Train loss: 0.01460427\r\n",
      "Epoch:  79 Step:   113 /   793 Train loss: 0.01889732\r\n",
      "Epoch:  79 Step:   114 /   793 Train loss: 0.03200647\r\n",
      "Epoch:  79 Step:   115 /   793 Train loss: 0.01717158\r\n",
      "Epoch:  79 Step:   116 /   793 Train loss: 0.02100737\r\n",
      "Epoch:  79 Step:   117 /   793 Train loss: 0.01954091\r\n",
      "Epoch:  79 Step:   118 /   793 Train loss: 0.02298456\r\n",
      "Epoch:  79 Step:   119 /   793 Train loss: 0.03726170\r\n",
      "Epoch:  79 Step:   120 /   793 Train loss: 0.03394622\r\n",
      "Epoch:  79 Step:   121 /   793 Train loss: 0.02478739\r\n",
      "Epoch:  79 Step:   122 /   793 Train loss: 0.02124072\r\n",
      "Epoch:  79 Step:   123 /   793 Train loss: 0.03156820\r\n",
      "Epoch:  79 Step:   124 /   793 Train loss: 0.02920620\r\n",
      "Epoch:  79 Step:   125 /   793 Train loss: 0.02180969\r\n",
      "Epoch:  79 Step:   126 /   793 Train loss: 0.02654599\r\n",
      "Epoch:  79 Step:   127 /   793 Train loss: 0.02151163\r\n",
      "Epoch:  79 Step:   128 /   793 Train loss: 0.02247920\r\n",
      "Epoch:  79 Step:   129 /   793 Train loss: 0.02786031\r\n",
      "Epoch:  79 Step:   130 /   793 Train loss: 0.01159909\r\n",
      "Epoch:  79 Step:   131 /   793 Train loss: 0.02236415\r\n",
      "Epoch:  79 Step:   132 /   793 Train loss: 0.02514119\r\n",
      "Epoch:  79 Step:   133 /   793 Train loss: 0.02683055\r\n",
      "Epoch:  79 Step:   134 /   793 Train loss: 0.04074132\r\n",
      "Epoch:  79 Step:   135 /   793 Train loss: 0.02525511\r\n",
      "Epoch:  79 Step:   136 /   793 Train loss: 0.01253335\r\n",
      "Epoch:  79 Step:   137 /   793 Train loss: 0.01994684\r\n",
      "Epoch:  79 Step:   138 /   793 Train loss: 0.04296474\r\n",
      "Epoch:  79 Step:   139 /   793 Train loss: 0.03658236\r\n",
      "Epoch:  79 Step:   140 /   793 Train loss: 0.01893134\r\n",
      "Epoch:  79 Step:   141 /   793 Train loss: 0.01021253\r\n",
      "Epoch:  79 Step:   142 /   793 Train loss: 0.02474799\r\n",
      "Epoch:  79 Step:   143 /   793 Train loss: 0.02003081\r\n",
      "Epoch:  79 Step:   144 /   793 Train loss: 0.02643039\r\n",
      "Epoch:  79 Step:   145 /   793 Train loss: 0.01146747\r\n",
      "Epoch:  79 Step:   146 /   793 Train loss: 0.02709967\r\n",
      "Epoch:  79 Step:   147 /   793 Train loss: 0.02905402\r\n",
      "Epoch:  79 Step:   148 /   793 Train loss: 0.01772750\r\n",
      "Epoch:  79 Step:   149 /   793 Train loss: 0.02497603\r\n",
      "Epoch:  79 Step:   150 /   793 Train loss: 0.02189152\r\n",
      "Epoch:  79 Step:   151 /   793 Train loss: 0.02882177\r\n",
      "Epoch:  79 Step:   152 /   793 Train loss: 0.02674282\r\n",
      "Epoch:  79 Step:   153 /   793 Train loss: 0.03509557\r\n",
      "Epoch:  79 Step:   154 /   793 Train loss: 0.01835276\r\n",
      "Epoch:  79 Step:   155 /   793 Train loss: 0.02278868\r\n",
      "Epoch:  79 Step:   156 /   793 Train loss: 0.02417307\r\n",
      "Epoch:  79 Step:   157 /   793 Train loss: 0.02615030\r\n",
      "Epoch:  79 Step:   158 /   793 Train loss: 0.01749030\r\n",
      "Epoch:  79 Step:   159 /   793 Train loss: 0.02061800\r\n",
      "Epoch:  79 Step:   160 /   793 Train loss: 0.02887360\r\n",
      "Epoch:  79 Step:   161 /   793 Train loss: 0.02458126\r\n",
      "Epoch:  79 Step:   162 /   793 Train loss: 0.02580313\r\n",
      "Epoch:  79 Step:   163 /   793 Train loss: 0.02677007\r\n",
      "Epoch:  79 Step:   164 /   793 Train loss: 0.02655805\r\n",
      "Epoch:  79 Step:   165 /   793 Train loss: 0.03052631\r\n",
      "Epoch:  79 Step:   166 /   793 Train loss: 0.03161034\r\n",
      "Epoch:  79 Step:   167 /   793 Train loss: 0.03788289\r\n",
      "Epoch:  79 Step:   168 /   793 Train loss: 0.01850961\r\n",
      "Epoch:  79 Step:   169 /   793 Train loss: 0.01767622\r\n",
      "Epoch:  79 Step:   170 /   793 Train loss: 0.02248788\r\n",
      "Epoch:  79 Step:   171 /   793 Train loss: 0.03190327\r\n",
      "Epoch:  79 Step:   172 /   793 Train loss: 0.02833525\r\n",
      "Epoch:  79 Step:   173 /   793 Train loss: 0.01341021\r\n",
      "Epoch:  79 Step:   174 /   793 Train loss: 0.01931381\r\n",
      "Epoch:  79 Step:   175 /   793 Train loss: 0.02825682\r\n",
      "Epoch:  79 Step:   176 /   793 Train loss: 0.02632302\r\n",
      "Epoch:  79 Step:   177 /   793 Train loss: 0.02980702\r\n",
      "Epoch:  79 Step:   178 /   793 Train loss: 0.01486805\r\n",
      "Epoch:  79 Step:   179 /   793 Train loss: 0.02691083\r\n",
      "Epoch:  79 Step:   180 /   793 Train loss: 0.02222652\r\n",
      "Epoch:  79 Step:   181 /   793 Train loss: 0.02302792\r\n",
      "Epoch:  79 Step:   182 /   793 Train loss: 0.02402839\r\n",
      "Epoch:  79 Step:   183 /   793 Train loss: 0.03300651\r\n",
      "Epoch:  79 Step:   184 /   793 Train loss: 0.02736567\r\n",
      "Epoch:  79 Step:   185 /   793 Train loss: 0.03414295\r\n",
      "Epoch:  79 Step:   186 /   793 Train loss: 0.02219779\r\n",
      "Epoch:  79 Step:   187 /   793 Train loss: 0.01473787\r\n",
      "Epoch:  79 Step:   188 /   793 Train loss: 0.00863499\r\n",
      "Epoch:  79 Step:   189 /   793 Train loss: 0.01875481\r\n",
      "Epoch:  79 Step:   190 /   793 Train loss: 0.01459645\r\n",
      "Epoch:  79 Step:   191 /   793 Train loss: 0.02194429\r\n",
      "Epoch:  79 Step:   192 /   793 Train loss: 0.01629818\r\n",
      "Epoch:  79 Step:   193 /   793 Train loss: 0.02978299\r\n",
      "Epoch:  79 Step:   194 /   793 Train loss: 0.01744771\r\n",
      "Epoch:  79 Step:   195 /   793 Train loss: 0.01903057\r\n",
      "Epoch:  79 Step:   196 /   793 Train loss: 0.02559542\r\n",
      "Epoch:  79 Step:   197 /   793 Train loss: 0.02057688\r\n",
      "Epoch:  79 Step:   198 /   793 Train loss: 0.02134708\r\n",
      "Epoch:  79 Step:   199 /   793 Train loss: 0.02408495\r\n",
      "Epoch:  79 Step:   200 /   793 Train loss: 0.01287265\r\n",
      "Epoch:  79 Step:   201 /   793 Train loss: 0.00993942\r\n",
      "Epoch:  79 Step:   202 /   793 Train loss: 0.03419210\r\n",
      "Epoch:  79 Step:   203 /   793 Train loss: 0.02131269\r\n",
      "Epoch:  79 Step:   204 /   793 Train loss: 0.02125990\r\n",
      "Epoch:  79 Step:   205 /   793 Train loss: 0.02431558\r\n",
      "Epoch:  79 Step:   206 /   793 Train loss: 0.01113362\r\n",
      "Epoch:  79 Step:   207 /   793 Train loss: 0.02993302\r\n",
      "Epoch:  79 Step:   208 /   793 Train loss: 0.02621607\r\n",
      "Epoch:  79 Step:   209 /   793 Train loss: 0.03558024\r\n",
      "Epoch:  79 Step:   210 /   793 Train loss: 0.02988455\r\n",
      "Epoch:  79 Step:   211 /   793 Train loss: 0.03927466\r\n",
      "Epoch:  79 Step:   212 /   793 Train loss: 0.02237444\r\n",
      "Epoch:  79 Step:   213 /   793 Train loss: 0.02207159\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  79 Step:   214 /   793 Train loss: 0.01750004\r\n",
      "Epoch:  79 Step:   215 /   793 Train loss: 0.03328903\r\n",
      "Epoch:  79 Step:   216 /   793 Train loss: 0.02734050\r\n",
      "Epoch:  79 Step:   217 /   793 Train loss: 0.01466449\r\n",
      "Epoch:  79 Step:   218 /   793 Train loss: 0.03179798\r\n",
      "Epoch:  79 Step:   219 /   793 Train loss: 0.01117278\r\n",
      "Epoch:  79 Step:   220 /   793 Train loss: 0.01360635\r\n",
      "Epoch:  79 Step:   221 /   793 Train loss: 0.02607827\r\n",
      "Epoch:  79 Step:   222 /   793 Train loss: 0.03374591\r\n",
      "Epoch:  79 Step:   223 /   793 Train loss: 0.02552764\r\n",
      "Epoch:  79 Step:   224 /   793 Train loss: 0.01128648\r\n",
      "Epoch:  79 Step:   225 /   793 Train loss: 0.03737839\r\n",
      "Epoch:  79 Step:   226 /   793 Train loss: 0.02267868\r\n",
      "Epoch:  79 Step:   227 /   793 Train loss: 0.01902610\r\n",
      "Epoch:  79 Step:   228 /   793 Train loss: 0.01541987\r\n",
      "Epoch:  79 Step:   229 /   793 Train loss: 0.02173972\r\n",
      "Epoch:  79 Step:   230 /   793 Train loss: 0.02853631\r\n",
      "Epoch:  79 Step:   231 /   793 Train loss: 0.03032474\r\n",
      "Epoch:  79 Step:   232 /   793 Train loss: 0.02585684\r\n",
      "Epoch:  79 Step:   233 /   793 Train loss: 0.02747991\r\n",
      "Epoch:  79 Step:   234 /   793 Train loss: 0.02955777\r\n",
      "Epoch:  79 Step:   235 /   793 Train loss: 0.01799589\r\n",
      "Epoch:  79 Step:   236 /   793 Train loss: 0.01983985\r\n",
      "Epoch:  79 Step:   237 /   793 Train loss: 0.02251451\r\n",
      "Epoch:  79 Step:   238 /   793 Train loss: 0.03354423\r\n",
      "Epoch:  79 Step:   239 /   793 Train loss: 0.03049029\r\n",
      "Epoch:  79 Step:   240 /   793 Train loss: 0.01487233\r\n",
      "Epoch:  79 Step:   241 /   793 Train loss: 0.02600176\r\n",
      "Epoch:  79 Step:   242 /   793 Train loss: 0.02233839\r\n",
      "Epoch:  79 Step:   243 /   793 Train loss: 0.02536127\r\n",
      "Epoch:  79 Step:   244 /   793 Train loss: 0.02358716\r\n",
      "Epoch:  79 Step:   245 /   793 Train loss: 0.02105463\r\n",
      "Epoch:  79 Step:   246 /   793 Train loss: 0.02801800\r\n",
      "Epoch:  79 Step:   247 /   793 Train loss: 0.01316710\r\n",
      "Epoch:  79 Step:   248 /   793 Train loss: 0.02452362\r\n",
      "Epoch:  79 Step:   249 /   793 Train loss: 0.02012651\r\n",
      "Epoch:  79 Step:   250 /   793 Train loss: 0.02540298\r\n",
      "Epoch:  79 Step:   251 /   793 Train loss: 0.03263791\r\n",
      "Epoch:  79 Step:   252 /   793 Train loss: 0.02079428\r\n",
      "Epoch:  79 Step:   253 /   793 Train loss: 0.01828759\r\n",
      "Epoch:  79 Step:   254 /   793 Train loss: 0.02430249\r\n",
      "Epoch:  79 Step:   255 /   793 Train loss: 0.03046968\r\n",
      "Epoch:  79 Step:   256 /   793 Train loss: 0.01425372\r\n",
      "Epoch:  79 Step:   257 /   793 Train loss: 0.02550428\r\n",
      "Epoch:  79 Step:   258 /   793 Train loss: 0.02142934\r\n",
      "Epoch:  79 Step:   259 /   793 Train loss: 0.01593710\r\n",
      "Epoch:  79 Step:   260 /   793 Train loss: 0.02469961\r\n",
      "Epoch:  79 Step:   261 /   793 Train loss: 0.01247417\r\n",
      "Epoch:  79 Step:   262 /   793 Train loss: 0.02160123\r\n",
      "Epoch:  79 Step:   263 /   793 Train loss: 0.01927743\r\n",
      "Epoch:  79 Step:   264 /   793 Train loss: 0.02318583\r\n",
      "Epoch:  79 Step:   265 /   793 Train loss: 0.02813037\r\n",
      "Epoch:  79 Step:   266 /   793 Train loss: 0.02652809\r\n",
      "Epoch:  79 Step:   267 /   793 Train loss: 0.02327784\r\n",
      "Epoch:  79 Step:   268 /   793 Train loss: 0.02553517\r\n",
      "Epoch:  79 Step:   269 /   793 Train loss: 0.02010292\r\n",
      "Epoch:  79 Step:   270 /   793 Train loss: 0.02894389\r\n",
      "Epoch:  79 Step:   271 /   793 Train loss: 0.02284968\r\n",
      "Epoch:  79 Step:   272 /   793 Train loss: 0.03380696\r\n",
      "Epoch:  79 Step:   273 /   793 Train loss: 0.02846502\r\n",
      "Epoch:  79 Step:   274 /   793 Train loss: 0.01365468\r\n",
      "Epoch:  79 Step:   275 /   793 Train loss: 0.03403012\r\n",
      "Epoch:  79 Step:   276 /   793 Train loss: 0.03399455\r\n",
      "Epoch:  79 Step:   277 /   793 Train loss: 0.02953364\r\n",
      "Epoch:  79 Step:   278 /   793 Train loss: 0.01701285\r\n",
      "Epoch:  79 Step:   279 /   793 Train loss: 0.03200514\r\n",
      "Epoch:  79 Step:   280 /   793 Train loss: 0.03448313\r\n",
      "Epoch:  79 Step:   281 /   793 Train loss: 0.02338050\r\n",
      "Epoch:  79 Step:   282 /   793 Train loss: 0.01845130\r\n",
      "Epoch:  79 Step:   283 /   793 Train loss: 0.03068407\r\n",
      "Epoch:  79 Step:   284 /   793 Train loss: 0.02208407\r\n",
      "Epoch:  79 Step:   285 /   793 Train loss: 0.02015652\r\n",
      "Epoch:  79 Step:   286 /   793 Train loss: 0.02586939\r\n",
      "Epoch:  79 Step:   287 /   793 Train loss: 0.02186412\r\n",
      "Epoch:  79 Step:   288 /   793 Train loss: 0.02678274\r\n",
      "Epoch:  79 Step:   289 /   793 Train loss: 0.02125580\r\n",
      "Epoch:  79 Step:   290 /   793 Train loss: 0.01169476\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  79 Step:   291 /   793 Train loss: 0.01947211\r\n",
      "Epoch:  79 Step:   292 /   793 Train loss: 0.02608491\r\n",
      "Epoch:  79 Step:   293 /   793 Train loss: 0.01749172\r\n",
      "Epoch:  79 Step:   294 /   793 Train loss: 0.02442278\r\n",
      "Epoch:  79 Step:   295 /   793 Train loss: 0.02049999\r\n",
      "Epoch:  79 Step:   296 /   793 Train loss: 0.02232703\r\n",
      "Epoch:  79 Step:   297 /   793 Train loss: 0.01932038\r\n",
      "Epoch:  79 Step:   298 /   793 Train loss: 0.02303055\r\n",
      "Epoch:  79 Step:   299 /   793 Train loss: 0.01694852\r\n",
      "Epoch:  79 Step:   300 /   793 Train loss: 0.02635115\r\n",
      "Epoch:  79 Step:   301 /   793 Train loss: 0.02470709\r\n",
      "Epoch:  79 Step:   302 /   793 Train loss: 0.02488309\r\n",
      "Epoch:  79 Step:   303 /   793 Train loss: 0.01951761\r\n",
      "Epoch:  79 Step:   304 /   793 Train loss: 0.03246200\r\n",
      "Epoch:  79 Step:   305 /   793 Train loss: 0.03268934\r\n",
      "Epoch:  79 Step:   306 /   793 Train loss: 0.01923992\r\n",
      "Epoch:  79 Step:   307 /   793 Train loss: 0.01373216\r\n",
      "Epoch:  79 Step:   308 /   793 Train loss: 0.01920874\r\n",
      "Epoch:  79 Step:   309 /   793 Train loss: 0.01078713\r\n",
      "Epoch:  79 Step:   310 /   793 Train loss: 0.03413617\r\n",
      "Epoch:  79 Step:   311 /   793 Train loss: 0.02050148\r\n",
      "Epoch:  79 Step:   312 /   793 Train loss: 0.01697259\r\n",
      "Epoch:  79 Step:   313 /   793 Train loss: 0.01558578\r\n",
      "Epoch:  79 Step:   314 /   793 Train loss: 0.01803887\r\n",
      "Epoch:  79 Step:   315 /   793 Train loss: 0.02507551\r\n",
      "Epoch:  79 Step:   316 /   793 Train loss: 0.02419204\r\n",
      "Epoch:  79 Step:   317 /   793 Train loss: 0.01633832\r\n",
      "Epoch:  79 Step:   318 /   793 Train loss: 0.01402377\r\n",
      "Epoch:  79 Step:   319 /   793 Train loss: 0.02027153\r\n",
      "Epoch:  79 Step:   320 /   793 Train loss: 0.03111023\r\n",
      "Epoch:  79 Step:   321 /   793 Train loss: 0.02013231\r\n",
      "Epoch:  79 Step:   322 /   793 Train loss: 0.02448622\r\n",
      "Epoch:  79 Step:   323 /   793 Train loss: 0.02924919\r\n",
      "Epoch:  79 Step:   324 /   793 Train loss: 0.02701939\r\n",
      "Epoch:  79 Step:   325 /   793 Train loss: 0.02291827\r\n",
      "Epoch:  79 Step:   326 /   793 Train loss: 0.02161032\r\n",
      "Epoch:  79 Step:   327 /   793 Train loss: 0.01645006\r\n",
      "Epoch:  79 Step:   328 /   793 Train loss: 0.03067426\r\n",
      "Epoch:  79 Step:   329 /   793 Train loss: 0.01829989\r\n",
      "Epoch:  79 Step:   330 /   793 Train loss: 0.02362124\r\n",
      "Epoch:  79 Step:   331 /   793 Train loss: 0.02003270\r\n",
      "Epoch:  79 Step:   332 /   793 Train loss: 0.02079116\r\n",
      "Epoch:  79 Step:   333 /   793 Train loss: 0.03431142\r\n",
      "Epoch:  79 Step:   334 /   793 Train loss: 0.02222686\r\n",
      "Epoch:  79 Step:   335 /   793 Train loss: 0.02281853\r\n",
      "Epoch:  79 Step:   336 /   793 Train loss: 0.02377800\r\n",
      "Epoch:  79 Step:   337 /   793 Train loss: 0.02236680\r\n",
      "Epoch:  79 Step:   338 /   793 Train loss: 0.01884094\r\n",
      "Epoch:  79 Step:   339 /   793 Train loss: 0.01781183\r\n",
      "Epoch:  79 Step:   340 /   793 Train loss: 0.02336374\r\n",
      "Epoch:  79 Step:   341 /   793 Train loss: 0.03074889\r\n",
      "Epoch:  79 Step:   342 /   793 Train loss: 0.01865975\r\n",
      "Epoch:  79 Step:   343 /   793 Train loss: 0.03577099\r\n",
      "Epoch:  79 Step:   344 /   793 Train loss: 0.01439269\r\n",
      "Epoch:  79 Step:   345 /   793 Train loss: 0.04044284\r\n",
      "Epoch:  79 Step:   346 /   793 Train loss: 0.02314453\r\n",
      "Epoch:  79 Step:   347 /   793 Train loss: 0.02470656\r\n",
      "Epoch:  79 Step:   348 /   793 Train loss: 0.02470839\r\n",
      "Epoch:  79 Step:   349 /   793 Train loss: 0.02637273\r\n",
      "Epoch:  79 Step:   350 /   793 Train loss: 0.01890248\r\n",
      "Epoch:  79 Step:   351 /   793 Train loss: 0.03028312\r\n",
      "Epoch:  79 Step:   352 /   793 Train loss: 0.02175048\r\n",
      "Epoch:  79 Step:   353 /   793 Train loss: 0.02447401\r\n",
      "Epoch:  79 Step:   354 /   793 Train loss: 0.04075067\r\n",
      "Epoch:  79 Step:   355 /   793 Train loss: 0.02535589\r\n",
      "Epoch:  79 Step:   356 /   793 Train loss: 0.03021021\r\n",
      "Epoch:  79 Step:   357 /   793 Train loss: 0.02562311\r\n",
      "Epoch:  79 Step:   358 /   793 Train loss: 0.02004674\r\n",
      "Epoch:  79 Step:   359 /   793 Train loss: 0.01517437\r\n",
      "Epoch:  79 Step:   360 /   793 Train loss: 0.01860145\r\n",
      "Epoch:  79 Step:   361 /   793 Train loss: 0.02528426\r\n",
      "Epoch:  79 Step:   362 /   793 Train loss: 0.02098194\r\n",
      "Epoch:  79 Step:   363 /   793 Train loss: 0.01559962\r\n",
      "Epoch:  79 Step:   364 /   793 Train loss: 0.01658076\r\n",
      "Epoch:  79 Step:   365 /   793 Train loss: 0.01901624\r\n",
      "Epoch:  79 Step:   366 /   793 Train loss: 0.03357543\r\n",
      "Epoch:  79 Step:   367 /   793 Train loss: 0.02507025\r\n",
      "Epoch:  79 Step:   368 /   793 Train loss: 0.02117860\r\n",
      "Epoch:  79 Step:   369 /   793 Train loss: 0.02601438\r\n",
      "Epoch:  79 Step:   370 /   793 Train loss: 0.00887237\r\n",
      "Epoch:  79 Step:   371 /   793 Train loss: 0.01932744\r\n",
      "Epoch:  79 Step:   372 /   793 Train loss: 0.02374941\r\n",
      "Epoch:  79 Step:   373 /   793 Train loss: 0.02453979\r\n",
      "Epoch:  79 Step:   374 /   793 Train loss: 0.03218565\r\n",
      "Epoch:  79 Step:   375 /   793 Train loss: 0.02538221\r\n",
      "Epoch:  79 Step:   376 /   793 Train loss: 0.02930994\r\n",
      "Epoch:  79 Step:   377 /   793 Train loss: 0.02443854\r\n",
      "Epoch:  79 Step:   378 /   793 Train loss: 0.02772220\r\n",
      "Epoch:  79 Step:   379 /   793 Train loss: 0.02584413\r\n",
      "Epoch:  79 Step:   380 /   793 Train loss: 0.01190469\r\n",
      "Epoch:  79 Step:   381 /   793 Train loss: 0.02536428\r\n",
      "Epoch:  79 Step:   382 /   793 Train loss: 0.01664201\r\n",
      "Epoch:  79 Step:   383 /   793 Train loss: 0.03187873\r\n",
      "Epoch:  79 Step:   384 /   793 Train loss: 0.02037927\r\n",
      "Epoch:  79 Step:   385 /   793 Train loss: 0.03494462\r\n",
      "Epoch:  79 Step:   386 /   793 Train loss: 0.03374986\r\n",
      "Epoch:  79 Step:   387 /   793 Train loss: 0.02898725\r\n",
      "Epoch:  79 Step:   388 /   793 Train loss: 0.02253883\r\n",
      "Epoch:  79 Step:   389 /   793 Train loss: 0.02568142\r\n",
      "Epoch:  79 Step:   390 /   793 Train loss: 0.02283432\r\n",
      "Epoch:  79 Step:   391 /   793 Train loss: 0.02390217\r\n",
      "Epoch:  79 Step:   392 /   793 Train loss: 0.02985763\r\n",
      "Epoch:  79 Step:   393 /   793 Train loss: 0.02402489\r\n",
      "Epoch:  79 Step:   394 /   793 Train loss: 0.02783621\r\n",
      "Epoch:  79 Step:   395 /   793 Train loss: 0.02529658\r\n",
      "Epoch:  79 Step:   396 /   793 Train loss: 0.02055150\r\n",
      "Epoch:  79 Step:   397 /   793 Train loss: 0.01632014\r\n",
      "Epoch:  79 Step:   398 /   793 Train loss: 0.02036531\r\n",
      "Epoch:  79 Step:   399 /   793 Train loss: 0.01806515\r\n",
      "Epoch:  79 Step:   400 /   793 Train loss: 0.01918682\r\n",
      "Epoch:  79 Step:   401 /   793 Train loss: 0.02918641\r\n",
      "Epoch:  79 Step:   402 /   793 Train loss: 0.02379311\r\n",
      "Epoch:  79 Step:   403 /   793 Train loss: 0.01940528\r\n",
      "Epoch:  79 Step:   404 /   793 Train loss: 0.01663441\r\n",
      "Epoch:  79 Step:   405 /   793 Train loss: 0.03361341\r\n",
      "Epoch:  79 Step:   406 /   793 Train loss: 0.02801015\r\n",
      "Epoch:  79 Step:   407 /   793 Train loss: 0.02911803\r\n",
      "Epoch:  79 Step:   408 /   793 Train loss: 0.02261878\r\n",
      "Epoch:  79 Step:   409 /   793 Train loss: 0.03870487\r\n",
      "Epoch:  79 Step:   410 /   793 Train loss: 0.03829187\r\n",
      "Epoch:  79 Step:   411 /   793 Train loss: 0.02591394\r\n",
      "Epoch:  79 Step:   412 /   793 Train loss: 0.02889565\r\n",
      "Epoch:  79 Step:   413 /   793 Train loss: 0.01052214\r\n",
      "Epoch:  79 Step:   414 /   793 Train loss: 0.00925512\r\n",
      "Epoch:  79 Step:   415 /   793 Train loss: 0.02427815\r\n",
      "Epoch:  79 Step:   416 /   793 Train loss: 0.02082298\r\n",
      "Epoch:  79 Step:   417 /   793 Train loss: 0.02226558\r\n",
      "Epoch:  79 Step:   418 /   793 Train loss: 0.01666422\r\n",
      "Epoch:  79 Step:   419 /   793 Train loss: 0.01952212\r\n",
      "Epoch:  79 Step:   420 /   793 Train loss: 0.02550185\r\n",
      "Epoch:  79 Step:   421 /   793 Train loss: 0.01301192\r\n",
      "Epoch:  79 Step:   422 /   793 Train loss: 0.04335605\r\n",
      "Epoch:  79 Step:   423 /   793 Train loss: 0.02842462\r\n",
      "Epoch:  79 Step:   424 /   793 Train loss: 0.02179101\r\n",
      "Epoch:  79 Step:   425 /   793 Train loss: 0.01754703\r\n",
      "Epoch:  79 Step:   426 /   793 Train loss: 0.02585188\r\n",
      "Epoch:  79 Step:   427 /   793 Train loss: 0.03670186\r\n",
      "Epoch:  79 Step:   428 /   793 Train loss: 0.01998845\r\n",
      "Epoch:  79 Step:   429 /   793 Train loss: 0.01864150\r\n",
      "Epoch:  79 Step:   430 /   793 Train loss: 0.01538761\r\n",
      "Epoch:  79 Step:   431 /   793 Train loss: 0.01515779\r\n",
      "Epoch:  79 Step:   432 /   793 Train loss: 0.01836291\r\n",
      "Epoch:  79 Step:   433 /   793 Train loss: 0.03202973\r\n",
      "Epoch:  79 Step:   434 /   793 Train loss: 0.02439074\r\n",
      "Epoch:  79 Step:   435 /   793 Train loss: 0.02251644\r\n",
      "Epoch:  79 Step:   436 /   793 Train loss: 0.03449007\r\n",
      "Epoch:  79 Step:   437 /   793 Train loss: 0.03182284\r\n",
      "Epoch:  79 Step:   438 /   793 Train loss: 0.02247758\r\n",
      "Epoch:  79 Step:   439 /   793 Train loss: 0.02249111\r\n",
      "Epoch:  79 Step:   440 /   793 Train loss: 0.02546936\r\n",
      "Epoch:  79 Step:   441 /   793 Train loss: 0.02311097\r\n",
      "Epoch:  79 Step:   442 /   793 Train loss: 0.02033417\r\n",
      "Epoch:  79 Step:   443 /   793 Train loss: 0.02366472\r\n",
      "Epoch:  79 Step:   444 /   793 Train loss: 0.03062331\r\n",
      "Epoch:  79 Step:   445 /   793 Train loss: 0.02200135\r\n",
      "Epoch:  79 Step:   446 /   793 Train loss: 0.01878594\r\n",
      "Epoch:  79 Step:   447 /   793 Train loss: 0.02454346\r\n",
      "Epoch:  79 Step:   448 /   793 Train loss: 0.02206825\r\n",
      "Epoch:  79 Step:   449 /   793 Train loss: 0.02507171\r\n",
      "Epoch:  79 Step:   450 /   793 Train loss: 0.01633671\r\n",
      "Epoch:  79 Step:   451 /   793 Train loss: 0.02155740\r\n",
      "Epoch:  79 Step:   452 /   793 Train loss: 0.02215847\r\n",
      "Epoch:  79 Step:   453 /   793 Train loss: 0.01317213\r\n",
      "Epoch:  79 Step:   454 /   793 Train loss: 0.02311641\r\n",
      "Epoch:  79 Step:   455 /   793 Train loss: 0.03144793\r\n",
      "Epoch:  79 Step:   456 /   793 Train loss: 0.01430615\r\n",
      "Epoch:  79 Step:   457 /   793 Train loss: 0.01152519\r\n",
      "Epoch:  79 Step:   458 /   793 Train loss: 0.02835861\r\n",
      "Epoch:  79 Step:   459 /   793 Train loss: 0.01497851\r\n",
      "Epoch:  79 Step:   460 /   793 Train loss: 0.02853809\r\n",
      "Epoch:  79 Step:   461 /   793 Train loss: 0.03980381\r\n",
      "Epoch:  79 Step:   462 /   793 Train loss: 0.02113337\r\n",
      "Epoch:  79 Step:   463 /   793 Train loss: 0.03259192\r\n",
      "Epoch:  79 Step:   464 /   793 Train loss: 0.02225316\r\n",
      "Epoch:  79 Step:   465 /   793 Train loss: 0.01808891\r\n",
      "Epoch:  79 Step:   466 /   793 Train loss: 0.02830038\r\n",
      "Epoch:  79 Step:   467 /   793 Train loss: 0.02301378\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  79 Step:   468 /   793 Train loss: 0.03873806\r\n",
      "Epoch:  79 Step:   469 /   793 Train loss: 0.02552191\r\n",
      "Epoch:  79 Step:   470 /   793 Train loss: 0.00877146\r\n",
      "Epoch:  79 Step:   471 /   793 Train loss: 0.02950974\r\n",
      "Epoch:  79 Step:   472 /   793 Train loss: 0.02184438\r\n",
      "Epoch:  79 Step:   473 /   793 Train loss: 0.02729301\r\n",
      "Epoch:  79 Step:   474 /   793 Train loss: 0.03334950\r\n",
      "Epoch:  79 Step:   475 /   793 Train loss: 0.01897755\r\n",
      "Epoch:  79 Step:   476 /   793 Train loss: 0.03012114\r\n",
      "Epoch:  79 Step:   477 /   793 Train loss: 0.02865540\r\n",
      "Epoch:  79 Step:   478 /   793 Train loss: 0.02126748\r\n",
      "Epoch:  79 Step:   479 /   793 Train loss: 0.03130130\r\n",
      "Epoch:  79 Step:   480 /   793 Train loss: 0.02424803\r\n",
      "Epoch:  79 Step:   481 /   793 Train loss: 0.03384762\r\n",
      "Epoch:  79 Step:   482 /   793 Train loss: 0.02407760\r\n",
      "Epoch:  79 Step:   483 /   793 Train loss: 0.01513405\r\n",
      "Epoch:  79 Step:   484 /   793 Train loss: 0.01485808\r\n",
      "Epoch:  79 Step:   485 /   793 Train loss: 0.03733055\r\n",
      "Epoch:  79 Step:   486 /   793 Train loss: 0.03022736\r\n",
      "Epoch:  79 Step:   487 /   793 Train loss: 0.02115350\r\n",
      "Epoch:  79 Step:   488 /   793 Train loss: 0.02700489\r\n",
      "Epoch:  79 Step:   489 /   793 Train loss: 0.02668231\r\n",
      "Epoch:  79 Step:   490 /   793 Train loss: 0.05150208\r\n",
      "Epoch:  79 Step:   491 /   793 Train loss: 0.03615256\r\n",
      "Epoch:  79 Step:   492 /   793 Train loss: 0.01846993\r\n",
      "Epoch:  79 Step:   493 /   793 Train loss: 0.01937724\r\n",
      "Epoch:  79 Step:   494 /   793 Train loss: 0.03403129\r\n",
      "Epoch:  79 Step:   495 /   793 Train loss: 0.02404522\r\n",
      "Epoch:  79 Step:   496 /   793 Train loss: 0.02638491\r\n",
      "Epoch:  79 Step:   497 /   793 Train loss: 0.01967626\r\n",
      "Epoch:  79 Step:   498 /   793 Train loss: 0.02251617\r\n",
      "Epoch:  79 Step:   499 /   793 Train loss: 0.03415850\r\n",
      "Epoch:  79 Step:   500 /   793 Train loss: 0.02612224\r\n",
      "Epoch:  79 Step:   501 /   793 Train loss: 0.03265733\r\n",
      "Epoch:  79 Step:   502 /   793 Train loss: 0.01766975\r\n",
      "Epoch:  79 Step:   503 /   793 Train loss: 0.02237000\r\n",
      "Epoch:  79 Step:   504 /   793 Train loss: 0.01767689\r\n",
      "Epoch:  79 Step:   505 /   793 Train loss: 0.02257603\r\n",
      "Epoch:  79 Step:   506 /   793 Train loss: 0.03723952\r\n",
      "Epoch:  79 Step:   507 /   793 Train loss: 0.03580950\r\n",
      "Epoch:  79 Step:   508 /   793 Train loss: 0.02723109\r\n",
      "Epoch:  79 Step:   509 /   793 Train loss: 0.03762437\r\n",
      "Epoch:  79 Step:   510 /   793 Train loss: 0.02923686\r\n",
      "Epoch:  79 Step:   511 /   793 Train loss: 0.02552387\r\n",
      "Epoch:  79 Step:   512 /   793 Train loss: 0.02677247\r\n",
      "Epoch:  79 Step:   513 /   793 Train loss: 0.02518542\r\n",
      "Epoch:  79 Step:   514 /   793 Train loss: 0.03779159\r\n",
      "Epoch:  79 Step:   515 /   793 Train loss: 0.01287768\r\n",
      "Epoch:  79 Step:   516 /   793 Train loss: 0.03879077\r\n",
      "Epoch:  79 Step:   517 /   793 Train loss: 0.03330993\r\n",
      "Epoch:  79 Step:   518 /   793 Train loss: 0.02806379\r\n",
      "Epoch:  79 Step:   519 /   793 Train loss: 0.02135570\r\n",
      "Epoch:  79 Step:   520 /   793 Train loss: 0.02688541\r\n",
      "Epoch:  79 Step:   521 /   793 Train loss: 0.01221384\r\n",
      "Epoch:  79 Step:   522 /   793 Train loss: 0.01047714\r\n",
      "Epoch:  79 Step:   523 /   793 Train loss: 0.02135903\r\n",
      "Epoch:  79 Step:   524 /   793 Train loss: 0.01904319\r\n",
      "Epoch:  79 Step:   525 /   793 Train loss: 0.02561051\r\n",
      "Epoch:  79 Step:   526 /   793 Train loss: 0.01173608\r\n",
      "Epoch:  79 Step:   527 /   793 Train loss: 0.02789934\r\n",
      "Epoch:  79 Step:   528 /   793 Train loss: 0.00913265\r\n",
      "Epoch:  79 Step:   529 /   793 Train loss: 0.02180359\r\n",
      "Epoch:  79 Step:   530 /   793 Train loss: 0.03260482\r\n",
      "Epoch:  79 Step:   531 /   793 Train loss: 0.02826441\r\n",
      "Epoch:  79 Step:   532 /   793 Train loss: 0.02413468\r\n",
      "Epoch:  79 Step:   533 /   793 Train loss: 0.03240892\r\n",
      "Epoch:  79 Step:   534 /   793 Train loss: 0.03006582\r\n",
      "Epoch:  79 Step:   535 /   793 Train loss: 0.02560663\r\n",
      "Epoch:  79 Step:   536 /   793 Train loss: 0.03133035\r\n",
      "Epoch:  79 Step:   537 /   793 Train loss: 0.03008732\r\n",
      "Epoch:  79 Step:   538 /   793 Train loss: 0.02372785\r\n",
      "Epoch:  79 Step:   539 /   793 Train loss: 0.01909281\r\n",
      "Epoch:  79 Step:   540 /   793 Train loss: 0.02622131\r\n",
      "Epoch:  79 Step:   541 /   793 Train loss: 0.01992106\r\n",
      "Epoch:  79 Step:   542 /   793 Train loss: 0.01803913\r\n",
      "Epoch:  79 Step:   543 /   793 Train loss: 0.00957133\r\n",
      "Epoch:  79 Step:   544 /   793 Train loss: 0.03271355\r\n",
      "Epoch:  79 Step:   545 /   793 Train loss: 0.02556656\r\n",
      "Epoch:  79 Step:   546 /   793 Train loss: 0.02345562\r\n",
      "Epoch:  79 Step:   547 /   793 Train loss: 0.03210808\r\n",
      "Epoch:  79 Step:   548 /   793 Train loss: 0.03420074\r\n",
      "Epoch:  79 Step:   549 /   793 Train loss: 0.02941276\r\n",
      "Epoch:  79 Step:   550 /   793 Train loss: 0.02639773\r\n",
      "Epoch:  79 Step:   551 /   793 Train loss: 0.02715592\r\n",
      "Epoch:  79 Step:   552 /   793 Train loss: 0.01782061\r\n",
      "Epoch:  79 Step:   553 /   793 Train loss: 0.03538938\r\n",
      "Epoch:  79 Step:   554 /   793 Train loss: 0.01556950\r\n",
      "Epoch:  79 Step:   555 /   793 Train loss: 0.01792710\r\n",
      "Epoch:  79 Step:   556 /   793 Train loss: 0.02915001\r\n",
      "Epoch:  79 Step:   557 /   793 Train loss: 0.02013936\r\n",
      "Epoch:  79 Step:   558 /   793 Train loss: 0.01765417\r\n",
      "Epoch:  79 Step:   559 /   793 Train loss: 0.01010933\r\n",
      "Epoch:  79 Step:   560 /   793 Train loss: 0.02974869\r\n",
      "Epoch:  79 Step:   561 /   793 Train loss: 0.02485239\r\n",
      "Epoch:  79 Step:   562 /   793 Train loss: 0.01644630\r\n",
      "Epoch:  79 Step:   563 /   793 Train loss: 0.02138576\r\n",
      "Epoch:  79 Step:   564 /   793 Train loss: 0.02442838\r\n",
      "Epoch:  79 Step:   565 /   793 Train loss: 0.01841372\r\n",
      "Epoch:  79 Step:   566 /   793 Train loss: 0.02666505\r\n",
      "Epoch:  79 Step:   567 /   793 Train loss: 0.02076722\r\n",
      "Epoch:  79 Step:   568 /   793 Train loss: 0.03068562\r\n",
      "Epoch:  79 Step:   569 /   793 Train loss: 0.02426264\r\n",
      "Epoch:  79 Step:   570 /   793 Train loss: 0.03084366\r\n",
      "Epoch:  79 Step:   571 /   793 Train loss: 0.02735583\r\n",
      "Epoch:  79 Step:   572 /   793 Train loss: 0.03055638\r\n",
      "Epoch:  79 Step:   573 /   793 Train loss: 0.01541792\r\n",
      "Epoch:  79 Step:   574 /   793 Train loss: 0.01991211\r\n",
      "Epoch:  79 Step:   575 /   793 Train loss: 0.02690461\r\n",
      "Epoch:  79 Step:   576 /   793 Train loss: 0.02135812\r\n",
      "Epoch:  79 Step:   577 /   793 Train loss: 0.01643163\r\n",
      "Epoch:  79 Step:   578 /   793 Train loss: 0.03519610\r\n",
      "Epoch:  79 Step:   579 /   793 Train loss: 0.01638871\r\n",
      "Epoch:  79 Step:   580 /   793 Train loss: 0.01922493\r\n",
      "Epoch:  79 Step:   581 /   793 Train loss: 0.02370512\r\n",
      "Epoch:  79 Step:   582 /   793 Train loss: 0.02692768\r\n",
      "Epoch:  79 Step:   583 /   793 Train loss: 0.03299802\r\n",
      "Epoch:  79 Step:   584 /   793 Train loss: 0.01843070\r\n",
      "Epoch:  79 Step:   585 /   793 Train loss: 0.01963604\r\n",
      "Epoch:  79 Step:   586 /   793 Train loss: 0.01595263\r\n",
      "Epoch:  79 Step:   587 /   793 Train loss: 0.01399599\r\n",
      "Epoch:  79 Step:   588 /   793 Train loss: 0.02345298\r\n",
      "Epoch:  79 Step:   589 /   793 Train loss: 0.03057861\r\n",
      "Epoch:  79 Step:   590 /   793 Train loss: 0.02669271\r\n",
      "Epoch:  79 Step:   591 /   793 Train loss: 0.01878484\r\n",
      "Epoch:  79 Step:   592 /   793 Train loss: 0.02165390\r\n",
      "Epoch:  79 Step:   593 /   793 Train loss: 0.02979834\r\n",
      "Epoch:  79 Step:   594 /   793 Train loss: 0.02407271\r\n",
      "Epoch:  79 Step:   595 /   793 Train loss: 0.02466190\r\n",
      "Epoch:  79 Step:   596 /   793 Train loss: 0.02454276\r\n",
      "Epoch:  79 Step:   597 /   793 Train loss: 0.03132653\r\n",
      "Epoch:  79 Step:   598 /   793 Train loss: 0.02964584\r\n",
      "Epoch:  79 Step:   599 /   793 Train loss: 0.02313384\r\n",
      "Epoch:  79 Step:   600 /   793 Train loss: 0.02766363\r\n",
      "Epoch:  79 Step:   601 /   793 Train loss: 0.02946755\r\n",
      "Epoch:  79 Step:   602 /   793 Train loss: 0.03154631\r\n",
      "Epoch:  79 Step:   603 /   793 Train loss: 0.02677833\r\n",
      "Epoch:  79 Step:   604 /   793 Train loss: 0.03163278\r\n",
      "Epoch:  79 Step:   605 /   793 Train loss: 0.01481864\r\n",
      "Epoch:  79 Step:   606 /   793 Train loss: 0.02222933\r\n",
      "Epoch:  79 Step:   607 /   793 Train loss: 0.03569628\r\n",
      "Epoch:  79 Step:   608 /   793 Train loss: 0.01718933\r\n",
      "Epoch:  79 Step:   609 /   793 Train loss: 0.01569625\r\n",
      "Epoch:  79 Step:   610 /   793 Train loss: 0.02709922\r\n",
      "Epoch:  79 Step:   611 /   793 Train loss: 0.03187003\r\n",
      "Epoch:  79 Step:   612 /   793 Train loss: 0.02746241\r\n",
      "Epoch:  79 Step:   613 /   793 Train loss: 0.01806127\r\n",
      "Epoch:  79 Step:   614 /   793 Train loss: 0.03142785\r\n",
      "Epoch:  79 Step:   615 /   793 Train loss: 0.02353219\r\n",
      "Epoch:  79 Step:   616 /   793 Train loss: 0.02248999\r\n",
      "Epoch:  79 Step:   617 /   793 Train loss: 0.02364835\r\n",
      "Epoch:  79 Step:   618 /   793 Train loss: 0.02344918\r\n",
      "Epoch:  79 Step:   619 /   793 Train loss: 0.01881590\r\n",
      "Epoch:  79 Step:   620 /   793 Train loss: 0.01332933\r\n",
      "Epoch:  79 Step:   621 /   793 Train loss: 0.01521109\r\n",
      "Epoch:  79 Step:   622 /   793 Train loss: 0.04198104\r\n",
      "Epoch:  79 Step:   623 /   793 Train loss: 0.01730789\r\n",
      "Epoch:  79 Step:   624 /   793 Train loss: 0.02151792\r\n",
      "Epoch:  79 Step:   625 /   793 Train loss: 0.02797759\r\n",
      "Epoch:  79 Step:   626 /   793 Train loss: 0.02762446\r\n",
      "Epoch:  79 Step:   627 /   793 Train loss: 0.01807890\r\n",
      "Epoch:  79 Step:   628 /   793 Train loss: 0.02025370\r\n",
      "Epoch:  79 Step:   629 /   793 Train loss: 0.02721579\r\n",
      "Epoch:  79 Step:   630 /   793 Train loss: 0.02783061\r\n",
      "Epoch:  79 Step:   631 /   793 Train loss: 0.01855659\r\n",
      "Epoch:  79 Step:   632 /   793 Train loss: 0.02496823\r\n",
      "Epoch:  79 Step:   633 /   793 Train loss: 0.01963518\r\n",
      "Epoch:  79 Step:   634 /   793 Train loss: 0.03066929\r\n",
      "Epoch:  79 Step:   635 /   793 Train loss: 0.03371733\r\n",
      "Epoch:  79 Step:   636 /   793 Train loss: 0.03678066\r\n",
      "Epoch:  79 Step:   637 /   793 Train loss: 0.02846020\r\n",
      "Epoch:  79 Step:   638 /   793 Train loss: 0.03402578\r\n",
      "Epoch:  79 Step:   639 /   793 Train loss: 0.01251601\r\n",
      "Epoch:  79 Step:   640 /   793 Train loss: 0.02260800\r\n",
      "Epoch:  79 Step:   641 /   793 Train loss: 0.02219436\r\n",
      "Epoch:  79 Step:   642 /   793 Train loss: 0.02435523\r\n",
      "Epoch:  79 Step:   643 /   793 Train loss: 0.02386600\r\n",
      "Epoch:  79 Step:   644 /   793 Train loss: 0.02127775\r\n",
      "Epoch:  79 Step:   645 /   793 Train loss: 0.03016553\r\n",
      "Epoch:  79 Step:   646 /   793 Train loss: 0.02575150\r\n",
      "Epoch:  79 Step:   647 /   793 Train loss: 0.02812710\r\n",
      "Epoch:  79 Step:   648 /   793 Train loss: 0.03278789\r\n",
      "Epoch:  79 Step:   649 /   793 Train loss: 0.02156050\r\n",
      "Epoch:  79 Step:   650 /   793 Train loss: 0.03234076\r\n",
      "Epoch:  79 Step:   651 /   793 Train loss: 0.03024544\r\n",
      "Epoch:  79 Step:   652 /   793 Train loss: 0.02808438\r\n",
      "Epoch:  79 Step:   653 /   793 Train loss: 0.03120827\r\n",
      "Epoch:  79 Step:   654 /   793 Train loss: 0.02985424\r\n",
      "Epoch:  79 Step:   655 /   793 Train loss: 0.02240977\r\n",
      "Epoch:  79 Step:   656 /   793 Train loss: 0.03331198\r\n",
      "Epoch:  79 Step:   657 /   793 Train loss: 0.01945546\r\n",
      "Epoch:  79 Step:   658 /   793 Train loss: 0.01524504\r\n",
      "Epoch:  79 Step:   659 /   793 Train loss: 0.02397178\r\n",
      "Epoch:  79 Step:   660 /   793 Train loss: 0.01861580\r\n",
      "Epoch:  79 Step:   661 /   793 Train loss: 0.02957350\r\n",
      "Epoch:  79 Step:   662 /   793 Train loss: 0.02290056\r\n",
      "Epoch:  79 Step:   663 /   793 Train loss: 0.02301689\r\n",
      "Epoch:  79 Step:   664 /   793 Train loss: 0.02612923\r\n",
      "Epoch:  79 Step:   665 /   793 Train loss: 0.02493245\r\n",
      "Epoch:  79 Step:   666 /   793 Train loss: 0.01492740\r\n",
      "Epoch:  79 Step:   667 /   793 Train loss: 0.02483010\r\n",
      "Epoch:  79 Step:   668 /   793 Train loss: 0.01968056\r\n",
      "Epoch:  79 Step:   669 /   793 Train loss: 0.01823440\r\n",
      "Epoch:  79 Step:   670 /   793 Train loss: 0.01652992\r\n",
      "Epoch:  79 Step:   671 /   793 Train loss: 0.02441724\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  79 Step:   672 /   793 Train loss: 0.02445714\r\n",
      "Epoch:  79 Step:   673 /   793 Train loss: 0.02289841\r\n",
      "Epoch:  79 Step:   674 /   793 Train loss: 0.02688921\r\n",
      "Epoch:  79 Step:   675 /   793 Train loss: 0.01639803\r\n",
      "Epoch:  79 Step:   676 /   793 Train loss: 0.02876966\r\n",
      "Epoch:  79 Step:   677 /   793 Train loss: 0.03942984\r\n",
      "Epoch:  79 Step:   678 /   793 Train loss: 0.03078512\r\n",
      "Epoch:  79 Step:   679 /   793 Train loss: 0.03693767\r\n",
      "Epoch:  79 Step:   680 /   793 Train loss: 0.03378895\r\n",
      "Epoch:  79 Step:   681 /   793 Train loss: 0.01990921\r\n",
      "Epoch:  79 Step:   682 /   793 Train loss: 0.01788379\r\n",
      "Epoch:  79 Step:   683 /   793 Train loss: 0.01337225\r\n",
      "Epoch:  79 Step:   684 /   793 Train loss: 0.02650258\r\n",
      "Epoch:  79 Step:   685 /   793 Train loss: 0.02103242\r\n",
      "Epoch:  79 Step:   686 /   793 Train loss: 0.02737667\r\n",
      "Epoch:  79 Step:   687 /   793 Train loss: 0.02464935\r\n",
      "Epoch:  79 Step:   688 /   793 Train loss: 0.02624418\r\n",
      "Epoch:  79 Step:   689 /   793 Train loss: 0.01883180\r\n",
      "Epoch:  79 Step:   690 /   793 Train loss: 0.03082211\r\n",
      "Epoch:  79 Step:   691 /   793 Train loss: 0.03744473\r\n",
      "Epoch:  79 Step:   692 /   793 Train loss: 0.02116549\r\n",
      "Epoch:  79 Step:   693 /   793 Train loss: 0.01328124\r\n",
      "Epoch:  79 Step:   694 /   793 Train loss: 0.01969114\r\n",
      "Epoch:  79 Step:   695 /   793 Train loss: 0.03272753\r\n",
      "Epoch:  79 Step:   696 /   793 Train loss: 0.01472084\r\n",
      "Epoch:  79 Step:   697 /   793 Train loss: 0.01775945\r\n",
      "Epoch:  79 Step:   698 /   793 Train loss: 0.02915738\r\n",
      "Epoch:  79 Step:   699 /   793 Train loss: 0.04004006\r\n",
      "Epoch:  79 Step:   700 /   793 Train loss: 0.02674882\r\n",
      "Epoch:  79 Step:   701 /   793 Train loss: 0.03487562\r\n",
      "Epoch:  79 Step:   702 /   793 Train loss: 0.03362413\r\n",
      "Epoch:  79 Step:   703 /   793 Train loss: 0.02533107\r\n",
      "Epoch:  79 Step:   704 /   793 Train loss: 0.01382459\r\n",
      "Epoch:  79 Step:   705 /   793 Train loss: 0.02315876\r\n",
      "Epoch:  79 Step:   706 /   793 Train loss: 0.01252073\r\n",
      "Epoch:  79 Step:   707 /   793 Train loss: 0.02650398\r\n",
      "Epoch:  79 Step:   708 /   793 Train loss: 0.02516915\r\n",
      "Epoch:  79 Step:   709 /   793 Train loss: 0.03415776\r\n",
      "Epoch:  79 Step:   710 /   793 Train loss: 0.01310809\r\n",
      "Epoch:  79 Step:   711 /   793 Train loss: 0.02288727\r\n",
      "Epoch:  79 Step:   712 /   793 Train loss: 0.01911181\r\n",
      "Epoch:  79 Step:   713 /   793 Train loss: 0.03050550\r\n",
      "Epoch:  79 Step:   714 /   793 Train loss: 0.02868175\r\n",
      "Epoch:  79 Step:   715 /   793 Train loss: 0.03199297\r\n",
      "Epoch:  79 Step:   716 /   793 Train loss: 0.02088918\r\n",
      "Epoch:  79 Step:   717 /   793 Train loss: 0.03385087\r\n",
      "Epoch:  79 Step:   718 /   793 Train loss: 0.02780828\r\n",
      "Epoch:  79 Step:   719 /   793 Train loss: 0.01701154\r\n",
      "Epoch:  79 Step:   720 /   793 Train loss: 0.04610562\r\n",
      "Epoch:  79 Step:   721 /   793 Train loss: 0.02897381\r\n",
      "Epoch:  79 Step:   722 /   793 Train loss: 0.01983356\r\n",
      "Epoch:  79 Step:   723 /   793 Train loss: 0.02711068\r\n",
      "Epoch:  79 Step:   724 /   793 Train loss: 0.02187501\r\n",
      "Epoch:  79 Step:   725 /   793 Train loss: 0.01821365\r\n",
      "Epoch:  79 Step:   726 /   793 Train loss: 0.02327438\r\n",
      "Epoch:  79 Step:   727 /   793 Train loss: 0.03341321\r\n",
      "Epoch:  79 Step:   728 /   793 Train loss: 0.01903303\r\n",
      "Epoch:  79 Step:   729 /   793 Train loss: 0.02778606\r\n",
      "Epoch:  79 Step:   730 /   793 Train loss: 0.02475733\r\n",
      "Epoch:  79 Step:   731 /   793 Train loss: 0.01195452\r\n",
      "Epoch:  79 Step:   732 /   793 Train loss: 0.04258298\r\n",
      "Epoch:  79 Step:   733 /   793 Train loss: 0.02243299\r\n",
      "Epoch:  79 Step:   734 /   793 Train loss: 0.02653645\r\n",
      "Epoch:  79 Step:   735 /   793 Train loss: 0.02627587\r\n",
      "Epoch:  79 Step:   736 /   793 Train loss: 0.02741767\r\n",
      "Epoch:  79 Step:   737 /   793 Train loss: 0.03346181\r\n",
      "Epoch:  79 Step:   738 /   793 Train loss: 0.01615845\r\n",
      "Epoch:  79 Step:   739 /   793 Train loss: 0.01873531\r\n",
      "Epoch:  79 Step:   740 /   793 Train loss: 0.02289343\r\n",
      "Epoch:  79 Step:   741 /   793 Train loss: 0.02458684\r\n",
      "Epoch:  79 Step:   742 /   793 Train loss: 0.02884927\r\n",
      "Epoch:  79 Step:   743 /   793 Train loss: 0.02811979\r\n",
      "Epoch:  79 Step:   744 /   793 Train loss: 0.02196459\r\n",
      "Epoch:  79 Step:   745 /   793 Train loss: 0.02417544\r\n",
      "Epoch:  79 Step:   746 /   793 Train loss: 0.01245502\r\n",
      "Epoch:  79 Step:   747 /   793 Train loss: 0.02317500\r\n",
      "Epoch:  79 Step:   748 /   793 Train loss: 0.02832362\r\n",
      "Epoch:  79 Step:   749 /   793 Train loss: 0.02315285\r\n",
      "Epoch:  79 Step:   750 /   793 Train loss: 0.01324557\r\n",
      "Epoch:  79 Step:   751 /   793 Train loss: 0.02179779\r\n",
      "Epoch:  79 Step:   752 /   793 Train loss: 0.02156373\r\n",
      "Epoch:  79 Step:   753 /   793 Train loss: 0.01784489\r\n",
      "Epoch:  79 Step:   754 /   793 Train loss: 0.02228481\r\n",
      "Epoch:  79 Step:   755 /   793 Train loss: 0.03997128\r\n",
      "Epoch:  79 Step:   756 /   793 Train loss: 0.02931693\r\n",
      "Epoch:  79 Step:   757 /   793 Train loss: 0.02053901\r\n",
      "Epoch:  79 Step:   758 /   793 Train loss: 0.02158418\r\n",
      "Epoch:  79 Step:   759 /   793 Train loss: 0.01683297\r\n",
      "Epoch:  79 Step:   760 /   793 Train loss: 0.02086114\r\n",
      "Epoch:  79 Step:   761 /   793 Train loss: 0.02933217\r\n",
      "Epoch:  79 Step:   762 /   793 Train loss: 0.02943268\r\n",
      "Epoch:  79 Step:   763 /   793 Train loss: 0.03194211\r\n",
      "Epoch:  79 Step:   764 /   793 Train loss: 0.02284514\r\n",
      "Epoch:  79 Step:   765 /   793 Train loss: 0.01382555\r\n",
      "Epoch:  79 Step:   766 /   793 Train loss: 0.01683428\r\n",
      "Epoch:  79 Step:   767 /   793 Train loss: 0.01932700\r\n",
      "Epoch:  79 Step:   768 /   793 Train loss: 0.02408249\r\n",
      "Epoch:  79 Step:   769 /   793 Train loss: 0.02773919\r\n",
      "Epoch:  79 Step:   770 /   793 Train loss: 0.02488376\r\n",
      "Epoch:  79 Step:   771 /   793 Train loss: 0.02007994\r\n",
      "Epoch:  79 Step:   772 /   793 Train loss: 0.01716013\r\n",
      "Epoch:  79 Step:   773 /   793 Train loss: 0.02735699\r\n",
      "Epoch:  79 Step:   774 /   793 Train loss: 0.02609765\r\n",
      "Epoch:  79 Step:   775 /   793 Train loss: 0.02071945\r\n",
      "Epoch:  79 Step:   776 /   793 Train loss: 0.02349471\r\n",
      "Epoch:  79 Step:   777 /   793 Train loss: 0.02908722\r\n",
      "Epoch:  79 Step:   778 /   793 Train loss: 0.02727402\r\n",
      "Epoch:  79 Step:   779 /   793 Train loss: 0.01631453\r\n",
      "Epoch:  79 Step:   780 /   793 Train loss: 0.03049680\r\n",
      "Epoch:  79 Step:   781 /   793 Train loss: 0.01994887\r\n",
      "Epoch:  79 Step:   782 /   793 Train loss: 0.02968910\r\n",
      "Epoch:  79 Step:   783 /   793 Train loss: 0.01602852\r\n",
      "Epoch:  79 Step:   784 /   793 Train loss: 0.02247583\r\n",
      "Epoch:  79 Step:   785 /   793 Train loss: 0.01918847\r\n",
      "Epoch:  79 Step:   786 /   793 Train loss: 0.03161399\r\n",
      "Epoch:  79 Step:   787 /   793 Train loss: 0.01516243\r\n",
      "Epoch:  79 Step:   788 /   793 Train loss: 0.03547142\r\n",
      "Epoch:  79 Step:   789 /   793 Train loss: 0.01608929\r\n",
      "Epoch:  79 Step:   790 /   793 Train loss: 0.02847756\r\n",
      "Epoch:  79 Step:   791 /   793 Train loss: 0.03324709\r\n",
      "Epoch:  79 Step:   792 /   793 Train loss: 0.02312091\r\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\r\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\r\n",
      "Epoch:  79 Validation loss: 0.01409525\r\n",
      "Epoch:  80 Step:     0 /   793 Train loss: 0.01863905\r\n",
      "Epoch:  80 Step:     1 /   793 Train loss: 0.02861143\r\n",
      "Epoch:  80 Step:     2 /   793 Train loss: 0.02838713\r\n",
      "Epoch:  80 Step:     3 /   793 Train loss: 0.02958132\r\n",
      "Epoch:  80 Step:     4 /   793 Train loss: 0.03154611\r\n",
      "Epoch:  80 Step:     5 /   793 Train loss: 0.02587324\r\n",
      "Epoch:  80 Step:     6 /   793 Train loss: 0.02914260\r\n",
      "Epoch:  80 Step:     7 /   793 Train loss: 0.01865685\r\n",
      "Epoch:  80 Step:     8 /   793 Train loss: 0.03885553\r\n",
      "Epoch:  80 Step:     9 /   793 Train loss: 0.02696565\r\n",
      "Epoch:  80 Step:    10 /   793 Train loss: 0.01921778\r\n",
      "Epoch:  80 Step:    11 /   793 Train loss: 0.04719932\r\n",
      "Epoch:  80 Step:    12 /   793 Train loss: 0.02631092\r\n",
      "Epoch:  80 Step:    13 /   793 Train loss: 0.02748021\r\n",
      "Epoch:  80 Step:    14 /   793 Train loss: 0.02269220\r\n",
      "Epoch:  80 Step:    15 /   793 Train loss: 0.02832021\r\n",
      "Epoch:  80 Step:    16 /   793 Train loss: 0.01997705\r\n",
      "Epoch:  80 Step:    17 /   793 Train loss: 0.02711607\r\n",
      "Epoch:  80 Step:    18 /   793 Train loss: 0.02677144\r\n",
      "Epoch:  80 Step:    19 /   793 Train loss: 0.02515057\r\n",
      "Epoch:  80 Step:    20 /   793 Train loss: 0.02716744\r\n",
      "Epoch:  80 Step:    21 /   793 Train loss: 0.02181242\r\n",
      "Epoch:  80 Step:    22 /   793 Train loss: 0.03434192\r\n",
      "Epoch:  80 Step:    23 /   793 Train loss: 0.02702505\r\n",
      "Epoch:  80 Step:    24 /   793 Train loss: 0.02533266\r\n",
      "Epoch:  80 Step:    25 /   793 Train loss: 0.02120874\r\n",
      "Epoch:  80 Step:    26 /   793 Train loss: 0.02306470\r\n",
      "Epoch:  80 Step:    27 /   793 Train loss: 0.02768978\r\n",
      "Epoch:  80 Step:    28 /   793 Train loss: 0.02836683\r\n",
      "Epoch:  80 Step:    29 /   793 Train loss: 0.03436820\r\n",
      "Epoch:  80 Step:    30 /   793 Train loss: 0.02217165\r\n",
      "Epoch:  80 Step:    31 /   793 Train loss: 0.03448157\r\n",
      "Epoch:  80 Step:    32 /   793 Train loss: 0.02833863\r\n",
      "Epoch:  80 Step:    33 /   793 Train loss: 0.01689660\r\n",
      "Epoch:  80 Step:    34 /   793 Train loss: 0.02530954\r\n",
      "Epoch:  80 Step:    35 /   793 Train loss: 0.01953136\r\n",
      "Epoch:  80 Step:    36 /   793 Train loss: 0.02675026\r\n",
      "Epoch:  80 Step:    37 /   793 Train loss: 0.01615270\r\n",
      "Epoch:  80 Step:    38 /   793 Train loss: 0.02819164\r\n",
      "Epoch:  80 Step:    39 /   793 Train loss: 0.02704917\r\n",
      "Epoch:  80 Step:    40 /   793 Train loss: 0.02261069\r\n",
      "Epoch:  80 Step:    41 /   793 Train loss: 0.02330026\r\n",
      "Epoch:  80 Step:    42 /   793 Train loss: 0.01832319\r\n",
      "Epoch:  80 Step:    43 /   793 Train loss: 0.02617984\r\n",
      "Epoch:  80 Step:    44 /   793 Train loss: 0.02061133\r\n",
      "Epoch:  80 Step:    45 /   793 Train loss: 0.01448296\r\n",
      "Epoch:  80 Step:    46 /   793 Train loss: 0.01570668\r\n",
      "Epoch:  80 Step:    47 /   793 Train loss: 0.02334033\r\n",
      "Epoch:  80 Step:    48 /   793 Train loss: 0.03637462\r\n",
      "Epoch:  80 Step:    49 /   793 Train loss: 0.02846394\r\n",
      "Epoch:  80 Step:    50 /   793 Train loss: 0.03028329\r\n",
      "Epoch:  80 Step:    51 /   793 Train loss: 0.01929744\r\n",
      "Epoch:  80 Step:    52 /   793 Train loss: 0.01635560\r\n",
      "Epoch:  80 Step:    53 /   793 Train loss: 0.02832582\r\n",
      "Epoch:  80 Step:    54 /   793 Train loss: 0.02661708\r\n",
      "Epoch:  80 Step:    55 /   793 Train loss: 0.01962397\r\n",
      "Epoch:  80 Step:    56 /   793 Train loss: 0.03153250\r\n",
      "Epoch:  80 Step:    57 /   793 Train loss: 0.02011751\r\n",
      "Epoch:  80 Step:    58 /   793 Train loss: 0.01708783\r\n",
      "Epoch:  80 Step:    59 /   793 Train loss: 0.01964159\r\n",
      "Epoch:  80 Step:    60 /   793 Train loss: 0.03335235\r\n",
      "Epoch:  80 Step:    61 /   793 Train loss: 0.02406933\r\n",
      "Epoch:  80 Step:    62 /   793 Train loss: 0.02146160\r\n",
      "Epoch:  80 Step:    63 /   793 Train loss: 0.01153026\r\n",
      "Epoch:  80 Step:    64 /   793 Train loss: 0.03418522\r\n",
      "Epoch:  80 Step:    65 /   793 Train loss: 0.01458177\r\n",
      "Epoch:  80 Step:    66 /   793 Train loss: 0.02591391\r\n",
      "Epoch:  80 Step:    67 /   793 Train loss: 0.03568796\r\n",
      "Epoch:  80 Step:    68 /   793 Train loss: 0.01545780\r\n",
      "Epoch:  80 Step:    69 /   793 Train loss: 0.02481159\r\n",
      "Epoch:  80 Step:    70 /   793 Train loss: 0.01298111\r\n",
      "Epoch:  80 Step:    71 /   793 Train loss: 0.01861618\r\n",
      "Epoch:  80 Step:    72 /   793 Train loss: 0.03013717\r\n",
      "Epoch:  80 Step:    73 /   793 Train loss: 0.03030253\r\n",
      "Epoch:  80 Step:    74 /   793 Train loss: 0.03586208\r\n",
      "Epoch:  80 Step:    75 /   793 Train loss: 0.01874086\r\n",
      "Epoch:  80 Step:    76 /   793 Train loss: 0.02044772\r\n",
      "Epoch:  80 Step:    77 /   793 Train loss: 0.02632277\r\n",
      "Epoch:  80 Step:    78 /   793 Train loss: 0.02485135\r\n",
      "Epoch:  80 Step:    79 /   793 Train loss: 0.02014081\r\n",
      "Epoch:  80 Step:    80 /   793 Train loss: 0.03135808\r\n",
      "Epoch:  80 Step:    81 /   793 Train loss: 0.02415246\r\n",
      "Epoch:  80 Step:    82 /   793 Train loss: 0.01259970\r\n",
      "Epoch:  80 Step:    83 /   793 Train loss: 0.03716246\r\n",
      "Epoch:  80 Step:    84 /   793 Train loss: 0.02302098\r\n",
      "Epoch:  80 Step:    85 /   793 Train loss: 0.02261681\r\n",
      "Epoch:  80 Step:    86 /   793 Train loss: 0.01409721\r\n",
      "Epoch:  80 Step:    87 /   793 Train loss: 0.03289456\r\n",
      "Epoch:  80 Step:    88 /   793 Train loss: 0.02083194\r\n",
      "Epoch:  80 Step:    89 /   793 Train loss: 0.02674924\r\n",
      "Epoch:  80 Step:    90 /   793 Train loss: 0.02246167\r\n",
      "Epoch:  80 Step:    91 /   793 Train loss: 0.02510381\r\n",
      "Epoch:  80 Step:    92 /   793 Train loss: 0.01633153\r\n",
      "Epoch:  80 Step:    93 /   793 Train loss: 0.01770717\r\n",
      "Epoch:  80 Step:    94 /   793 Train loss: 0.02381953\r\n",
      "Epoch:  80 Step:    95 /   793 Train loss: 0.03087148\r\n",
      "Epoch:  80 Step:    96 /   793 Train loss: 0.02797464\r\n",
      "Epoch:  80 Step:    97 /   793 Train loss: 0.02165462\r\n",
      "Epoch:  80 Step:    98 /   793 Train loss: 0.03061904\r\n",
      "Epoch:  80 Step:    99 /   793 Train loss: 0.02934489\r\n",
      "Epoch:  80 Step:   100 /   793 Train loss: 0.01890760\r\n",
      "Epoch:  80 Step:   101 /   793 Train loss: 0.02353978\r\n",
      "Epoch:  80 Step:   102 /   793 Train loss: 0.02444510\r\n",
      "Epoch:  80 Step:   103 /   793 Train loss: 0.02513272\r\n",
      "Epoch:  80 Step:   104 /   793 Train loss: 0.01222302\r\n",
      "Epoch:  80 Step:   105 /   793 Train loss: 0.01755720\r\n",
      "Epoch:  80 Step:   106 /   793 Train loss: 0.01659160\r\n",
      "Epoch:  80 Step:   107 /   793 Train loss: 0.01504730\r\n",
      "Epoch:  80 Step:   108 /   793 Train loss: 0.03264458\r\n",
      "Epoch:  80 Step:   109 /   793 Train loss: 0.02247664\r\n",
      "Epoch:  80 Step:   110 /   793 Train loss: 0.02485398\r\n",
      "Epoch:  80 Step:   111 /   793 Train loss: 0.04055045\r\n",
      "Epoch:  80 Step:   112 /   793 Train loss: 0.03495649\r\n",
      "Epoch:  80 Step:   113 /   793 Train loss: 0.03109797\r\n",
      "Epoch:  80 Step:   114 /   793 Train loss: 0.03208041\r\n",
      "Epoch:  80 Step:   115 /   793 Train loss: 0.01914346\r\n",
      "Epoch:  80 Step:   116 /   793 Train loss: 0.01837209\r\n",
      "Epoch:  80 Step:   117 /   793 Train loss: 0.02019778\r\n",
      "Epoch:  80 Step:   118 /   793 Train loss: 0.01884582\r\n",
      "Epoch:  80 Step:   119 /   793 Train loss: 0.02291512\r\n",
      "Epoch:  80 Step:   120 /   793 Train loss: 0.03914440\r\n",
      "Epoch:  80 Step:   121 /   793 Train loss: 0.01228842\r\n",
      "Epoch:  80 Step:   122 /   793 Train loss: 0.02609826\r\n",
      "Epoch:  80 Step:   123 /   793 Train loss: 0.01867318\r\n",
      "Epoch:  80 Step:   124 /   793 Train loss: 0.03071445\r\n",
      "Epoch:  80 Step:   125 /   793 Train loss: 0.01667057\r\n",
      "Epoch:  80 Step:   126 /   793 Train loss: 0.02330729\r\n",
      "Epoch:  80 Step:   127 /   793 Train loss: 0.02086758\r\n",
      "Epoch:  80 Step:   128 /   793 Train loss: 0.02671671\r\n",
      "Epoch:  80 Step:   129 /   793 Train loss: 0.02500716\r\n",
      "Epoch:  80 Step:   130 /   793 Train loss: 0.01492548\r\n",
      "Epoch:  80 Step:   131 /   793 Train loss: 0.02723325\r\n",
      "Epoch:  80 Step:   132 /   793 Train loss: 0.02801240\r\n",
      "Epoch:  80 Step:   133 /   793 Train loss: 0.04364599\r\n",
      "Epoch:  80 Step:   134 /   793 Train loss: 0.01595205\r\n",
      "Epoch:  80 Step:   135 /   793 Train loss: 0.02419438\r\n",
      "Epoch:  80 Step:   136 /   793 Train loss: 0.03514980\r\n",
      "Epoch:  80 Step:   137 /   793 Train loss: 0.02411617\r\n",
      "Epoch:  80 Step:   138 /   793 Train loss: 0.01953064\r\n",
      "Epoch:  80 Step:   139 /   793 Train loss: 0.02702510\r\n",
      "Epoch:  80 Step:   140 /   793 Train loss: 0.02997017\r\n",
      "Epoch:  80 Step:   141 /   793 Train loss: 0.02188751\r\n",
      "Epoch:  80 Step:   142 /   793 Train loss: 0.01512849\r\n",
      "Epoch:  80 Step:   143 /   793 Train loss: 0.02225514\r\n",
      "Epoch:  80 Step:   144 /   793 Train loss: 0.01276273\r\n",
      "Epoch:  80 Step:   145 /   793 Train loss: 0.01291905\r\n",
      "Epoch:  80 Step:   146 /   793 Train loss: 0.02993998\r\n",
      "Epoch:  80 Step:   147 /   793 Train loss: 0.02487073\r\n",
      "Epoch:  80 Step:   148 /   793 Train loss: 0.01223953\r\n",
      "Epoch:  80 Step:   149 /   793 Train loss: 0.04191242\r\n",
      "Epoch:  80 Step:   150 /   793 Train loss: 0.02293842\r\n",
      "Epoch:  80 Step:   151 /   793 Train loss: 0.02102989\r\n",
      "Epoch:  80 Step:   152 /   793 Train loss: 0.02340282\r\n",
      "Epoch:  80 Step:   153 /   793 Train loss: 0.03914097\r\n",
      "Epoch:  80 Step:   154 /   793 Train loss: 0.03435622\r\n",
      "Epoch:  80 Step:   155 /   793 Train loss: 0.02523619\r\n",
      "Epoch:  80 Step:   156 /   793 Train loss: 0.01958448\r\n",
      "Epoch:  80 Step:   157 /   793 Train loss: 0.03371360\r\n",
      "Epoch:  80 Step:   158 /   793 Train loss: 0.03139992\r\n",
      "Epoch:  80 Step:   159 /   793 Train loss: 0.02616282\r\n",
      "Epoch:  80 Step:   160 /   793 Train loss: 0.02018892\r\n",
      "Epoch:  80 Step:   161 /   793 Train loss: 0.01284504\r\n",
      "Epoch:  80 Step:   162 /   793 Train loss: 0.02813024\r\n",
      "Epoch:  80 Step:   163 /   793 Train loss: 0.02136686\r\n",
      "Epoch:  80 Step:   164 /   793 Train loss: 0.02299084\r\n",
      "Epoch:  80 Step:   165 /   793 Train loss: 0.02990520\r\n",
      "Epoch:  80 Step:   166 /   793 Train loss: 0.01775790\r\n",
      "Epoch:  80 Step:   167 /   793 Train loss: 0.01223927\r\n",
      "Epoch:  80 Step:   168 /   793 Train loss: 0.01863623\r\n",
      "Epoch:  80 Step:   169 /   793 Train loss: 0.01866588\r\n",
      "Epoch:  80 Step:   170 /   793 Train loss: 0.02219607\r\n",
      "Epoch:  80 Step:   171 /   793 Train loss: 0.03203510\r\n",
      "Epoch:  80 Step:   172 /   793 Train loss: 0.02050838\r\n",
      "Epoch:  80 Step:   173 /   793 Train loss: 0.02885675\r\n",
      "Epoch:  80 Step:   174 /   793 Train loss: 0.02451012\r\n",
      "Epoch:  80 Step:   175 /   793 Train loss: 0.01902725\r\n",
      "Epoch:  80 Step:   176 /   793 Train loss: 0.02808120\r\n",
      "Epoch:  80 Step:   177 /   793 Train loss: 0.02689993\r\n",
      "Epoch:  80 Step:   178 /   793 Train loss: 0.02259677\r\n",
      "Epoch:  80 Step:   179 /   793 Train loss: 0.02390925\r\n",
      "Epoch:  80 Step:   180 /   793 Train loss: 0.02849441\r\n",
      "Epoch:  80 Step:   181 /   793 Train loss: 0.03032413\r\n",
      "Epoch:  80 Step:   182 /   793 Train loss: 0.02824945\r\n",
      "Epoch:  80 Step:   183 /   793 Train loss: 0.03693575\r\n",
      "Epoch:  80 Step:   184 /   793 Train loss: 0.03444847\r\n",
      "Epoch:  80 Step:   185 /   793 Train loss: 0.01710819\r\n",
      "Epoch:  80 Step:   186 /   793 Train loss: 0.02503856\r\n",
      "Epoch:  80 Step:   187 /   793 Train loss: 0.02457188\r\n",
      "Epoch:  80 Step:   188 /   793 Train loss: 0.02493100\r\n",
      "Epoch:  80 Step:   189 /   793 Train loss: 0.02289219\r\n",
      "Epoch:  80 Step:   190 /   793 Train loss: 0.01222569\r\n",
      "Epoch:  80 Step:   191 /   793 Train loss: 0.01827758\r\n",
      "Epoch:  80 Step:   192 /   793 Train loss: 0.02959910\r\n",
      "Epoch:  80 Step:   193 /   793 Train loss: 0.01786636\r\n",
      "Epoch:  80 Step:   194 /   793 Train loss: 0.02269750\r\n",
      "Epoch:  80 Step:   195 /   793 Train loss: 0.02438794\r\n",
      "Epoch:  80 Step:   196 /   793 Train loss: 0.02292009\r\n",
      "Epoch:  80 Step:   197 /   793 Train loss: 0.02154032\r\n",
      "Epoch:  80 Step:   198 /   793 Train loss: 0.02685068\r\n",
      "Epoch:  80 Step:   199 /   793 Train loss: 0.02947400\r\n",
      "Epoch:  80 Step:   200 /   793 Train loss: 0.01937270\r\n",
      "Epoch:  80 Step:   201 /   793 Train loss: 0.02030393\r\n",
      "Epoch:  80 Step:   202 /   793 Train loss: 0.02392345\r\n",
      "Epoch:  80 Step:   203 /   793 Train loss: 0.01645350\r\n",
      "Epoch:  80 Step:   204 /   793 Train loss: 0.02612675\r\n",
      "Epoch:  80 Step:   205 /   793 Train loss: 0.04074892\r\n",
      "Epoch:  80 Step:   206 /   793 Train loss: 0.02377066\r\n",
      "Epoch:  80 Step:   207 /   793 Train loss: 0.01320594\r\n",
      "Epoch:  80 Step:   208 /   793 Train loss: 0.01364838\r\n",
      "Epoch:  80 Step:   209 /   793 Train loss: 0.02730042\r\n",
      "Epoch:  80 Step:   210 /   793 Train loss: 0.03332019\r\n",
      "Epoch:  80 Step:   211 /   793 Train loss: 0.03394607\r\n",
      "Epoch:  80 Step:   212 /   793 Train loss: 0.02974916\r\n",
      "Epoch:  80 Step:   213 /   793 Train loss: 0.02756944\r\n",
      "Epoch:  80 Step:   214 /   793 Train loss: 0.03332201\r\n",
      "Epoch:  80 Step:   215 /   793 Train loss: 0.02975882\r\n",
      "Epoch:  80 Step:   216 /   793 Train loss: 0.02826414\r\n",
      "Epoch:  80 Step:   217 /   793 Train loss: 0.02495500\r\n",
      "Epoch:  80 Step:   218 /   793 Train loss: 0.02986046\r\n",
      "Epoch:  80 Step:   219 /   793 Train loss: 0.02010986\r\n",
      "Epoch:  80 Step:   220 /   793 Train loss: 0.02235886\r\n",
      "Epoch:  80 Step:   221 /   793 Train loss: 0.02766235\r\n",
      "Epoch:  80 Step:   222 /   793 Train loss: 0.03240750\r\n",
      "Epoch:  80 Step:   223 /   793 Train loss: 0.02525718\r\n",
      "Epoch:  80 Step:   224 /   793 Train loss: 0.03416618\r\n",
      "Epoch:  80 Step:   225 /   793 Train loss: 0.02636885\r\n",
      "Epoch:  80 Step:   226 /   793 Train loss: 0.02606555\r\n",
      "Epoch:  80 Step:   227 /   793 Train loss: 0.04074186\r\n",
      "Epoch:  80 Step:   228 /   793 Train loss: 0.02708379\r\n",
      "Epoch:  80 Step:   229 /   793 Train loss: 0.02461702\r\n",
      "Epoch:  80 Step:   230 /   793 Train loss: 0.02634946\r\n",
      "Epoch:  80 Step:   231 /   793 Train loss: 0.02484044\r\n",
      "Epoch:  80 Step:   232 /   793 Train loss: 0.01446917\r\n",
      "Epoch:  80 Step:   233 /   793 Train loss: 0.04132051\r\n",
      "Epoch:  80 Step:   234 /   793 Train loss: 0.02723598\r\n",
      "Epoch:  80 Step:   235 /   793 Train loss: 0.02236565\r\n",
      "Epoch:  80 Step:   236 /   793 Train loss: 0.02631742\r\n",
      "Epoch:  80 Step:   237 /   793 Train loss: 0.02305169\r\n",
      "Epoch:  80 Step:   238 /   793 Train loss: 0.03033398\r\n",
      "Epoch:  80 Step:   239 /   793 Train loss: 0.01958769\r\n",
      "Epoch:  80 Step:   240 /   793 Train loss: 0.02208003\r\n",
      "Epoch:  80 Step:   241 /   793 Train loss: 0.03430411\r\n",
      "Epoch:  80 Step:   242 /   793 Train loss: 0.02297975\r\n",
      "Epoch:  80 Step:   243 /   793 Train loss: 0.02987829\r\n",
      "Epoch:  80 Step:   244 /   793 Train loss: 0.03242527\r\n",
      "Epoch:  80 Step:   245 /   793 Train loss: 0.03579432\r\n",
      "Epoch:  80 Step:   246 /   793 Train loss: 0.02480144\r\n",
      "Epoch:  80 Step:   247 /   793 Train loss: 0.03282322\r\n",
      "Epoch:  80 Step:   248 /   793 Train loss: 0.02435600\r\n",
      "Epoch:  80 Step:   249 /   793 Train loss: 0.01578521\r\n",
      "Epoch:  80 Step:   250 /   793 Train loss: 0.01941027\r\n",
      "Epoch:  80 Step:   251 /   793 Train loss: 0.02661336\r\n",
      "Epoch:  80 Step:   252 /   793 Train loss: 0.01992481\r\n",
      "Epoch:  80 Step:   253 /   793 Train loss: 0.03554809\r\n",
      "Epoch:  80 Step:   254 /   793 Train loss: 0.02582458\r\n",
      "Epoch:  80 Step:   255 /   793 Train loss: 0.01482926\r\n",
      "Epoch:  80 Step:   256 /   793 Train loss: 0.02392814\r\n",
      "Epoch:  80 Step:   257 /   793 Train loss: 0.02544012\r\n",
      "Epoch:  80 Step:   258 /   793 Train loss: 0.01378344\r\n",
      "Epoch:  80 Step:   259 /   793 Train loss: 0.03406229\r\n",
      "Epoch:  80 Step:   260 /   793 Train loss: 0.04215201\r\n",
      "Epoch:  80 Step:   261 /   793 Train loss: 0.03081626\r\n",
      "Epoch:  80 Step:   262 /   793 Train loss: 0.02091271\r\n",
      "Epoch:  80 Step:   263 /   793 Train loss: 0.03346530\r\n",
      "Epoch:  80 Step:   264 /   793 Train loss: 0.01152383\r\n",
      "Epoch:  80 Step:   265 /   793 Train loss: 0.03486655\r\n",
      "Epoch:  80 Step:   266 /   793 Train loss: 0.02321568\r\n",
      "Epoch:  80 Step:   267 /   793 Train loss: 0.03856188\r\n",
      "Epoch:  80 Step:   268 /   793 Train loss: 0.01992458\r\n",
      "Epoch:  80 Step:   269 /   793 Train loss: 0.03769691\r\n",
      "Epoch:  80 Step:   270 /   793 Train loss: 0.01635124\r\n",
      "Epoch:  80 Step:   271 /   793 Train loss: 0.02144320\r\n",
      "Epoch:  80 Step:   272 /   793 Train loss: 0.01748015\r\n",
      "Epoch:  80 Step:   273 /   793 Train loss: 0.01736543\r\n",
      "Epoch:  80 Step:   274 /   793 Train loss: 0.02072758\r\n",
      "Epoch:  80 Step:   275 /   793 Train loss: 0.02339809\r\n",
      "Epoch:  80 Step:   276 /   793 Train loss: 0.02009043\r\n",
      "Epoch:  80 Step:   277 /   793 Train loss: 0.02094485\r\n",
      "Epoch:  80 Step:   278 /   793 Train loss: 0.01618245\r\n",
      "Epoch:  80 Step:   279 /   793 Train loss: 0.01570468\r\n",
      "Epoch:  80 Step:   280 /   793 Train loss: 0.04523188\r\n",
      "Epoch:  80 Step:   281 /   793 Train loss: 0.02051179\r\n",
      "Epoch:  80 Step:   282 /   793 Train loss: 0.03099584\r\n",
      "Epoch:  80 Step:   283 /   793 Train loss: 0.01626140\r\n",
      "Epoch:  80 Step:   284 /   793 Train loss: 0.03466196\r\n",
      "Epoch:  80 Step:   285 /   793 Train loss: 0.03258549\r\n",
      "Epoch:  80 Step:   286 /   793 Train loss: 0.02575322\r\n",
      "Epoch:  80 Step:   287 /   793 Train loss: 0.02422919\r\n",
      "Epoch:  80 Step:   288 /   793 Train loss: 0.03237817\r\n",
      "Epoch:  80 Step:   289 /   793 Train loss: 0.02750933\r\n",
      "Epoch:  80 Step:   290 /   793 Train loss: 0.01863659\r\n",
      "Epoch:  80 Step:   291 /   793 Train loss: 0.04067965\r\n",
      "Epoch:  80 Step:   292 /   793 Train loss: 0.02206637\r\n",
      "Epoch:  80 Step:   293 /   793 Train loss: 0.02668367\r\n",
      "Epoch:  80 Step:   294 /   793 Train loss: 0.01358934\r\n",
      "Epoch:  80 Step:   295 /   793 Train loss: 0.02904660\r\n",
      "Epoch:  80 Step:   296 /   793 Train loss: 0.01879748\r\n",
      "Epoch:  80 Step:   297 /   793 Train loss: 0.02851915\r\n",
      "Epoch:  80 Step:   298 /   793 Train loss: 0.02503762\r\n",
      "Epoch:  80 Step:   299 /   793 Train loss: 0.03021040\r\n",
      "Epoch:  80 Step:   300 /   793 Train loss: 0.03812543\r\n",
      "Epoch:  80 Step:   301 /   793 Train loss: 0.02221033\r\n",
      "Epoch:  80 Step:   302 /   793 Train loss: 0.01733609\r\n",
      "Epoch:  80 Step:   303 /   793 Train loss: 0.02946560\r\n",
      "Epoch:  80 Step:   304 /   793 Train loss: 0.01414884\r\n",
      "Epoch:  80 Step:   305 /   793 Train loss: 0.01616002\r\n",
      "Epoch:  80 Step:   306 /   793 Train loss: 0.02572832\r\n",
      "Epoch:  80 Step:   307 /   793 Train loss: 0.03007966\r\n",
      "Epoch:  80 Step:   308 /   793 Train loss: 0.01913464\r\n",
      "Epoch:  80 Step:   309 /   793 Train loss: 0.01468376\r\n",
      "Epoch:  80 Step:   310 /   793 Train loss: 0.02402244\r\n",
      "Epoch:  80 Step:   311 /   793 Train loss: 0.02135700\r\n",
      "Epoch:  80 Step:   312 /   793 Train loss: 0.02613338\r\n",
      "Epoch:  80 Step:   313 /   793 Train loss: 0.02584441\r\n",
      "Epoch:  80 Step:   314 /   793 Train loss: 0.01470825\r\n",
      "Epoch:  80 Step:   315 /   793 Train loss: 0.03448886\r\n",
      "Epoch:  80 Step:   316 /   793 Train loss: 0.01824741\r\n",
      "Epoch:  80 Step:   317 /   793 Train loss: 0.02686203\r\n",
      "Epoch:  80 Step:   318 /   793 Train loss: 0.02097655\r\n",
      "Epoch:  80 Step:   319 /   793 Train loss: 0.02011860\r\n",
      "Epoch:  80 Step:   320 /   793 Train loss: 0.01756437\r\n",
      "Epoch:  80 Step:   321 /   793 Train loss: 0.01957908\r\n",
      "Epoch:  80 Step:   322 /   793 Train loss: 0.03496034\r\n",
      "Epoch:  80 Step:   323 /   793 Train loss: 0.02682142\r\n",
      "Epoch:  80 Step:   324 /   793 Train loss: 0.02448914\r\n",
      "Epoch:  80 Step:   325 /   793 Train loss: 0.02543234\r\n",
      "Epoch:  80 Step:   326 /   793 Train loss: 0.01243265\r\n",
      "Epoch:  80 Step:   327 /   793 Train loss: 0.03092798\r\n",
      "Epoch:  80 Step:   328 /   793 Train loss: 0.01864994\r\n",
      "Epoch:  80 Step:   329 /   793 Train loss: 0.01845203\r\n",
      "Epoch:  80 Step:   330 /   793 Train loss: 0.03887700\r\n",
      "Epoch:  80 Step:   331 /   793 Train loss: 0.02873401\r\n",
      "Epoch:  80 Step:   332 /   793 Train loss: 0.01778826\r\n",
      "Epoch:  80 Step:   333 /   793 Train loss: 0.03148698\r\n",
      "Epoch:  80 Step:   334 /   793 Train loss: 0.02891113\r\n",
      "Epoch:  80 Step:   335 /   793 Train loss: 0.02282067\r\n",
      "Epoch:  80 Step:   336 /   793 Train loss: 0.01548543\r\n",
      "Epoch:  80 Step:   337 /   793 Train loss: 0.02623428\r\n",
      "Epoch:  80 Step:   338 /   793 Train loss: 0.02155450\r\n",
      "Epoch:  80 Step:   339 /   793 Train loss: 0.01261951\r\n",
      "Epoch:  80 Step:   340 /   793 Train loss: 0.02958711\r\n",
      "Epoch:  80 Step:   341 /   793 Train loss: 0.03908914\r\n",
      "Epoch:  80 Step:   342 /   793 Train loss: 0.02691380\r\n",
      "Epoch:  80 Step:   343 /   793 Train loss: 0.01503550\r\n",
      "Epoch:  80 Step:   344 /   793 Train loss: 0.02799522\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  80 Step:   345 /   793 Train loss: 0.02499198\r\n",
      "Epoch:  80 Step:   346 /   793 Train loss: 0.02016100\r\n",
      "Epoch:  80 Step:   347 /   793 Train loss: 0.01551838\r\n",
      "Epoch:  80 Step:   348 /   793 Train loss: 0.02682088\r\n",
      "Epoch:  80 Step:   349 /   793 Train loss: 0.02465245\r\n",
      "Epoch:  80 Step:   350 /   793 Train loss: 0.02952445\r\n",
      "Epoch:  80 Step:   351 /   793 Train loss: 0.02480112\r\n",
      "Epoch:  80 Step:   352 /   793 Train loss: 0.02321917\r\n",
      "Epoch:  80 Step:   353 /   793 Train loss: 0.02954034\r\n",
      "Epoch:  80 Step:   354 /   793 Train loss: 0.02761431\r\n",
      "Epoch:  80 Step:   355 /   793 Train loss: 0.01773278\r\n",
      "Epoch:  80 Step:   356 /   793 Train loss: 0.02158562\r\n",
      "Epoch:  80 Step:   357 /   793 Train loss: 0.01718840\r\n",
      "Epoch:  80 Step:   358 /   793 Train loss: 0.02877649\r\n",
      "Epoch:  80 Step:   359 /   793 Train loss: 0.01803800\r\n",
      "Epoch:  80 Step:   360 /   793 Train loss: 0.02225351\r\n",
      "Epoch:  80 Step:   361 /   793 Train loss: 0.01346031\r\n",
      "Epoch:  80 Step:   362 /   793 Train loss: 0.03358967\r\n",
      "Epoch:  80 Step:   363 /   793 Train loss: 0.02947295\r\n",
      "Epoch:  80 Step:   364 /   793 Train loss: 0.03669421\r\n",
      "Epoch:  80 Step:   365 /   793 Train loss: 0.02275456\r\n",
      "Epoch:  80 Step:   366 /   793 Train loss: 0.02957096\r\n",
      "Epoch:  80 Step:   367 /   793 Train loss: 0.02631439\r\n",
      "Epoch:  80 Step:   368 /   793 Train loss: 0.03440980\r\n",
      "Epoch:  80 Step:   369 /   793 Train loss: 0.02238906\r\n",
      "Epoch:  80 Step:   370 /   793 Train loss: 0.03425221\r\n",
      "Epoch:  80 Step:   371 /   793 Train loss: 0.02489874\r\n",
      "Epoch:  80 Step:   372 /   793 Train loss: 0.01988524\r\n",
      "Epoch:  80 Step:   373 /   793 Train loss: 0.02340249\r\n",
      "Epoch:  80 Step:   374 /   793 Train loss: 0.02315243\r\n",
      "Epoch:  80 Step:   375 /   793 Train loss: 0.00983823\r\n",
      "Epoch:  80 Step:   376 /   793 Train loss: 0.03054822\r\n",
      "Epoch:  80 Step:   377 /   793 Train loss: 0.02720549\r\n",
      "Epoch:  80 Step:   378 /   793 Train loss: 0.02763625\r\n",
      "Epoch:  80 Step:   379 /   793 Train loss: 0.02004976\r\n",
      "Epoch:  80 Step:   380 /   793 Train loss: 0.02506772\r\n",
      "Epoch:  80 Step:   381 /   793 Train loss: 0.02321922\r\n",
      "Epoch:  80 Step:   382 /   793 Train loss: 0.02473557\r\n",
      "Epoch:  80 Step:   383 /   793 Train loss: 0.02637075\r\n",
      "Epoch:  80 Step:   384 /   793 Train loss: 0.02206160\r\n",
      "Epoch:  80 Step:   385 /   793 Train loss: 0.02451527\r\n",
      "Epoch:  80 Step:   386 /   793 Train loss: 0.02447514\r\n",
      "Epoch:  80 Step:   387 /   793 Train loss: 0.03404615\r\n",
      "Epoch:  80 Step:   388 /   793 Train loss: 0.01596359\r\n",
      "Epoch:  80 Step:   389 /   793 Train loss: 0.02792107\r\n",
      "Epoch:  80 Step:   390 /   793 Train loss: 0.02407997\r\n",
      "Epoch:  80 Step:   391 /   793 Train loss: 0.02984192\r\n",
      "Epoch:  80 Step:   392 /   793 Train loss: 0.03202102\r\n",
      "Epoch:  80 Step:   393 /   793 Train loss: 0.01629453\r\n",
      "Epoch:  80 Step:   394 /   793 Train loss: 0.01585549\r\n",
      "Epoch:  80 Step:   395 /   793 Train loss: 0.02272548\r\n",
      "Epoch:  80 Step:   396 /   793 Train loss: 0.03649947\r\n",
      "Epoch:  80 Step:   397 /   793 Train loss: 0.01527673\r\n",
      "Epoch:  80 Step:   398 /   793 Train loss: 0.01614587\r\n",
      "Epoch:  80 Step:   399 /   793 Train loss: 0.02054404\r\n",
      "Epoch:  80 Step:   400 /   793 Train loss: 0.02802094\r\n",
      "Epoch:  80 Step:   401 /   793 Train loss: 0.03198569\r\n",
      "Epoch:  80 Step:   402 /   793 Train loss: 0.01271774\r\n",
      "Epoch:  80 Step:   403 /   793 Train loss: 0.00886954\r\n",
      "Epoch:  80 Step:   404 /   793 Train loss: 0.01789079\r\n",
      "Epoch:  80 Step:   405 /   793 Train loss: 0.03053570\r\n",
      "Epoch:  80 Step:   406 /   793 Train loss: 0.01736416\r\n",
      "Epoch:  80 Step:   407 /   793 Train loss: 0.02955295\r\n",
      "Epoch:  80 Step:   408 /   793 Train loss: 0.02252897\r\n",
      "Epoch:  80 Step:   409 /   793 Train loss: 0.02576385\r\n",
      "Epoch:  80 Step:   410 /   793 Train loss: 0.02698836\r\n",
      "Epoch:  80 Step:   411 /   793 Train loss: 0.02262849\r\n",
      "Epoch:  80 Step:   412 /   793 Train loss: 0.01506779\r\n",
      "Epoch:  80 Step:   413 /   793 Train loss: 0.02774659\r\n",
      "Epoch:  80 Step:   414 /   793 Train loss: 0.01719762\r\n",
      "Epoch:  80 Step:   415 /   793 Train loss: 0.01360884\r\n",
      "Epoch:  80 Step:   416 /   793 Train loss: 0.01795468\r\n",
      "Epoch:  80 Step:   417 /   793 Train loss: 0.03113348\r\n",
      "Epoch:  80 Step:   418 /   793 Train loss: 0.01809772\r\n",
      "Epoch:  80 Step:   419 /   793 Train loss: 0.02912095\r\n",
      "Epoch:  80 Step:   420 /   793 Train loss: 0.01883018\r\n",
      "Epoch:  80 Step:   421 /   793 Train loss: 0.03736453\r\n",
      "Epoch:  80 Step:   422 /   793 Train loss: 0.01488461\r\n",
      "Epoch:  80 Step:   423 /   793 Train loss: 0.03643986\r\n",
      "Epoch:  80 Step:   424 /   793 Train loss: 0.01192453\r\n",
      "Epoch:  80 Step:   425 /   793 Train loss: 0.01477187\r\n",
      "Epoch:  80 Step:   426 /   793 Train loss: 0.01868983\r\n",
      "Epoch:  80 Step:   427 /   793 Train loss: 0.01944573\r\n",
      "Epoch:  80 Step:   428 /   793 Train loss: 0.02369924\r\n",
      "Epoch:  80 Step:   429 /   793 Train loss: 0.02920389\r\n",
      "Epoch:  80 Step:   430 /   793 Train loss: 0.02673627\r\n",
      "Epoch:  80 Step:   431 /   793 Train loss: 0.01634314\r\n",
      "Epoch:  80 Step:   432 /   793 Train loss: 0.01795960\r\n",
      "Epoch:  80 Step:   433 /   793 Train loss: 0.01907576\r\n",
      "Epoch:  80 Step:   434 /   793 Train loss: 0.03758337\r\n",
      "Epoch:  80 Step:   435 /   793 Train loss: 0.01305533\r\n",
      "Epoch:  80 Step:   436 /   793 Train loss: 0.01619659\r\n",
      "Epoch:  80 Step:   437 /   793 Train loss: 0.02146244\r\n",
      "Epoch:  80 Step:   438 /   793 Train loss: 0.03434637\r\n",
      "Epoch:  80 Step:   439 /   793 Train loss: 0.03190351\r\n",
      "Epoch:  80 Step:   440 /   793 Train loss: 0.02040548\r\n",
      "Epoch:  80 Step:   441 /   793 Train loss: 0.03467867\r\n",
      "Epoch:  80 Step:   442 /   793 Train loss: 0.01256298\r\n",
      "Epoch:  80 Step:   443 /   793 Train loss: 0.01796717\r\n",
      "Epoch:  80 Step:   444 /   793 Train loss: 0.01829576\r\n",
      "Epoch:  80 Step:   445 /   793 Train loss: 0.01305202\r\n",
      "Epoch:  80 Step:   446 /   793 Train loss: 0.01469790\r\n",
      "Epoch:  80 Step:   447 /   793 Train loss: 0.02745008\r\n",
      "Epoch:  80 Step:   448 /   793 Train loss: 0.02822745\r\n",
      "Epoch:  80 Step:   449 /   793 Train loss: 0.02474928\r\n",
      "Epoch:  80 Step:   450 /   793 Train loss: 0.02042164\r\n",
      "Epoch:  80 Step:   451 /   793 Train loss: 0.02120648\r\n",
      "Epoch:  80 Step:   452 /   793 Train loss: 0.01527841\r\n",
      "Epoch:  80 Step:   453 /   793 Train loss: 0.01786179\r\n",
      "Epoch:  80 Step:   454 /   793 Train loss: 0.02858702\r\n",
      "Epoch:  80 Step:   455 /   793 Train loss: 0.03001703\r\n",
      "Epoch:  80 Step:   456 /   793 Train loss: 0.02899720\r\n",
      "Epoch:  80 Step:   457 /   793 Train loss: 0.02263470\r\n",
      "Epoch:  80 Step:   458 /   793 Train loss: 0.02093432\r\n",
      "Epoch:  80 Step:   459 /   793 Train loss: 0.01799166\r\n",
      "Epoch:  80 Step:   460 /   793 Train loss: 0.02486984\r\n",
      "Epoch:  80 Step:   461 /   793 Train loss: 0.02218197\r\n",
      "Epoch:  80 Step:   462 /   793 Train loss: 0.02475532\r\n",
      "Epoch:  80 Step:   463 /   793 Train loss: 0.03094941\r\n",
      "Epoch:  80 Step:   464 /   793 Train loss: 0.03536666\r\n",
      "Epoch:  80 Step:   465 /   793 Train loss: 0.03079447\r\n",
      "Epoch:  80 Step:   466 /   793 Train loss: 0.01947546\r\n",
      "Epoch:  80 Step:   467 /   793 Train loss: 0.01868210\r\n",
      "Epoch:  80 Step:   468 /   793 Train loss: 0.01496010\r\n",
      "Epoch:  80 Step:   469 /   793 Train loss: 0.02922599\r\n",
      "Epoch:  80 Step:   470 /   793 Train loss: 0.02203432\r\n",
      "Epoch:  80 Step:   471 /   793 Train loss: 0.02305582\r\n",
      "Epoch:  80 Step:   472 /   793 Train loss: 0.01908050\r\n",
      "Epoch:  80 Step:   473 /   793 Train loss: 0.02310463\r\n",
      "Epoch:  80 Step:   474 /   793 Train loss: 0.02561936\r\n",
      "Epoch:  80 Step:   475 /   793 Train loss: 0.02494122\r\n",
      "Epoch:  80 Step:   476 /   793 Train loss: 0.02585136\r\n",
      "Epoch:  80 Step:   477 /   793 Train loss: 0.02690501\r\n",
      "Epoch:  80 Step:   478 /   793 Train loss: 0.01921005\r\n",
      "Epoch:  80 Step:   479 /   793 Train loss: 0.03775853\r\n",
      "Epoch:  80 Step:   480 /   793 Train loss: 0.02973195\r\n",
      "Epoch:  80 Step:   481 /   793 Train loss: 0.02354008\r\n",
      "Epoch:  80 Step:   482 /   793 Train loss: 0.01366074\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  80 Step:   483 /   793 Train loss: 0.03117839\r\n",
      "Epoch:  80 Step:   484 /   793 Train loss: 0.02693246\r\n",
      "Epoch:  80 Step:   485 /   793 Train loss: 0.02093109\r\n",
      "Epoch:  80 Step:   486 /   793 Train loss: 0.02222757\r\n",
      "Epoch:  80 Step:   487 /   793 Train loss: 0.04280914\r\n",
      "Epoch:  80 Step:   488 /   793 Train loss: 0.02234852\r\n",
      "Epoch:  80 Step:   489 /   793 Train loss: 0.03280148\r\n",
      "Epoch:  80 Step:   490 /   793 Train loss: 0.03246281\r\n",
      "Epoch:  80 Step:   491 /   793 Train loss: 0.02032303\r\n",
      "Epoch:  80 Step:   492 /   793 Train loss: 0.02929402\r\n",
      "Epoch:  80 Step:   493 /   793 Train loss: 0.01181452\r\n",
      "Epoch:  80 Step:   494 /   793 Train loss: 0.02012200\r\n",
      "Epoch:  80 Step:   495 /   793 Train loss: 0.02425667\r\n",
      "Epoch:  80 Step:   496 /   793 Train loss: 0.02493424\r\n",
      "Epoch:  80 Step:   497 /   793 Train loss: 0.02436423\r\n",
      "Epoch:  80 Step:   498 /   793 Train loss: 0.02873349\r\n",
      "Epoch:  80 Step:   499 /   793 Train loss: 0.01932438\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  80 Step:   500 /   793 Train loss: 0.03994981\r\n",
      "Epoch:  80 Step:   501 /   793 Train loss: 0.02564745\r\n",
      "Epoch:  80 Step:   502 /   793 Train loss: 0.02774443\r\n",
      "Epoch:  80 Step:   503 /   793 Train loss: 0.01463304\r\n",
      "Epoch:  80 Step:   504 /   793 Train loss: 0.02319023\r\n",
      "Epoch:  80 Step:   505 /   793 Train loss: 0.02960212\r\n",
      "Epoch:  80 Step:   506 /   793 Train loss: 0.02526719\r\n",
      "Epoch:  80 Step:   507 /   793 Train loss: 0.02742713\r\n",
      "Epoch:  80 Step:   508 /   793 Train loss: 0.01611445\r\n",
      "Epoch:  80 Step:   509 /   793 Train loss: 0.02127347\r\n",
      "Epoch:  80 Step:   510 /   793 Train loss: 0.01823036\r\n",
      "Epoch:  80 Step:   511 /   793 Train loss: 0.02387961\r\n",
      "Epoch:  80 Step:   512 /   793 Train loss: 0.03196724\r\n",
      "Epoch:  80 Step:   513 /   793 Train loss: 0.02642171\r\n",
      "Epoch:  80 Step:   514 /   793 Train loss: 0.01900222\r\n",
      "Epoch:  80 Step:   515 /   793 Train loss: 0.02171021\r\n",
      "Epoch:  80 Step:   516 /   793 Train loss: 0.02121502\r\n",
      "Epoch:  80 Step:   517 /   793 Train loss: 0.02290973\r\n",
      "Epoch:  80 Step:   518 /   793 Train loss: 0.02086162\r\n",
      "Epoch:  80 Step:   519 /   793 Train loss: 0.01690762\r\n",
      "Epoch:  80 Step:   520 /   793 Train loss: 0.01895482\r\n",
      "Epoch:  80 Step:   521 /   793 Train loss: 0.02999916\r\n",
      "Epoch:  80 Step:   522 /   793 Train loss: 0.02168727\r\n",
      "Epoch:  80 Step:   523 /   793 Train loss: 0.02839564\r\n",
      "Epoch:  80 Step:   524 /   793 Train loss: 0.01172565\r\n",
      "Epoch:  80 Step:   525 /   793 Train loss: 0.02009502\r\n",
      "Epoch:  80 Step:   526 /   793 Train loss: 0.02472161\r\n",
      "Epoch:  80 Step:   527 /   793 Train loss: 0.02396748\r\n",
      "Epoch:  80 Step:   528 /   793 Train loss: 0.03975970\r\n",
      "Epoch:  80 Step:   529 /   793 Train loss: 0.03509977\r\n",
      "Epoch:  80 Step:   530 /   793 Train loss: 0.03089390\r\n",
      "Epoch:  80 Step:   531 /   793 Train loss: 0.01563396\r\n",
      "Epoch:  80 Step:   532 /   793 Train loss: 0.03091243\r\n",
      "Epoch:  80 Step:   533 /   793 Train loss: 0.02008280\r\n",
      "Epoch:  80 Step:   534 /   793 Train loss: 0.02046099\r\n",
      "Epoch:  80 Step:   535 /   793 Train loss: 0.02039986\r\n",
      "Epoch:  80 Step:   536 /   793 Train loss: 0.01475259\r\n",
      "Epoch:  80 Step:   537 /   793 Train loss: 0.02257270\r\n",
      "Epoch:  80 Step:   538 /   793 Train loss: 0.02650620\r\n",
      "Epoch:  80 Step:   539 /   793 Train loss: 0.02258718\r\n",
      "Epoch:  80 Step:   540 /   793 Train loss: 0.02011369\r\n",
      "Epoch:  80 Step:   541 /   793 Train loss: 0.02300053\r\n",
      "Epoch:  80 Step:   542 /   793 Train loss: 0.03544607\r\n",
      "Epoch:  80 Step:   543 /   793 Train loss: 0.02351329\r\n",
      "Epoch:  80 Step:   544 /   793 Train loss: 0.03036387\r\n",
      "Epoch:  80 Step:   545 /   793 Train loss: 0.01903603\r\n",
      "Epoch:  80 Step:   546 /   793 Train loss: 0.02918781\r\n",
      "Epoch:  80 Step:   547 /   793 Train loss: 0.01824807\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  80 Step:   548 /   793 Train loss: 0.02197011\r\n",
      "Epoch:  80 Step:   549 /   793 Train loss: 0.03144125\r\n",
      "Epoch:  80 Step:   550 /   793 Train loss: 0.02040010\r\n",
      "Epoch:  80 Step:   551 /   793 Train loss: 0.03093753\r\n",
      "Epoch:  80 Step:   552 /   793 Train loss: 0.02935691\r\n",
      "Epoch:  80 Step:   553 /   793 Train loss: 0.02076687\r\n",
      "Epoch:  80 Step:   554 /   793 Train loss: 0.01793589\r\n",
      "Epoch:  80 Step:   555 /   793 Train loss: 0.02112014\r\n",
      "Epoch:  80 Step:   556 /   793 Train loss: 0.02177523\r\n",
      "Epoch:  80 Step:   557 /   793 Train loss: 0.02880966\r\n",
      "Epoch:  80 Step:   558 /   793 Train loss: 0.01976767\r\n",
      "Epoch:  80 Step:   559 /   793 Train loss: 0.03227322\r\n",
      "Epoch:  80 Step:   560 /   793 Train loss: 0.02128723\r\n",
      "Epoch:  80 Step:   561 /   793 Train loss: 0.01723344\r\n",
      "Epoch:  80 Step:   562 /   793 Train loss: 0.02469384\r\n",
      "Epoch:  80 Step:   563 /   793 Train loss: 0.02289589\r\n",
      "Epoch:  80 Step:   564 /   793 Train loss: 0.03839396\r\n",
      "Epoch:  80 Step:   565 /   793 Train loss: 0.01229768\r\n",
      "Epoch:  80 Step:   566 /   793 Train loss: 0.02793616\r\n",
      "Epoch:  80 Step:   567 /   793 Train loss: 0.02353114\r\n",
      "Epoch:  80 Step:   568 /   793 Train loss: 0.01967179\r\n",
      "Epoch:  80 Step:   569 /   793 Train loss: 0.03386248\r\n",
      "Epoch:  80 Step:   570 /   793 Train loss: 0.02013089\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  80 Step:   571 /   793 Train loss: 0.02639341\r\n",
      "Epoch:  80 Step:   572 /   793 Train loss: 0.04218917\r\n",
      "Epoch:  80 Step:   573 /   793 Train loss: 0.01749209\r\n",
      "Epoch:  80 Step:   574 /   793 Train loss: 0.02720494\r\n",
      "Epoch:  80 Step:   575 /   793 Train loss: 0.02108211\r\n",
      "Epoch:  80 Step:   576 /   793 Train loss: 0.01979455\r\n",
      "Epoch:  80 Step:   577 /   793 Train loss: 0.01888483\r\n",
      "Epoch:  80 Step:   578 /   793 Train loss: 0.02993293\r\n",
      "Epoch:  80 Step:   579 /   793 Train loss: 0.02517666\r\n",
      "Epoch:  80 Step:   580 /   793 Train loss: 0.02822181\r\n",
      "Epoch:  80 Step:   581 /   793 Train loss: 0.03632595\r\n",
      "Epoch:  80 Step:   582 /   793 Train loss: 0.03308351\r\n",
      "Epoch:  80 Step:   583 /   793 Train loss: 0.01650123\r\n",
      "Epoch:  80 Step:   584 /   793 Train loss: 0.02814623\r\n",
      "Epoch:  80 Step:   585 /   793 Train loss: 0.02650105\r\n",
      "Epoch:  80 Step:   586 /   793 Train loss: 0.01956304\r\n",
      "Epoch:  80 Step:   587 /   793 Train loss: 0.01381929\r\n",
      "Epoch:  80 Step:   588 /   793 Train loss: 0.02201976\r\n",
      "Epoch:  80 Step:   589 /   793 Train loss: 0.03085365\r\n",
      "Epoch:  80 Step:   590 /   793 Train loss: 0.02923838\r\n",
      "Epoch:  80 Step:   591 /   793 Train loss: 0.01850918\r\n",
      "Epoch:  80 Step:   592 /   793 Train loss: 0.02502911\r\n",
      "Epoch:  80 Step:   593 /   793 Train loss: 0.02358287\r\n",
      "Epoch:  80 Step:   594 /   793 Train loss: 0.02649364\r\n",
      "Epoch:  80 Step:   595 /   793 Train loss: 0.02570995\r\n",
      "Epoch:  80 Step:   596 /   793 Train loss: 0.01954452\r\n",
      "Epoch:  80 Step:   597 /   793 Train loss: 0.03095916\r\n",
      "Epoch:  80 Step:   598 /   793 Train loss: 0.03356425\r\n",
      "Epoch:  80 Step:   599 /   793 Train loss: 0.02309098\r\n",
      "Epoch:  80 Step:   600 /   793 Train loss: 0.02613653\r\n",
      "Epoch:  80 Step:   601 /   793 Train loss: 0.02511378\r\n",
      "Epoch:  80 Step:   602 /   793 Train loss: 0.01317109\r\n",
      "Epoch:  80 Step:   603 /   793 Train loss: 0.02916313\r\n",
      "Epoch:  80 Step:   604 /   793 Train loss: 0.03030342\r\n",
      "Epoch:  80 Step:   605 /   793 Train loss: 0.01893868\r\n",
      "Epoch:  80 Step:   606 /   793 Train loss: 0.02137395\r\n",
      "Epoch:  80 Step:   607 /   793 Train loss: 0.02337501\r\n",
      "Epoch:  80 Step:   608 /   793 Train loss: 0.03131709\r\n",
      "Epoch:  80 Step:   609 /   793 Train loss: 0.02317522\r\n",
      "Epoch:  80 Step:   610 /   793 Train loss: 0.01936741\r\n",
      "Epoch:  80 Step:   611 /   793 Train loss: 0.02636407\r\n",
      "Epoch:  80 Step:   612 /   793 Train loss: 0.02653418\r\n",
      "Epoch:  80 Step:   613 /   793 Train loss: 0.02237341\r\n",
      "Epoch:  80 Step:   614 /   793 Train loss: 0.01132827\r\n",
      "Epoch:  80 Step:   615 /   793 Train loss: 0.02621870\r\n",
      "Epoch:  80 Step:   616 /   793 Train loss: 0.02029225\r\n",
      "Epoch:  80 Step:   617 /   793 Train loss: 0.02768581\r\n",
      "Epoch:  80 Step:   618 /   793 Train loss: 0.01734800\r\n",
      "Epoch:  80 Step:   619 /   793 Train loss: 0.02437646\r\n",
      "Epoch:  80 Step:   620 /   793 Train loss: 0.02598979\r\n",
      "Epoch:  80 Step:   621 /   793 Train loss: 0.03657883\r\n",
      "Epoch:  80 Step:   622 /   793 Train loss: 0.01442059\r\n",
      "Epoch:  80 Step:   623 /   793 Train loss: 0.02955576\r\n",
      "Epoch:  80 Step:   624 /   793 Train loss: 0.02206653\r\n",
      "Epoch:  80 Step:   625 /   793 Train loss: 0.02681168\r\n",
      "Epoch:  80 Step:   626 /   793 Train loss: 0.02241342\r\n",
      "Epoch:  80 Step:   627 /   793 Train loss: 0.02319288\r\n",
      "Epoch:  80 Step:   628 /   793 Train loss: 0.02469053\r\n",
      "Epoch:  80 Step:   629 /   793 Train loss: 0.02415762\r\n",
      "Epoch:  80 Step:   630 /   793 Train loss: 0.01492094\r\n",
      "Epoch:  80 Step:   631 /   793 Train loss: 0.02510275\r\n",
      "Epoch:  80 Step:   632 /   793 Train loss: 0.02767506\r\n",
      "Epoch:  80 Step:   633 /   793 Train loss: 0.02154428\r\n",
      "Epoch:  80 Step:   634 /   793 Train loss: 0.02553552\r\n",
      "Epoch:  80 Step:   635 /   793 Train loss: 0.02497417\r\n",
      "Epoch:  80 Step:   636 /   793 Train loss: 0.02137268\r\n",
      "Epoch:  80 Step:   637 /   793 Train loss: 0.01438062\r\n",
      "Epoch:  80 Step:   638 /   793 Train loss: 0.01681087\r\n",
      "Epoch:  80 Step:   639 /   793 Train loss: 0.02147807\r\n",
      "Epoch:  80 Step:   640 /   793 Train loss: 0.03659173\r\n",
      "Epoch:  80 Step:   641 /   793 Train loss: 0.02932744\r\n",
      "Epoch:  80 Step:   642 /   793 Train loss: 0.02419835\r\n",
      "Epoch:  80 Step:   643 /   793 Train loss: 0.02102970\r\n",
      "Epoch:  80 Step:   644 /   793 Train loss: 0.02255175\r\n",
      "Epoch:  80 Step:   645 /   793 Train loss: 0.01768699\r\n",
      "Epoch:  80 Step:   646 /   793 Train loss: 0.01706741\r\n",
      "Epoch:  80 Step:   647 /   793 Train loss: 0.01275697\r\n",
      "Epoch:  80 Step:   648 /   793 Train loss: 0.03699221\r\n",
      "Epoch:  80 Step:   649 /   793 Train loss: 0.01684678\r\n",
      "Epoch:  80 Step:   650 /   793 Train loss: 0.02124748\r\n",
      "Epoch:  80 Step:   651 /   793 Train loss: 0.01730092\r\n",
      "Epoch:  80 Step:   652 /   793 Train loss: 0.01181805\r\n",
      "Epoch:  80 Step:   653 /   793 Train loss: 0.01969868\r\n",
      "Epoch:  80 Step:   654 /   793 Train loss: 0.01700370\r\n",
      "Epoch:  80 Step:   655 /   793 Train loss: 0.02258451\r\n",
      "Epoch:  80 Step:   656 /   793 Train loss: 0.02080616\r\n",
      "Epoch:  80 Step:   657 /   793 Train loss: 0.01982197\r\n",
      "Epoch:  80 Step:   658 /   793 Train loss: 0.01376780\r\n",
      "Epoch:  80 Step:   659 /   793 Train loss: 0.02498367\r\n",
      "Epoch:  80 Step:   660 /   793 Train loss: 0.02514590\r\n",
      "Epoch:  80 Step:   661 /   793 Train loss: 0.02469330\r\n",
      "Epoch:  80 Step:   662 /   793 Train loss: 0.02164717\r\n",
      "Epoch:  80 Step:   663 /   793 Train loss: 0.01679557\r\n",
      "Epoch:  80 Step:   664 /   793 Train loss: 0.02436512\r\n",
      "Epoch:  80 Step:   665 /   793 Train loss: 0.02176353\r\n",
      "Epoch:  80 Step:   666 /   793 Train loss: 0.02146056\r\n",
      "Epoch:  80 Step:   667 /   793 Train loss: 0.01657629\r\n",
      "Epoch:  80 Step:   668 /   793 Train loss: 0.01462886\r\n",
      "Epoch:  80 Step:   669 /   793 Train loss: 0.02367614\r\n",
      "Epoch:  80 Step:   670 /   793 Train loss: 0.02218921\r\n",
      "Epoch:  80 Step:   671 /   793 Train loss: 0.02149624\r\n",
      "Epoch:  80 Step:   672 /   793 Train loss: 0.02309150\r\n",
      "Epoch:  80 Step:   673 /   793 Train loss: 0.03479755\r\n",
      "Epoch:  80 Step:   674 /   793 Train loss: 0.02497717\r\n",
      "Epoch:  80 Step:   675 /   793 Train loss: 0.02404873\r\n",
      "Epoch:  80 Step:   676 /   793 Train loss: 0.02067859\r\n",
      "Epoch:  80 Step:   677 /   793 Train loss: 0.02010942\r\n",
      "Epoch:  80 Step:   678 /   793 Train loss: 0.01628393\r\n",
      "Epoch:  80 Step:   679 /   793 Train loss: 0.01456067\r\n",
      "Epoch:  80 Step:   680 /   793 Train loss: 0.04041060\r\n",
      "Epoch:  80 Step:   681 /   793 Train loss: 0.02885386\r\n",
      "Epoch:  80 Step:   682 /   793 Train loss: 0.03138290\r\n",
      "Epoch:  80 Step:   683 /   793 Train loss: 0.02142264\r\n",
      "Epoch:  80 Step:   684 /   793 Train loss: 0.02018969\r\n",
      "Epoch:  80 Step:   685 /   793 Train loss: 0.02260409\r\n",
      "Epoch:  80 Step:   686 /   793 Train loss: 0.02688026\r\n",
      "Epoch:  80 Step:   687 /   793 Train loss: 0.00949739\r\n",
      "Epoch:  80 Step:   688 /   793 Train loss: 0.00901833\r\n",
      "Epoch:  80 Step:   689 /   793 Train loss: 0.02044227\r\n",
      "Epoch:  80 Step:   690 /   793 Train loss: 0.02046552\r\n",
      "Epoch:  80 Step:   691 /   793 Train loss: 0.02356407\r\n",
      "Epoch:  80 Step:   692 /   793 Train loss: 0.01961218\r\n",
      "Epoch:  80 Step:   693 /   793 Train loss: 0.01680583\r\n",
      "Epoch:  80 Step:   694 /   793 Train loss: 0.02252179\r\n",
      "Epoch:  80 Step:   695 /   793 Train loss: 0.01609225\r\n",
      "Epoch:  80 Step:   696 /   793 Train loss: 0.03029267\r\n",
      "Epoch:  80 Step:   697 /   793 Train loss: 0.01548750\r\n",
      "Epoch:  80 Step:   698 /   793 Train loss: 0.02150214\r\n",
      "Epoch:  80 Step:   699 /   793 Train loss: 0.03014567\r\n",
      "Epoch:  80 Step:   700 /   793 Train loss: 0.03158438\r\n",
      "Epoch:  80 Step:   701 /   793 Train loss: 0.02429365\r\n",
      "Epoch:  80 Step:   702 /   793 Train loss: 0.01939450\r\n",
      "Epoch:  80 Step:   703 /   793 Train loss: 0.02400690\r\n",
      "Epoch:  80 Step:   704 /   793 Train loss: 0.02102004\r\n",
      "Epoch:  80 Step:   705 /   793 Train loss: 0.01827229\r\n",
      "Epoch:  80 Step:   706 /   793 Train loss: 0.01849518\r\n",
      "Epoch:  80 Step:   707 /   793 Train loss: 0.02816080\r\n",
      "Epoch:  80 Step:   708 /   793 Train loss: 0.02182721\r\n",
      "Epoch:  80 Step:   709 /   793 Train loss: 0.01154207\r\n",
      "Epoch:  80 Step:   710 /   793 Train loss: 0.02410650\r\n",
      "Epoch:  80 Step:   711 /   793 Train loss: 0.02935399\r\n",
      "Epoch:  80 Step:   712 /   793 Train loss: 0.02977988\r\n",
      "Epoch:  80 Step:   713 /   793 Train loss: 0.02892702\r\n",
      "Epoch:  80 Step:   714 /   793 Train loss: 0.02558697\r\n",
      "Epoch:  80 Step:   715 /   793 Train loss: 0.03569473\r\n",
      "Epoch:  80 Step:   716 /   793 Train loss: 0.01700731\r\n",
      "Epoch:  80 Step:   717 /   793 Train loss: 0.02006717\r\n",
      "Epoch:  80 Step:   718 /   793 Train loss: 0.02783713\r\n",
      "Epoch:  80 Step:   719 /   793 Train loss: 0.02337367\r\n",
      "Epoch:  80 Step:   720 /   793 Train loss: 0.02409336\r\n",
      "Epoch:  80 Step:   721 /   793 Train loss: 0.03007290\r\n",
      "Epoch:  80 Step:   722 /   793 Train loss: 0.01175574\r\n",
      "Epoch:  80 Step:   723 /   793 Train loss: 0.03623830\r\n",
      "Epoch:  80 Step:   724 /   793 Train loss: 0.02611810\r\n",
      "Epoch:  80 Step:   725 /   793 Train loss: 0.02882699\r\n",
      "Epoch:  80 Step:   726 /   793 Train loss: 0.04186157\r\n",
      "Epoch:  80 Step:   727 /   793 Train loss: 0.03274209\r\n",
      "Epoch:  80 Step:   728 /   793 Train loss: 0.01467170\r\n",
      "Epoch:  80 Step:   729 /   793 Train loss: 0.01970745\r\n",
      "Epoch:  80 Step:   730 /   793 Train loss: 0.03049125\r\n",
      "Epoch:  80 Step:   731 /   793 Train loss: 0.02930195\r\n",
      "Epoch:  80 Step:   732 /   793 Train loss: 0.01483424\r\n",
      "Epoch:  80 Step:   733 /   793 Train loss: 0.02637228\r\n",
      "Epoch:  80 Step:   734 /   793 Train loss: 0.01965815\r\n",
      "Epoch:  80 Step:   735 /   793 Train loss: 0.03210600\r\n",
      "Epoch:  80 Step:   736 /   793 Train loss: 0.02371798\r\n",
      "Epoch:  80 Step:   737 /   793 Train loss: 0.01947957\r\n",
      "Epoch:  80 Step:   738 /   793 Train loss: 0.03447487\r\n",
      "Epoch:  80 Step:   739 /   793 Train loss: 0.01855983\r\n",
      "Epoch:  80 Step:   740 /   793 Train loss: 0.02302217\r\n",
      "Epoch:  80 Step:   741 /   793 Train loss: 0.02285499\r\n",
      "Epoch:  80 Step:   742 /   793 Train loss: 0.01189733\r\n",
      "Epoch:  80 Step:   743 /   793 Train loss: 0.02837902\r\n",
      "Epoch:  80 Step:   744 /   793 Train loss: 0.02768319\r\n",
      "Epoch:  80 Step:   745 /   793 Train loss: 0.01733739\r\n",
      "Epoch:  80 Step:   746 /   793 Train loss: 0.02718255\r\n",
      "Epoch:  80 Step:   747 /   793 Train loss: 0.02304885\r\n",
      "Epoch:  80 Step:   748 /   793 Train loss: 0.01724035\r\n",
      "Epoch:  80 Step:   749 /   793 Train loss: 0.02417482\r\n",
      "Epoch:  80 Step:   750 /   793 Train loss: 0.01284095\r\n",
      "Epoch:  80 Step:   751 /   793 Train loss: 0.03124202\r\n",
      "Epoch:  80 Step:   752 /   793 Train loss: 0.02491144\r\n",
      "Epoch:  80 Step:   753 /   793 Train loss: 0.01519989\r\n",
      "Epoch:  80 Step:   754 /   793 Train loss: 0.01934703\r\n",
      "Epoch:  80 Step:   755 /   793 Train loss: 0.03293575\r\n",
      "Epoch:  80 Step:   756 /   793 Train loss: 0.02203211\r\n",
      "Epoch:  80 Step:   757 /   793 Train loss: 0.01941395\r\n",
      "Epoch:  80 Step:   758 /   793 Train loss: 0.01582812\r\n",
      "Epoch:  80 Step:   759 /   793 Train loss: 0.02204714\r\n",
      "Epoch:  80 Step:   760 /   793 Train loss: 0.03075270\r\n",
      "Epoch:  80 Step:   761 /   793 Train loss: 0.02509418\r\n",
      "Epoch:  80 Step:   762 /   793 Train loss: 0.01302134\r\n",
      "Epoch:  80 Step:   763 /   793 Train loss: 0.02367245\r\n",
      "Epoch:  80 Step:   764 /   793 Train loss: 0.02476460\r\n",
      "Epoch:  80 Step:   765 /   793 Train loss: 0.02758646\r\n",
      "Epoch:  80 Step:   766 /   793 Train loss: 0.02930363\r\n",
      "Epoch:  80 Step:   767 /   793 Train loss: 0.02787790\r\n",
      "Epoch:  80 Step:   768 /   793 Train loss: 0.02048975\r\n",
      "Epoch:  80 Step:   769 /   793 Train loss: 0.02129018\r\n",
      "Epoch:  80 Step:   770 /   793 Train loss: 0.02574098\r\n",
      "Epoch:  80 Step:   771 /   793 Train loss: 0.02748047\r\n",
      "Epoch:  80 Step:   772 /   793 Train loss: 0.02371486\r\n",
      "Epoch:  80 Step:   773 /   793 Train loss: 0.02091243\r\n",
      "Epoch:  80 Step:   774 /   793 Train loss: 0.01791933\r\n",
      "Epoch:  80 Step:   775 /   793 Train loss: 0.02020225\r\n",
      "Epoch:  80 Step:   776 /   793 Train loss: 0.04587978\r\n",
      "Epoch:  80 Step:   777 /   793 Train loss: 0.02791585\r\n",
      "Epoch:  80 Step:   778 /   793 Train loss: 0.02406616\r\n",
      "Epoch:  80 Step:   779 /   793 Train loss: 0.02580508\r\n",
      "Epoch:  80 Step:   780 /   793 Train loss: 0.03045445\r\n",
      "Epoch:  80 Step:   781 /   793 Train loss: 0.02295109\r\n",
      "Epoch:  80 Step:   782 /   793 Train loss: 0.02802100\r\n",
      "Epoch:  80 Step:   783 /   793 Train loss: 0.03618505\r\n",
      "Epoch:  80 Step:   784 /   793 Train loss: 0.01939919\r\n",
      "Epoch:  80 Step:   785 /   793 Train loss: 0.01834447\r\n",
      "Epoch:  80 Step:   786 /   793 Train loss: 0.02103605\r\n",
      "Epoch:  80 Step:   787 /   793 Train loss: 0.02653815\r\n",
      "Epoch:  80 Step:   788 /   793 Train loss: 0.02891325\r\n",
      "Epoch:  80 Step:   789 /   793 Train loss: 0.02533104\r\n",
      "Epoch:  80 Step:   790 /   793 Train loss: 0.01864264\r\n",
      "Epoch:  80 Step:   791 /   793 Train loss: 0.03876117\r\n",
      "Epoch:  80 Step:   792 /   793 Train loss: 0.01598913\r\n",
      "Epoch:  81 Step:     0 /   793 Train loss: 0.02115455\r\n",
      "Epoch:  81 Step:     1 /   793 Train loss: 0.01946378\r\n",
      "Epoch:  81 Step:     2 /   793 Train loss: 0.02375341\r\n",
      "Epoch:  81 Step:     3 /   793 Train loss: 0.01460495\r\n",
      "Epoch:  81 Step:     4 /   793 Train loss: 0.01467190\r\n",
      "Epoch:  81 Step:     5 /   793 Train loss: 0.03433278\r\n",
      "Epoch:  81 Step:     6 /   793 Train loss: 0.02974179\r\n",
      "Epoch:  81 Step:     7 /   793 Train loss: 0.01809957\r\n",
      "Epoch:  81 Step:     8 /   793 Train loss: 0.01912940\r\n",
      "Epoch:  81 Step:     9 /   793 Train loss: 0.00964437\r\n",
      "Epoch:  81 Step:    10 /   793 Train loss: 0.01852319\r\n",
      "Epoch:  81 Step:    11 /   793 Train loss: 0.02199957\r\n",
      "Epoch:  81 Step:    12 /   793 Train loss: 0.01657319\r\n",
      "Epoch:  81 Step:    13 /   793 Train loss: 0.01220169\r\n",
      "Epoch:  81 Step:    14 /   793 Train loss: 0.01584497\r\n",
      "Epoch:  81 Step:    15 /   793 Train loss: 0.01851243\r\n",
      "Epoch:  81 Step:    16 /   793 Train loss: 0.02328111\r\n",
      "Epoch:  81 Step:    17 /   793 Train loss: 0.02107646\r\n",
      "Epoch:  81 Step:    18 /   793 Train loss: 0.02964182\r\n",
      "Epoch:  81 Step:    19 /   793 Train loss: 0.01630140\r\n",
      "Epoch:  81 Step:    20 /   793 Train loss: 0.01767251\r\n",
      "Epoch:  81 Step:    21 /   793 Train loss: 0.02502956\r\n",
      "Epoch:  81 Step:    22 /   793 Train loss: 0.02042444\r\n",
      "Epoch:  81 Step:    23 /   793 Train loss: 0.04068938\r\n",
      "Epoch:  81 Step:    24 /   793 Train loss: 0.01627638\r\n",
      "Epoch:  81 Step:    25 /   793 Train loss: 0.02137994\r\n",
      "Epoch:  81 Step:    26 /   793 Train loss: 0.00832777\r\n",
      "Epoch:  81 Step:    27 /   793 Train loss: 0.02941163\r\n",
      "Epoch:  81 Step:    28 /   793 Train loss: 0.01665294\r\n",
      "Epoch:  81 Step:    29 /   793 Train loss: 0.03937704\r\n",
      "Epoch:  81 Step:    30 /   793 Train loss: 0.01736430\r\n",
      "Epoch:  81 Step:    31 /   793 Train loss: 0.02367697\r\n",
      "Epoch:  81 Step:    32 /   793 Train loss: 0.02224612\r\n",
      "Epoch:  81 Step:    33 /   793 Train loss: 0.02022632\r\n",
      "Epoch:  81 Step:    34 /   793 Train loss: 0.01679404\r\n",
      "Epoch:  81 Step:    35 /   793 Train loss: 0.01920076\r\n",
      "Epoch:  81 Step:    36 /   793 Train loss: 0.03216202\r\n",
      "Epoch:  81 Step:    37 /   793 Train loss: 0.03029990\r\n",
      "Epoch:  81 Step:    38 /   793 Train loss: 0.02323548\r\n",
      "Epoch:  81 Step:    39 /   793 Train loss: 0.02603690\r\n",
      "Epoch:  81 Step:    40 /   793 Train loss: 0.03008299\r\n",
      "Epoch:  81 Step:    41 /   793 Train loss: 0.02133766\r\n",
      "Epoch:  81 Step:    42 /   793 Train loss: 0.02582354\r\n",
      "Epoch:  81 Step:    43 /   793 Train loss: 0.01953565\r\n",
      "Epoch:  81 Step:    44 /   793 Train loss: 0.03041206\r\n",
      "Epoch:  81 Step:    45 /   793 Train loss: 0.01844259\r\n",
      "Epoch:  81 Step:    46 /   793 Train loss: 0.01360896\r\n",
      "Epoch:  81 Step:    47 /   793 Train loss: 0.01272590\r\n",
      "Epoch:  81 Step:    48 /   793 Train loss: 0.02590703\r\n",
      "Epoch:  81 Step:    49 /   793 Train loss: 0.01973260\r\n",
      "Epoch:  81 Step:    50 /   793 Train loss: 0.02624698\r\n",
      "Epoch:  81 Step:    51 /   793 Train loss: 0.01879849\r\n",
      "Epoch:  81 Step:    52 /   793 Train loss: 0.02129699\r\n",
      "Epoch:  81 Step:    53 /   793 Train loss: 0.01977757\r\n",
      "Epoch:  81 Step:    54 /   793 Train loss: 0.02828956\r\n",
      "Epoch:  81 Step:    55 /   793 Train loss: 0.02832808\r\n",
      "Epoch:  81 Step:    56 /   793 Train loss: 0.02337765\r\n",
      "Epoch:  81 Step:    57 /   793 Train loss: 0.03550013\r\n",
      "Epoch:  81 Step:    58 /   793 Train loss: 0.01666589\r\n",
      "Epoch:  81 Step:    59 /   793 Train loss: 0.03750945\r\n",
      "Epoch:  81 Step:    60 /   793 Train loss: 0.01876955\r\n",
      "Epoch:  81 Step:    61 /   793 Train loss: 0.02239899\r\n",
      "Epoch:  81 Step:    62 /   793 Train loss: 0.03808749\r\n",
      "Epoch:  81 Step:    63 /   793 Train loss: 0.02220977\r\n",
      "Epoch:  81 Step:    64 /   793 Train loss: 0.02611732\r\n",
      "Epoch:  81 Step:    65 /   793 Train loss: 0.02235310\r\n",
      "Epoch:  81 Step:    66 /   793 Train loss: 0.02119853\r\n",
      "Epoch:  81 Step:    67 /   793 Train loss: 0.01893611\r\n",
      "Epoch:  81 Step:    68 /   793 Train loss: 0.01551852\r\n",
      "Epoch:  81 Step:    69 /   793 Train loss: 0.02543812\r\n",
      "Epoch:  81 Step:    70 /   793 Train loss: 0.03274514\r\n",
      "Epoch:  81 Step:    71 /   793 Train loss: 0.03322224\r\n",
      "Epoch:  81 Step:    72 /   793 Train loss: 0.04463925\r\n",
      "Epoch:  81 Step:    73 /   793 Train loss: 0.03344359\r\n",
      "Epoch:  81 Step:    74 /   793 Train loss: 0.02238643\r\n",
      "Epoch:  81 Step:    75 /   793 Train loss: 0.01751441\r\n",
      "Epoch:  81 Step:    76 /   793 Train loss: 0.02744120\r\n",
      "Epoch:  81 Step:    77 /   793 Train loss: 0.03270423\r\n",
      "Epoch:  81 Step:    78 /   793 Train loss: 0.02551226\r\n",
      "Epoch:  81 Step:    79 /   793 Train loss: 0.02019903\r\n",
      "Epoch:  81 Step:    80 /   793 Train loss: 0.01578879\r\n",
      "Epoch:  81 Step:    81 /   793 Train loss: 0.02378787\r\n",
      "Epoch:  81 Step:    82 /   793 Train loss: 0.02264747\r\n",
      "Epoch:  81 Step:    83 /   793 Train loss: 0.01434871\r\n",
      "Epoch:  81 Step:    84 /   793 Train loss: 0.02151761\r\n",
      "Epoch:  81 Step:    85 /   793 Train loss: 0.03093808\r\n",
      "Epoch:  81 Step:    86 /   793 Train loss: 0.02809384\r\n",
      "Epoch:  81 Step:    87 /   793 Train loss: 0.03072240\r\n",
      "Epoch:  81 Step:    88 /   793 Train loss: 0.01807145\r\n",
      "Epoch:  81 Step:    89 /   793 Train loss: 0.01986161\r\n",
      "Epoch:  81 Step:    90 /   793 Train loss: 0.02950237\r\n",
      "Epoch:  81 Step:    91 /   793 Train loss: 0.02978223\r\n",
      "Epoch:  81 Step:    92 /   793 Train loss: 0.02336134\r\n",
      "Epoch:  81 Step:    93 /   793 Train loss: 0.02835679\r\n",
      "Epoch:  81 Step:    94 /   793 Train loss: 0.01470528\r\n",
      "Epoch:  81 Step:    95 /   793 Train loss: 0.01861147\r\n",
      "Epoch:  81 Step:    96 /   793 Train loss: 0.02482773\r\n",
      "Epoch:  81 Step:    97 /   793 Train loss: 0.02090380\r\n",
      "Epoch:  81 Step:    98 /   793 Train loss: 0.01080041\r\n",
      "Epoch:  81 Step:    99 /   793 Train loss: 0.02759795\r\n",
      "Epoch:  81 Step:   100 /   793 Train loss: 0.02248236\r\n",
      "Epoch:  81 Step:   101 /   793 Train loss: 0.03271140\r\n",
      "Epoch:  81 Step:   102 /   793 Train loss: 0.03924114\r\n",
      "Epoch:  81 Step:   103 /   793 Train loss: 0.02151994\r\n",
      "Epoch:  81 Step:   104 /   793 Train loss: 0.02042727\r\n",
      "Epoch:  81 Step:   105 /   793 Train loss: 0.02800406\r\n",
      "Epoch:  81 Step:   106 /   793 Train loss: 0.02802761\r\n",
      "Epoch:  81 Step:   107 /   793 Train loss: 0.01691552\r\n",
      "Epoch:  81 Step:   108 /   793 Train loss: 0.03758546\r\n",
      "Epoch:  81 Step:   109 /   793 Train loss: 0.02689944\r\n",
      "Epoch:  81 Step:   110 /   793 Train loss: 0.03226706\r\n",
      "Epoch:  81 Step:   111 /   793 Train loss: 0.02687618\r\n",
      "Epoch:  81 Step:   112 /   793 Train loss: 0.01289475\r\n",
      "Epoch:  81 Step:   113 /   793 Train loss: 0.02036570\r\n",
      "Epoch:  81 Step:   114 /   793 Train loss: 0.02503467\r\n",
      "Epoch:  81 Step:   115 /   793 Train loss: 0.03291177\r\n",
      "Epoch:  81 Step:   116 /   793 Train loss: 0.01967002\r\n",
      "Epoch:  81 Step:   117 /   793 Train loss: 0.02513074\r\n",
      "Epoch:  81 Step:   118 /   793 Train loss: 0.03301663\r\n",
      "Epoch:  81 Step:   119 /   793 Train loss: 0.01941737\r\n",
      "Epoch:  81 Step:   120 /   793 Train loss: 0.02840829\r\n",
      "Epoch:  81 Step:   121 /   793 Train loss: 0.01374765\r\n",
      "Epoch:  81 Step:   122 /   793 Train loss: 0.02133890\r\n",
      "Epoch:  81 Step:   123 /   793 Train loss: 0.02107085\r\n",
      "Epoch:  81 Step:   124 /   793 Train loss: 0.02573126\r\n",
      "Epoch:  81 Step:   125 /   793 Train loss: 0.01631087\r\n",
      "Epoch:  81 Step:   126 /   793 Train loss: 0.01830800\r\n",
      "Epoch:  81 Step:   127 /   793 Train loss: 0.02860583\r\n",
      "Epoch:  81 Step:   128 /   793 Train loss: 0.01883253\r\n",
      "Epoch:  81 Step:   129 /   793 Train loss: 0.02417809\r\n",
      "Epoch:  81 Step:   130 /   793 Train loss: 0.01373822\r\n",
      "Epoch:  81 Step:   131 /   793 Train loss: 0.01767473\r\n",
      "Epoch:  81 Step:   132 /   793 Train loss: 0.02643008\r\n",
      "Epoch:  81 Step:   133 /   793 Train loss: 0.03123526\r\n",
      "Epoch:  81 Step:   134 /   793 Train loss: 0.02700652\r\n",
      "Epoch:  81 Step:   135 /   793 Train loss: 0.01446169\r\n",
      "Epoch:  81 Step:   136 /   793 Train loss: 0.02476884\r\n",
      "Epoch:  81 Step:   137 /   793 Train loss: 0.01167881\r\n",
      "Epoch:  81 Step:   138 /   793 Train loss: 0.02116151\r\n",
      "Epoch:  81 Step:   139 /   793 Train loss: 0.02988490\r\n",
      "Epoch:  81 Step:   140 /   793 Train loss: 0.02825772\r\n",
      "Epoch:  81 Step:   141 /   793 Train loss: 0.02934898\r\n",
      "Epoch:  81 Step:   142 /   793 Train loss: 0.02987619\r\n",
      "Epoch:  81 Step:   143 /   793 Train loss: 0.01937079\r\n",
      "Epoch:  81 Step:   144 /   793 Train loss: 0.02946966\r\n",
      "Epoch:  81 Step:   145 /   793 Train loss: 0.01905287\r\n",
      "Epoch:  81 Step:   146 /   793 Train loss: 0.03124314\r\n",
      "Epoch:  81 Step:   147 /   793 Train loss: 0.01737028\r\n",
      "Epoch:  81 Step:   148 /   793 Train loss: 0.02175372\r\n",
      "Epoch:  81 Step:   149 /   793 Train loss: 0.02021873\r\n",
      "Epoch:  81 Step:   150 /   793 Train loss: 0.01569386\r\n",
      "Epoch:  81 Step:   151 /   793 Train loss: 0.02298664\r\n",
      "Epoch:  81 Step:   152 /   793 Train loss: 0.02452406\r\n",
      "Epoch:  81 Step:   153 /   793 Train loss: 0.01458511\r\n",
      "Epoch:  81 Step:   154 /   793 Train loss: 0.01747996\r\n",
      "Epoch:  81 Step:   155 /   793 Train loss: 0.02491681\r\n",
      "Epoch:  81 Step:   156 /   793 Train loss: 0.01300970\r\n",
      "Epoch:  81 Step:   157 /   793 Train loss: 0.03206403\r\n",
      "Epoch:  81 Step:   158 /   793 Train loss: 0.02157394\r\n",
      "Epoch:  81 Step:   159 /   793 Train loss: 0.02198865\r\n",
      "Epoch:  81 Step:   160 /   793 Train loss: 0.03390676\r\n",
      "Epoch:  81 Step:   161 /   793 Train loss: 0.02640424\r\n",
      "Epoch:  81 Step:   162 /   793 Train loss: 0.02064252\r\n",
      "Epoch:  81 Step:   163 /   793 Train loss: 0.02107708\r\n",
      "Epoch:  81 Step:   164 /   793 Train loss: 0.02217997\r\n",
      "Epoch:  81 Step:   165 /   793 Train loss: 0.02892528\r\n",
      "Epoch:  81 Step:   166 /   793 Train loss: 0.02821737\r\n",
      "Epoch:  81 Step:   167 /   793 Train loss: 0.02565342\r\n",
      "Epoch:  81 Step:   168 /   793 Train loss: 0.02354275\r\n",
      "Epoch:  81 Step:   169 /   793 Train loss: 0.02036641\r\n",
      "Epoch:  81 Step:   170 /   793 Train loss: 0.03253882\r\n",
      "Epoch:  81 Step:   171 /   793 Train loss: 0.02301666\r\n",
      "Epoch:  81 Step:   172 /   793 Train loss: 0.03333393\r\n",
      "Epoch:  81 Step:   173 /   793 Train loss: 0.02793096\r\n",
      "Epoch:  81 Step:   174 /   793 Train loss: 0.02509795\r\n",
      "Epoch:  81 Step:   175 /   793 Train loss: 0.02941787\r\n",
      "Epoch:  81 Step:   176 /   793 Train loss: 0.02508302\r\n",
      "Epoch:  81 Step:   177 /   793 Train loss: 0.04207085\r\n",
      "Epoch:  81 Step:   178 /   793 Train loss: 0.01307110\r\n",
      "Epoch:  81 Step:   179 /   793 Train loss: 0.02193877\r\n",
      "Epoch:  81 Step:   180 /   793 Train loss: 0.02625729\r\n",
      "Epoch:  81 Step:   181 /   793 Train loss: 0.02367849\r\n",
      "Epoch:  81 Step:   182 /   793 Train loss: 0.02913959\r\n",
      "Epoch:  81 Step:   183 /   793 Train loss: 0.01651855\r\n",
      "Epoch:  81 Step:   184 /   793 Train loss: 0.02063033\r\n",
      "Epoch:  81 Step:   185 /   793 Train loss: 0.03480038\r\n",
      "Epoch:  81 Step:   186 /   793 Train loss: 0.01275488\r\n",
      "Epoch:  81 Step:   187 /   793 Train loss: 0.02340827\r\n",
      "Epoch:  81 Step:   188 /   793 Train loss: 0.01903067\r\n",
      "Epoch:  81 Step:   189 /   793 Train loss: 0.01717217\r\n",
      "Epoch:  81 Step:   190 /   793 Train loss: 0.03594470\r\n",
      "Epoch:  81 Step:   191 /   793 Train loss: 0.02561889\r\n",
      "Epoch:  81 Step:   192 /   793 Train loss: 0.02174770\r\n",
      "Epoch:  81 Step:   193 /   793 Train loss: 0.01192990\r\n",
      "Epoch:  81 Step:   194 /   793 Train loss: 0.02772196\r\n",
      "Epoch:  81 Step:   195 /   793 Train loss: 0.02189299\r\n",
      "Epoch:  81 Step:   196 /   793 Train loss: 0.01676510\r\n",
      "Epoch:  81 Step:   197 /   793 Train loss: 0.02221861\r\n",
      "Epoch:  81 Step:   198 /   793 Train loss: 0.01945101\r\n",
      "Epoch:  81 Step:   199 /   793 Train loss: 0.02530655\r\n",
      "Epoch:  81 Step:   200 /   793 Train loss: 0.01626810\r\n",
      "Epoch:  81 Step:   201 /   793 Train loss: 0.02045507\r\n",
      "Epoch:  81 Step:   202 /   793 Train loss: 0.03164975\r\n",
      "Epoch:  81 Step:   203 /   793 Train loss: 0.03257369\r\n",
      "Epoch:  81 Step:   204 /   793 Train loss: 0.02134264\r\n",
      "Epoch:  81 Step:   205 /   793 Train loss: 0.02323686\r\n",
      "Epoch:  81 Step:   206 /   793 Train loss: 0.02542478\r\n",
      "Epoch:  81 Step:   207 /   793 Train loss: 0.03361048\r\n",
      "Epoch:  81 Step:   208 /   793 Train loss: 0.01698461\r\n",
      "Epoch:  81 Step:   209 /   793 Train loss: 0.01463625\r\n",
      "Epoch:  81 Step:   210 /   793 Train loss: 0.02737410\r\n",
      "Epoch:  81 Step:   211 /   793 Train loss: 0.02356952\r\n",
      "Epoch:  81 Step:   212 /   793 Train loss: 0.03088894\r\n",
      "Epoch:  81 Step:   213 /   793 Train loss: 0.02763571\r\n",
      "Epoch:  81 Step:   214 /   793 Train loss: 0.01780606\r\n",
      "Epoch:  81 Step:   215 /   793 Train loss: 0.03301407\r\n",
      "Epoch:  81 Step:   216 /   793 Train loss: 0.03069861\r\n",
      "Epoch:  81 Step:   217 /   793 Train loss: 0.01943689\r\n",
      "Epoch:  81 Step:   218 /   793 Train loss: 0.02426747\r\n",
      "Epoch:  81 Step:   219 /   793 Train loss: 0.01923513\r\n",
      "Epoch:  81 Step:   220 /   793 Train loss: 0.02393051\r\n",
      "Epoch:  81 Step:   221 /   793 Train loss: 0.02690866\r\n",
      "Epoch:  81 Step:   222 /   793 Train loss: 0.02664923\r\n",
      "Epoch:  81 Step:   223 /   793 Train loss: 0.00932845\r\n",
      "Epoch:  81 Step:   224 /   793 Train loss: 0.02543071\r\n",
      "Epoch:  81 Step:   225 /   793 Train loss: 0.03315383\r\n",
      "Epoch:  81 Step:   226 /   793 Train loss: 0.02521314\r\n",
      "Epoch:  81 Step:   227 /   793 Train loss: 0.03189837\r\n",
      "Epoch:  81 Step:   228 /   793 Train loss: 0.02650229\r\n",
      "Epoch:  81 Step:   229 /   793 Train loss: 0.02384659\r\n",
      "Epoch:  81 Step:   230 /   793 Train loss: 0.02761418\r\n",
      "Epoch:  81 Step:   231 /   793 Train loss: 0.01224413\r\n",
      "Epoch:  81 Step:   232 /   793 Train loss: 0.02376886\r\n",
      "Epoch:  81 Step:   233 /   793 Train loss: 0.02604739\r\n",
      "Epoch:  81 Step:   234 /   793 Train loss: 0.02781107\r\n",
      "Epoch:  81 Step:   235 /   793 Train loss: 0.03533487\r\n",
      "Epoch:  81 Step:   236 /   793 Train loss: 0.02856079\r\n",
      "Epoch:  81 Step:   237 /   793 Train loss: 0.02235051\r\n",
      "Epoch:  81 Step:   238 /   793 Train loss: 0.02405093\r\n",
      "Epoch:  81 Step:   239 /   793 Train loss: 0.01624215\r\n",
      "Epoch:  81 Step:   240 /   793 Train loss: 0.02084129\r\n",
      "Epoch:  81 Step:   241 /   793 Train loss: 0.03012350\r\n",
      "Epoch:  81 Step:   242 /   793 Train loss: 0.02852681\r\n",
      "Epoch:  81 Step:   243 /   793 Train loss: 0.01526294\r\n",
      "Epoch:  81 Step:   244 /   793 Train loss: 0.01825682\r\n",
      "Epoch:  81 Step:   245 /   793 Train loss: 0.03525592\r\n",
      "Epoch:  81 Step:   246 /   793 Train loss: 0.02672477\r\n",
      "Epoch:  81 Step:   247 /   793 Train loss: 0.01540956\r\n",
      "Epoch:  81 Step:   248 /   793 Train loss: 0.02117926\r\n",
      "Epoch:  81 Step:   249 /   793 Train loss: 0.01746639\r\n",
      "Epoch:  81 Step:   250 /   793 Train loss: 0.01757452\r\n",
      "Epoch:  81 Step:   251 /   793 Train loss: 0.02257100\r\n",
      "Epoch:  81 Step:   252 /   793 Train loss: 0.03072017\r\n",
      "Epoch:  81 Step:   253 /   793 Train loss: 0.02818207\r\n",
      "Epoch:  81 Step:   254 /   793 Train loss: 0.02819408\r\n",
      "Premature end of JPEG file\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  81 Step:   255 /   793 Train loss: 0.02093486\r\n",
      "Epoch:  81 Step:   256 /   793 Train loss: 0.01721673\r\n",
      "Epoch:  81 Step:   257 /   793 Train loss: 0.02605992\r\n",
      "Epoch:  81 Step:   258 /   793 Train loss: 0.01619690\r\n",
      "Epoch:  81 Step:   259 /   793 Train loss: 0.02394479\r\n",
      "Epoch:  81 Step:   260 /   793 Train loss: 0.02502346\r\n",
      "Epoch:  81 Step:   261 /   793 Train loss: 0.02358781\r\n",
      "Epoch:  81 Step:   262 /   793 Train loss: 0.01239992\r\n",
      "Epoch:  81 Step:   263 /   793 Train loss: 0.01720233\r\n",
      "Epoch:  81 Step:   264 /   793 Train loss: 0.04172613\r\n",
      "Epoch:  81 Step:   265 /   793 Train loss: 0.02099065\r\n",
      "Epoch:  81 Step:   266 /   793 Train loss: 0.04051293\r\n",
      "Epoch:  81 Step:   267 /   793 Train loss: 0.01544083\r\n",
      "Epoch:  81 Step:   268 /   793 Train loss: 0.02270240\r\n",
      "Epoch:  81 Step:   269 /   793 Train loss: 0.01815373\r\n",
      "Epoch:  81 Step:   270 /   793 Train loss: 0.01360932\r\n",
      "Epoch:  81 Step:   271 /   793 Train loss: 0.03062112\r\n",
      "Epoch:  81 Step:   272 /   793 Train loss: 0.02528600\r\n",
      "Epoch:  81 Step:   273 /   793 Train loss: 0.03539098\r\n",
      "Epoch:  81 Step:   274 /   793 Train loss: 0.03543159\r\n",
      "Epoch:  81 Step:   275 /   793 Train loss: 0.02631532\r\n",
      "Epoch:  81 Step:   276 /   793 Train loss: 0.01581445\r\n",
      "Epoch:  81 Step:   277 /   793 Train loss: 0.01466192\r\n",
      "Epoch:  81 Step:   278 /   793 Train loss: 0.02573687\r\n",
      "Epoch:  81 Step:   279 /   793 Train loss: 0.01521154\r\n",
      "Epoch:  81 Step:   280 /   793 Train loss: 0.02122198\r\n",
      "Epoch:  81 Step:   281 /   793 Train loss: 0.02186769\r\n",
      "Epoch:  81 Step:   282 /   793 Train loss: 0.02106791\r\n",
      "Epoch:  81 Step:   283 /   793 Train loss: 0.00630070\r\n",
      "Epoch:  81 Step:   284 /   793 Train loss: 0.01564044\r\n",
      "Epoch:  81 Step:   285 /   793 Train loss: 0.01954219\r\n",
      "Epoch:  81 Step:   286 /   793 Train loss: 0.01782262\r\n",
      "Epoch:  81 Step:   287 /   793 Train loss: 0.02439387\r\n",
      "Epoch:  81 Step:   288 /   793 Train loss: 0.01387297\r\n",
      "Epoch:  81 Step:   289 /   793 Train loss: 0.01902799\r\n",
      "Epoch:  81 Step:   290 /   793 Train loss: 0.01984584\r\n",
      "Epoch:  81 Step:   291 /   793 Train loss: 0.03158381\r\n",
      "Epoch:  81 Step:   292 /   793 Train loss: 0.02747581\r\n",
      "Epoch:  81 Step:   293 /   793 Train loss: 0.01134253\r\n",
      "Epoch:  81 Step:   294 /   793 Train loss: 0.02653546\r\n",
      "Epoch:  81 Step:   295 /   793 Train loss: 0.02765577\r\n",
      "Epoch:  81 Step:   296 /   793 Train loss: 0.03273641\r\n",
      "Epoch:  81 Step:   297 /   793 Train loss: 0.01801047\r\n",
      "Epoch:  81 Step:   298 /   793 Train loss: 0.03748692\r\n",
      "Epoch:  81 Step:   299 /   793 Train loss: 0.02133363\r\n",
      "Epoch:  81 Step:   300 /   793 Train loss: 0.03218865\r\n",
      "Epoch:  81 Step:   301 /   793 Train loss: 0.02275329\r\n",
      "Epoch:  81 Step:   302 /   793 Train loss: 0.02734320\r\n",
      "Epoch:  81 Step:   303 /   793 Train loss: 0.02249690\r\n",
      "Epoch:  81 Step:   304 /   793 Train loss: 0.01249010\r\n",
      "Epoch:  81 Step:   305 /   793 Train loss: 0.02899209\r\n",
      "Epoch:  81 Step:   306 /   793 Train loss: 0.02410290\r\n",
      "Epoch:  81 Step:   307 /   793 Train loss: 0.03729828\r\n",
      "Epoch:  81 Step:   308 /   793 Train loss: 0.02222088\r\n",
      "Epoch:  81 Step:   309 /   793 Train loss: 0.03188691\r\n",
      "Epoch:  81 Step:   310 /   793 Train loss: 0.02135593\r\n",
      "Epoch:  81 Step:   311 /   793 Train loss: 0.01573927\r\n",
      "Epoch:  81 Step:   312 /   793 Train loss: 0.02237713\r\n",
      "Epoch:  81 Step:   313 /   793 Train loss: 0.02461249\r\n",
      "Epoch:  81 Step:   314 /   793 Train loss: 0.02078029\r\n",
      "Epoch:  81 Step:   315 /   793 Train loss: 0.03154977\r\n",
      "Epoch:  81 Step:   316 /   793 Train loss: 0.01848743\r\n",
      "Epoch:  81 Step:   317 /   793 Train loss: 0.01516467\r\n",
      "Epoch:  81 Step:   318 /   793 Train loss: 0.02341082\r\n",
      "Epoch:  81 Step:   319 /   793 Train loss: 0.03372416\r\n",
      "Epoch:  81 Step:   320 /   793 Train loss: 0.02540287\r\n",
      "Epoch:  81 Step:   321 /   793 Train loss: 0.01352482\r\n",
      "Epoch:  81 Step:   322 /   793 Train loss: 0.03203638\r\n",
      "Epoch:  81 Step:   323 /   793 Train loss: 0.01960328\r\n",
      "Epoch:  81 Step:   324 /   793 Train loss: 0.03308358\r\n",
      "Epoch:  81 Step:   325 /   793 Train loss: 0.03728263\r\n",
      "Epoch:  81 Step:   326 /   793 Train loss: 0.03402162\r\n",
      "Epoch:  81 Step:   327 /   793 Train loss: 0.03333548\r\n",
      "Epoch:  81 Step:   328 /   793 Train loss: 0.02767021\r\n",
      "Epoch:  81 Step:   329 /   793 Train loss: 0.02069482\r\n",
      "Epoch:  81 Step:   330 /   793 Train loss: 0.02541155\r\n",
      "Epoch:  81 Step:   331 /   793 Train loss: 0.01680206\r\n",
      "Epoch:  81 Step:   332 /   793 Train loss: 0.04021519\r\n",
      "Epoch:  81 Step:   333 /   793 Train loss: 0.03060695\r\n",
      "Epoch:  81 Step:   334 /   793 Train loss: 0.02516263\r\n",
      "Epoch:  81 Step:   335 /   793 Train loss: 0.03577927\r\n",
      "Epoch:  81 Step:   336 /   793 Train loss: 0.01593814\r\n",
      "Epoch:  81 Step:   337 /   793 Train loss: 0.02400196\r\n",
      "Epoch:  81 Step:   338 /   793 Train loss: 0.02857558\r\n",
      "Epoch:  81 Step:   339 /   793 Train loss: 0.02481229\r\n",
      "Epoch:  81 Step:   340 /   793 Train loss: 0.02999337\r\n",
      "Epoch:  81 Step:   341 /   793 Train loss: 0.02315294\r\n",
      "Epoch:  81 Step:   342 /   793 Train loss: 0.03094165\r\n",
      "Epoch:  81 Step:   343 /   793 Train loss: 0.01901884\r\n",
      "Epoch:  81 Step:   344 /   793 Train loss: 0.01814895\r\n",
      "Epoch:  81 Step:   345 /   793 Train loss: 0.02208351\r\n",
      "Epoch:  81 Step:   346 /   793 Train loss: 0.02459456\r\n",
      "Epoch:  81 Step:   347 /   793 Train loss: 0.03767887\r\n",
      "Epoch:  81 Step:   348 /   793 Train loss: 0.01944729\r\n",
      "Epoch:  81 Step:   349 /   793 Train loss: 0.01921596\r\n",
      "Epoch:  81 Step:   350 /   793 Train loss: 0.02413231\r\n",
      "Epoch:  81 Step:   351 /   793 Train loss: 0.03461076\r\n",
      "Epoch:  81 Step:   352 /   793 Train loss: 0.03360858\r\n",
      "Epoch:  81 Step:   353 /   793 Train loss: 0.01842848\r\n",
      "Epoch:  81 Step:   354 /   793 Train loss: 0.01876471\r\n",
      "Epoch:  81 Step:   355 /   793 Train loss: 0.01862104\r\n",
      "Epoch:  81 Step:   356 /   793 Train loss: 0.02816519\r\n",
      "Epoch:  81 Step:   357 /   793 Train loss: 0.01312261\r\n",
      "Epoch:  81 Step:   358 /   793 Train loss: 0.03008766\r\n",
      "Epoch:  81 Step:   359 /   793 Train loss: 0.02294249\r\n",
      "Epoch:  81 Step:   360 /   793 Train loss: 0.02171839\r\n",
      "Epoch:  81 Step:   361 /   793 Train loss: 0.02937214\r\n",
      "Epoch:  81 Step:   362 /   793 Train loss: 0.02686692\r\n",
      "Epoch:  81 Step:   363 /   793 Train loss: 0.02720524\r\n",
      "Epoch:  81 Step:   364 /   793 Train loss: 0.03767242\r\n",
      "Epoch:  81 Step:   365 /   793 Train loss: 0.01968303\r\n",
      "Epoch:  81 Step:   366 /   793 Train loss: 0.02109879\r\n",
      "Epoch:  81 Step:   367 /   793 Train loss: 0.04088907\r\n",
      "Epoch:  81 Step:   368 /   793 Train loss: 0.02018271\r\n",
      "Epoch:  81 Step:   369 /   793 Train loss: 0.02049503\r\n",
      "Epoch:  81 Step:   370 /   793 Train loss: 0.02511916\r\n",
      "Epoch:  81 Step:   371 /   793 Train loss: 0.03107937\r\n",
      "Epoch:  81 Step:   372 /   793 Train loss: 0.02288361\r\n",
      "Epoch:  81 Step:   373 /   793 Train loss: 0.01657094\r\n",
      "Epoch:  81 Step:   374 /   793 Train loss: 0.03806980\r\n",
      "Epoch:  81 Step:   375 /   793 Train loss: 0.01996307\r\n",
      "Epoch:  81 Step:   376 /   793 Train loss: 0.01337229\r\n",
      "Epoch:  81 Step:   377 /   793 Train loss: 0.02288967\r\n",
      "Epoch:  81 Step:   378 /   793 Train loss: 0.02723686\r\n",
      "Epoch:  81 Step:   379 /   793 Train loss: 0.02621082\r\n",
      "Epoch:  81 Step:   380 /   793 Train loss: 0.02276403\r\n",
      "Epoch:  81 Step:   381 /   793 Train loss: 0.03117245\r\n",
      "Epoch:  81 Step:   382 /   793 Train loss: 0.01601825\r\n",
      "Epoch:  81 Step:   383 /   793 Train loss: 0.02389690\r\n",
      "Epoch:  81 Step:   384 /   793 Train loss: 0.02902949\r\n",
      "Epoch:  81 Step:   385 /   793 Train loss: 0.02511220\r\n",
      "Epoch:  81 Step:   386 /   793 Train loss: 0.02539359\r\n",
      "Epoch:  81 Step:   387 /   793 Train loss: 0.02678075\r\n",
      "Epoch:  81 Step:   388 /   793 Train loss: 0.02268230\r\n",
      "Epoch:  81 Step:   389 /   793 Train loss: 0.03221046\r\n",
      "Epoch:  81 Step:   390 /   793 Train loss: 0.02328391\r\n",
      "Epoch:  81 Step:   391 /   793 Train loss: 0.02236051\r\n",
      "Epoch:  81 Step:   392 /   793 Train loss: 0.02334028\r\n",
      "Epoch:  81 Step:   393 /   793 Train loss: 0.02556332\r\n",
      "Epoch:  81 Step:   394 /   793 Train loss: 0.01604273\r\n",
      "Epoch:  81 Step:   395 /   793 Train loss: 0.02542939\r\n",
      "Epoch:  81 Step:   396 /   793 Train loss: 0.03004878\r\n",
      "Epoch:  81 Step:   397 /   793 Train loss: 0.01550445\r\n",
      "Epoch:  81 Step:   398 /   793 Train loss: 0.02898926\r\n",
      "Epoch:  81 Step:   399 /   793 Train loss: 0.02100674\r\n",
      "Epoch:  81 Step:   400 /   793 Train loss: 0.02648498\r\n",
      "Epoch:  81 Step:   401 /   793 Train loss: 0.02722561\r\n",
      "Epoch:  81 Step:   402 /   793 Train loss: 0.03087121\r\n",
      "Epoch:  81 Step:   403 /   793 Train loss: 0.03576659\r\n",
      "Epoch:  81 Step:   404 /   793 Train loss: 0.02125855\r\n",
      "Epoch:  81 Step:   405 /   793 Train loss: 0.01618014\r\n",
      "Epoch:  81 Step:   406 /   793 Train loss: 0.03030205\r\n",
      "Epoch:  81 Step:   407 /   793 Train loss: 0.01327504\r\n",
      "Epoch:  81 Step:   408 /   793 Train loss: 0.02293319\r\n",
      "Epoch:  81 Step:   409 /   793 Train loss: 0.01798988\r\n",
      "Epoch:  81 Step:   410 /   793 Train loss: 0.03414867\r\n",
      "Epoch:  81 Step:   411 /   793 Train loss: 0.01358727\r\n",
      "Epoch:  81 Step:   412 /   793 Train loss: 0.01876332\r\n",
      "Epoch:  81 Step:   413 /   793 Train loss: 0.02269382\r\n",
      "Epoch:  81 Step:   414 /   793 Train loss: 0.01922376\r\n",
      "Epoch:  81 Step:   415 /   793 Train loss: 0.02847442\r\n",
      "Epoch:  81 Step:   416 /   793 Train loss: 0.01631945\r\n",
      "Epoch:  81 Step:   417 /   793 Train loss: 0.01889740\r\n",
      "Epoch:  81 Step:   418 /   793 Train loss: 0.03025468\r\n",
      "Epoch:  81 Step:   419 /   793 Train loss: 0.02790689\r\n",
      "Epoch:  81 Step:   420 /   793 Train loss: 0.03751681\r\n",
      "Epoch:  81 Step:   421 /   793 Train loss: 0.02055908\r\n",
      "Epoch:  81 Step:   422 /   793 Train loss: 0.03031124\r\n",
      "Epoch:  81 Step:   423 /   793 Train loss: 0.02129938\r\n",
      "Epoch:  81 Step:   424 /   793 Train loss: 0.02139120\r\n",
      "Epoch:  81 Step:   425 /   793 Train loss: 0.03279925\r\n",
      "Epoch:  81 Step:   426 /   793 Train loss: 0.02953318\r\n",
      "Epoch:  81 Step:   427 /   793 Train loss: 0.01330597\r\n",
      "Epoch:  81 Step:   428 /   793 Train loss: 0.01679892\r\n",
      "Epoch:  81 Step:   429 /   793 Train loss: 0.03197083\r\n",
      "Epoch:  81 Step:   430 /   793 Train loss: 0.02285113\r\n",
      "Epoch:  81 Step:   431 /   793 Train loss: 0.02493485\r\n",
      "Epoch:  81 Step:   432 /   793 Train loss: 0.04149635\r\n",
      "Epoch:  81 Step:   433 /   793 Train loss: 0.03114051\r\n",
      "Epoch:  81 Step:   434 /   793 Train loss: 0.02147715\r\n",
      "Epoch:  81 Step:   435 /   793 Train loss: 0.02041314\r\n",
      "Epoch:  81 Step:   436 /   793 Train loss: 0.02425096\r\n",
      "Epoch:  81 Step:   437 /   793 Train loss: 0.01923305\r\n",
      "Epoch:  81 Step:   438 /   793 Train loss: 0.01842231\r\n",
      "Epoch:  81 Step:   439 /   793 Train loss: 0.02477443\r\n",
      "Epoch:  81 Step:   440 /   793 Train loss: 0.02671370\r\n",
      "Epoch:  81 Step:   441 /   793 Train loss: 0.02236059\r\n",
      "Epoch:  81 Step:   442 /   793 Train loss: 0.02760027\r\n",
      "Epoch:  81 Step:   443 /   793 Train loss: 0.03445462\r\n",
      "Epoch:  81 Step:   444 /   793 Train loss: 0.01190379\r\n",
      "Epoch:  81 Step:   445 /   793 Train loss: 0.02823357\r\n",
      "Epoch:  81 Step:   446 /   793 Train loss: 0.02005945\r\n",
      "Epoch:  81 Step:   447 /   793 Train loss: 0.02553995\r\n",
      "Epoch:  81 Step:   448 /   793 Train loss: 0.02194146\r\n",
      "Epoch:  81 Step:   449 /   793 Train loss: 0.02559606\r\n",
      "Epoch:  81 Step:   450 /   793 Train loss: 0.03108580\r\n",
      "Epoch:  81 Step:   451 /   793 Train loss: 0.02576627\r\n",
      "Epoch:  81 Step:   452 /   793 Train loss: 0.01762838\r\n",
      "Epoch:  81 Step:   453 /   793 Train loss: 0.03194034\r\n",
      "Epoch:  81 Step:   454 /   793 Train loss: 0.02517115\r\n",
      "Epoch:  81 Step:   455 /   793 Train loss: 0.02021691\r\n",
      "Epoch:  81 Step:   456 /   793 Train loss: 0.02265415\r\n",
      "Epoch:  81 Step:   457 /   793 Train loss: 0.01743308\r\n",
      "Epoch:  81 Step:   458 /   793 Train loss: 0.02807502\r\n",
      "Epoch:  81 Step:   459 /   793 Train loss: 0.02152252\r\n",
      "Epoch:  81 Step:   460 /   793 Train loss: 0.02566246\r\n",
      "Epoch:  81 Step:   461 /   793 Train loss: 0.02673709\r\n",
      "Epoch:  81 Step:   462 /   793 Train loss: 0.03643901\r\n",
      "Epoch:  81 Step:   463 /   793 Train loss: 0.01744677\r\n",
      "Epoch:  81 Step:   464 /   793 Train loss: 0.01090742\r\n",
      "Epoch:  81 Step:   465 /   793 Train loss: 0.03335105\r\n",
      "Epoch:  81 Step:   466 /   793 Train loss: 0.02630997\r\n",
      "Epoch:  81 Step:   467 /   793 Train loss: 0.02149390\r\n",
      "Epoch:  81 Step:   468 /   793 Train loss: 0.02927360\r\n",
      "Epoch:  81 Step:   469 /   793 Train loss: 0.04115612\r\n",
      "Epoch:  81 Step:   470 /   793 Train loss: 0.02720338\r\n",
      "Epoch:  81 Step:   471 /   793 Train loss: 0.02753388\r\n",
      "Epoch:  81 Step:   472 /   793 Train loss: 0.02737258\r\n",
      "Epoch:  81 Step:   473 /   793 Train loss: 0.02416924\r\n",
      "Epoch:  81 Step:   474 /   793 Train loss: 0.02326252\r\n",
      "Epoch:  81 Step:   475 /   793 Train loss: 0.03786014\r\n",
      "Epoch:  81 Step:   476 /   793 Train loss: 0.02836610\r\n",
      "Epoch:  81 Step:   477 /   793 Train loss: 0.02136728\r\n",
      "Epoch:  81 Step:   478 /   793 Train loss: 0.03606705\r\n",
      "Epoch:  81 Step:   479 /   793 Train loss: 0.03064574\r\n",
      "Epoch:  81 Step:   480 /   793 Train loss: 0.01650680\r\n",
      "Epoch:  81 Step:   481 /   793 Train loss: 0.03046368\r\n",
      "Epoch:  81 Step:   482 /   793 Train loss: 0.03349271\r\n",
      "Epoch:  81 Step:   483 /   793 Train loss: 0.02084025\r\n",
      "Epoch:  81 Step:   484 /   793 Train loss: 0.01992724\r\n",
      "Epoch:  81 Step:   485 /   793 Train loss: 0.02182362\r\n",
      "Epoch:  81 Step:   486 /   793 Train loss: 0.02112992\r\n",
      "Epoch:  81 Step:   487 /   793 Train loss: 0.02441804\r\n",
      "Epoch:  81 Step:   488 /   793 Train loss: 0.02074086\r\n",
      "Epoch:  81 Step:   489 /   793 Train loss: 0.02545700\r\n",
      "Epoch:  81 Step:   490 /   793 Train loss: 0.03014392\r\n",
      "Epoch:  81 Step:   491 /   793 Train loss: 0.02018259\r\n",
      "Epoch:  81 Step:   492 /   793 Train loss: 0.01832207\r\n",
      "Epoch:  81 Step:   493 /   793 Train loss: 0.02376483\r\n",
      "Epoch:  81 Step:   494 /   793 Train loss: 0.02385576\r\n",
      "Epoch:  81 Step:   495 /   793 Train loss: 0.02045579\r\n",
      "Epoch:  81 Step:   496 /   793 Train loss: 0.01622667\r\n",
      "Epoch:  81 Step:   497 /   793 Train loss: 0.03007768\r\n",
      "Epoch:  81 Step:   498 /   793 Train loss: 0.04683254\r\n",
      "Epoch:  81 Step:   499 /   793 Train loss: 0.03459136\r\n",
      "Epoch:  81 Step:   500 /   793 Train loss: 0.02593483\r\n",
      "Epoch:  81 Step:   501 /   793 Train loss: 0.01689584\r\n",
      "Epoch:  81 Step:   502 /   793 Train loss: 0.02288071\r\n",
      "Epoch:  81 Step:   503 /   793 Train loss: 0.02163928\r\n",
      "Epoch:  81 Step:   504 /   793 Train loss: 0.02054430\r\n",
      "Epoch:  81 Step:   505 /   793 Train loss: 0.00666309\r\n",
      "Epoch:  81 Step:   506 /   793 Train loss: 0.02043080\r\n",
      "Epoch:  81 Step:   507 /   793 Train loss: 0.03760953\r\n",
      "Epoch:  81 Step:   508 /   793 Train loss: 0.02823664\r\n",
      "Epoch:  81 Step:   509 /   793 Train loss: 0.01702278\r\n",
      "Epoch:  81 Step:   510 /   793 Train loss: 0.02469702\r\n",
      "Epoch:  81 Step:   511 /   793 Train loss: 0.03615481\r\n",
      "Epoch:  81 Step:   512 /   793 Train loss: 0.02149694\r\n",
      "Epoch:  81 Step:   513 /   793 Train loss: 0.01127011\r\n",
      "Epoch:  81 Step:   514 /   793 Train loss: 0.02878855\r\n",
      "Epoch:  81 Step:   515 /   793 Train loss: 0.02204936\r\n",
      "Epoch:  81 Step:   516 /   793 Train loss: 0.01852187\r\n",
      "Epoch:  81 Step:   517 /   793 Train loss: 0.01529520\r\n",
      "Epoch:  81 Step:   518 /   793 Train loss: 0.01768003\r\n",
      "Epoch:  81 Step:   519 /   793 Train loss: 0.03530408\r\n",
      "Epoch:  81 Step:   520 /   793 Train loss: 0.02690620\r\n",
      "Epoch:  81 Step:   521 /   793 Train loss: 0.01675343\r\n",
      "Epoch:  81 Step:   522 /   793 Train loss: 0.02024254\r\n",
      "Epoch:  81 Step:   523 /   793 Train loss: 0.01985987\r\n",
      "Epoch:  81 Step:   524 /   793 Train loss: 0.01815406\r\n",
      "Epoch:  81 Step:   525 /   793 Train loss: 0.02372171\r\n",
      "Epoch:  81 Step:   526 /   793 Train loss: 0.03070652\r\n",
      "Epoch:  81 Step:   527 /   793 Train loss: 0.02587036\r\n",
      "Epoch:  81 Step:   528 /   793 Train loss: 0.02189891\r\n",
      "Epoch:  81 Step:   529 /   793 Train loss: 0.02096325\r\n",
      "Epoch:  81 Step:   530 /   793 Train loss: 0.01363423\r\n",
      "Epoch:  81 Step:   531 /   793 Train loss: 0.02742878\r\n",
      "Epoch:  81 Step:   532 /   793 Train loss: 0.02040127\r\n",
      "Epoch:  81 Step:   533 /   793 Train loss: 0.03852006\r\n",
      "Epoch:  81 Step:   534 /   793 Train loss: 0.02700372\r\n",
      "Epoch:  81 Step:   535 /   793 Train loss: 0.03706696\r\n",
      "Epoch:  81 Step:   536 /   793 Train loss: 0.02808568\r\n",
      "Epoch:  81 Step:   537 /   793 Train loss: 0.02582065\r\n",
      "Epoch:  81 Step:   538 /   793 Train loss: 0.02065889\r\n",
      "Epoch:  81 Step:   539 /   793 Train loss: 0.03799070\r\n",
      "Epoch:  81 Step:   540 /   793 Train loss: 0.02653834\r\n",
      "Epoch:  81 Step:   541 /   793 Train loss: 0.01977416\r\n",
      "Epoch:  81 Step:   542 /   793 Train loss: 0.01712398\r\n",
      "Epoch:  81 Step:   543 /   793 Train loss: 0.02541437\r\n",
      "Epoch:  81 Step:   544 /   793 Train loss: 0.02948001\r\n",
      "Epoch:  81 Step:   545 /   793 Train loss: 0.02489464\r\n",
      "Epoch:  81 Step:   546 /   793 Train loss: 0.02731956\r\n",
      "Epoch:  81 Step:   547 /   793 Train loss: 0.02289652\r\n",
      "Epoch:  81 Step:   548 /   793 Train loss: 0.03243998\r\n",
      "Epoch:  81 Step:   549 /   793 Train loss: 0.02492441\r\n",
      "Epoch:  81 Step:   550 /   793 Train loss: 0.02459979\r\n",
      "Epoch:  81 Step:   551 /   793 Train loss: 0.03175575\r\n",
      "Epoch:  81 Step:   552 /   793 Train loss: 0.02207385\r\n",
      "Epoch:  81 Step:   553 /   793 Train loss: 0.02881128\r\n",
      "Epoch:  81 Step:   554 /   793 Train loss: 0.01895447\r\n",
      "Epoch:  81 Step:   555 /   793 Train loss: 0.02147360\r\n",
      "Epoch:  81 Step:   556 /   793 Train loss: 0.02585264\r\n",
      "Epoch:  81 Step:   557 /   793 Train loss: 0.02350194\r\n",
      "Epoch:  81 Step:   558 /   793 Train loss: 0.02333980\r\n",
      "Epoch:  81 Step:   559 /   793 Train loss: 0.01987569\r\n",
      "Epoch:  81 Step:   560 /   793 Train loss: 0.02298066\r\n",
      "Epoch:  81 Step:   561 /   793 Train loss: 0.03757981\r\n",
      "Epoch:  81 Step:   562 /   793 Train loss: 0.03929061\r\n",
      "Epoch:  81 Step:   563 /   793 Train loss: 0.02671005\r\n",
      "Epoch:  81 Step:   564 /   793 Train loss: 0.02177916\r\n",
      "Epoch:  81 Step:   565 /   793 Train loss: 0.02051655\r\n",
      "Epoch:  81 Step:   566 /   793 Train loss: 0.02591172\r\n",
      "Epoch:  81 Step:   567 /   793 Train loss: 0.02064097\r\n",
      "Epoch:  81 Step:   568 /   793 Train loss: 0.03292026\r\n",
      "Epoch:  81 Step:   569 /   793 Train loss: 0.03273280\r\n",
      "Epoch:  81 Step:   570 /   793 Train loss: 0.02364310\r\n",
      "Epoch:  81 Step:   571 /   793 Train loss: 0.02109825\r\n",
      "Epoch:  81 Step:   572 /   793 Train loss: 0.03171742\r\n",
      "Epoch:  81 Step:   573 /   793 Train loss: 0.02340423\r\n",
      "Epoch:  81 Step:   574 /   793 Train loss: 0.02103689\r\n",
      "Epoch:  81 Step:   575 /   793 Train loss: 0.02657386\r\n",
      "Epoch:  81 Step:   576 /   793 Train loss: 0.01145368\r\n",
      "Epoch:  81 Step:   577 /   793 Train loss: 0.02118899\r\n",
      "Epoch:  81 Step:   578 /   793 Train loss: 0.03197116\r\n",
      "Epoch:  81 Step:   579 /   793 Train loss: 0.03048827\r\n",
      "Epoch:  81 Step:   580 /   793 Train loss: 0.03113790\r\n",
      "Epoch:  81 Step:   581 /   793 Train loss: 0.02253492\r\n",
      "Epoch:  81 Step:   582 /   793 Train loss: 0.01900573\r\n",
      "Epoch:  81 Step:   583 /   793 Train loss: 0.03036192\r\n",
      "Epoch:  81 Step:   584 /   793 Train loss: 0.03195144\r\n",
      "Epoch:  81 Step:   585 /   793 Train loss: 0.02900249\r\n",
      "Epoch:  81 Step:   586 /   793 Train loss: 0.02385132\r\n",
      "Epoch:  81 Step:   587 /   793 Train loss: 0.03941527\r\n",
      "Epoch:  81 Step:   588 /   793 Train loss: 0.01628949\r\n",
      "Epoch:  81 Step:   589 /   793 Train loss: 0.02409837\r\n",
      "Epoch:  81 Step:   590 /   793 Train loss: 0.01712173\r\n",
      "Epoch:  81 Step:   591 /   793 Train loss: 0.01613708\r\n",
      "Epoch:  81 Step:   592 /   793 Train loss: 0.01899666\r\n",
      "Epoch:  81 Step:   593 /   793 Train loss: 0.01390430\r\n",
      "Epoch:  81 Step:   594 /   793 Train loss: 0.02173940\r\n",
      "Epoch:  81 Step:   595 /   793 Train loss: 0.01564996\r\n",
      "Epoch:  81 Step:   596 /   793 Train loss: 0.01902133\r\n",
      "Epoch:  81 Step:   597 /   793 Train loss: 0.03055761\r\n",
      "Epoch:  81 Step:   598 /   793 Train loss: 0.01968958\r\n",
      "Epoch:  81 Step:   599 /   793 Train loss: 0.02268648\r\n",
      "Epoch:  81 Step:   600 /   793 Train loss: 0.02545521\r\n",
      "Epoch:  81 Step:   601 /   793 Train loss: 0.02027044\r\n",
      "Epoch:  81 Step:   602 /   793 Train loss: 0.02376500\r\n",
      "Epoch:  81 Step:   603 /   793 Train loss: 0.02880644\r\n",
      "Epoch:  81 Step:   604 /   793 Train loss: 0.02660254\r\n",
      "Epoch:  81 Step:   605 /   793 Train loss: 0.03248606\r\n",
      "Epoch:  81 Step:   606 /   793 Train loss: 0.02470693\r\n",
      "Epoch:  81 Step:   607 /   793 Train loss: 0.02218160\r\n",
      "Epoch:  81 Step:   608 /   793 Train loss: 0.01840455\r\n",
      "Epoch:  81 Step:   609 /   793 Train loss: 0.02724271\r\n",
      "Epoch:  81 Step:   610 /   793 Train loss: 0.02299797\r\n",
      "Epoch:  81 Step:   611 /   793 Train loss: 0.01696863\r\n",
      "Epoch:  81 Step:   612 /   793 Train loss: 0.02377591\r\n",
      "Epoch:  81 Step:   613 /   793 Train loss: 0.02130568\r\n",
      "Epoch:  81 Step:   614 /   793 Train loss: 0.02106702\r\n",
      "Epoch:  81 Step:   615 /   793 Train loss: 0.01975140\r\n",
      "Epoch:  81 Step:   616 /   793 Train loss: 0.02255983\r\n",
      "Epoch:  81 Step:   617 /   793 Train loss: 0.02671156\r\n",
      "Epoch:  81 Step:   618 /   793 Train loss: 0.02818347\r\n",
      "Epoch:  81 Step:   619 /   793 Train loss: 0.02665932\r\n",
      "Epoch:  81 Step:   620 /   793 Train loss: 0.01994604\r\n",
      "Epoch:  81 Step:   621 /   793 Train loss: 0.02504583\r\n",
      "Epoch:  81 Step:   622 /   793 Train loss: 0.03699435\r\n",
      "Epoch:  81 Step:   623 /   793 Train loss: 0.01971988\r\n",
      "Epoch:  81 Step:   624 /   793 Train loss: 0.02697580\r\n",
      "Epoch:  81 Step:   625 /   793 Train loss: 0.02341226\r\n",
      "Epoch:  81 Step:   626 /   793 Train loss: 0.03598474\r\n",
      "Epoch:  81 Step:   627 /   793 Train loss: 0.02127417\r\n",
      "Epoch:  81 Step:   628 /   793 Train loss: 0.02450634\r\n",
      "Epoch:  81 Step:   629 /   793 Train loss: 0.02590881\r\n",
      "Epoch:  81 Step:   630 /   793 Train loss: 0.02378911\r\n",
      "Epoch:  81 Step:   631 /   793 Train loss: 0.02429877\r\n",
      "Epoch:  81 Step:   632 /   793 Train loss: 0.01884795\r\n",
      "Epoch:  81 Step:   633 /   793 Train loss: 0.02825381\r\n",
      "Epoch:  81 Step:   634 /   793 Train loss: 0.01941519\r\n",
      "Epoch:  81 Step:   635 /   793 Train loss: 0.02242611\r\n",
      "Epoch:  81 Step:   636 /   793 Train loss: 0.02163266\r\n",
      "Epoch:  81 Step:   637 /   793 Train loss: 0.02027908\r\n",
      "Epoch:  81 Step:   638 /   793 Train loss: 0.02740843\r\n",
      "Epoch:  81 Step:   639 /   793 Train loss: 0.03085942\r\n",
      "Epoch:  81 Step:   640 /   793 Train loss: 0.02092554\r\n",
      "Epoch:  81 Step:   641 /   793 Train loss: 0.01842578\r\n",
      "Epoch:  81 Step:   642 /   793 Train loss: 0.03183777\r\n",
      "Epoch:  81 Step:   643 /   793 Train loss: 0.02690441\r\n",
      "Epoch:  81 Step:   644 /   793 Train loss: 0.03398422\r\n",
      "Epoch:  81 Step:   645 /   793 Train loss: 0.02890745\r\n",
      "Epoch:  81 Step:   646 /   793 Train loss: 0.01503608\r\n",
      "Epoch:  81 Step:   647 /   793 Train loss: 0.01572652\r\n",
      "Epoch:  81 Step:   648 /   793 Train loss: 0.02179383\r\n",
      "Epoch:  81 Step:   649 /   793 Train loss: 0.02964541\r\n",
      "Epoch:  81 Step:   650 /   793 Train loss: 0.01279094\r\n",
      "Epoch:  81 Step:   651 /   793 Train loss: 0.01997430\r\n",
      "Epoch:  81 Step:   652 /   793 Train loss: 0.02208600\r\n",
      "Epoch:  81 Step:   653 /   793 Train loss: 0.02762771\r\n",
      "Epoch:  81 Step:   654 /   793 Train loss: 0.02074833\r\n",
      "Epoch:  81 Step:   655 /   793 Train loss: 0.02707677\r\n",
      "Epoch:  81 Step:   656 /   793 Train loss: 0.02439513\r\n",
      "Epoch:  81 Step:   657 /   793 Train loss: 0.01782979\r\n",
      "Epoch:  81 Step:   658 /   793 Train loss: 0.01019478\r\n",
      "Epoch:  81 Step:   659 /   793 Train loss: 0.02278107\r\n",
      "Epoch:  81 Step:   660 /   793 Train loss: 0.02800959\r\n",
      "Epoch:  81 Step:   661 /   793 Train loss: 0.01777600\r\n",
      "Epoch:  81 Step:   662 /   793 Train loss: 0.02195965\r\n",
      "Epoch:  81 Step:   663 /   793 Train loss: 0.02057657\r\n",
      "Epoch:  81 Step:   664 /   793 Train loss: 0.01495228\r\n",
      "Epoch:  81 Step:   665 /   793 Train loss: 0.02110406\r\n",
      "Epoch:  81 Step:   666 /   793 Train loss: 0.02082486\r\n",
      "Epoch:  81 Step:   667 /   793 Train loss: 0.03036009\r\n",
      "Epoch:  81 Step:   668 /   793 Train loss: 0.01899573\r\n",
      "Epoch:  81 Step:   669 /   793 Train loss: 0.02273192\r\n",
      "Epoch:  81 Step:   670 /   793 Train loss: 0.03242713\r\n",
      "Epoch:  81 Step:   671 /   793 Train loss: 0.02217821\r\n",
      "Epoch:  81 Step:   672 /   793 Train loss: 0.02788136\r\n",
      "Epoch:  81 Step:   673 /   793 Train loss: 0.02970854\r\n",
      "Epoch:  81 Step:   674 /   793 Train loss: 0.02576724\r\n",
      "Epoch:  81 Step:   675 /   793 Train loss: 0.02535467\r\n",
      "Epoch:  81 Step:   676 /   793 Train loss: 0.03575730\r\n",
      "Epoch:  81 Step:   677 /   793 Train loss: 0.02421901\r\n",
      "Epoch:  81 Step:   678 /   793 Train loss: 0.01776030\r\n",
      "Epoch:  81 Step:   679 /   793 Train loss: 0.02884894\r\n",
      "Epoch:  81 Step:   680 /   793 Train loss: 0.00857326\r\n",
      "Epoch:  81 Step:   681 /   793 Train loss: 0.02666626\r\n",
      "Epoch:  81 Step:   682 /   793 Train loss: 0.03200037\r\n",
      "Epoch:  81 Step:   683 /   793 Train loss: 0.02817040\r\n",
      "Epoch:  81 Step:   684 /   793 Train loss: 0.01358224\r\n",
      "Epoch:  81 Step:   685 /   793 Train loss: 0.01090042\r\n",
      "Epoch:  81 Step:   686 /   793 Train loss: 0.02794155\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  81 Step:   687 /   793 Train loss: 0.03417919\r\n",
      "Epoch:  81 Step:   688 /   793 Train loss: 0.02959978\r\n",
      "Epoch:  81 Step:   689 /   793 Train loss: 0.02672870\r\n",
      "Epoch:  81 Step:   690 /   793 Train loss: 0.02954021\r\n",
      "Epoch:  81 Step:   691 /   793 Train loss: 0.02535166\r\n",
      "Epoch:  81 Step:   692 /   793 Train loss: 0.02412797\r\n",
      "Epoch:  81 Step:   693 /   793 Train loss: 0.01968213\r\n",
      "Epoch:  81 Step:   694 /   793 Train loss: 0.01738067\r\n",
      "Epoch:  81 Step:   695 /   793 Train loss: 0.02425859\r\n",
      "Epoch:  81 Step:   696 /   793 Train loss: 0.02889387\r\n",
      "Epoch:  81 Step:   697 /   793 Train loss: 0.02094359\r\n",
      "Epoch:  81 Step:   698 /   793 Train loss: 0.02327242\r\n",
      "Epoch:  81 Step:   699 /   793 Train loss: 0.01694987\r\n",
      "Epoch:  81 Step:   700 /   793 Train loss: 0.02262473\r\n",
      "Epoch:  81 Step:   701 /   793 Train loss: 0.02465388\r\n",
      "Epoch:  81 Step:   702 /   793 Train loss: 0.02412652\r\n",
      "Epoch:  81 Step:   703 /   793 Train loss: 0.02173237\r\n",
      "Epoch:  81 Step:   704 /   793 Train loss: 0.02703748\r\n",
      "Epoch:  81 Step:   705 /   793 Train loss: 0.02827656\r\n",
      "Epoch:  81 Step:   706 /   793 Train loss: 0.01628405\r\n",
      "Epoch:  81 Step:   707 /   793 Train loss: 0.01740493\r\n",
      "Epoch:  81 Step:   708 /   793 Train loss: 0.02558990\r\n",
      "Epoch:  81 Step:   709 /   793 Train loss: 0.01750534\r\n",
      "Epoch:  81 Step:   710 /   793 Train loss: 0.01977254\r\n",
      "Epoch:  81 Step:   711 /   793 Train loss: 0.02207305\r\n",
      "Epoch:  81 Step:   712 /   793 Train loss: 0.02971388\r\n",
      "Epoch:  81 Step:   713 /   793 Train loss: 0.01827022\r\n",
      "Epoch:  81 Step:   714 /   793 Train loss: 0.01356831\r\n",
      "Epoch:  81 Step:   715 /   793 Train loss: 0.01832754\r\n",
      "Epoch:  81 Step:   716 /   793 Train loss: 0.01823882\r\n",
      "Epoch:  81 Step:   717 /   793 Train loss: 0.03239825\r\n",
      "Epoch:  81 Step:   718 /   793 Train loss: 0.02695774\r\n",
      "Epoch:  81 Step:   719 /   793 Train loss: 0.02087196\r\n",
      "Epoch:  81 Step:   720 /   793 Train loss: 0.02896946\r\n",
      "Epoch:  81 Step:   721 /   793 Train loss: 0.03640082\r\n",
      "Epoch:  81 Step:   722 /   793 Train loss: 0.02041833\r\n",
      "Epoch:  81 Step:   723 /   793 Train loss: 0.02575631\r\n",
      "Epoch:  81 Step:   724 /   793 Train loss: 0.02408185\r\n",
      "Epoch:  81 Step:   725 /   793 Train loss: 0.02890120\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  81 Step:   726 /   793 Train loss: 0.01272480\r\n",
      "Epoch:  81 Step:   727 /   793 Train loss: 0.02347645\r\n",
      "Epoch:  81 Step:   728 /   793 Train loss: 0.04227787\r\n",
      "Epoch:  81 Step:   729 /   793 Train loss: 0.02943515\r\n",
      "Epoch:  81 Step:   730 /   793 Train loss: 0.02110345\r\n",
      "Epoch:  81 Step:   731 /   793 Train loss: 0.03010396\r\n",
      "Epoch:  81 Step:   732 /   793 Train loss: 0.03058038\r\n",
      "Epoch:  81 Step:   733 /   793 Train loss: 0.01915177\r\n",
      "Epoch:  81 Step:   734 /   793 Train loss: 0.01556894\r\n",
      "Epoch:  81 Step:   735 /   793 Train loss: 0.02071486\r\n",
      "Epoch:  81 Step:   736 /   793 Train loss: 0.02169149\r\n",
      "Epoch:  81 Step:   737 /   793 Train loss: 0.02671832\r\n",
      "Epoch:  81 Step:   738 /   793 Train loss: 0.02922972\r\n",
      "Epoch:  81 Step:   739 /   793 Train loss: 0.02475664\r\n",
      "Epoch:  81 Step:   740 /   793 Train loss: 0.02752934\r\n",
      "Epoch:  81 Step:   741 /   793 Train loss: 0.02684923\r\n",
      "Epoch:  81 Step:   742 /   793 Train loss: 0.02922410\r\n",
      "Epoch:  81 Step:   743 /   793 Train loss: 0.01969795\r\n",
      "Epoch:  81 Step:   744 /   793 Train loss: 0.02448208\r\n",
      "Epoch:  81 Step:   745 /   793 Train loss: 0.02060572\r\n",
      "Epoch:  81 Step:   746 /   793 Train loss: 0.02913920\r\n",
      "Epoch:  81 Step:   747 /   793 Train loss: 0.02990222\r\n",
      "Epoch:  81 Step:   748 /   793 Train loss: 0.02400414\r\n",
      "Epoch:  81 Step:   749 /   793 Train loss: 0.01964165\r\n",
      "Epoch:  81 Step:   750 /   793 Train loss: 0.01928698\r\n",
      "Epoch:  81 Step:   751 /   793 Train loss: 0.02558874\r\n",
      "Epoch:  81 Step:   752 /   793 Train loss: 0.02439214\r\n",
      "Epoch:  81 Step:   753 /   793 Train loss: 0.01981873\r\n",
      "Epoch:  81 Step:   754 /   793 Train loss: 0.02564335\r\n",
      "Epoch:  81 Step:   755 /   793 Train loss: 0.01788235\r\n",
      "Epoch:  81 Step:   756 /   793 Train loss: 0.02833294\r\n",
      "Epoch:  81 Step:   757 /   793 Train loss: 0.01628748\r\n",
      "Epoch:  81 Step:   758 /   793 Train loss: 0.03472677\r\n",
      "Epoch:  81 Step:   759 /   793 Train loss: 0.03616055\r\n",
      "Epoch:  81 Step:   760 /   793 Train loss: 0.01998025\r\n",
      "Epoch:  81 Step:   761 /   793 Train loss: 0.03543669\r\n",
      "Epoch:  81 Step:   762 /   793 Train loss: 0.02150569\r\n",
      "Epoch:  81 Step:   763 /   793 Train loss: 0.03883682\r\n",
      "Epoch:  81 Step:   764 /   793 Train loss: 0.01644576\r\n",
      "Epoch:  81 Step:   765 /   793 Train loss: 0.01014664\r\n",
      "Epoch:  81 Step:   766 /   793 Train loss: 0.02251219\r\n",
      "Epoch:  81 Step:   767 /   793 Train loss: 0.02948631\r\n",
      "Epoch:  81 Step:   768 /   793 Train loss: 0.02478735\r\n",
      "Epoch:  81 Step:   769 /   793 Train loss: 0.02736942\r\n",
      "Epoch:  81 Step:   770 /   793 Train loss: 0.02331821\r\n",
      "Epoch:  81 Step:   771 /   793 Train loss: 0.02083986\r\n",
      "Epoch:  81 Step:   772 /   793 Train loss: 0.02381718\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  81 Step:   773 /   793 Train loss: 0.02799356\r\n",
      "Epoch:  81 Step:   774 /   793 Train loss: 0.02358433\r\n",
      "Epoch:  81 Step:   775 /   793 Train loss: 0.02810416\r\n",
      "Epoch:  81 Step:   776 /   793 Train loss: 0.02967320\r\n",
      "Epoch:  81 Step:   777 /   793 Train loss: 0.02177198\r\n",
      "Epoch:  81 Step:   778 /   793 Train loss: 0.02161874\r\n",
      "Epoch:  81 Step:   779 /   793 Train loss: 0.03211905\r\n",
      "Epoch:  81 Step:   780 /   793 Train loss: 0.02814469\r\n",
      "Epoch:  81 Step:   781 /   793 Train loss: 0.02913558\r\n",
      "Epoch:  81 Step:   782 /   793 Train loss: 0.02145160\r\n",
      "Epoch:  81 Step:   783 /   793 Train loss: 0.01870718\r\n",
      "Epoch:  81 Step:   784 /   793 Train loss: 0.02727553\r\n",
      "Epoch:  81 Step:   785 /   793 Train loss: 0.02060528\r\n",
      "Epoch:  81 Step:   786 /   793 Train loss: 0.03340208\r\n",
      "Epoch:  81 Step:   787 /   793 Train loss: 0.02335692\r\n",
      "Epoch:  81 Step:   788 /   793 Train loss: 0.02307499\r\n",
      "Epoch:  81 Step:   789 /   793 Train loss: 0.02401153\r\n",
      "Epoch:  81 Step:   790 /   793 Train loss: 0.02570048\r\n",
      "Epoch:  81 Step:   791 /   793 Train loss: 0.01882688\r\n",
      "Epoch:  81 Step:   792 /   793 Train loss: 0.03147938\r\n",
      "Epoch:  81 Validation loss: 0.01411484\r\n",
      "Epoch:  82 Step:     0 /   793 Train loss: 0.02676113\r\n",
      "Epoch:  82 Step:     1 /   793 Train loss: 0.02221265\r\n",
      "Epoch:  82 Step:     2 /   793 Train loss: 0.03641977\r\n",
      "Epoch:  82 Step:     3 /   793 Train loss: 0.02193671\r\n",
      "Epoch:  82 Step:     4 /   793 Train loss: 0.02012472\r\n",
      "Epoch:  82 Step:     5 /   793 Train loss: 0.01798990\r\n",
      "Epoch:  82 Step:     6 /   793 Train loss: 0.02962181\r\n",
      "Epoch:  82 Step:     7 /   793 Train loss: 0.02567617\r\n",
      "Epoch:  82 Step:     8 /   793 Train loss: 0.02682935\r\n",
      "Epoch:  82 Step:     9 /   793 Train loss: 0.01950226\r\n",
      "Epoch:  82 Step:    10 /   793 Train loss: 0.01626163\r\n",
      "Epoch:  82 Step:    11 /   793 Train loss: 0.02524404\r\n",
      "Epoch:  82 Step:    12 /   793 Train loss: 0.03132196\r\n",
      "Epoch:  82 Step:    13 /   793 Train loss: 0.02347044\r\n",
      "Epoch:  82 Step:    14 /   793 Train loss: 0.02319172\r\n",
      "Epoch:  82 Step:    15 /   793 Train loss: 0.02506266\r\n",
      "Epoch:  82 Step:    16 /   793 Train loss: 0.02025125\r\n",
      "Epoch:  82 Step:    17 /   793 Train loss: 0.03187343\r\n",
      "Epoch:  82 Step:    18 /   793 Train loss: 0.02850984\r\n",
      "Epoch:  82 Step:    19 /   793 Train loss: 0.01945894\r\n",
      "Epoch:  82 Step:    20 /   793 Train loss: 0.03243908\r\n",
      "Epoch:  82 Step:    21 /   793 Train loss: 0.02601414\r\n",
      "Epoch:  82 Step:    22 /   793 Train loss: 0.02443448\r\n",
      "Epoch:  82 Step:    23 /   793 Train loss: 0.01491231\r\n",
      "Epoch:  82 Step:    24 /   793 Train loss: 0.03468037\r\n",
      "Epoch:  82 Step:    25 /   793 Train loss: 0.02997379\r\n",
      "Epoch:  82 Step:    26 /   793 Train loss: 0.03352241\r\n",
      "Epoch:  82 Step:    27 /   793 Train loss: 0.00901828\r\n",
      "Epoch:  82 Step:    28 /   793 Train loss: 0.02223346\r\n",
      "Epoch:  82 Step:    29 /   793 Train loss: 0.02141649\r\n",
      "Epoch:  82 Step:    30 /   793 Train loss: 0.02546671\r\n",
      "Epoch:  82 Step:    31 /   793 Train loss: 0.02052763\r\n",
      "Epoch:  82 Step:    32 /   793 Train loss: 0.02166862\r\n",
      "Epoch:  82 Step:    33 /   793 Train loss: 0.01736736\r\n",
      "Epoch:  82 Step:    34 /   793 Train loss: 0.01479551\r\n",
      "Epoch:  82 Step:    35 /   793 Train loss: 0.02409554\r\n",
      "Epoch:  82 Step:    36 /   793 Train loss: 0.01885315\r\n",
      "Epoch:  82 Step:    37 /   793 Train loss: 0.01856853\r\n",
      "Epoch:  82 Step:    38 /   793 Train loss: 0.02130540\r\n",
      "Epoch:  82 Step:    39 /   793 Train loss: 0.01816058\r\n",
      "Epoch:  82 Step:    40 /   793 Train loss: 0.02772729\r\n",
      "Epoch:  82 Step:    41 /   793 Train loss: 0.02405406\r\n",
      "Epoch:  82 Step:    42 /   793 Train loss: 0.02798686\r\n",
      "Epoch:  82 Step:    43 /   793 Train loss: 0.03334828\r\n",
      "Epoch:  82 Step:    44 /   793 Train loss: 0.02093715\r\n",
      "Epoch:  82 Step:    45 /   793 Train loss: 0.02182854\r\n",
      "Epoch:  82 Step:    46 /   793 Train loss: 0.03323407\r\n",
      "Epoch:  82 Step:    47 /   793 Train loss: 0.02866537\r\n",
      "Epoch:  82 Step:    48 /   793 Train loss: 0.01935132\r\n",
      "Epoch:  82 Step:    49 /   793 Train loss: 0.02226093\r\n",
      "Epoch:  82 Step:    50 /   793 Train loss: 0.01605716\r\n",
      "Epoch:  82 Step:    51 /   793 Train loss: 0.01834451\r\n",
      "Epoch:  82 Step:    52 /   793 Train loss: 0.01732287\r\n",
      "Epoch:  82 Step:    53 /   793 Train loss: 0.01532601\r\n",
      "Epoch:  82 Step:    54 /   793 Train loss: 0.01949742\r\n",
      "Epoch:  82 Step:    55 /   793 Train loss: 0.04296206\r\n",
      "Epoch:  82 Step:    56 /   793 Train loss: 0.03019238\r\n",
      "Epoch:  82 Step:    57 /   793 Train loss: 0.02580533\r\n",
      "Epoch:  82 Step:    58 /   793 Train loss: 0.03024044\r\n",
      "Epoch:  82 Step:    59 /   793 Train loss: 0.02652105\r\n",
      "Epoch:  82 Step:    60 /   793 Train loss: 0.02158500\r\n",
      "Epoch:  82 Step:    61 /   793 Train loss: 0.02461549\r\n",
      "Epoch:  82 Step:    62 /   793 Train loss: 0.01939093\r\n",
      "Epoch:  82 Step:    63 /   793 Train loss: 0.02353373\r\n",
      "Epoch:  82 Step:    64 /   793 Train loss: 0.03300049\r\n",
      "Epoch:  82 Step:    65 /   793 Train loss: 0.03371941\r\n",
      "Epoch:  82 Step:    66 /   793 Train loss: 0.01888150\r\n",
      "Epoch:  82 Step:    67 /   793 Train loss: 0.01776340\r\n",
      "Epoch:  82 Step:    68 /   793 Train loss: 0.02369845\r\n",
      "Epoch:  82 Step:    69 /   793 Train loss: 0.02349216\r\n",
      "Epoch:  82 Step:    70 /   793 Train loss: 0.02347613\r\n",
      "Epoch:  82 Step:    71 /   793 Train loss: 0.02467410\r\n",
      "Epoch:  82 Step:    72 /   793 Train loss: 0.02901911\r\n",
      "Epoch:  82 Step:    73 /   793 Train loss: 0.01565992\r\n",
      "Epoch:  82 Step:    74 /   793 Train loss: 0.01329417\r\n",
      "Epoch:  82 Step:    75 /   793 Train loss: 0.01756826\r\n",
      "Epoch:  82 Step:    76 /   793 Train loss: 0.01724649\r\n",
      "Epoch:  82 Step:    77 /   793 Train loss: 0.02702648\r\n",
      "Epoch:  82 Step:    78 /   793 Train loss: 0.02670166\r\n",
      "Epoch:  82 Step:    79 /   793 Train loss: 0.01790026\r\n",
      "Epoch:  82 Step:    80 /   793 Train loss: 0.03959310\r\n",
      "Epoch:  82 Step:    81 /   793 Train loss: 0.02888916\r\n",
      "Epoch:  82 Step:    82 /   793 Train loss: 0.01766287\r\n",
      "Epoch:  82 Step:    83 /   793 Train loss: 0.01357731\r\n",
      "Epoch:  82 Step:    84 /   793 Train loss: 0.02343313\r\n",
      "Epoch:  82 Step:    85 /   793 Train loss: 0.03302482\r\n",
      "Epoch:  82 Step:    86 /   793 Train loss: 0.02256959\r\n",
      "Epoch:  82 Step:    87 /   793 Train loss: 0.03089761\r\n",
      "Epoch:  82 Step:    88 /   793 Train loss: 0.02811290\r\n",
      "Epoch:  82 Step:    89 /   793 Train loss: 0.02534796\r\n",
      "Epoch:  82 Step:    90 /   793 Train loss: 0.03019533\r\n",
      "Epoch:  82 Step:    91 /   793 Train loss: 0.04133123\r\n",
      "Epoch:  82 Step:    92 /   793 Train loss: 0.03959465\r\n",
      "Epoch:  82 Step:    93 /   793 Train loss: 0.02542431\r\n",
      "Epoch:  82 Step:    94 /   793 Train loss: 0.01739948\r\n",
      "Epoch:  82 Step:    95 /   793 Train loss: 0.02280009\r\n",
      "Epoch:  82 Step:    96 /   793 Train loss: 0.02141264\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  82 Step:    97 /   793 Train loss: 0.02128417\r\n",
      "Epoch:  82 Step:    98 /   793 Train loss: 0.02015732\r\n",
      "Epoch:  82 Step:    99 /   793 Train loss: 0.01767099\r\n",
      "Epoch:  82 Step:   100 /   793 Train loss: 0.02165263\r\n",
      "Epoch:  82 Step:   101 /   793 Train loss: 0.01732226\r\n",
      "Epoch:  82 Step:   102 /   793 Train loss: 0.01921361\r\n",
      "Epoch:  82 Step:   103 /   793 Train loss: 0.03219335\r\n",
      "Epoch:  82 Step:   104 /   793 Train loss: 0.01815297\r\n",
      "Epoch:  82 Step:   105 /   793 Train loss: 0.03177439\r\n",
      "Epoch:  82 Step:   106 /   793 Train loss: 0.02801722\r\n",
      "Epoch:  82 Step:   107 /   793 Train loss: 0.02043689\r\n",
      "Epoch:  82 Step:   108 /   793 Train loss: 0.02207320\r\n",
      "Epoch:  82 Step:   109 /   793 Train loss: 0.02407298\r\n",
      "Epoch:  82 Step:   110 /   793 Train loss: 0.02119927\r\n",
      "Epoch:  82 Step:   111 /   793 Train loss: 0.01750139\r\n",
      "Epoch:  82 Step:   112 /   793 Train loss: 0.01411309\r\n",
      "Epoch:  82 Step:   113 /   793 Train loss: 0.02009809\r\n",
      "Epoch:  82 Step:   114 /   793 Train loss: 0.03995355\r\n",
      "Epoch:  82 Step:   115 /   793 Train loss: 0.03643760\r\n",
      "Epoch:  82 Step:   116 /   793 Train loss: 0.02491114\r\n",
      "Epoch:  82 Step:   117 /   793 Train loss: 0.02415623\r\n",
      "Epoch:  82 Step:   118 /   793 Train loss: 0.02188195\r\n",
      "Epoch:  82 Step:   119 /   793 Train loss: 0.02986432\r\n",
      "Epoch:  82 Step:   120 /   793 Train loss: 0.03460389\r\n",
      "Epoch:  82 Step:   121 /   793 Train loss: 0.02252193\r\n",
      "Epoch:  82 Step:   122 /   793 Train loss: 0.02689254\r\n",
      "Epoch:  82 Step:   123 /   793 Train loss: 0.01629481\r\n",
      "Epoch:  82 Step:   124 /   793 Train loss: 0.01523055\r\n",
      "Epoch:  82 Step:   125 /   793 Train loss: 0.01607323\r\n",
      "Epoch:  82 Step:   126 /   793 Train loss: 0.01848142\r\n",
      "Epoch:  82 Step:   127 /   793 Train loss: 0.02701286\r\n",
      "Epoch:  82 Step:   128 /   793 Train loss: 0.01977572\r\n",
      "Epoch:  82 Step:   129 /   793 Train loss: 0.01712311\r\n",
      "Epoch:  82 Step:   130 /   793 Train loss: 0.02008577\r\n",
      "Epoch:  82 Step:   131 /   793 Train loss: 0.03335913\r\n",
      "Epoch:  82 Step:   132 /   793 Train loss: 0.01525853\r\n",
      "Epoch:  82 Step:   133 /   793 Train loss: 0.02856119\r\n",
      "Epoch:  82 Step:   134 /   793 Train loss: 0.02359557\r\n",
      "Epoch:  82 Step:   135 /   793 Train loss: 0.01842850\r\n",
      "Epoch:  82 Step:   136 /   793 Train loss: 0.01929154\r\n",
      "Epoch:  82 Step:   137 /   793 Train loss: 0.03811446\r\n",
      "Epoch:  82 Step:   138 /   793 Train loss: 0.01330320\r\n",
      "Epoch:  82 Step:   139 /   793 Train loss: 0.01417241\r\n",
      "Epoch:  82 Step:   140 /   793 Train loss: 0.00839850\r\n",
      "Epoch:  82 Step:   141 /   793 Train loss: 0.02392661\r\n",
      "Epoch:  82 Step:   142 /   793 Train loss: 0.02520346\r\n",
      "Epoch:  82 Step:   143 /   793 Train loss: 0.04830935\r\n",
      "Epoch:  82 Step:   144 /   793 Train loss: 0.04136898\r\n",
      "Epoch:  82 Step:   145 /   793 Train loss: 0.02833847\r\n",
      "Epoch:  82 Step:   146 /   793 Train loss: 0.01595921\r\n",
      "Epoch:  82 Step:   147 /   793 Train loss: 0.02117414\r\n",
      "Epoch:  82 Step:   148 /   793 Train loss: 0.02793816\r\n",
      "Epoch:  82 Step:   149 /   793 Train loss: 0.02855862\r\n",
      "Epoch:  82 Step:   150 /   793 Train loss: 0.02425907\r\n",
      "Epoch:  82 Step:   151 /   793 Train loss: 0.02539213\r\n",
      "Epoch:  82 Step:   152 /   793 Train loss: 0.03090137\r\n",
      "Epoch:  82 Step:   153 /   793 Train loss: 0.02565678\r\n",
      "Epoch:  82 Step:   154 /   793 Train loss: 0.03589908\r\n",
      "Epoch:  82 Step:   155 /   793 Train loss: 0.01407585\r\n",
      "Epoch:  82 Step:   156 /   793 Train loss: 0.02193427\r\n",
      "Epoch:  82 Step:   157 /   793 Train loss: 0.02156030\r\n",
      "Epoch:  82 Step:   158 /   793 Train loss: 0.02265053\r\n",
      "Epoch:  82 Step:   159 /   793 Train loss: 0.02333957\r\n",
      "Epoch:  82 Step:   160 /   793 Train loss: 0.01283577\r\n",
      "Epoch:  82 Step:   161 /   793 Train loss: 0.02371352\r\n",
      "Epoch:  82 Step:   162 /   793 Train loss: 0.02078021\r\n",
      "Epoch:  82 Step:   163 /   793 Train loss: 0.02457860\r\n",
      "Epoch:  82 Step:   164 /   793 Train loss: 0.02965343\r\n",
      "Epoch:  82 Step:   165 /   793 Train loss: 0.02095014\r\n",
      "Epoch:  82 Step:   166 /   793 Train loss: 0.01151559\r\n",
      "Epoch:  82 Step:   167 /   793 Train loss: 0.01817503\r\n",
      "Epoch:  82 Step:   168 /   793 Train loss: 0.02128423\r\n",
      "Epoch:  82 Step:   169 /   793 Train loss: 0.00882139\r\n",
      "Epoch:  82 Step:   170 /   793 Train loss: 0.01948120\r\n",
      "Epoch:  82 Step:   171 /   793 Train loss: 0.02976449\r\n",
      "Epoch:  82 Step:   172 /   793 Train loss: 0.04145296\r\n",
      "Epoch:  82 Step:   173 /   793 Train loss: 0.02820341\r\n",
      "Epoch:  82 Step:   174 /   793 Train loss: 0.01989845\r\n",
      "Epoch:  82 Step:   175 /   793 Train loss: 0.03551217\r\n",
      "Epoch:  82 Step:   176 /   793 Train loss: 0.03264670\r\n",
      "Epoch:  82 Step:   177 /   793 Train loss: 0.02823048\r\n",
      "Epoch:  82 Step:   178 /   793 Train loss: 0.02139017\r\n",
      "Epoch:  82 Step:   179 /   793 Train loss: 0.03159932\r\n",
      "Epoch:  82 Step:   180 /   793 Train loss: 0.02507760\r\n",
      "Epoch:  82 Step:   181 /   793 Train loss: 0.02210598\r\n",
      "Epoch:  82 Step:   182 /   793 Train loss: 0.02060118\r\n",
      "Epoch:  82 Step:   183 /   793 Train loss: 0.02010300\r\n",
      "Epoch:  82 Step:   184 /   793 Train loss: 0.02071393\r\n",
      "Epoch:  82 Step:   185 /   793 Train loss: 0.03027921\r\n",
      "Epoch:  82 Step:   186 /   793 Train loss: 0.02793546\r\n",
      "Epoch:  82 Step:   187 /   793 Train loss: 0.02801944\r\n",
      "Epoch:  82 Step:   188 /   793 Train loss: 0.01830727\r\n",
      "Epoch:  82 Step:   189 /   793 Train loss: 0.04027636\r\n",
      "Epoch:  82 Step:   190 /   793 Train loss: 0.02625766\r\n",
      "Epoch:  82 Step:   191 /   793 Train loss: 0.01566631\r\n",
      "Epoch:  82 Step:   192 /   793 Train loss: 0.02308623\r\n",
      "Epoch:  82 Step:   193 /   793 Train loss: 0.04036498\r\n",
      "Epoch:  82 Step:   194 /   793 Train loss: 0.03557830\r\n",
      "Epoch:  82 Step:   195 /   793 Train loss: 0.01922411\r\n",
      "Epoch:  82 Step:   196 /   793 Train loss: 0.01742861\r\n",
      "Epoch:  82 Step:   197 /   793 Train loss: 0.01235172\r\n",
      "Epoch:  82 Step:   198 /   793 Train loss: 0.04262173\r\n",
      "Epoch:  82 Step:   199 /   793 Train loss: 0.01741843\r\n",
      "Epoch:  82 Step:   200 /   793 Train loss: 0.02915930\r\n",
      "Epoch:  82 Step:   201 /   793 Train loss: 0.02671985\r\n",
      "Epoch:  82 Step:   202 /   793 Train loss: 0.01663614\r\n",
      "Epoch:  82 Step:   203 /   793 Train loss: 0.01780489\r\n",
      "Epoch:  82 Step:   204 /   793 Train loss: 0.01671525\r\n",
      "Epoch:  82 Step:   205 /   793 Train loss: 0.02506413\r\n",
      "Epoch:  82 Step:   206 /   793 Train loss: 0.02566702\r\n",
      "Epoch:  82 Step:   207 /   793 Train loss: 0.01939645\r\n",
      "Epoch:  82 Step:   208 /   793 Train loss: 0.02744981\r\n",
      "Epoch:  82 Step:   209 /   793 Train loss: 0.01582843\r\n",
      "Epoch:  82 Step:   210 /   793 Train loss: 0.01801431\r\n",
      "Epoch:  82 Step:   211 /   793 Train loss: 0.01891132\r\n",
      "Epoch:  82 Step:   212 /   793 Train loss: 0.01414456\r\n",
      "Epoch:  82 Step:   213 /   793 Train loss: 0.03073540\r\n",
      "Epoch:  82 Step:   214 /   793 Train loss: 0.01814008\r\n",
      "Epoch:  82 Step:   215 /   793 Train loss: 0.01723644\r\n",
      "Epoch:  82 Step:   216 /   793 Train loss: 0.02109368\r\n",
      "Epoch:  82 Step:   217 /   793 Train loss: 0.02870886\r\n",
      "Epoch:  82 Step:   218 /   793 Train loss: 0.02373289\r\n",
      "Epoch:  82 Step:   219 /   793 Train loss: 0.02514035\r\n",
      "Epoch:  82 Step:   220 /   793 Train loss: 0.01968270\r\n",
      "Epoch:  82 Step:   221 /   793 Train loss: 0.02165882\r\n",
      "Epoch:  82 Step:   222 /   793 Train loss: 0.02894539\r\n",
      "Epoch:  82 Step:   223 /   793 Train loss: 0.03047080\r\n",
      "Epoch:  82 Step:   224 /   793 Train loss: 0.03131440\r\n",
      "Epoch:  82 Step:   225 /   793 Train loss: 0.01976981\r\n",
      "Epoch:  82 Step:   226 /   793 Train loss: 0.03611394\r\n",
      "Epoch:  82 Step:   227 /   793 Train loss: 0.02161517\r\n",
      "Epoch:  82 Step:   228 /   793 Train loss: 0.01586929\r\n",
      "Epoch:  82 Step:   229 /   793 Train loss: 0.02266482\r\n",
      "Epoch:  82 Step:   230 /   793 Train loss: 0.02959759\r\n",
      "Epoch:  82 Step:   231 /   793 Train loss: 0.02776968\r\n",
      "Epoch:  82 Step:   232 /   793 Train loss: 0.02349501\r\n",
      "Epoch:  82 Step:   233 /   793 Train loss: 0.01868474\r\n",
      "Epoch:  82 Step:   234 /   793 Train loss: 0.02346384\r\n",
      "Epoch:  82 Step:   235 /   793 Train loss: 0.01982095\r\n",
      "Epoch:  82 Step:   236 /   793 Train loss: 0.02325044\r\n",
      "Epoch:  82 Step:   237 /   793 Train loss: 0.03455100\r\n",
      "Epoch:  82 Step:   238 /   793 Train loss: 0.03032421\r\n",
      "Epoch:  82 Step:   239 /   793 Train loss: 0.03127225\r\n",
      "Epoch:  82 Step:   240 /   793 Train loss: 0.02590391\r\n",
      "Epoch:  82 Step:   241 /   793 Train loss: 0.01796124\r\n",
      "Epoch:  82 Step:   242 /   793 Train loss: 0.01405779\r\n",
      "Epoch:  82 Step:   243 /   793 Train loss: 0.02722120\r\n",
      "Epoch:  82 Step:   244 /   793 Train loss: 0.02813224\r\n",
      "Epoch:  82 Step:   245 /   793 Train loss: 0.02225503\r\n",
      "Epoch:  82 Step:   246 /   793 Train loss: 0.03040721\r\n",
      "Epoch:  82 Step:   247 /   793 Train loss: 0.01634027\r\n",
      "Epoch:  82 Step:   248 /   793 Train loss: 0.02134522\r\n",
      "Epoch:  82 Step:   249 /   793 Train loss: 0.01901827\r\n",
      "Epoch:  82 Step:   250 /   793 Train loss: 0.02155961\r\n",
      "Epoch:  82 Step:   251 /   793 Train loss: 0.02028947\r\n",
      "Epoch:  82 Step:   252 /   793 Train loss: 0.02068114\r\n",
      "Epoch:  82 Step:   253 /   793 Train loss: 0.01763254\r\n",
      "Epoch:  82 Step:   254 /   793 Train loss: 0.01919490\r\n",
      "Epoch:  82 Step:   255 /   793 Train loss: 0.02272963\r\n",
      "Epoch:  82 Step:   256 /   793 Train loss: 0.02439597\r\n",
      "Epoch:  82 Step:   257 /   793 Train loss: 0.02718769\r\n",
      "Epoch:  82 Step:   258 /   793 Train loss: 0.01947778\r\n",
      "Epoch:  82 Step:   259 /   793 Train loss: 0.03065708\r\n",
      "Epoch:  82 Step:   260 /   793 Train loss: 0.02943078\r\n",
      "Epoch:  82 Step:   261 /   793 Train loss: 0.01869535\r\n",
      "Epoch:  82 Step:   262 /   793 Train loss: 0.01768176\r\n",
      "Epoch:  82 Step:   263 /   793 Train loss: 0.02888670\r\n",
      "Epoch:  82 Step:   264 /   793 Train loss: 0.02104978\r\n",
      "Epoch:  82 Step:   265 /   793 Train loss: 0.02608361\r\n",
      "Epoch:  82 Step:   266 /   793 Train loss: 0.03771192\r\n",
      "Epoch:  82 Step:   267 /   793 Train loss: 0.01913642\r\n",
      "Epoch:  82 Step:   268 /   793 Train loss: 0.02031517\r\n",
      "Epoch:  82 Step:   269 /   793 Train loss: 0.02859972\r\n",
      "Epoch:  82 Step:   270 /   793 Train loss: 0.01349602\r\n",
      "Epoch:  82 Step:   271 /   793 Train loss: 0.02097967\r\n",
      "Epoch:  82 Step:   272 /   793 Train loss: 0.02172644\r\n",
      "Epoch:  82 Step:   273 /   793 Train loss: 0.02677014\r\n",
      "Epoch:  82 Step:   274 /   793 Train loss: 0.03694230\r\n",
      "Epoch:  82 Step:   275 /   793 Train loss: 0.02942221\r\n",
      "Epoch:  82 Step:   276 /   793 Train loss: 0.02508910\r\n",
      "Epoch:  82 Step:   277 /   793 Train loss: 0.03828305\r\n",
      "Epoch:  82 Step:   278 /   793 Train loss: 0.02529833\r\n",
      "Epoch:  82 Step:   279 /   793 Train loss: 0.02254594\r\n",
      "Epoch:  82 Step:   280 /   793 Train loss: 0.02455849\r\n",
      "Epoch:  82 Step:   281 /   793 Train loss: 0.02799119\r\n",
      "Epoch:  82 Step:   282 /   793 Train loss: 0.02587008\r\n",
      "Epoch:  82 Step:   283 /   793 Train loss: 0.01701634\r\n",
      "Epoch:  82 Step:   284 /   793 Train loss: 0.01625395\r\n",
      "Epoch:  82 Step:   285 /   793 Train loss: 0.01933210\r\n",
      "Epoch:  82 Step:   286 /   793 Train loss: 0.01750961\r\n",
      "Epoch:  82 Step:   287 /   793 Train loss: 0.03111436\r\n",
      "Epoch:  82 Step:   288 /   793 Train loss: 0.01426364\r\n",
      "Epoch:  82 Step:   289 /   793 Train loss: 0.01002316\r\n",
      "Epoch:  82 Step:   290 /   793 Train loss: 0.02558425\r\n",
      "Epoch:  82 Step:   291 /   793 Train loss: 0.01643420\r\n",
      "Epoch:  82 Step:   292 /   793 Train loss: 0.01722321\r\n",
      "Epoch:  82 Step:   293 /   793 Train loss: 0.02635277\r\n",
      "Epoch:  82 Step:   294 /   793 Train loss: 0.04517249\r\n",
      "Epoch:  82 Step:   295 /   793 Train loss: 0.01453450\r\n",
      "Epoch:  82 Step:   296 /   793 Train loss: 0.03168239\r\n",
      "Epoch:  82 Step:   297 /   793 Train loss: 0.01458243\r\n",
      "Epoch:  82 Step:   298 /   793 Train loss: 0.02672990\r\n",
      "Epoch:  82 Step:   299 /   793 Train loss: 0.01896305\r\n",
      "Epoch:  82 Step:   300 /   793 Train loss: 0.02432457\r\n",
      "Epoch:  82 Step:   301 /   793 Train loss: 0.01345377\r\n",
      "Epoch:  82 Step:   302 /   793 Train loss: 0.01908094\r\n",
      "Epoch:  82 Step:   303 /   793 Train loss: 0.02130610\r\n",
      "Epoch:  82 Step:   304 /   793 Train loss: 0.03364473\r\n",
      "Epoch:  82 Step:   305 /   793 Train loss: 0.01543056\r\n",
      "Epoch:  82 Step:   306 /   793 Train loss: 0.02029642\r\n",
      "Epoch:  82 Step:   307 /   793 Train loss: 0.02465411\r\n",
      "Epoch:  82 Step:   308 /   793 Train loss: 0.03584492\r\n",
      "Epoch:  82 Step:   309 /   793 Train loss: 0.01358694\r\n",
      "Epoch:  82 Step:   310 /   793 Train loss: 0.01580406\r\n",
      "Epoch:  82 Step:   311 /   793 Train loss: 0.02995348\r\n",
      "Epoch:  82 Step:   312 /   793 Train loss: 0.02515707\r\n",
      "Epoch:  82 Step:   313 /   793 Train loss: 0.03608042\r\n",
      "Epoch:  82 Step:   314 /   793 Train loss: 0.03258040\r\n",
      "Epoch:  82 Step:   315 /   793 Train loss: 0.03562069\r\n",
      "Epoch:  82 Step:   316 /   793 Train loss: 0.02345484\r\n",
      "Epoch:  82 Step:   317 /   793 Train loss: 0.02153969\r\n",
      "Epoch:  82 Step:   318 /   793 Train loss: 0.01905004\r\n",
      "Epoch:  82 Step:   319 /   793 Train loss: 0.02479366\r\n",
      "Epoch:  82 Step:   320 /   793 Train loss: 0.03132604\r\n",
      "Epoch:  82 Step:   321 /   793 Train loss: 0.01691984\r\n",
      "Epoch:  82 Step:   322 /   793 Train loss: 0.02943404\r\n",
      "Epoch:  82 Step:   323 /   793 Train loss: 0.02401754\r\n",
      "Epoch:  82 Step:   324 /   793 Train loss: 0.02562483\r\n",
      "Epoch:  82 Step:   325 /   793 Train loss: 0.02252365\r\n",
      "Epoch:  82 Step:   326 /   793 Train loss: 0.02009641\r\n",
      "Epoch:  82 Step:   327 /   793 Train loss: 0.02296319\r\n",
      "Epoch:  82 Step:   328 /   793 Train loss: 0.03359895\r\n",
      "Epoch:  82 Step:   329 /   793 Train loss: 0.01863478\r\n",
      "Epoch:  82 Step:   330 /   793 Train loss: 0.02174493\r\n",
      "Epoch:  82 Step:   331 /   793 Train loss: 0.02114086\r\n",
      "Epoch:  82 Step:   332 /   793 Train loss: 0.02242766\r\n",
      "Epoch:  82 Step:   333 /   793 Train loss: 0.03238606\r\n",
      "Epoch:  82 Step:   334 /   793 Train loss: 0.03115881\r\n",
      "Epoch:  82 Step:   335 /   793 Train loss: 0.02655219\r\n",
      "Epoch:  82 Step:   336 /   793 Train loss: 0.02006819\r\n",
      "Epoch:  82 Step:   337 /   793 Train loss: 0.02211834\r\n",
      "Epoch:  82 Step:   338 /   793 Train loss: 0.03158820\r\n",
      "Epoch:  82 Step:   339 /   793 Train loss: 0.03439470\r\n",
      "Epoch:  82 Step:   340 /   793 Train loss: 0.02930992\r\n",
      "Epoch:  82 Step:   341 /   793 Train loss: 0.03477027\r\n",
      "Epoch:  82 Step:   342 /   793 Train loss: 0.02043369\r\n",
      "Epoch:  82 Step:   343 /   793 Train loss: 0.01489655\r\n",
      "Epoch:  82 Step:   344 /   793 Train loss: 0.03318013\r\n",
      "Epoch:  82 Step:   345 /   793 Train loss: 0.02770056\r\n",
      "Epoch:  82 Step:   346 /   793 Train loss: 0.01736208\r\n",
      "Epoch:  82 Step:   347 /   793 Train loss: 0.02127878\r\n",
      "Epoch:  82 Step:   348 /   793 Train loss: 0.01528317\r\n",
      "Epoch:  82 Step:   349 /   793 Train loss: 0.02006716\r\n",
      "Epoch:  82 Step:   350 /   793 Train loss: 0.02145533\r\n",
      "Epoch:  82 Step:   351 /   793 Train loss: 0.03981663\r\n",
      "Epoch:  82 Step:   352 /   793 Train loss: 0.01521579\r\n",
      "Epoch:  82 Step:   353 /   793 Train loss: 0.02019441\r\n",
      "Epoch:  82 Step:   354 /   793 Train loss: 0.02803888\r\n",
      "Epoch:  82 Step:   355 /   793 Train loss: 0.03646968\r\n",
      "Epoch:  82 Step:   356 /   793 Train loss: 0.02392944\r\n",
      "Epoch:  82 Step:   357 /   793 Train loss: 0.02100214\r\n",
      "Epoch:  82 Step:   358 /   793 Train loss: 0.01891060\r\n",
      "Epoch:  82 Step:   359 /   793 Train loss: 0.03193318\r\n",
      "Epoch:  82 Step:   360 /   793 Train loss: 0.01863920\r\n",
      "Epoch:  82 Step:   361 /   793 Train loss: 0.02928987\r\n",
      "Epoch:  82 Step:   362 /   793 Train loss: 0.03057653\r\n",
      "Epoch:  82 Step:   363 /   793 Train loss: 0.02685854\r\n",
      "Epoch:  82 Step:   364 /   793 Train loss: 0.01590763\r\n",
      "Epoch:  82 Step:   365 /   793 Train loss: 0.02286774\r\n",
      "Epoch:  82 Step:   366 /   793 Train loss: 0.01851831\r\n",
      "Epoch:  82 Step:   367 /   793 Train loss: 0.02154985\r\n",
      "Epoch:  82 Step:   368 /   793 Train loss: 0.02375006\r\n",
      "Epoch:  82 Step:   369 /   793 Train loss: 0.02878209\r\n",
      "Epoch:  82 Step:   370 /   793 Train loss: 0.01840884\r\n",
      "Epoch:  82 Step:   371 /   793 Train loss: 0.02692339\r\n",
      "Epoch:  82 Step:   372 /   793 Train loss: 0.03601412\r\n",
      "Epoch:  82 Step:   373 /   793 Train loss: 0.02837322\r\n",
      "Epoch:  82 Step:   374 /   793 Train loss: 0.01861397\r\n",
      "Epoch:  82 Step:   375 /   793 Train loss: 0.01817944\r\n",
      "Epoch:  82 Step:   376 /   793 Train loss: 0.01968667\r\n",
      "Epoch:  82 Step:   377 /   793 Train loss: 0.01782020\r\n",
      "Epoch:  82 Step:   378 /   793 Train loss: 0.01800843\r\n",
      "Epoch:  82 Step:   379 /   793 Train loss: 0.02622603\r\n",
      "Epoch:  82 Step:   380 /   793 Train loss: 0.02829504\r\n",
      "Epoch:  82 Step:   381 /   793 Train loss: 0.04832041\r\n",
      "Epoch:  82 Step:   382 /   793 Train loss: 0.02317477\r\n",
      "Epoch:  82 Step:   383 /   793 Train loss: 0.01873153\r\n",
      "Epoch:  82 Step:   384 /   793 Train loss: 0.03515716\r\n",
      "Epoch:  82 Step:   385 /   793 Train loss: 0.02714685\r\n",
      "Epoch:  82 Step:   386 /   793 Train loss: 0.02839646\r\n",
      "Epoch:  82 Step:   387 /   793 Train loss: 0.03924596\r\n",
      "Epoch:  82 Step:   388 /   793 Train loss: 0.03078111\r\n",
      "Epoch:  82 Step:   389 /   793 Train loss: 0.02712772\r\n",
      "Epoch:  82 Step:   390 /   793 Train loss: 0.02256448\r\n",
      "Epoch:  82 Step:   391 /   793 Train loss: 0.02852663\r\n",
      "Epoch:  82 Step:   392 /   793 Train loss: 0.02874619\r\n",
      "Epoch:  82 Step:   393 /   793 Train loss: 0.03245389\r\n",
      "Epoch:  82 Step:   394 /   793 Train loss: 0.02351052\r\n",
      "Epoch:  82 Step:   395 /   793 Train loss: 0.01601421\r\n",
      "Epoch:  82 Step:   396 /   793 Train loss: 0.02765264\r\n",
      "Epoch:  82 Step:   397 /   793 Train loss: 0.02850680\r\n",
      "Epoch:  82 Step:   398 /   793 Train loss: 0.02862985\r\n",
      "Epoch:  82 Step:   399 /   793 Train loss: 0.03344439\r\n",
      "Epoch:  82 Step:   400 /   793 Train loss: 0.02123535\r\n",
      "Epoch:  82 Step:   401 /   793 Train loss: 0.02884048\r\n",
      "Epoch:  82 Step:   402 /   793 Train loss: 0.03666702\r\n",
      "Epoch:  82 Step:   403 /   793 Train loss: 0.02488845\r\n",
      "Epoch:  82 Step:   404 /   793 Train loss: 0.01199905\r\n",
      "Epoch:  82 Step:   405 /   793 Train loss: 0.02490417\r\n",
      "Epoch:  82 Step:   406 /   793 Train loss: 0.02304662\r\n",
      "Epoch:  82 Step:   407 /   793 Train loss: 0.02374399\r\n",
      "Epoch:  82 Step:   408 /   793 Train loss: 0.02194662\r\n",
      "Epoch:  82 Step:   409 /   793 Train loss: 0.02350140\r\n",
      "Epoch:  82 Step:   410 /   793 Train loss: 0.01995769\r\n",
      "Epoch:  82 Step:   411 /   793 Train loss: 0.02044316\r\n",
      "Epoch:  82 Step:   412 /   793 Train loss: 0.02547577\r\n",
      "Epoch:  82 Step:   413 /   793 Train loss: 0.02586748\r\n",
      "Epoch:  82 Step:   414 /   793 Train loss: 0.02502465\r\n",
      "Epoch:  82 Step:   415 /   793 Train loss: 0.01671093\r\n",
      "Epoch:  82 Step:   416 /   793 Train loss: 0.01914587\r\n",
      "Epoch:  82 Step:   417 /   793 Train loss: 0.02866220\r\n",
      "Epoch:  82 Step:   418 /   793 Train loss: 0.01665777\r\n",
      "Epoch:  82 Step:   419 /   793 Train loss: 0.02338920\r\n",
      "Epoch:  82 Step:   420 /   793 Train loss: 0.01504043\r\n",
      "Epoch:  82 Step:   421 /   793 Train loss: 0.01766633\r\n",
      "Epoch:  82 Step:   422 /   793 Train loss: 0.01535526\r\n",
      "Epoch:  82 Step:   423 /   793 Train loss: 0.01634671\r\n",
      "Epoch:  82 Step:   424 /   793 Train loss: 0.02531616\r\n",
      "Epoch:  82 Step:   425 /   793 Train loss: 0.02138269\r\n",
      "Epoch:  82 Step:   426 /   793 Train loss: 0.02577402\r\n",
      "Epoch:  82 Step:   427 /   793 Train loss: 0.03572862\r\n",
      "Epoch:  82 Step:   428 /   793 Train loss: 0.02707233\r\n",
      "Epoch:  82 Step:   429 /   793 Train loss: 0.02760071\r\n",
      "Epoch:  82 Step:   430 /   793 Train loss: 0.01499333\r\n",
      "Epoch:  82 Step:   431 /   793 Train loss: 0.02976933\r\n",
      "Epoch:  82 Step:   432 /   793 Train loss: 0.02719692\r\n",
      "Epoch:  82 Step:   433 /   793 Train loss: 0.02731764\r\n",
      "Epoch:  82 Step:   434 /   793 Train loss: 0.01466908\r\n",
      "Epoch:  82 Step:   435 /   793 Train loss: 0.01642645\r\n",
      "Epoch:  82 Step:   436 /   793 Train loss: 0.01646486\r\n",
      "Epoch:  82 Step:   437 /   793 Train loss: 0.02889410\r\n",
      "Epoch:  82 Step:   438 /   793 Train loss: 0.02280784\r\n",
      "Epoch:  82 Step:   439 /   793 Train loss: 0.02330049\r\n",
      "Epoch:  82 Step:   440 /   793 Train loss: 0.02205615\r\n",
      "Epoch:  82 Step:   441 /   793 Train loss: 0.02935477\r\n",
      "Epoch:  82 Step:   442 /   793 Train loss: 0.03556844\r\n",
      "Epoch:  82 Step:   443 /   793 Train loss: 0.02453445\r\n",
      "Epoch:  82 Step:   444 /   793 Train loss: 0.02614029\r\n",
      "Epoch:  82 Step:   445 /   793 Train loss: 0.02574928\r\n",
      "Epoch:  82 Step:   446 /   793 Train loss: 0.03018038\r\n",
      "Epoch:  82 Step:   447 /   793 Train loss: 0.03609522\r\n",
      "Epoch:  82 Step:   448 /   793 Train loss: 0.02786036\r\n",
      "Epoch:  82 Step:   449 /   793 Train loss: 0.02997217\r\n",
      "Epoch:  82 Step:   450 /   793 Train loss: 0.02479624\r\n",
      "Epoch:  82 Step:   451 /   793 Train loss: 0.02529629\r\n",
      "Epoch:  82 Step:   452 /   793 Train loss: 0.02511488\r\n",
      "Epoch:  82 Step:   453 /   793 Train loss: 0.03292633\r\n",
      "Epoch:  82 Step:   454 /   793 Train loss: 0.03143979\r\n",
      "Epoch:  82 Step:   455 /   793 Train loss: 0.02793784\r\n",
      "Epoch:  82 Step:   456 /   793 Train loss: 0.01683522\r\n",
      "Epoch:  82 Step:   457 /   793 Train loss: 0.01808957\r\n",
      "Epoch:  82 Step:   458 /   793 Train loss: 0.02801928\r\n",
      "Epoch:  82 Step:   459 /   793 Train loss: 0.02839701\r\n",
      "Epoch:  82 Step:   460 /   793 Train loss: 0.01887465\r\n",
      "Epoch:  82 Step:   461 /   793 Train loss: 0.02234565\r\n",
      "Epoch:  82 Step:   462 /   793 Train loss: 0.02335311\r\n",
      "Epoch:  82 Step:   463 /   793 Train loss: 0.02025166\r\n",
      "Epoch:  82 Step:   464 /   793 Train loss: 0.01269228\r\n",
      "Epoch:  82 Step:   465 /   793 Train loss: 0.02366296\r\n",
      "Epoch:  82 Step:   466 /   793 Train loss: 0.02937225\r\n",
      "Epoch:  82 Step:   467 /   793 Train loss: 0.02320144\r\n",
      "Epoch:  82 Step:   468 /   793 Train loss: 0.03417455\r\n",
      "Epoch:  82 Step:   469 /   793 Train loss: 0.03470078\r\n",
      "Epoch:  82 Step:   470 /   793 Train loss: 0.01845441\r\n",
      "Epoch:  82 Step:   471 /   793 Train loss: 0.02885208\r\n",
      "Epoch:  82 Step:   472 /   793 Train loss: 0.02322707\r\n",
      "Epoch:  82 Step:   473 /   793 Train loss: 0.01504142\r\n",
      "Epoch:  82 Step:   474 /   793 Train loss: 0.03084210\r\n",
      "Epoch:  82 Step:   475 /   793 Train loss: 0.02213309\r\n",
      "Epoch:  82 Step:   476 /   793 Train loss: 0.02555170\r\n",
      "Epoch:  82 Step:   477 /   793 Train loss: 0.02864262\r\n",
      "Epoch:  82 Step:   478 /   793 Train loss: 0.02084305\r\n",
      "Epoch:  82 Step:   479 /   793 Train loss: 0.02943935\r\n",
      "Epoch:  82 Step:   480 /   793 Train loss: 0.02070805\r\n",
      "Epoch:  82 Step:   481 /   793 Train loss: 0.02503052\r\n",
      "Epoch:  82 Step:   482 /   793 Train loss: 0.03079909\r\n",
      "Epoch:  82 Step:   483 /   793 Train loss: 0.02337906\r\n",
      "Epoch:  82 Step:   484 /   793 Train loss: 0.02058869\r\n",
      "Epoch:  82 Step:   485 /   793 Train loss: 0.02958094\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  82 Step:   486 /   793 Train loss: 0.02007364\r\n",
      "Epoch:  82 Step:   487 /   793 Train loss: 0.02385180\r\n",
      "Epoch:  82 Step:   488 /   793 Train loss: 0.01969359\r\n",
      "Epoch:  82 Step:   489 /   793 Train loss: 0.02520365\r\n",
      "Epoch:  82 Step:   490 /   793 Train loss: 0.03420583\r\n",
      "Epoch:  82 Step:   491 /   793 Train loss: 0.02202323\r\n",
      "Epoch:  82 Step:   492 /   793 Train loss: 0.02047656\r\n",
      "Epoch:  82 Step:   493 /   793 Train loss: 0.01299268\r\n",
      "Epoch:  82 Step:   494 /   793 Train loss: 0.01500554\r\n",
      "Epoch:  82 Step:   495 /   793 Train loss: 0.01329394\r\n",
      "Epoch:  82 Step:   496 /   793 Train loss: 0.01643319\r\n",
      "Epoch:  82 Step:   497 /   793 Train loss: 0.02888412\r\n",
      "Epoch:  82 Step:   498 /   793 Train loss: 0.03598190\r\n",
      "Epoch:  82 Step:   499 /   793 Train loss: 0.01989148\r\n",
      "Epoch:  82 Step:   500 /   793 Train loss: 0.01424896\r\n",
      "Epoch:  82 Step:   501 /   793 Train loss: 0.02002949\r\n",
      "Epoch:  82 Step:   502 /   793 Train loss: 0.02892057\r\n",
      "Epoch:  82 Step:   503 /   793 Train loss: 0.01657885\r\n",
      "Epoch:  82 Step:   504 /   793 Train loss: 0.02396676\r\n",
      "Epoch:  82 Step:   505 /   793 Train loss: 0.01513773\r\n",
      "Epoch:  82 Step:   506 /   793 Train loss: 0.02528803\r\n",
      "Epoch:  82 Step:   507 /   793 Train loss: 0.02198030\r\n",
      "Epoch:  82 Step:   508 /   793 Train loss: 0.02077632\r\n",
      "Epoch:  82 Step:   509 /   793 Train loss: 0.01995857\r\n",
      "Epoch:  82 Step:   510 /   793 Train loss: 0.02606364\r\n",
      "Epoch:  82 Step:   511 /   793 Train loss: 0.03685531\r\n",
      "Epoch:  82 Step:   512 /   793 Train loss: 0.03227134\r\n",
      "Epoch:  82 Step:   513 /   793 Train loss: 0.02856305\r\n",
      "Epoch:  82 Step:   514 /   793 Train loss: 0.02883438\r\n",
      "Epoch:  82 Step:   515 /   793 Train loss: 0.03608602\r\n",
      "Epoch:  82 Step:   516 /   793 Train loss: 0.01431156\r\n",
      "Epoch:  82 Step:   517 /   793 Train loss: 0.01697347\r\n",
      "Epoch:  82 Step:   518 /   793 Train loss: 0.02020485\r\n",
      "Epoch:  82 Step:   519 /   793 Train loss: 0.02335605\r\n",
      "Epoch:  82 Step:   520 /   793 Train loss: 0.02015272\r\n",
      "Epoch:  82 Step:   521 /   793 Train loss: 0.01621694\r\n",
      "Epoch:  82 Step:   522 /   793 Train loss: 0.02708229\r\n",
      "Epoch:  82 Step:   523 /   793 Train loss: 0.02300399\r\n",
      "Epoch:  82 Step:   524 /   793 Train loss: 0.01835267\r\n",
      "Epoch:  82 Step:   525 /   793 Train loss: 0.03554755\r\n",
      "Epoch:  82 Step:   526 /   793 Train loss: 0.02557576\r\n",
      "Epoch:  82 Step:   527 /   793 Train loss: 0.03192610\r\n",
      "Epoch:  82 Step:   528 /   793 Train loss: 0.02731456\r\n",
      "Epoch:  82 Step:   529 /   793 Train loss: 0.01897839\r\n",
      "Epoch:  82 Step:   530 /   793 Train loss: 0.01484003\r\n",
      "Epoch:  82 Step:   531 /   793 Train loss: 0.01386124\r\n",
      "Epoch:  82 Step:   532 /   793 Train loss: 0.02328082\r\n",
      "Epoch:  82 Step:   533 /   793 Train loss: 0.02109679\r\n",
      "Epoch:  82 Step:   534 /   793 Train loss: 0.02076280\r\n",
      "Epoch:  82 Step:   535 /   793 Train loss: 0.02208440\r\n",
      "Epoch:  82 Step:   536 /   793 Train loss: 0.02510007\r\n",
      "Epoch:  82 Step:   537 /   793 Train loss: 0.01936018\r\n",
      "Epoch:  82 Step:   538 /   793 Train loss: 0.01782953\r\n",
      "Epoch:  82 Step:   539 /   793 Train loss: 0.01854106\r\n",
      "Epoch:  82 Step:   540 /   793 Train loss: 0.02904321\r\n",
      "Epoch:  82 Step:   541 /   793 Train loss: 0.01823988\r\n",
      "Epoch:  82 Step:   542 /   793 Train loss: 0.02517638\r\n",
      "Epoch:  82 Step:   543 /   793 Train loss: 0.03083785\r\n",
      "Epoch:  82 Step:   544 /   793 Train loss: 0.02307715\r\n",
      "Epoch:  82 Step:   545 /   793 Train loss: 0.03182151\r\n",
      "Epoch:  82 Step:   546 /   793 Train loss: 0.03656683\r\n",
      "Epoch:  82 Step:   547 /   793 Train loss: 0.01972696\r\n",
      "Epoch:  82 Step:   548 /   793 Train loss: 0.02525434\r\n",
      "Epoch:  82 Step:   549 /   793 Train loss: 0.01846737\r\n",
      "Epoch:  82 Step:   550 /   793 Train loss: 0.02592595\r\n",
      "Epoch:  82 Step:   551 /   793 Train loss: 0.01949701\r\n",
      "Epoch:  82 Step:   552 /   793 Train loss: 0.02481416\r\n",
      "Epoch:  82 Step:   553 /   793 Train loss: 0.02418121\r\n",
      "Epoch:  82 Step:   554 /   793 Train loss: 0.01453826\r\n",
      "Epoch:  82 Step:   555 /   793 Train loss: 0.01359960\r\n",
      "Epoch:  82 Step:   556 /   793 Train loss: 0.01577023\r\n",
      "Epoch:  82 Step:   557 /   793 Train loss: 0.02384728\r\n",
      "Epoch:  82 Step:   558 /   793 Train loss: 0.03000429\r\n",
      "Epoch:  82 Step:   559 /   793 Train loss: 0.03366539\r\n",
      "Epoch:  82 Step:   560 /   793 Train loss: 0.03679240\r\n",
      "Epoch:  82 Step:   561 /   793 Train loss: 0.02591242\r\n",
      "Epoch:  82 Step:   562 /   793 Train loss: 0.02719205\r\n",
      "Epoch:  82 Step:   563 /   793 Train loss: 0.02404251\r\n",
      "Epoch:  82 Step:   564 /   793 Train loss: 0.02215760\r\n",
      "Epoch:  82 Step:   565 /   793 Train loss: 0.01756376\r\n",
      "Epoch:  82 Step:   566 /   793 Train loss: 0.01678523\r\n",
      "Epoch:  82 Step:   567 /   793 Train loss: 0.02986973\r\n",
      "Epoch:  82 Step:   568 /   793 Train loss: 0.03374619\r\n",
      "Epoch:  82 Step:   569 /   793 Train loss: 0.02254151\r\n",
      "Epoch:  82 Step:   570 /   793 Train loss: 0.02252635\r\n",
      "Epoch:  82 Step:   571 /   793 Train loss: 0.02636685\r\n",
      "Epoch:  82 Step:   572 /   793 Train loss: 0.01917372\r\n",
      "Epoch:  82 Step:   573 /   793 Train loss: 0.03216494\r\n",
      "Epoch:  82 Step:   574 /   793 Train loss: 0.01184786\r\n",
      "Epoch:  82 Step:   575 /   793 Train loss: 0.02773932\r\n",
      "Epoch:  82 Step:   576 /   793 Train loss: 0.03128687\r\n",
      "Epoch:  82 Step:   577 /   793 Train loss: 0.01827263\r\n",
      "Epoch:  82 Step:   578 /   793 Train loss: 0.02055367\r\n",
      "Epoch:  82 Step:   579 /   793 Train loss: 0.02373018\r\n",
      "Epoch:  82 Step:   580 /   793 Train loss: 0.04738835\r\n",
      "Epoch:  82 Step:   581 /   793 Train loss: 0.02108147\r\n",
      "Epoch:  82 Step:   582 /   793 Train loss: 0.02097593\r\n",
      "Epoch:  82 Step:   583 /   793 Train loss: 0.02033832\r\n",
      "Epoch:  82 Step:   584 /   793 Train loss: 0.03283401\r\n",
      "Epoch:  82 Step:   585 /   793 Train loss: 0.02332521\r\n",
      "Epoch:  82 Step:   586 /   793 Train loss: 0.01428788\r\n",
      "Epoch:  82 Step:   587 /   793 Train loss: 0.01474899\r\n",
      "Epoch:  82 Step:   588 /   793 Train loss: 0.01740886\r\n",
      "Epoch:  82 Step:   589 /   793 Train loss: 0.02314747\r\n",
      "Epoch:  82 Step:   590 /   793 Train loss: 0.02807827\r\n",
      "Epoch:  82 Step:   591 /   793 Train loss: 0.02381629\r\n",
      "Epoch:  82 Step:   592 /   793 Train loss: 0.01877509\r\n",
      "Epoch:  82 Step:   593 /   793 Train loss: 0.02969405\r\n",
      "Epoch:  82 Step:   594 /   793 Train loss: 0.02030624\r\n",
      "Epoch:  82 Step:   595 /   793 Train loss: 0.01163825\r\n",
      "Epoch:  82 Step:   596 /   793 Train loss: 0.02699892\r\n",
      "Epoch:  82 Step:   597 /   793 Train loss: 0.02482577\r\n",
      "Epoch:  82 Step:   598 /   793 Train loss: 0.02072870\r\n",
      "Epoch:  82 Step:   599 /   793 Train loss: 0.02450704\r\n",
      "Epoch:  82 Step:   600 /   793 Train loss: 0.01899611\r\n",
      "Epoch:  82 Step:   601 /   793 Train loss: 0.02477182\r\n",
      "Epoch:  82 Step:   602 /   793 Train loss: 0.02168207\r\n",
      "Epoch:  82 Step:   603 /   793 Train loss: 0.02095117\r\n",
      "Epoch:  82 Step:   604 /   793 Train loss: 0.01981447\r\n",
      "Epoch:  82 Step:   605 /   793 Train loss: 0.03498447\r\n",
      "Epoch:  82 Step:   606 /   793 Train loss: 0.02054363\r\n",
      "Epoch:  82 Step:   607 /   793 Train loss: 0.02313962\r\n",
      "Epoch:  82 Step:   608 /   793 Train loss: 0.02898354\r\n",
      "Epoch:  82 Step:   609 /   793 Train loss: 0.01315980\r\n",
      "Epoch:  82 Step:   610 /   793 Train loss: 0.03152809\r\n",
      "Epoch:  82 Step:   611 /   793 Train loss: 0.01631618\r\n",
      "Epoch:  82 Step:   612 /   793 Train loss: 0.03198430\r\n",
      "Epoch:  82 Step:   613 /   793 Train loss: 0.02593810\r\n",
      "Epoch:  82 Step:   614 /   793 Train loss: 0.01240350\r\n",
      "Epoch:  82 Step:   615 /   793 Train loss: 0.02842602\r\n",
      "Epoch:  82 Step:   616 /   793 Train loss: 0.02549595\r\n",
      "Epoch:  82 Step:   617 /   793 Train loss: 0.02594071\r\n",
      "Epoch:  82 Step:   618 /   793 Train loss: 0.03765189\r\n",
      "Epoch:  82 Step:   619 /   793 Train loss: 0.01733599\r\n",
      "Epoch:  82 Step:   620 /   793 Train loss: 0.04665347\r\n",
      "Epoch:  82 Step:   621 /   793 Train loss: 0.01778698\r\n",
      "Epoch:  82 Step:   622 /   793 Train loss: 0.01656091\r\n",
      "Epoch:  82 Step:   623 /   793 Train loss: 0.03642021\r\n",
      "Epoch:  82 Step:   624 /   793 Train loss: 0.01945579\r\n",
      "Epoch:  82 Step:   625 /   793 Train loss: 0.03426966\r\n",
      "Epoch:  82 Step:   626 /   793 Train loss: 0.02682840\r\n",
      "Epoch:  82 Step:   627 /   793 Train loss: 0.01604863\r\n",
      "Epoch:  82 Step:   628 /   793 Train loss: 0.02000458\r\n",
      "Epoch:  82 Step:   629 /   793 Train loss: 0.02947903\r\n",
      "Epoch:  82 Step:   630 /   793 Train loss: 0.02465056\r\n",
      "Epoch:  82 Step:   631 /   793 Train loss: 0.02805144\r\n",
      "Epoch:  82 Step:   632 /   793 Train loss: 0.04068436\r\n",
      "Epoch:  82 Step:   633 /   793 Train loss: 0.01153308\r\n",
      "Epoch:  82 Step:   634 /   793 Train loss: 0.02371509\r\n",
      "Epoch:  82 Step:   635 /   793 Train loss: 0.03112316\r\n",
      "Epoch:  82 Step:   636 /   793 Train loss: 0.02324948\r\n",
      "Epoch:  82 Step:   637 /   793 Train loss: 0.02161610\r\n",
      "Epoch:  82 Step:   638 /   793 Train loss: 0.01174761\r\n",
      "Epoch:  82 Step:   639 /   793 Train loss: 0.02539205\r\n",
      "Epoch:  82 Step:   640 /   793 Train loss: 0.02092096\r\n",
      "Epoch:  82 Step:   641 /   793 Train loss: 0.01983415\r\n",
      "Epoch:  82 Step:   642 /   793 Train loss: 0.03641515\r\n",
      "Epoch:  82 Step:   643 /   793 Train loss: 0.02481821\r\n",
      "Epoch:  82 Step:   644 /   793 Train loss: 0.03325430\r\n",
      "Epoch:  82 Step:   645 /   793 Train loss: 0.03140581\r\n",
      "Epoch:  82 Step:   646 /   793 Train loss: 0.01592844\r\n",
      "Epoch:  82 Step:   647 /   793 Train loss: 0.01238801\r\n",
      "Epoch:  82 Step:   648 /   793 Train loss: 0.02622664\r\n",
      "Epoch:  82 Step:   649 /   793 Train loss: 0.01645366\r\n",
      "Epoch:  82 Step:   650 /   793 Train loss: 0.01224850\r\n",
      "Epoch:  82 Step:   651 /   793 Train loss: 0.02841143\r\n",
      "Epoch:  82 Step:   652 /   793 Train loss: 0.02101841\r\n",
      "Epoch:  82 Step:   653 /   793 Train loss: 0.02536250\r\n",
      "Epoch:  82 Step:   654 /   793 Train loss: 0.02940888\r\n",
      "Epoch:  82 Step:   655 /   793 Train loss: 0.02586533\r\n",
      "Epoch:  82 Step:   656 /   793 Train loss: 0.01918217\r\n",
      "Epoch:  82 Step:   657 /   793 Train loss: 0.01124091\r\n",
      "Epoch:  82 Step:   658 /   793 Train loss: 0.01036248\r\n",
      "Epoch:  82 Step:   659 /   793 Train loss: 0.02012155\r\n",
      "Epoch:  82 Step:   660 /   793 Train loss: 0.01883527\r\n",
      "Epoch:  82 Step:   661 /   793 Train loss: 0.02237751\r\n",
      "Epoch:  82 Step:   662 /   793 Train loss: 0.03709907\r\n",
      "Epoch:  82 Step:   663 /   793 Train loss: 0.03724620\r\n",
      "Epoch:  82 Step:   664 /   793 Train loss: 0.03161497\r\n",
      "Epoch:  82 Step:   665 /   793 Train loss: 0.03052771\r\n",
      "Epoch:  82 Step:   666 /   793 Train loss: 0.02925904\r\n",
      "Epoch:  82 Step:   667 /   793 Train loss: 0.02317031\r\n",
      "Epoch:  82 Step:   668 /   793 Train loss: 0.01005545\r\n",
      "Epoch:  82 Step:   669 /   793 Train loss: 0.03056495\r\n",
      "Epoch:  82 Step:   670 /   793 Train loss: 0.01465600\r\n",
      "Epoch:  82 Step:   671 /   793 Train loss: 0.03138027\r\n",
      "Epoch:  82 Step:   672 /   793 Train loss: 0.02634500\r\n",
      "Epoch:  82 Step:   673 /   793 Train loss: 0.02363617\r\n",
      "Epoch:  82 Step:   674 /   793 Train loss: 0.03042424\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  82 Step:   675 /   793 Train loss: 0.02606497\r\n",
      "Epoch:  82 Step:   676 /   793 Train loss: 0.02385456\r\n",
      "Epoch:  82 Step:   677 /   793 Train loss: 0.01751518\r\n",
      "Epoch:  82 Step:   678 /   793 Train loss: 0.02002942\r\n",
      "Epoch:  82 Step:   679 /   793 Train loss: 0.02203025\r\n",
      "Epoch:  82 Step:   680 /   793 Train loss: 0.02906047\r\n",
      "Epoch:  82 Step:   681 /   793 Train loss: 0.03447751\r\n",
      "Epoch:  82 Step:   682 /   793 Train loss: 0.04366115\r\n",
      "Epoch:  82 Step:   683 /   793 Train loss: 0.01721606\r\n",
      "Epoch:  82 Step:   684 /   793 Train loss: 0.01546568\r\n",
      "Epoch:  82 Step:   685 /   793 Train loss: 0.02042313\r\n",
      "Epoch:  82 Step:   686 /   793 Train loss: 0.01939763\r\n",
      "Epoch:  82 Step:   687 /   793 Train loss: 0.03246592\r\n",
      "Epoch:  82 Step:   688 /   793 Train loss: 0.01905110\r\n",
      "Epoch:  82 Step:   689 /   793 Train loss: 0.04356962\r\n",
      "Epoch:  82 Step:   690 /   793 Train loss: 0.01352008\r\n",
      "Epoch:  82 Step:   691 /   793 Train loss: 0.01771543\r\n",
      "Epoch:  82 Step:   692 /   793 Train loss: 0.03075628\r\n",
      "Epoch:  82 Step:   693 /   793 Train loss: 0.02730129\r\n",
      "Epoch:  82 Step:   694 /   793 Train loss: 0.01647148\r\n",
      "Epoch:  82 Step:   695 /   793 Train loss: 0.01758823\r\n",
      "Epoch:  82 Step:   696 /   793 Train loss: 0.02031328\r\n",
      "Epoch:  82 Step:   697 /   793 Train loss: 0.02385688\r\n",
      "Epoch:  82 Step:   698 /   793 Train loss: 0.02605520\r\n",
      "Epoch:  82 Step:   699 /   793 Train loss: 0.02373364\r\n",
      "Epoch:  82 Step:   700 /   793 Train loss: 0.02305634\r\n",
      "Epoch:  82 Step:   701 /   793 Train loss: 0.02643028\r\n",
      "Epoch:  82 Step:   702 /   793 Train loss: 0.02522074\r\n",
      "Epoch:  82 Step:   703 /   793 Train loss: 0.02852380\r\n",
      "Epoch:  82 Step:   704 /   793 Train loss: 0.02296712\r\n",
      "Epoch:  82 Step:   705 /   793 Train loss: 0.01860674\r\n",
      "Epoch:  82 Step:   706 /   793 Train loss: 0.02693361\r\n",
      "Epoch:  82 Step:   707 /   793 Train loss: 0.02589472\r\n",
      "Epoch:  82 Step:   708 /   793 Train loss: 0.02610189\r\n",
      "Epoch:  82 Step:   709 /   793 Train loss: 0.03138540\r\n",
      "Epoch:  82 Step:   710 /   793 Train loss: 0.01969557\r\n",
      "Epoch:  82 Step:   711 /   793 Train loss: 0.03275011\r\n",
      "Epoch:  82 Step:   712 /   793 Train loss: 0.02099351\r\n",
      "Epoch:  82 Step:   713 /   793 Train loss: 0.03573167\r\n",
      "Epoch:  82 Step:   714 /   793 Train loss: 0.01980746\r\n",
      "Epoch:  82 Step:   715 /   793 Train loss: 0.02829913\r\n",
      "Epoch:  82 Step:   716 /   793 Train loss: 0.03745528\r\n",
      "Epoch:  82 Step:   717 /   793 Train loss: 0.01327353\r\n",
      "Epoch:  82 Step:   718 /   793 Train loss: 0.03117798\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  82 Step:   719 /   793 Train loss: 0.01902999\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  82 Step:   720 /   793 Train loss: 0.02851733\r\n",
      "Epoch:  82 Step:   721 /   793 Train loss: 0.03123401\r\n",
      "Epoch:  82 Step:   722 /   793 Train loss: 0.01541772\r\n",
      "Epoch:  82 Step:   723 /   793 Train loss: 0.02956394\r\n",
      "Epoch:  82 Step:   724 /   793 Train loss: 0.01335948\r\n",
      "Epoch:  82 Step:   725 /   793 Train loss: 0.02412710\r\n",
      "Epoch:  82 Step:   726 /   793 Train loss: 0.01803138\r\n",
      "Epoch:  82 Step:   727 /   793 Train loss: 0.02032409\r\n",
      "Epoch:  82 Step:   728 /   793 Train loss: 0.03536089\r\n",
      "Epoch:  82 Step:   729 /   793 Train loss: 0.02182125\r\n",
      "Epoch:  82 Step:   730 /   793 Train loss: 0.03416204\r\n",
      "Epoch:  82 Step:   731 /   793 Train loss: 0.03258704\r\n",
      "Epoch:  82 Step:   732 /   793 Train loss: 0.02765822\r\n",
      "Epoch:  82 Step:   733 /   793 Train loss: 0.03163593\r\n",
      "Epoch:  82 Step:   734 /   793 Train loss: 0.02827137\r\n",
      "Epoch:  82 Step:   735 /   793 Train loss: 0.01734814\r\n",
      "Epoch:  82 Step:   736 /   793 Train loss: 0.01340850\r\n",
      "Epoch:  82 Step:   737 /   793 Train loss: 0.02527110\r\n",
      "Epoch:  82 Step:   738 /   793 Train loss: 0.02036594\r\n",
      "Epoch:  82 Step:   739 /   793 Train loss: 0.02777174\r\n",
      "Epoch:  82 Step:   740 /   793 Train loss: 0.03921960\r\n",
      "Epoch:  82 Step:   741 /   793 Train loss: 0.02090103\r\n",
      "Epoch:  82 Step:   742 /   793 Train loss: 0.02517230\r\n",
      "Epoch:  82 Step:   743 /   793 Train loss: 0.01930860\r\n",
      "Epoch:  82 Step:   744 /   793 Train loss: 0.02256904\r\n",
      "Epoch:  82 Step:   745 /   793 Train loss: 0.04017825\r\n",
      "Epoch:  82 Step:   746 /   793 Train loss: 0.01845549\r\n",
      "Epoch:  82 Step:   747 /   793 Train loss: 0.01866676\r\n",
      "Epoch:  82 Step:   748 /   793 Train loss: 0.01476048\r\n",
      "Epoch:  82 Step:   749 /   793 Train loss: 0.03029036\r\n",
      "Epoch:  82 Step:   750 /   793 Train loss: 0.02136567\r\n",
      "Epoch:  82 Step:   751 /   793 Train loss: 0.03106287\r\n",
      "Epoch:  82 Step:   752 /   793 Train loss: 0.01376946\r\n",
      "Epoch:  82 Step:   753 /   793 Train loss: 0.03100953\r\n",
      "Epoch:  82 Step:   754 /   793 Train loss: 0.02805243\r\n",
      "Epoch:  82 Step:   755 /   793 Train loss: 0.03504026\r\n",
      "Epoch:  82 Step:   756 /   793 Train loss: 0.03778084\r\n",
      "Epoch:  82 Step:   757 /   793 Train loss: 0.01328045\r\n",
      "Epoch:  82 Step:   758 /   793 Train loss: 0.02307747\r\n",
      "Epoch:  82 Step:   759 /   793 Train loss: 0.02272359\r\n",
      "Epoch:  82 Step:   760 /   793 Train loss: 0.03223565\r\n",
      "Epoch:  82 Step:   761 /   793 Train loss: 0.02098282\r\n",
      "Epoch:  82 Step:   762 /   793 Train loss: 0.02173847\r\n",
      "Epoch:  82 Step:   763 /   793 Train loss: 0.02421898\r\n",
      "Epoch:  82 Step:   764 /   793 Train loss: 0.03824784\r\n",
      "Epoch:  82 Step:   765 /   793 Train loss: 0.02376100\r\n",
      "Epoch:  82 Step:   766 /   793 Train loss: 0.02158645\r\n",
      "Epoch:  82 Step:   767 /   793 Train loss: 0.02209767\r\n",
      "Epoch:  82 Step:   768 /   793 Train loss: 0.02495831\r\n",
      "Epoch:  82 Step:   769 /   793 Train loss: 0.02785725\r\n",
      "Epoch:  82 Step:   770 /   793 Train loss: 0.01665508\r\n",
      "Epoch:  82 Step:   771 /   793 Train loss: 0.02179785\r\n",
      "Epoch:  82 Step:   772 /   793 Train loss: 0.02520729\r\n",
      "Epoch:  82 Step:   773 /   793 Train loss: 0.02099777\r\n",
      "Epoch:  82 Step:   774 /   793 Train loss: 0.02257442\r\n",
      "Epoch:  82 Step:   775 /   793 Train loss: 0.01253269\r\n",
      "Epoch:  82 Step:   776 /   793 Train loss: 0.02579574\r\n",
      "Epoch:  82 Step:   777 /   793 Train loss: 0.03689665\r\n",
      "Epoch:  82 Step:   778 /   793 Train loss: 0.02037210\r\n",
      "Epoch:  82 Step:   779 /   793 Train loss: 0.02378322\r\n",
      "Epoch:  82 Step:   780 /   793 Train loss: 0.02818955\r\n",
      "Epoch:  82 Step:   781 /   793 Train loss: 0.02234989\r\n",
      "Epoch:  82 Step:   782 /   793 Train loss: 0.02748084\r\n",
      "Epoch:  82 Step:   783 /   793 Train loss: 0.01851935\r\n",
      "Epoch:  82 Step:   784 /   793 Train loss: 0.03526360\r\n",
      "Epoch:  82 Step:   785 /   793 Train loss: 0.02258433\r\n",
      "Epoch:  82 Step:   786 /   793 Train loss: 0.02244786\r\n",
      "Epoch:  82 Step:   787 /   793 Train loss: 0.03361642\r\n",
      "Epoch:  82 Step:   788 /   793 Train loss: 0.03213940\r\n",
      "Epoch:  82 Step:   789 /   793 Train loss: 0.03931296\r\n",
      "Epoch:  82 Step:   790 /   793 Train loss: 0.01858673\r\n",
      "Epoch:  82 Step:   791 /   793 Train loss: 0.01829473\r\n",
      "Epoch:  82 Step:   792 /   793 Train loss: 0.02839250\r\n",
      "Epoch:  83 Step:     0 /   793 Train loss: 0.02687434\r\n",
      "Epoch:  83 Step:     1 /   793 Train loss: 0.01506325\r\n",
      "Epoch:  83 Step:     2 /   793 Train loss: 0.01841876\r\n",
      "Epoch:  83 Step:     3 /   793 Train loss: 0.02122296\r\n",
      "Epoch:  83 Step:     4 /   793 Train loss: 0.01949739\r\n",
      "Epoch:  83 Step:     5 /   793 Train loss: 0.02762669\r\n",
      "Epoch:  83 Step:     6 /   793 Train loss: 0.02214864\r\n",
      "Epoch:  83 Step:     7 /   793 Train loss: 0.02362442\r\n",
      "Epoch:  83 Step:     8 /   793 Train loss: 0.02605863\r\n",
      "Epoch:  83 Step:     9 /   793 Train loss: 0.02834002\r\n",
      "Epoch:  83 Step:    10 /   793 Train loss: 0.02552138\r\n",
      "Epoch:  83 Step:    11 /   793 Train loss: 0.03109905\r\n",
      "Epoch:  83 Step:    12 /   793 Train loss: 0.02222279\r\n",
      "Epoch:  83 Step:    13 /   793 Train loss: 0.01897214\r\n",
      "Epoch:  83 Step:    14 /   793 Train loss: 0.01809800\r\n",
      "Epoch:  83 Step:    15 /   793 Train loss: 0.02115596\r\n",
      "Epoch:  83 Step:    16 /   793 Train loss: 0.03042462\r\n",
      "Epoch:  83 Step:    17 /   793 Train loss: 0.01604530\r\n",
      "Epoch:  83 Step:    18 /   793 Train loss: 0.02804721\r\n",
      "Epoch:  83 Step:    19 /   793 Train loss: 0.02438708\r\n",
      "Epoch:  83 Step:    20 /   793 Train loss: 0.04023221\r\n",
      "Epoch:  83 Step:    21 /   793 Train loss: 0.02386630\r\n",
      "Epoch:  83 Step:    22 /   793 Train loss: 0.01467966\r\n",
      "Epoch:  83 Step:    23 /   793 Train loss: 0.01728981\r\n",
      "Epoch:  83 Step:    24 /   793 Train loss: 0.02645556\r\n",
      "Epoch:  83 Step:    25 /   793 Train loss: 0.01716883\r\n",
      "Epoch:  83 Step:    26 /   793 Train loss: 0.01710970\r\n",
      "Epoch:  83 Step:    27 /   793 Train loss: 0.01342159\r\n",
      "Epoch:  83 Step:    28 /   793 Train loss: 0.02135800\r\n",
      "Epoch:  83 Step:    29 /   793 Train loss: 0.01373752\r\n",
      "Epoch:  83 Step:    30 /   793 Train loss: 0.02914270\r\n",
      "Epoch:  83 Step:    31 /   793 Train loss: 0.02594388\r\n",
      "Epoch:  83 Step:    32 /   793 Train loss: 0.01573155\r\n",
      "Epoch:  83 Step:    33 /   793 Train loss: 0.02293049\r\n",
      "Epoch:  83 Step:    34 /   793 Train loss: 0.01799923\r\n",
      "Epoch:  83 Step:    35 /   793 Train loss: 0.02577613\r\n",
      "Epoch:  83 Step:    36 /   793 Train loss: 0.02572159\r\n",
      "Epoch:  83 Step:    37 /   793 Train loss: 0.02278542\r\n",
      "Epoch:  83 Step:    38 /   793 Train loss: 0.02257651\r\n",
      "Epoch:  83 Step:    39 /   793 Train loss: 0.01869461\r\n",
      "Epoch:  83 Step:    40 /   793 Train loss: 0.02184360\r\n",
      "Epoch:  83 Step:    41 /   793 Train loss: 0.01987763\r\n",
      "Epoch:  83 Step:    42 /   793 Train loss: 0.01410808\r\n",
      "Epoch:  83 Step:    43 /   793 Train loss: 0.02557965\r\n",
      "Epoch:  83 Step:    44 /   793 Train loss: 0.01854026\r\n",
      "Epoch:  83 Step:    45 /   793 Train loss: 0.03316820\r\n",
      "Epoch:  83 Step:    46 /   793 Train loss: 0.03245104\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  83 Step:    47 /   793 Train loss: 0.03212843\r\n",
      "Epoch:  83 Step:    48 /   793 Train loss: 0.02598953\r\n",
      "Epoch:  83 Step:    49 /   793 Train loss: 0.02360278\r\n",
      "Epoch:  83 Step:    50 /   793 Train loss: 0.01903948\r\n",
      "Epoch:  83 Step:    51 /   793 Train loss: 0.01749861\r\n",
      "Epoch:  83 Step:    52 /   793 Train loss: 0.02326913\r\n",
      "Epoch:  83 Step:    53 /   793 Train loss: 0.01636221\r\n",
      "Epoch:  83 Step:    54 /   793 Train loss: 0.01483513\r\n",
      "Epoch:  83 Step:    55 /   793 Train loss: 0.02165558\r\n",
      "Epoch:  83 Step:    56 /   793 Train loss: 0.03244628\r\n",
      "Epoch:  83 Step:    57 /   793 Train loss: 0.01746279\r\n",
      "Epoch:  83 Step:    58 /   793 Train loss: 0.01955568\r\n",
      "Epoch:  83 Step:    59 /   793 Train loss: 0.03562846\r\n",
      "Epoch:  83 Step:    60 /   793 Train loss: 0.02014075\r\n",
      "Epoch:  83 Step:    61 /   793 Train loss: 0.02392264\r\n",
      "Epoch:  83 Step:    62 /   793 Train loss: 0.02082220\r\n",
      "Epoch:  83 Step:    63 /   793 Train loss: 0.02350545\r\n",
      "Epoch:  83 Step:    64 /   793 Train loss: 0.02536255\r\n",
      "Epoch:  83 Step:    65 /   793 Train loss: 0.03812298\r\n",
      "Epoch:  83 Step:    66 /   793 Train loss: 0.02284754\r\n",
      "Epoch:  83 Step:    67 /   793 Train loss: 0.01316183\r\n",
      "Epoch:  83 Step:    68 /   793 Train loss: 0.02591398\r\n",
      "Epoch:  83 Step:    69 /   793 Train loss: 0.03437365\r\n",
      "Epoch:  83 Step:    70 /   793 Train loss: 0.03061432\r\n",
      "Epoch:  83 Step:    71 /   793 Train loss: 0.02113193\r\n",
      "Epoch:  83 Step:    72 /   793 Train loss: 0.01414729\r\n",
      "Epoch:  83 Step:    73 /   793 Train loss: 0.01524570\r\n",
      "Epoch:  83 Step:    74 /   793 Train loss: 0.02956760\r\n",
      "Epoch:  83 Step:    75 /   793 Train loss: 0.02373325\r\n",
      "Epoch:  83 Step:    76 /   793 Train loss: 0.01666807\r\n",
      "Epoch:  83 Step:    77 /   793 Train loss: 0.02350354\r\n",
      "Epoch:  83 Step:    78 /   793 Train loss: 0.04225566\r\n",
      "Epoch:  83 Step:    79 /   793 Train loss: 0.03553832\r\n",
      "Epoch:  83 Step:    80 /   793 Train loss: 0.02071848\r\n",
      "Epoch:  83 Step:    81 /   793 Train loss: 0.03855154\r\n",
      "Epoch:  83 Step:    82 /   793 Train loss: 0.02311092\r\n",
      "Epoch:  83 Step:    83 /   793 Train loss: 0.01699362\r\n",
      "Epoch:  83 Step:    84 /   793 Train loss: 0.02835256\r\n",
      "Epoch:  83 Step:    85 /   793 Train loss: 0.02590501\r\n",
      "Epoch:  83 Step:    86 /   793 Train loss: 0.02749740\r\n",
      "Epoch:  83 Step:    87 /   793 Train loss: 0.03638147\r\n",
      "Epoch:  83 Step:    88 /   793 Train loss: 0.01878640\r\n",
      "Epoch:  83 Step:    89 /   793 Train loss: 0.01510446\r\n",
      "Epoch:  83 Step:    90 /   793 Train loss: 0.02663284\r\n",
      "Epoch:  83 Step:    91 /   793 Train loss: 0.02372918\r\n",
      "Epoch:  83 Step:    92 /   793 Train loss: 0.01534786\r\n",
      "Epoch:  83 Step:    93 /   793 Train loss: 0.02338550\r\n",
      "Epoch:  83 Step:    94 /   793 Train loss: 0.01345927\r\n",
      "Epoch:  83 Step:    95 /   793 Train loss: 0.02960764\r\n",
      "Epoch:  83 Step:    96 /   793 Train loss: 0.02256157\r\n",
      "Epoch:  83 Step:    97 /   793 Train loss: 0.01792137\r\n",
      "Epoch:  83 Step:    98 /   793 Train loss: 0.02918838\r\n",
      "Epoch:  83 Step:    99 /   793 Train loss: 0.02252771\r\n",
      "Epoch:  83 Step:   100 /   793 Train loss: 0.02058970\r\n",
      "Epoch:  83 Step:   101 /   793 Train loss: 0.01471896\r\n",
      "Epoch:  83 Step:   102 /   793 Train loss: 0.02520414\r\n",
      "Epoch:  83 Step:   103 /   793 Train loss: 0.02337730\r\n",
      "Epoch:  83 Step:   104 /   793 Train loss: 0.02231684\r\n",
      "Epoch:  83 Step:   105 /   793 Train loss: 0.02105884\r\n",
      "Epoch:  83 Step:   106 /   793 Train loss: 0.02726706\r\n",
      "Epoch:  83 Step:   107 /   793 Train loss: 0.02263352\r\n",
      "Epoch:  83 Step:   108 /   793 Train loss: 0.03008686\r\n",
      "Epoch:  83 Step:   109 /   793 Train loss: 0.02097007\r\n",
      "Epoch:  83 Step:   110 /   793 Train loss: 0.02373437\r\n",
      "Epoch:  83 Step:   111 /   793 Train loss: 0.03264246\r\n",
      "Epoch:  83 Step:   112 /   793 Train loss: 0.03205912\r\n",
      "Epoch:  83 Step:   113 /   793 Train loss: 0.02130107\r\n",
      "Epoch:  83 Step:   114 /   793 Train loss: 0.02821796\r\n",
      "Epoch:  83 Step:   115 /   793 Train loss: 0.03032845\r\n",
      "Epoch:  83 Step:   116 /   793 Train loss: 0.02545542\r\n",
      "Epoch:  83 Step:   117 /   793 Train loss: 0.03200519\r\n",
      "Epoch:  83 Step:   118 /   793 Train loss: 0.03362371\r\n",
      "Epoch:  83 Step:   119 /   793 Train loss: 0.03727359\r\n",
      "Epoch:  83 Step:   120 /   793 Train loss: 0.04800757\r\n",
      "Epoch:  83 Step:   121 /   793 Train loss: 0.02629245\r\n",
      "Epoch:  83 Step:   122 /   793 Train loss: 0.02738403\r\n",
      "Epoch:  83 Step:   123 /   793 Train loss: 0.03026892\r\n",
      "Epoch:  83 Step:   124 /   793 Train loss: 0.02107816\r\n",
      "Epoch:  83 Step:   125 /   793 Train loss: 0.02206768\r\n",
      "Epoch:  83 Step:   126 /   793 Train loss: 0.02143167\r\n",
      "Epoch:  83 Step:   127 /   793 Train loss: 0.02246548\r\n",
      "Epoch:  83 Step:   128 /   793 Train loss: 0.01531647\r\n",
      "Epoch:  83 Step:   129 /   793 Train loss: 0.01610124\r\n",
      "Epoch:  83 Step:   130 /   793 Train loss: 0.02347958\r\n",
      "Epoch:  83 Step:   131 /   793 Train loss: 0.02528021\r\n",
      "Epoch:  83 Step:   132 /   793 Train loss: 0.02886378\r\n",
      "Epoch:  83 Step:   133 /   793 Train loss: 0.03281331\r\n",
      "Epoch:  83 Step:   134 /   793 Train loss: 0.03170129\r\n",
      "Epoch:  83 Step:   135 /   793 Train loss: 0.01433572\r\n",
      "Epoch:  83 Step:   136 /   793 Train loss: 0.02632288\r\n",
      "Epoch:  83 Step:   137 /   793 Train loss: 0.02436686\r\n",
      "Epoch:  83 Step:   138 /   793 Train loss: 0.03735116\r\n",
      "Epoch:  83 Step:   139 /   793 Train loss: 0.02959900\r\n",
      "Epoch:  83 Step:   140 /   793 Train loss: 0.03328528\r\n",
      "Epoch:  83 Step:   141 /   793 Train loss: 0.02230630\r\n",
      "Epoch:  83 Step:   142 /   793 Train loss: 0.01438906\r\n",
      "Epoch:  83 Step:   143 /   793 Train loss: 0.01759315\r\n",
      "Epoch:  83 Step:   144 /   793 Train loss: 0.02526797\r\n",
      "Epoch:  83 Step:   145 /   793 Train loss: 0.01792627\r\n",
      "Epoch:  83 Step:   146 /   793 Train loss: 0.01792489\r\n",
      "Epoch:  83 Step:   147 /   793 Train loss: 0.02963592\r\n",
      "Epoch:  83 Step:   148 /   793 Train loss: 0.02986441\r\n",
      "Epoch:  83 Step:   149 /   793 Train loss: 0.02349562\r\n",
      "Epoch:  83 Step:   150 /   793 Train loss: 0.02557372\r\n",
      "Epoch:  83 Step:   151 /   793 Train loss: 0.03474884\r\n",
      "Epoch:  83 Step:   152 /   793 Train loss: 0.02681521\r\n",
      "Epoch:  83 Step:   153 /   793 Train loss: 0.02016657\r\n",
      "Epoch:  83 Step:   154 /   793 Train loss: 0.01195097\r\n",
      "Epoch:  83 Step:   155 /   793 Train loss: 0.02910367\r\n",
      "Epoch:  83 Step:   156 /   793 Train loss: 0.02190985\r\n",
      "Epoch:  83 Step:   157 /   793 Train loss: 0.02171260\r\n",
      "Epoch:  83 Step:   158 /   793 Train loss: 0.02037735\r\n",
      "Epoch:  83 Step:   159 /   793 Train loss: 0.01645550\r\n",
      "Epoch:  83 Step:   160 /   793 Train loss: 0.02185781\r\n",
      "Epoch:  83 Step:   161 /   793 Train loss: 0.03208986\r\n",
      "Epoch:  83 Step:   162 /   793 Train loss: 0.04233082\r\n",
      "Epoch:  83 Step:   163 /   793 Train loss: 0.03437046\r\n",
      "Epoch:  83 Step:   164 /   793 Train loss: 0.03024136\r\n",
      "Epoch:  83 Step:   165 /   793 Train loss: 0.02415823\r\n",
      "Epoch:  83 Step:   166 /   793 Train loss: 0.02577565\r\n",
      "Epoch:  83 Step:   167 /   793 Train loss: 0.02658754\r\n",
      "Epoch:  83 Step:   168 /   793 Train loss: 0.02660785\r\n",
      "Epoch:  83 Step:   169 /   793 Train loss: 0.02711636\r\n",
      "Epoch:  83 Step:   170 /   793 Train loss: 0.01873416\r\n",
      "Epoch:  83 Step:   171 /   793 Train loss: 0.02547268\r\n",
      "Epoch:  83 Step:   172 /   793 Train loss: 0.02260304\r\n",
      "Epoch:  83 Step:   173 /   793 Train loss: 0.03267343\r\n",
      "Epoch:  83 Step:   174 /   793 Train loss: 0.02595064\r\n",
      "Epoch:  83 Step:   175 /   793 Train loss: 0.03083711\r\n",
      "Epoch:  83 Step:   176 /   793 Train loss: 0.02518802\r\n",
      "Epoch:  83 Step:   177 /   793 Train loss: 0.01509387\r\n",
      "Epoch:  83 Step:   178 /   793 Train loss: 0.02358315\r\n",
      "Epoch:  83 Step:   179 /   793 Train loss: 0.02481024\r\n",
      "Epoch:  83 Step:   180 /   793 Train loss: 0.02398711\r\n",
      "Epoch:  83 Step:   181 /   793 Train loss: 0.02346117\r\n",
      "Epoch:  83 Step:   182 /   793 Train loss: 0.02460885\r\n",
      "Epoch:  83 Step:   183 /   793 Train loss: 0.03383518\r\n",
      "Epoch:  83 Step:   184 /   793 Train loss: 0.01517750\r\n",
      "Epoch:  83 Step:   185 /   793 Train loss: 0.01902554\r\n",
      "Epoch:  83 Step:   186 /   793 Train loss: 0.01661030\r\n",
      "Epoch:  83 Step:   187 /   793 Train loss: 0.01679444\r\n",
      "Epoch:  83 Step:   188 /   793 Train loss: 0.01788380\r\n",
      "Epoch:  83 Step:   189 /   793 Train loss: 0.01208959\r\n",
      "Epoch:  83 Step:   190 /   793 Train loss: 0.01890989\r\n",
      "Epoch:  83 Step:   191 /   793 Train loss: 0.02173002\r\n",
      "Epoch:  83 Step:   192 /   793 Train loss: 0.02234583\r\n",
      "Epoch:  83 Step:   193 /   793 Train loss: 0.01907547\r\n",
      "Epoch:  83 Step:   194 /   793 Train loss: 0.02208620\r\n",
      "Epoch:  83 Step:   195 /   793 Train loss: 0.01523386\r\n",
      "Epoch:  83 Step:   196 /   793 Train loss: 0.01857054\r\n",
      "Epoch:  83 Step:   197 /   793 Train loss: 0.02766230\r\n",
      "Epoch:  83 Step:   198 /   793 Train loss: 0.02705373\r\n",
      "Epoch:  83 Step:   199 /   793 Train loss: 0.02644723\r\n",
      "Epoch:  83 Step:   200 /   793 Train loss: 0.01521492\r\n",
      "Epoch:  83 Step:   201 /   793 Train loss: 0.03001498\r\n",
      "Epoch:  83 Step:   202 /   793 Train loss: 0.01674565\r\n",
      "Epoch:  83 Step:   203 /   793 Train loss: 0.02524931\r\n",
      "Epoch:  83 Step:   204 /   793 Train loss: 0.02536577\r\n",
      "Epoch:  83 Step:   205 /   793 Train loss: 0.02391464\r\n",
      "Epoch:  83 Step:   206 /   793 Train loss: 0.02061912\r\n",
      "Epoch:  83 Step:   207 /   793 Train loss: 0.02891270\r\n",
      "Epoch:  83 Step:   208 /   793 Train loss: 0.02050553\r\n",
      "Epoch:  83 Step:   209 /   793 Train loss: 0.01830684\r\n",
      "Epoch:  83 Step:   210 /   793 Train loss: 0.02111762\r\n",
      "Epoch:  83 Step:   211 /   793 Train loss: 0.03117915\r\n",
      "Epoch:  83 Step:   212 /   793 Train loss: 0.03120515\r\n",
      "Epoch:  83 Step:   213 /   793 Train loss: 0.02715565\r\n",
      "Epoch:  83 Step:   214 /   793 Train loss: 0.02806912\r\n",
      "Epoch:  83 Step:   215 /   793 Train loss: 0.03641923\r\n",
      "Epoch:  83 Step:   216 /   793 Train loss: 0.02777087\r\n",
      "Epoch:  83 Step:   217 /   793 Train loss: 0.02671010\r\n",
      "Epoch:  83 Step:   218 /   793 Train loss: 0.03791986\r\n",
      "Epoch:  83 Step:   219 /   793 Train loss: 0.03008877\r\n",
      "Epoch:  83 Step:   220 /   793 Train loss: 0.01874139\r\n",
      "Epoch:  83 Step:   221 /   793 Train loss: 0.01315027\r\n",
      "Epoch:  83 Step:   222 /   793 Train loss: 0.02423247\r\n",
      "Epoch:  83 Step:   223 /   793 Train loss: 0.01671892\r\n",
      "Epoch:  83 Step:   224 /   793 Train loss: 0.02708233\r\n",
      "Epoch:  83 Step:   225 /   793 Train loss: 0.03846429\r\n",
      "Epoch:  83 Step:   226 /   793 Train loss: 0.01867712\r\n",
      "Epoch:  83 Step:   227 /   793 Train loss: 0.01706268\r\n",
      "Epoch:  83 Step:   228 /   793 Train loss: 0.02133930\r\n",
      "Epoch:  83 Step:   229 /   793 Train loss: 0.00927337\r\n",
      "Epoch:  83 Step:   230 /   793 Train loss: 0.01830516\r\n",
      "Epoch:  83 Step:   231 /   793 Train loss: 0.03032379\r\n",
      "Epoch:  83 Step:   232 /   793 Train loss: 0.02327022\r\n",
      "Epoch:  83 Step:   233 /   793 Train loss: 0.03261703\r\n",
      "Epoch:  83 Step:   234 /   793 Train loss: 0.02659848\r\n",
      "Epoch:  83 Step:   235 /   793 Train loss: 0.02555124\r\n",
      "Epoch:  83 Step:   236 /   793 Train loss: 0.02468413\r\n",
      "Epoch:  83 Step:   237 /   793 Train loss: 0.01579183\r\n",
      "Epoch:  83 Step:   238 /   793 Train loss: 0.02448711\r\n",
      "Epoch:  83 Step:   239 /   793 Train loss: 0.01857459\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  83 Step:   240 /   793 Train loss: 0.02129335\r\n",
      "Epoch:  83 Step:   241 /   793 Train loss: 0.01443930\r\n",
      "Epoch:  83 Step:   242 /   793 Train loss: 0.03391011\r\n",
      "Epoch:  83 Step:   243 /   793 Train loss: 0.02921884\r\n",
      "Epoch:  83 Step:   244 /   793 Train loss: 0.01915659\r\n",
      "Epoch:  83 Step:   245 /   793 Train loss: 0.02733374\r\n",
      "Epoch:  83 Step:   246 /   793 Train loss: 0.02379501\r\n",
      "Epoch:  83 Step:   247 /   793 Train loss: 0.01855833\r\n",
      "Epoch:  83 Step:   248 /   793 Train loss: 0.02650145\r\n",
      "Epoch:  83 Step:   249 /   793 Train loss: 0.03227141\r\n",
      "Epoch:  83 Step:   250 /   793 Train loss: 0.02891610\r\n",
      "Epoch:  83 Step:   251 /   793 Train loss: 0.02944364\r\n",
      "Epoch:  83 Step:   252 /   793 Train loss: 0.02214774\r\n",
      "Epoch:  83 Step:   253 /   793 Train loss: 0.02592587\r\n",
      "Epoch:  83 Step:   254 /   793 Train loss: 0.03197907\r\n",
      "Epoch:  83 Step:   255 /   793 Train loss: 0.02086621\r\n",
      "Epoch:  83 Step:   256 /   793 Train loss: 0.02475222\r\n",
      "Epoch:  83 Step:   257 /   793 Train loss: 0.02355066\r\n",
      "Epoch:  83 Step:   258 /   793 Train loss: 0.01233281\r\n",
      "Epoch:  83 Step:   259 /   793 Train loss: 0.02328540\r\n",
      "Epoch:  83 Step:   260 /   793 Train loss: 0.01366579\r\n",
      "Epoch:  83 Step:   261 /   793 Train loss: 0.03245811\r\n",
      "Epoch:  83 Step:   262 /   793 Train loss: 0.01591469\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  83 Step:   263 /   793 Train loss: 0.02011931\r\n",
      "Epoch:  83 Step:   264 /   793 Train loss: 0.02819943\r\n",
      "Epoch:  83 Step:   265 /   793 Train loss: 0.02772658\r\n",
      "Epoch:  83 Step:   266 /   793 Train loss: 0.02224896\r\n",
      "Epoch:  83 Step:   267 /   793 Train loss: 0.02385910\r\n",
      "Epoch:  83 Step:   268 /   793 Train loss: 0.02872258\r\n",
      "Epoch:  83 Step:   269 /   793 Train loss: 0.02132125\r\n",
      "Epoch:  83 Step:   270 /   793 Train loss: 0.02425831\r\n",
      "Epoch:  83 Step:   271 /   793 Train loss: 0.02126415\r\n",
      "Epoch:  83 Step:   272 /   793 Train loss: 0.01531285\r\n",
      "Epoch:  83 Step:   273 /   793 Train loss: 0.02431908\r\n",
      "Epoch:  83 Step:   274 /   793 Train loss: 0.01798854\r\n",
      "Epoch:  83 Step:   275 /   793 Train loss: 0.02258107\r\n",
      "Epoch:  83 Step:   276 /   793 Train loss: 0.03199836\r\n",
      "Epoch:  83 Step:   277 /   793 Train loss: 0.02856743\r\n",
      "Epoch:  83 Step:   278 /   793 Train loss: 0.02041373\r\n",
      "Epoch:  83 Step:   279 /   793 Train loss: 0.02850490\r\n",
      "Epoch:  83 Step:   280 /   793 Train loss: 0.01792384\r\n",
      "Epoch:  83 Step:   281 /   793 Train loss: 0.02104865\r\n",
      "Epoch:  83 Step:   282 /   793 Train loss: 0.03503142\r\n",
      "Epoch:  83 Step:   283 /   793 Train loss: 0.02840666\r\n",
      "Epoch:  83 Step:   284 /   793 Train loss: 0.02270992\r\n",
      "Epoch:  83 Step:   285 /   793 Train loss: 0.03076743\r\n",
      "Epoch:  83 Step:   286 /   793 Train loss: 0.03108274\r\n",
      "Epoch:  83 Step:   287 /   793 Train loss: 0.02372469\r\n",
      "Epoch:  83 Step:   288 /   793 Train loss: 0.02972977\r\n",
      "Epoch:  83 Step:   289 /   793 Train loss: 0.01894203\r\n",
      "Epoch:  83 Step:   290 /   793 Train loss: 0.02995239\r\n",
      "Epoch:  83 Step:   291 /   793 Train loss: 0.02045007\r\n",
      "Epoch:  83 Step:   292 /   793 Train loss: 0.02058654\r\n",
      "Epoch:  83 Step:   293 /   793 Train loss: 0.02786968\r\n",
      "Epoch:  83 Step:   294 /   793 Train loss: 0.01377044\r\n",
      "Epoch:  83 Step:   295 /   793 Train loss: 0.02471141\r\n",
      "Epoch:  83 Step:   296 /   793 Train loss: 0.03009540\r\n",
      "Epoch:  83 Step:   297 /   793 Train loss: 0.01619577\r\n",
      "Epoch:  83 Step:   298 /   793 Train loss: 0.01897937\r\n",
      "Epoch:  83 Step:   299 /   793 Train loss: 0.02181888\r\n",
      "Epoch:  83 Step:   300 /   793 Train loss: 0.01875610\r\n",
      "Epoch:  83 Step:   301 /   793 Train loss: 0.03782155\r\n",
      "Epoch:  83 Step:   302 /   793 Train loss: 0.02459936\r\n",
      "Epoch:  83 Step:   303 /   793 Train loss: 0.02706223\r\n",
      "Epoch:  83 Step:   304 /   793 Train loss: 0.02446561\r\n",
      "Epoch:  83 Step:   305 /   793 Train loss: 0.02272987\r\n",
      "Epoch:  83 Step:   306 /   793 Train loss: 0.02659740\r\n",
      "Epoch:  83 Step:   307 /   793 Train loss: 0.02486776\r\n",
      "Epoch:  83 Step:   308 /   793 Train loss: 0.02711040\r\n",
      "Epoch:  83 Step:   309 /   793 Train loss: 0.01936237\r\n",
      "Epoch:  83 Step:   310 /   793 Train loss: 0.01236727\r\n",
      "Epoch:  83 Step:   311 /   793 Train loss: 0.03394493\r\n",
      "Epoch:  83 Step:   312 /   793 Train loss: 0.02312880\r\n",
      "Epoch:  83 Step:   313 /   793 Train loss: 0.02879896\r\n",
      "Epoch:  83 Step:   314 /   793 Train loss: 0.01784278\r\n",
      "Epoch:  83 Step:   315 /   793 Train loss: 0.03688509\r\n",
      "Epoch:  83 Step:   316 /   793 Train loss: 0.02619769\r\n",
      "Epoch:  83 Step:   317 /   793 Train loss: 0.01583987\r\n",
      "Epoch:  83 Step:   318 /   793 Train loss: 0.02022123\r\n",
      "Epoch:  83 Step:   319 /   793 Train loss: 0.03146175\r\n",
      "Epoch:  83 Step:   320 /   793 Train loss: 0.02001945\r\n",
      "Epoch:  83 Step:   321 /   793 Train loss: 0.01524741\r\n",
      "Epoch:  83 Step:   322 /   793 Train loss: 0.02002472\r\n",
      "Epoch:  83 Step:   323 /   793 Train loss: 0.03907736\r\n",
      "Epoch:  83 Step:   324 /   793 Train loss: 0.02394257\r\n",
      "Epoch:  83 Step:   325 /   793 Train loss: 0.03365666\r\n",
      "Epoch:  83 Step:   326 /   793 Train loss: 0.03587043\r\n",
      "Epoch:  83 Step:   327 /   793 Train loss: 0.02906976\r\n",
      "Epoch:  83 Step:   328 /   793 Train loss: 0.02748443\r\n",
      "Epoch:  83 Step:   329 /   793 Train loss: 0.03322938\r\n",
      "Epoch:  83 Step:   330 /   793 Train loss: 0.01117377\r\n",
      "Epoch:  83 Step:   331 /   793 Train loss: 0.03611131\r\n",
      "Epoch:  83 Step:   332 /   793 Train loss: 0.02323862\r\n",
      "Epoch:  83 Step:   333 /   793 Train loss: 0.03492553\r\n",
      "Epoch:  83 Step:   334 /   793 Train loss: 0.02841105\r\n",
      "Epoch:  83 Step:   335 /   793 Train loss: 0.02705909\r\n",
      "Epoch:  83 Step:   336 /   793 Train loss: 0.02635199\r\n",
      "Epoch:  83 Step:   337 /   793 Train loss: 0.01589213\r\n",
      "Epoch:  83 Step:   338 /   793 Train loss: 0.01423590\r\n",
      "Epoch:  83 Step:   339 /   793 Train loss: 0.02242925\r\n",
      "Epoch:  83 Step:   340 /   793 Train loss: 0.02871978\r\n",
      "Epoch:  83 Step:   341 /   793 Train loss: 0.01691776\r\n",
      "Epoch:  83 Step:   342 /   793 Train loss: 0.01378153\r\n",
      "Epoch:  83 Step:   343 /   793 Train loss: 0.02274852\r\n",
      "Epoch:  83 Step:   344 /   793 Train loss: 0.02876518\r\n",
      "Epoch:  83 Step:   345 /   793 Train loss: 0.02812162\r\n",
      "Epoch:  83 Step:   346 /   793 Train loss: 0.02358746\r\n",
      "Epoch:  83 Step:   347 /   793 Train loss: 0.02248404\r\n",
      "Epoch:  83 Step:   348 /   793 Train loss: 0.00891247\r\n",
      "Epoch:  83 Step:   349 /   793 Train loss: 0.02209459\r\n",
      "Epoch:  83 Step:   350 /   793 Train loss: 0.02023908\r\n",
      "Epoch:  83 Step:   351 /   793 Train loss: 0.01323223\r\n",
      "Epoch:  83 Step:   352 /   793 Train loss: 0.02708957\r\n",
      "Epoch:  83 Step:   353 /   793 Train loss: 0.03413176\r\n",
      "Epoch:  83 Step:   354 /   793 Train loss: 0.01971808\r\n",
      "Epoch:  83 Step:   355 /   793 Train loss: 0.01250527\r\n",
      "Epoch:  83 Step:   356 /   793 Train loss: 0.02158799\r\n",
      "Epoch:  83 Step:   357 /   793 Train loss: 0.02056969\r\n",
      "Epoch:  83 Step:   358 /   793 Train loss: 0.02416424\r\n",
      "Epoch:  83 Step:   359 /   793 Train loss: 0.03789359\r\n",
      "Epoch:  83 Step:   360 /   793 Train loss: 0.03859554\r\n",
      "Epoch:  83 Step:   361 /   793 Train loss: 0.01940117\r\n",
      "Epoch:  83 Step:   362 /   793 Train loss: 0.02235191\r\n",
      "Epoch:  83 Step:   363 /   793 Train loss: 0.01621156\r\n",
      "Epoch:  83 Step:   364 /   793 Train loss: 0.01012629\r\n",
      "Epoch:  83 Step:   365 /   793 Train loss: 0.02735921\r\n",
      "Epoch:  83 Step:   366 /   793 Train loss: 0.01833675\r\n",
      "Epoch:  83 Step:   367 /   793 Train loss: 0.03603423\r\n",
      "Epoch:  83 Step:   368 /   793 Train loss: 0.01923761\r\n",
      "Epoch:  83 Step:   369 /   793 Train loss: 0.01384165\r\n",
      "Epoch:  83 Step:   370 /   793 Train loss: 0.03405797\r\n",
      "Epoch:  83 Step:   371 /   793 Train loss: 0.02368568\r\n",
      "Epoch:  83 Step:   372 /   793 Train loss: 0.03702718\r\n",
      "Epoch:  83 Step:   373 /   793 Train loss: 0.02420259\r\n",
      "Epoch:  83 Step:   374 /   793 Train loss: 0.02241882\r\n",
      "Epoch:  83 Step:   375 /   793 Train loss: 0.01976888\r\n",
      "Epoch:  83 Step:   376 /   793 Train loss: 0.02702181\r\n",
      "Epoch:  83 Step:   377 /   793 Train loss: 0.01473390\r\n",
      "Epoch:  83 Step:   378 /   793 Train loss: 0.02693884\r\n",
      "Epoch:  83 Step:   379 /   793 Train loss: 0.02708448\r\n",
      "Epoch:  83 Step:   380 /   793 Train loss: 0.02387031\r\n",
      "Epoch:  83 Step:   381 /   793 Train loss: 0.01712640\r\n",
      "Epoch:  83 Step:   382 /   793 Train loss: 0.02916315\r\n",
      "Epoch:  83 Step:   383 /   793 Train loss: 0.02273753\r\n",
      "Epoch:  83 Step:   384 /   793 Train loss: 0.03184874\r\n",
      "Epoch:  83 Step:   385 /   793 Train loss: 0.02568296\r\n",
      "Epoch:  83 Step:   386 /   793 Train loss: 0.01661804\r\n",
      "Epoch:  83 Step:   387 /   793 Train loss: 0.01747702\r\n",
      "Epoch:  83 Step:   388 /   793 Train loss: 0.01575968\r\n",
      "Epoch:  83 Step:   389 /   793 Train loss: 0.02212856\r\n",
      "Epoch:  83 Step:   390 /   793 Train loss: 0.02576188\r\n",
      "Epoch:  83 Step:   391 /   793 Train loss: 0.01946749\r\n",
      "Epoch:  83 Step:   392 /   793 Train loss: 0.02924380\r\n",
      "Epoch:  83 Step:   393 /   793 Train loss: 0.02880712\r\n",
      "Epoch:  83 Step:   394 /   793 Train loss: 0.02079051\r\n",
      "Epoch:  83 Step:   395 /   793 Train loss: 0.02535382\r\n",
      "Epoch:  83 Step:   396 /   793 Train loss: 0.01675967\r\n",
      "Epoch:  83 Step:   397 /   793 Train loss: 0.02699833\r\n",
      "Epoch:  83 Step:   398 /   793 Train loss: 0.02768110\r\n",
      "Epoch:  83 Step:   399 /   793 Train loss: 0.02096583\r\n",
      "Epoch:  83 Step:   400 /   793 Train loss: 0.02964815\r\n",
      "Epoch:  83 Step:   401 /   793 Train loss: 0.02118766\r\n",
      "Epoch:  83 Step:   402 /   793 Train loss: 0.02644248\r\n",
      "Epoch:  83 Step:   403 /   793 Train loss: 0.02620617\r\n",
      "Epoch:  83 Step:   404 /   793 Train loss: 0.02089903\r\n",
      "Epoch:  83 Step:   405 /   793 Train loss: 0.01806889\r\n",
      "Epoch:  83 Step:   406 /   793 Train loss: 0.02380667\r\n",
      "Epoch:  83 Step:   407 /   793 Train loss: 0.02687379\r\n",
      "Epoch:  83 Step:   408 /   793 Train loss: 0.01986364\r\n",
      "Epoch:  83 Step:   409 /   793 Train loss: 0.01967422\r\n",
      "Epoch:  83 Step:   410 /   793 Train loss: 0.03488768\r\n",
      "Epoch:  83 Step:   411 /   793 Train loss: 0.02323037\r\n",
      "Epoch:  83 Step:   412 /   793 Train loss: 0.01550997\r\n",
      "Epoch:  83 Step:   413 /   793 Train loss: 0.03744201\r\n",
      "Epoch:  83 Step:   414 /   793 Train loss: 0.01779007\r\n",
      "Epoch:  83 Step:   415 /   793 Train loss: 0.02215601\r\n",
      "Epoch:  83 Step:   416 /   793 Train loss: 0.02451345\r\n",
      "Epoch:  83 Step:   417 /   793 Train loss: 0.01449694\r\n",
      "Epoch:  83 Step:   418 /   793 Train loss: 0.02912121\r\n",
      "Epoch:  83 Step:   419 /   793 Train loss: 0.01953978\r\n",
      "Epoch:  83 Step:   420 /   793 Train loss: 0.02529264\r\n",
      "Epoch:  83 Step:   421 /   793 Train loss: 0.01842352\r\n",
      "Epoch:  83 Step:   422 /   793 Train loss: 0.02417375\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  83 Step:   423 /   793 Train loss: 0.03138210\r\n",
      "Epoch:  83 Step:   424 /   793 Train loss: 0.01248867\r\n",
      "Epoch:  83 Step:   425 /   793 Train loss: 0.02656467\r\n",
      "Epoch:  83 Step:   426 /   793 Train loss: 0.00891738\r\n",
      "Epoch:  83 Step:   427 /   793 Train loss: 0.01657276\r\n",
      "Epoch:  83 Step:   428 /   793 Train loss: 0.02553463\r\n",
      "Epoch:  83 Step:   429 /   793 Train loss: 0.02559143\r\n",
      "Epoch:  83 Step:   430 /   793 Train loss: 0.03505816\r\n",
      "Epoch:  83 Step:   431 /   793 Train loss: 0.02329212\r\n",
      "Epoch:  83 Step:   432 /   793 Train loss: 0.03023126\r\n",
      "Epoch:  83 Step:   433 /   793 Train loss: 0.02576803\r\n",
      "Epoch:  83 Step:   434 /   793 Train loss: 0.03173130\r\n",
      "Epoch:  83 Step:   435 /   793 Train loss: 0.03342084\r\n",
      "Epoch:  83 Step:   436 /   793 Train loss: 0.01154290\r\n",
      "Epoch:  83 Step:   437 /   793 Train loss: 0.01682705\r\n",
      "Epoch:  83 Step:   438 /   793 Train loss: 0.01603939\r\n",
      "Epoch:  83 Step:   439 /   793 Train loss: 0.02200706\r\n",
      "Epoch:  83 Step:   440 /   793 Train loss: 0.01539570\r\n",
      "Epoch:  83 Step:   441 /   793 Train loss: 0.02249057\r\n",
      "Epoch:  83 Step:   442 /   793 Train loss: 0.01735597\r\n",
      "Epoch:  83 Step:   443 /   793 Train loss: 0.00998904\r\n",
      "Epoch:  83 Step:   444 /   793 Train loss: 0.03168815\r\n",
      "Epoch:  83 Step:   445 /   793 Train loss: 0.01856806\r\n",
      "Epoch:  83 Step:   446 /   793 Train loss: 0.02295711\r\n",
      "Epoch:  83 Step:   447 /   793 Train loss: 0.02695340\r\n",
      "Epoch:  83 Step:   448 /   793 Train loss: 0.03370263\r\n",
      "Epoch:  83 Step:   449 /   793 Train loss: 0.02262580\r\n",
      "Epoch:  83 Step:   450 /   793 Train loss: 0.03169928\r\n",
      "Epoch:  83 Step:   451 /   793 Train loss: 0.01029843\r\n",
      "Epoch:  83 Step:   452 /   793 Train loss: 0.02988074\r\n",
      "Epoch:  83 Step:   453 /   793 Train loss: 0.02137289\r\n",
      "Epoch:  83 Step:   454 /   793 Train loss: 0.02505473\r\n",
      "Epoch:  83 Step:   455 /   793 Train loss: 0.01953826\r\n",
      "Epoch:  83 Step:   456 /   793 Train loss: 0.02366265\r\n",
      "Epoch:  83 Step:   457 /   793 Train loss: 0.04796668\r\n",
      "Epoch:  83 Step:   458 /   793 Train loss: 0.01443677\r\n",
      "Epoch:  83 Step:   459 /   793 Train loss: 0.02213821\r\n",
      "Epoch:  83 Step:   460 /   793 Train loss: 0.01907100\r\n",
      "Epoch:  83 Step:   461 /   793 Train loss: 0.01819404\r\n",
      "Epoch:  83 Step:   462 /   793 Train loss: 0.02179696\r\n",
      "Epoch:  83 Step:   463 /   793 Train loss: 0.01886576\r\n",
      "Epoch:  83 Step:   464 /   793 Train loss: 0.03063080\r\n",
      "Epoch:  83 Step:   465 /   793 Train loss: 0.02062794\r\n",
      "Epoch:  83 Step:   466 /   793 Train loss: 0.03136140\r\n",
      "Epoch:  83 Step:   467 /   793 Train loss: 0.02655174\r\n",
      "Epoch:  83 Step:   468 /   793 Train loss: 0.02485314\r\n",
      "Epoch:  83 Step:   469 /   793 Train loss: 0.02007420\r\n",
      "Epoch:  83 Step:   470 /   793 Train loss: 0.04507883\r\n",
      "Epoch:  83 Step:   471 /   793 Train loss: 0.02949809\r\n",
      "Epoch:  83 Step:   472 /   793 Train loss: 0.01823123\r\n",
      "Epoch:  83 Step:   473 /   793 Train loss: 0.02434979\r\n",
      "Epoch:  83 Step:   474 /   793 Train loss: 0.02489185\r\n",
      "Epoch:  83 Step:   475 /   793 Train loss: 0.03168355\r\n",
      "Epoch:  83 Step:   476 /   793 Train loss: 0.02602283\r\n",
      "Epoch:  83 Step:   477 /   793 Train loss: 0.01892038\r\n",
      "Epoch:  83 Step:   478 /   793 Train loss: 0.02327918\r\n",
      "Epoch:  83 Step:   479 /   793 Train loss: 0.01862714\r\n",
      "Epoch:  83 Step:   480 /   793 Train loss: 0.03536831\r\n",
      "Epoch:  83 Step:   481 /   793 Train loss: 0.02115897\r\n",
      "Epoch:  83 Step:   482 /   793 Train loss: 0.02909134\r\n",
      "Epoch:  83 Step:   483 /   793 Train loss: 0.02483873\r\n",
      "Epoch:  83 Step:   484 /   793 Train loss: 0.03383864\r\n",
      "Epoch:  83 Step:   485 /   793 Train loss: 0.01756047\r\n",
      "Epoch:  83 Step:   486 /   793 Train loss: 0.03311384\r\n",
      "Epoch:  83 Step:   487 /   793 Train loss: 0.02540408\r\n",
      "Epoch:  83 Step:   488 /   793 Train loss: 0.00982429\r\n",
      "Epoch:  83 Step:   489 /   793 Train loss: 0.02371005\r\n",
      "Epoch:  83 Step:   490 /   793 Train loss: 0.03004010\r\n",
      "Epoch:  83 Step:   491 /   793 Train loss: 0.01770263\r\n",
      "Epoch:  83 Step:   492 /   793 Train loss: 0.03093757\r\n",
      "Epoch:  83 Step:   493 /   793 Train loss: 0.02257281\r\n",
      "Epoch:  83 Step:   494 /   793 Train loss: 0.03008773\r\n",
      "Epoch:  83 Step:   495 /   793 Train loss: 0.01962097\r\n",
      "Epoch:  83 Step:   496 /   793 Train loss: 0.02410009\r\n",
      "Epoch:  83 Step:   497 /   793 Train loss: 0.03509315\r\n",
      "Epoch:  83 Step:   498 /   793 Train loss: 0.02025441\r\n",
      "Epoch:  83 Step:   499 /   793 Train loss: 0.02802399\r\n",
      "Epoch:  83 Step:   500 /   793 Train loss: 0.02622417\r\n",
      "Epoch:  83 Step:   501 /   793 Train loss: 0.02466450\r\n",
      "Epoch:  83 Step:   502 /   793 Train loss: 0.02413763\r\n",
      "Epoch:  83 Step:   503 /   793 Train loss: 0.03320982\r\n",
      "Epoch:  83 Step:   504 /   793 Train loss: 0.01673764\r\n",
      "Epoch:  83 Step:   505 /   793 Train loss: 0.03177637\r\n",
      "Epoch:  83 Step:   506 /   793 Train loss: 0.02788796\r\n",
      "Epoch:  83 Step:   507 /   793 Train loss: 0.02434564\r\n",
      "Epoch:  83 Step:   508 /   793 Train loss: 0.02123073\r\n",
      "Epoch:  83 Step:   509 /   793 Train loss: 0.02207862\r\n",
      "Epoch:  83 Step:   510 /   793 Train loss: 0.01691899\r\n",
      "Epoch:  83 Step:   511 /   793 Train loss: 0.01870830\r\n",
      "Epoch:  83 Step:   512 /   793 Train loss: 0.02352411\r\n",
      "Epoch:  83 Step:   513 /   793 Train loss: 0.01526052\r\n",
      "Epoch:  83 Step:   514 /   793 Train loss: 0.02553486\r\n",
      "Epoch:  83 Step:   515 /   793 Train loss: 0.03943452\r\n",
      "Epoch:  83 Step:   516 /   793 Train loss: 0.02933539\r\n",
      "Epoch:  83 Step:   517 /   793 Train loss: 0.02413084\r\n",
      "Epoch:  83 Step:   518 /   793 Train loss: 0.01366965\r\n",
      "Epoch:  83 Step:   519 /   793 Train loss: 0.01514195\r\n",
      "Epoch:  83 Step:   520 /   793 Train loss: 0.02544776\r\n",
      "Epoch:  83 Step:   521 /   793 Train loss: 0.02177971\r\n",
      "Epoch:  83 Step:   522 /   793 Train loss: 0.02147956\r\n",
      "Epoch:  83 Step:   523 /   793 Train loss: 0.02301446\r\n",
      "Epoch:  83 Step:   524 /   793 Train loss: 0.01587769\r\n",
      "Epoch:  83 Step:   525 /   793 Train loss: 0.02314300\r\n",
      "Epoch:  83 Step:   526 /   793 Train loss: 0.02903761\r\n",
      "Epoch:  83 Step:   527 /   793 Train loss: 0.01585912\r\n",
      "Epoch:  83 Step:   528 /   793 Train loss: 0.02515787\r\n",
      "Epoch:  83 Step:   529 /   793 Train loss: 0.01928515\r\n",
      "Epoch:  83 Step:   530 /   793 Train loss: 0.01208589\r\n",
      "Epoch:  83 Step:   531 /   793 Train loss: 0.03604982\r\n",
      "Epoch:  83 Step:   532 /   793 Train loss: 0.02374767\r\n",
      "Epoch:  83 Step:   533 /   793 Train loss: 0.01885586\r\n",
      "Epoch:  83 Step:   534 /   793 Train loss: 0.03109129\r\n",
      "Epoch:  83 Step:   535 /   793 Train loss: 0.03395601\r\n",
      "Epoch:  83 Step:   536 /   793 Train loss: 0.02092422\r\n",
      "Epoch:  83 Step:   537 /   793 Train loss: 0.01976817\r\n",
      "Epoch:  83 Step:   538 /   793 Train loss: 0.03377385\r\n",
      "Epoch:  83 Step:   539 /   793 Train loss: 0.01888426\r\n",
      "Epoch:  83 Step:   540 /   793 Train loss: 0.02826258\r\n",
      "Epoch:  83 Step:   541 /   793 Train loss: 0.02202505\r\n",
      "Epoch:  83 Step:   542 /   793 Train loss: 0.01135181\r\n",
      "Epoch:  83 Step:   543 /   793 Train loss: 0.02202377\r\n",
      "Epoch:  83 Step:   544 /   793 Train loss: 0.01741242\r\n",
      "Epoch:  83 Step:   545 /   793 Train loss: 0.04523402\r\n",
      "Epoch:  83 Step:   546 /   793 Train loss: 0.02611209\r\n",
      "Epoch:  83 Step:   547 /   793 Train loss: 0.01608223\r\n",
      "Epoch:  83 Step:   548 /   793 Train loss: 0.02039191\r\n",
      "Epoch:  83 Step:   549 /   793 Train loss: 0.01541958\r\n",
      "Epoch:  83 Step:   550 /   793 Train loss: 0.02876796\r\n",
      "Epoch:  83 Step:   551 /   793 Train loss: 0.02117784\r\n",
      "Epoch:  83 Step:   552 /   793 Train loss: 0.01662790\r\n",
      "Epoch:  83 Step:   553 /   793 Train loss: 0.01887173\r\n",
      "Epoch:  83 Step:   554 /   793 Train loss: 0.02336805\r\n",
      "Epoch:  83 Step:   555 /   793 Train loss: 0.02306757\r\n",
      "Epoch:  83 Step:   556 /   793 Train loss: 0.01834462\r\n",
      "Epoch:  83 Step:   557 /   793 Train loss: 0.01521697\r\n",
      "Epoch:  83 Step:   558 /   793 Train loss: 0.02321815\r\n",
      "Epoch:  83 Step:   559 /   793 Train loss: 0.02795930\r\n",
      "Epoch:  83 Step:   560 /   793 Train loss: 0.02007999\r\n",
      "Epoch:  83 Step:   561 /   793 Train loss: 0.02564052\r\n",
      "Epoch:  83 Step:   562 /   793 Train loss: 0.01481069\r\n",
      "Epoch:  83 Step:   563 /   793 Train loss: 0.02741218\r\n",
      "Epoch:  83 Step:   564 /   793 Train loss: 0.01861203\r\n",
      "Epoch:  83 Step:   565 /   793 Train loss: 0.03051015\r\n",
      "Epoch:  83 Step:   566 /   793 Train loss: 0.01755916\r\n",
      "Epoch:  83 Step:   567 /   793 Train loss: 0.02279308\r\n",
      "Epoch:  83 Step:   568 /   793 Train loss: 0.02540866\r\n",
      "Epoch:  83 Step:   569 /   793 Train loss: 0.02125884\r\n",
      "Epoch:  83 Step:   570 /   793 Train loss: 0.02189386\r\n",
      "Epoch:  83 Step:   571 /   793 Train loss: 0.02886206\r\n",
      "Epoch:  83 Step:   572 /   793 Train loss: 0.03172180\r\n",
      "Epoch:  83 Step:   573 /   793 Train loss: 0.02380468\r\n",
      "Epoch:  83 Step:   574 /   793 Train loss: 0.02203300\r\n",
      "Epoch:  83 Step:   575 /   793 Train loss: 0.01408838\r\n",
      "Epoch:  83 Step:   576 /   793 Train loss: 0.02134132\r\n",
      "Epoch:  83 Step:   577 /   793 Train loss: 0.03320521\r\n",
      "Epoch:  83 Step:   578 /   793 Train loss: 0.03211158\r\n",
      "Epoch:  83 Step:   579 /   793 Train loss: 0.02717839\r\n",
      "Epoch:  83 Step:   580 /   793 Train loss: 0.02506190\r\n",
      "Epoch:  83 Step:   581 /   793 Train loss: 0.03221159\r\n",
      "Epoch:  83 Step:   582 /   793 Train loss: 0.02737059\r\n",
      "Epoch:  83 Step:   583 /   793 Train loss: 0.01854325\r\n",
      "Epoch:  83 Step:   584 /   793 Train loss: 0.01755678\r\n",
      "Epoch:  83 Step:   585 /   793 Train loss: 0.01171735\r\n",
      "Epoch:  83 Step:   586 /   793 Train loss: 0.02515782\r\n",
      "Epoch:  83 Step:   587 /   793 Train loss: 0.03131512\r\n",
      "Epoch:  83 Step:   588 /   793 Train loss: 0.02485295\r\n",
      "Epoch:  83 Step:   589 /   793 Train loss: 0.03136438\r\n",
      "Epoch:  83 Step:   590 /   793 Train loss: 0.02164698\r\n",
      "Epoch:  83 Step:   591 /   793 Train loss: 0.04227263\r\n",
      "Epoch:  83 Step:   592 /   793 Train loss: 0.03692121\r\n",
      "Epoch:  83 Step:   593 /   793 Train loss: 0.02798860\r\n",
      "Epoch:  83 Step:   594 /   793 Train loss: 0.03155544\r\n",
      "Epoch:  83 Step:   595 /   793 Train loss: 0.01507594\r\n",
      "Epoch:  83 Step:   596 /   793 Train loss: 0.03573904\r\n",
      "Epoch:  83 Step:   597 /   793 Train loss: 0.01270849\r\n",
      "Epoch:  83 Step:   598 /   793 Train loss: 0.03480081\r\n",
      "Epoch:  83 Step:   599 /   793 Train loss: 0.01945203\r\n",
      "Epoch:  83 Step:   600 /   793 Train loss: 0.02461927\r\n",
      "Epoch:  83 Step:   601 /   793 Train loss: 0.01826921\r\n",
      "Epoch:  83 Step:   602 /   793 Train loss: 0.02489691\r\n",
      "Epoch:  83 Step:   603 /   793 Train loss: 0.02058049\r\n",
      "Epoch:  83 Step:   604 /   793 Train loss: 0.02291707\r\n",
      "Epoch:  83 Step:   605 /   793 Train loss: 0.01338494\r\n",
      "Epoch:  83 Step:   606 /   793 Train loss: 0.02756993\r\n",
      "Epoch:  83 Step:   607 /   793 Train loss: 0.01992677\r\n",
      "Epoch:  83 Step:   608 /   793 Train loss: 0.01176086\r\n",
      "Epoch:  83 Step:   609 /   793 Train loss: 0.02349558\r\n",
      "Epoch:  83 Step:   610 /   793 Train loss: 0.03126784\r\n",
      "Epoch:  83 Step:   611 /   793 Train loss: 0.01649846\r\n",
      "Epoch:  83 Step:   612 /   793 Train loss: 0.01804130\r\n",
      "Epoch:  83 Step:   613 /   793 Train loss: 0.02610678\r\n",
      "Epoch:  83 Step:   614 /   793 Train loss: 0.03851169\r\n",
      "Epoch:  83 Step:   615 /   793 Train loss: 0.02804886\r\n",
      "Epoch:  83 Step:   616 /   793 Train loss: 0.02168515\r\n",
      "Epoch:  83 Step:   617 /   793 Train loss: 0.02291737\r\n",
      "Epoch:  83 Step:   618 /   793 Train loss: 0.01263648\r\n",
      "Epoch:  83 Step:   619 /   793 Train loss: 0.03367701\r\n",
      "Epoch:  83 Step:   620 /   793 Train loss: 0.02230923\r\n",
      "Epoch:  83 Step:   621 /   793 Train loss: 0.02387321\r\n",
      "Epoch:  83 Step:   622 /   793 Train loss: 0.03059280\r\n",
      "Epoch:  83 Step:   623 /   793 Train loss: 0.02034532\r\n",
      "Epoch:  83 Step:   624 /   793 Train loss: 0.03376370\r\n",
      "Epoch:  83 Step:   625 /   793 Train loss: 0.01953480\r\n",
      "Epoch:  83 Step:   626 /   793 Train loss: 0.02514353\r\n",
      "Epoch:  83 Step:   627 /   793 Train loss: 0.02645941\r\n",
      "Epoch:  83 Step:   628 /   793 Train loss: 0.02246237\r\n",
      "Epoch:  83 Step:   629 /   793 Train loss: 0.03033297\r\n",
      "Epoch:  83 Step:   630 /   793 Train loss: 0.02503371\r\n",
      "Epoch:  83 Step:   631 /   793 Train loss: 0.01430677\r\n",
      "Epoch:  83 Step:   632 /   793 Train loss: 0.03560134\r\n",
      "Epoch:  83 Step:   633 /   793 Train loss: 0.04188976\r\n",
      "Epoch:  83 Step:   634 /   793 Train loss: 0.01402017\r\n",
      "Epoch:  83 Step:   635 /   793 Train loss: 0.02224841\r\n",
      "Epoch:  83 Step:   636 /   793 Train loss: 0.00998964\r\n",
      "Epoch:  83 Step:   637 /   793 Train loss: 0.03751518\r\n",
      "Epoch:  83 Step:   638 /   793 Train loss: 0.03972029\r\n",
      "Epoch:  83 Step:   639 /   793 Train loss: 0.01693859\r\n",
      "Epoch:  83 Step:   640 /   793 Train loss: 0.02099056\r\n",
      "Epoch:  83 Step:   641 /   793 Train loss: 0.01138348\r\n",
      "Epoch:  83 Step:   642 /   793 Train loss: 0.02942049\r\n",
      "Epoch:  83 Step:   643 /   793 Train loss: 0.02681280\r\n",
      "Epoch:  83 Step:   644 /   793 Train loss: 0.02523699\r\n",
      "Epoch:  83 Step:   645 /   793 Train loss: 0.03722472\r\n",
      "Epoch:  83 Step:   646 /   793 Train loss: 0.02242050\r\n",
      "Epoch:  83 Step:   647 /   793 Train loss: 0.03566914\r\n",
      "Epoch:  83 Step:   648 /   793 Train loss: 0.03488799\r\n",
      "Epoch:  83 Step:   649 /   793 Train loss: 0.02536795\r\n",
      "Epoch:  83 Step:   650 /   793 Train loss: 0.01876473\r\n",
      "Epoch:  83 Step:   651 /   793 Train loss: 0.02237195\r\n",
      "Epoch:  83 Step:   652 /   793 Train loss: 0.02090457\r\n",
      "Epoch:  83 Step:   653 /   793 Train loss: 0.01822362\r\n",
      "Epoch:  83 Step:   654 /   793 Train loss: 0.02945506\r\n",
      "Epoch:  83 Step:   655 /   793 Train loss: 0.03203855\r\n",
      "Epoch:  83 Step:   656 /   793 Train loss: 0.02876436\r\n",
      "Epoch:  83 Step:   657 /   793 Train loss: 0.01719103\r\n",
      "Epoch:  83 Step:   658 /   793 Train loss: 0.01899690\r\n",
      "Epoch:  83 Step:   659 /   793 Train loss: 0.02232689\r\n",
      "Epoch:  83 Step:   660 /   793 Train loss: 0.03313461\r\n",
      "Epoch:  83 Step:   661 /   793 Train loss: 0.01656727\r\n",
      "Epoch:  83 Step:   662 /   793 Train loss: 0.01798683\r\n",
      "Epoch:  83 Step:   663 /   793 Train loss: 0.02094714\r\n",
      "Epoch:  83 Step:   664 /   793 Train loss: 0.01458394\r\n",
      "Epoch:  83 Step:   665 /   793 Train loss: 0.02855063\r\n",
      "Epoch:  83 Step:   666 /   793 Train loss: 0.03476010\r\n",
      "Epoch:  83 Step:   667 /   793 Train loss: 0.02216235\r\n",
      "Epoch:  83 Step:   668 /   793 Train loss: 0.02107940\r\n",
      "Epoch:  83 Step:   669 /   793 Train loss: 0.03214344\r\n",
      "Epoch:  83 Step:   670 /   793 Train loss: 0.02950775\r\n",
      "Epoch:  83 Step:   671 /   793 Train loss: 0.04145382\r\n",
      "Epoch:  83 Step:   672 /   793 Train loss: 0.04197557\r\n",
      "Epoch:  83 Step:   673 /   793 Train loss: 0.02640457\r\n",
      "Epoch:  83 Step:   674 /   793 Train loss: 0.02829745\r\n",
      "Epoch:  83 Step:   675 /   793 Train loss: 0.01901107\r\n",
      "Epoch:  83 Step:   676 /   793 Train loss: 0.03427354\r\n",
      "Epoch:  83 Step:   677 /   793 Train loss: 0.02617860\r\n",
      "Epoch:  83 Step:   678 /   793 Train loss: 0.02495379\r\n",
      "Epoch:  83 Step:   679 /   793 Train loss: 0.02616707\r\n",
      "Epoch:  83 Step:   680 /   793 Train loss: 0.03587345\r\n",
      "Epoch:  83 Step:   681 /   793 Train loss: 0.02730209\r\n",
      "Epoch:  83 Step:   682 /   793 Train loss: 0.03082919\r\n",
      "Epoch:  83 Step:   683 /   793 Train loss: 0.03076254\r\n",
      "Epoch:  83 Step:   684 /   793 Train loss: 0.02904068\r\n",
      "Epoch:  83 Step:   685 /   793 Train loss: 0.02837102\r\n",
      "Epoch:  83 Step:   686 /   793 Train loss: 0.02363052\r\n",
      "Epoch:  83 Step:   687 /   793 Train loss: 0.01770939\r\n",
      "Epoch:  83 Step:   688 /   793 Train loss: 0.02132036\r\n",
      "Epoch:  83 Step:   689 /   793 Train loss: 0.02638369\r\n",
      "Epoch:  83 Step:   690 /   793 Train loss: 0.02666019\r\n",
      "Epoch:  83 Step:   691 /   793 Train loss: 0.02703838\r\n",
      "Epoch:  83 Step:   692 /   793 Train loss: 0.01913914\r\n",
      "Epoch:  83 Step:   693 /   793 Train loss: 0.02780071\r\n",
      "Epoch:  83 Step:   694 /   793 Train loss: 0.02009027\r\n",
      "Epoch:  83 Step:   695 /   793 Train loss: 0.02292202\r\n",
      "Epoch:  83 Step:   696 /   793 Train loss: 0.03028691\r\n",
      "Epoch:  83 Step:   697 /   793 Train loss: 0.02096124\r\n",
      "Epoch:  83 Step:   698 /   793 Train loss: 0.02683025\r\n",
      "Epoch:  83 Step:   699 /   793 Train loss: 0.02994093\r\n",
      "Epoch:  83 Step:   700 /   793 Train loss: 0.01929129\r\n",
      "Epoch:  83 Step:   701 /   793 Train loss: 0.02320006\r\n",
      "Epoch:  83 Step:   702 /   793 Train loss: 0.01785626\r\n",
      "Epoch:  83 Step:   703 /   793 Train loss: 0.02045586\r\n",
      "Epoch:  83 Step:   704 /   793 Train loss: 0.03151660\r\n",
      "Epoch:  83 Step:   705 /   793 Train loss: 0.03446455\r\n",
      "Epoch:  83 Step:   706 /   793 Train loss: 0.02602021\r\n",
      "Epoch:  83 Step:   707 /   793 Train loss: 0.02561862\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  83 Step:   708 /   793 Train loss: 0.00903333\r\n",
      "Epoch:  83 Step:   709 /   793 Train loss: 0.02381750\r\n",
      "Epoch:  83 Step:   710 /   793 Train loss: 0.02874583\r\n",
      "Epoch:  83 Step:   711 /   793 Train loss: 0.01160162\r\n",
      "Epoch:  83 Step:   712 /   793 Train loss: 0.02325941\r\n",
      "Epoch:  83 Step:   713 /   793 Train loss: 0.02044313\r\n",
      "Epoch:  83 Step:   714 /   793 Train loss: 0.02248919\r\n",
      "Epoch:  83 Step:   715 /   793 Train loss: 0.02578158\r\n",
      "Epoch:  83 Step:   716 /   793 Train loss: 0.02896465\r\n",
      "Epoch:  83 Step:   717 /   793 Train loss: 0.02673209\r\n",
      "Epoch:  83 Step:   718 /   793 Train loss: 0.01194754\r\n",
      "Epoch:  83 Step:   719 /   793 Train loss: 0.02218466\r\n",
      "Epoch:  83 Step:   720 /   793 Train loss: 0.02599910\r\n",
      "Epoch:  83 Step:   721 /   793 Train loss: 0.02747421\r\n",
      "Epoch:  83 Step:   722 /   793 Train loss: 0.01387712\r\n",
      "Epoch:  83 Step:   723 /   793 Train loss: 0.01778958\r\n",
      "Epoch:  83 Step:   724 /   793 Train loss: 0.02418694\r\n",
      "Epoch:  83 Step:   725 /   793 Train loss: 0.02594075\r\n",
      "Epoch:  83 Step:   726 /   793 Train loss: 0.03238995\r\n",
      "Epoch:  83 Step:   727 /   793 Train loss: 0.01804711\r\n",
      "Epoch:  83 Step:   728 /   793 Train loss: 0.02958954\r\n",
      "Epoch:  83 Step:   729 /   793 Train loss: 0.04034972\r\n",
      "Epoch:  83 Step:   730 /   793 Train loss: 0.03306628\r\n",
      "Epoch:  83 Step:   731 /   793 Train loss: 0.02345268\r\n",
      "Epoch:  83 Step:   732 /   793 Train loss: 0.02282428\r\n",
      "Epoch:  83 Step:   733 /   793 Train loss: 0.03207040\r\n",
      "Epoch:  83 Step:   734 /   793 Train loss: 0.02158059\r\n",
      "Epoch:  83 Step:   735 /   793 Train loss: 0.02189642\r\n",
      "Epoch:  83 Step:   736 /   793 Train loss: 0.02659709\r\n",
      "Epoch:  83 Step:   737 /   793 Train loss: 0.02856657\r\n",
      "Epoch:  83 Step:   738 /   793 Train loss: 0.02929186\r\n",
      "Epoch:  83 Step:   739 /   793 Train loss: 0.03156719\r\n",
      "Epoch:  83 Step:   740 /   793 Train loss: 0.03984895\r\n",
      "Epoch:  83 Step:   741 /   793 Train loss: 0.02640795\r\n",
      "Epoch:  83 Step:   742 /   793 Train loss: 0.02177580\r\n",
      "Epoch:  83 Step:   743 /   793 Train loss: 0.02723535\r\n",
      "Epoch:  83 Step:   744 /   793 Train loss: 0.03233893\r\n",
      "Epoch:  83 Step:   745 /   793 Train loss: 0.02011688\r\n",
      "Epoch:  83 Step:   746 /   793 Train loss: 0.02977371\r\n",
      "Epoch:  83 Step:   747 /   793 Train loss: 0.02010721\r\n",
      "Epoch:  83 Step:   748 /   793 Train loss: 0.02540454\r\n",
      "Epoch:  83 Step:   749 /   793 Train loss: 0.02156897\r\n",
      "Epoch:  83 Step:   750 /   793 Train loss: 0.02780729\r\n",
      "Epoch:  83 Step:   751 /   793 Train loss: 0.02864150\r\n",
      "Epoch:  83 Step:   752 /   793 Train loss: 0.01087493\r\n",
      "Epoch:  83 Step:   753 /   793 Train loss: 0.02910797\r\n",
      "Epoch:  83 Step:   754 /   793 Train loss: 0.01889351\r\n",
      "Epoch:  83 Step:   755 /   793 Train loss: 0.02747959\r\n",
      "Epoch:  83 Step:   756 /   793 Train loss: 0.01758498\r\n",
      "Epoch:  83 Step:   757 /   793 Train loss: 0.02175963\r\n",
      "Epoch:  83 Step:   758 /   793 Train loss: 0.02197435\r\n",
      "Epoch:  83 Step:   759 /   793 Train loss: 0.02690497\r\n",
      "Epoch:  83 Step:   760 /   793 Train loss: 0.01127573\r\n",
      "Epoch:  83 Step:   761 /   793 Train loss: 0.02236430\r\n",
      "Epoch:  83 Step:   762 /   793 Train loss: 0.02515773\r\n",
      "Epoch:  83 Step:   763 /   793 Train loss: 0.01632121\r\n",
      "Epoch:  83 Step:   764 /   793 Train loss: 0.03016786\r\n",
      "Epoch:  83 Step:   765 /   793 Train loss: 0.01579083\r\n",
      "Epoch:  83 Step:   766 /   793 Train loss: 0.03408802\r\n",
      "Epoch:  83 Step:   767 /   793 Train loss: 0.02626568\r\n",
      "Epoch:  83 Step:   768 /   793 Train loss: 0.01878663\r\n",
      "Epoch:  83 Step:   769 /   793 Train loss: 0.01308960\r\n",
      "Epoch:  83 Step:   770 /   793 Train loss: 0.02483855\r\n",
      "Epoch:  83 Step:   771 /   793 Train loss: 0.01925298\r\n",
      "Epoch:  83 Step:   772 /   793 Train loss: 0.01854599\r\n",
      "Epoch:  83 Step:   773 /   793 Train loss: 0.02807771\r\n",
      "Epoch:  83 Step:   774 /   793 Train loss: 0.03294544\r\n",
      "Epoch:  83 Step:   775 /   793 Train loss: 0.02276197\r\n",
      "Epoch:  83 Step:   776 /   793 Train loss: 0.02092244\r\n",
      "Epoch:  83 Step:   777 /   793 Train loss: 0.02498286\r\n",
      "Epoch:  83 Step:   778 /   793 Train loss: 0.02700092\r\n",
      "Epoch:  83 Step:   779 /   793 Train loss: 0.01741637\r\n",
      "Epoch:  83 Step:   780 /   793 Train loss: 0.02403239\r\n",
      "Epoch:  83 Step:   781 /   793 Train loss: 0.01977018\r\n",
      "Epoch:  83 Step:   782 /   793 Train loss: 0.01561314\r\n",
      "Epoch:  83 Step:   783 /   793 Train loss: 0.03012889\r\n",
      "Epoch:  83 Step:   784 /   793 Train loss: 0.03010458\r\n",
      "Epoch:  83 Step:   785 /   793 Train loss: 0.03123769\r\n",
      "Epoch:  83 Step:   786 /   793 Train loss: 0.02043483\r\n",
      "Epoch:  83 Step:   787 /   793 Train loss: 0.02584922\r\n",
      "Epoch:  83 Step:   788 /   793 Train loss: 0.02628588\r\n",
      "Epoch:  83 Step:   789 /   793 Train loss: 0.01075193\r\n",
      "Epoch:  83 Step:   790 /   793 Train loss: 0.02509132\r\n",
      "Epoch:  83 Step:   791 /   793 Train loss: 0.02278639\r\n",
      "Epoch:  83 Step:   792 /   793 Train loss: 0.02350464\r\n",
      "Epoch:  83 Validation loss: 0.01432216\r\n",
      "Epoch:  84 Step:     0 /   793 Train loss: 0.01932988\r\n",
      "Epoch:  84 Step:     1 /   793 Train loss: 0.03392043\r\n",
      "Epoch:  84 Step:     2 /   793 Train loss: 0.02228052\r\n",
      "Epoch:  84 Step:     3 /   793 Train loss: 0.03138583\r\n",
      "Epoch:  84 Step:     4 /   793 Train loss: 0.02957329\r\n",
      "Epoch:  84 Step:     5 /   793 Train loss: 0.04132875\r\n",
      "Epoch:  84 Step:     6 /   793 Train loss: 0.01886669\r\n",
      "Epoch:  84 Step:     7 /   793 Train loss: 0.02210914\r\n",
      "Epoch:  84 Step:     8 /   793 Train loss: 0.02396280\r\n",
      "Epoch:  84 Step:     9 /   793 Train loss: 0.02928980\r\n",
      "Epoch:  84 Step:    10 /   793 Train loss: 0.02722402\r\n",
      "Epoch:  84 Step:    11 /   793 Train loss: 0.02215682\r\n",
      "Epoch:  84 Step:    12 /   793 Train loss: 0.01993003\r\n",
      "Epoch:  84 Step:    13 /   793 Train loss: 0.02209140\r\n",
      "Epoch:  84 Step:    14 /   793 Train loss: 0.03060228\r\n",
      "Epoch:  84 Step:    15 /   793 Train loss: 0.03320023\r\n",
      "Epoch:  84 Step:    16 /   793 Train loss: 0.02011615\r\n",
      "Epoch:  84 Step:    17 /   793 Train loss: 0.03508749\r\n",
      "Epoch:  84 Step:    18 /   793 Train loss: 0.01940180\r\n",
      "Epoch:  84 Step:    19 /   793 Train loss: 0.02141435\r\n",
      "Epoch:  84 Step:    20 /   793 Train loss: 0.01800999\r\n",
      "Epoch:  84 Step:    21 /   793 Train loss: 0.00672779\r\n",
      "Epoch:  84 Step:    22 /   793 Train loss: 0.02069031\r\n",
      "Epoch:  84 Step:    23 /   793 Train loss: 0.02585503\r\n",
      "Epoch:  84 Step:    24 /   793 Train loss: 0.02298310\r\n",
      "Epoch:  84 Step:    25 /   793 Train loss: 0.01260524\r\n",
      "Epoch:  84 Step:    26 /   793 Train loss: 0.01815293\r\n",
      "Epoch:  84 Step:    27 /   793 Train loss: 0.02186271\r\n",
      "Epoch:  84 Step:    28 /   793 Train loss: 0.01408434\r\n",
      "Epoch:  84 Step:    29 /   793 Train loss: 0.02218194\r\n",
      "Epoch:  84 Step:    30 /   793 Train loss: 0.02281685\r\n",
      "Epoch:  84 Step:    31 /   793 Train loss: 0.01831969\r\n",
      "Epoch:  84 Step:    32 /   793 Train loss: 0.02626710\r\n",
      "Epoch:  84 Step:    33 /   793 Train loss: 0.02739742\r\n",
      "Epoch:  84 Step:    34 /   793 Train loss: 0.02051092\r\n",
      "Epoch:  84 Step:    35 /   793 Train loss: 0.03388442\r\n",
      "Epoch:  84 Step:    36 /   793 Train loss: 0.03543596\r\n",
      "Epoch:  84 Step:    37 /   793 Train loss: 0.01894202\r\n",
      "Epoch:  84 Step:    38 /   793 Train loss: 0.02533178\r\n",
      "Epoch:  84 Step:    39 /   793 Train loss: 0.02280938\r\n",
      "Epoch:  84 Step:    40 /   793 Train loss: 0.01935881\r\n",
      "Epoch:  84 Step:    41 /   793 Train loss: 0.02396713\r\n",
      "Epoch:  84 Step:    42 /   793 Train loss: 0.01781583\r\n",
      "Epoch:  84 Step:    43 /   793 Train loss: 0.04377866\r\n",
      "Epoch:  84 Step:    44 /   793 Train loss: 0.02750597\r\n",
      "Epoch:  84 Step:    45 /   793 Train loss: 0.03002130\r\n",
      "Epoch:  84 Step:    46 /   793 Train loss: 0.02629230\r\n",
      "Epoch:  84 Step:    47 /   793 Train loss: 0.02644769\r\n",
      "Epoch:  84 Step:    48 /   793 Train loss: 0.01846871\r\n",
      "Epoch:  84 Step:    49 /   793 Train loss: 0.02102799\r\n",
      "Epoch:  84 Step:    50 /   793 Train loss: 0.02713977\r\n",
      "Epoch:  84 Step:    51 /   793 Train loss: 0.03106417\r\n",
      "Epoch:  84 Step:    52 /   793 Train loss: 0.02857173\r\n",
      "Epoch:  84 Step:    53 /   793 Train loss: 0.01833016\r\n",
      "Epoch:  84 Step:    54 /   793 Train loss: 0.03548209\r\n",
      "Epoch:  84 Step:    55 /   793 Train loss: 0.01961874\r\n",
      "Epoch:  84 Step:    56 /   793 Train loss: 0.03023403\r\n",
      "Epoch:  84 Step:    57 /   793 Train loss: 0.01842972\r\n",
      "Epoch:  84 Step:    58 /   793 Train loss: 0.01920506\r\n",
      "Epoch:  84 Step:    59 /   793 Train loss: 0.03167538\r\n",
      "Epoch:  84 Step:    60 /   793 Train loss: 0.01626930\r\n",
      "Epoch:  84 Step:    61 /   793 Train loss: 0.01290183\r\n",
      "Epoch:  84 Step:    62 /   793 Train loss: 0.01839515\r\n",
      "Epoch:  84 Step:    63 /   793 Train loss: 0.02556021\r\n",
      "Epoch:  84 Step:    64 /   793 Train loss: 0.02383576\r\n",
      "Epoch:  84 Step:    65 /   793 Train loss: 0.02035639\r\n",
      "Epoch:  84 Step:    66 /   793 Train loss: 0.02874531\r\n",
      "Epoch:  84 Step:    67 /   793 Train loss: 0.02083385\r\n",
      "Epoch:  84 Step:    68 /   793 Train loss: 0.02916945\r\n",
      "Epoch:  84 Step:    69 /   793 Train loss: 0.01471966\r\n",
      "Epoch:  84 Step:    70 /   793 Train loss: 0.02358300\r\n",
      "Epoch:  84 Step:    71 /   793 Train loss: 0.01990068\r\n",
      "Epoch:  84 Step:    72 /   793 Train loss: 0.01456439\r\n",
      "Epoch:  84 Step:    73 /   793 Train loss: 0.02510317\r\n",
      "Epoch:  84 Step:    74 /   793 Train loss: 0.03113668\r\n",
      "Epoch:  84 Step:    75 /   793 Train loss: 0.04043201\r\n",
      "Epoch:  84 Step:    76 /   793 Train loss: 0.01720144\r\n",
      "Epoch:  84 Step:    77 /   793 Train loss: 0.03157576\r\n",
      "Epoch:  84 Step:    78 /   793 Train loss: 0.03663815\r\n",
      "Epoch:  84 Step:    79 /   793 Train loss: 0.03093473\r\n",
      "Epoch:  84 Step:    80 /   793 Train loss: 0.02347300\r\n",
      "Epoch:  84 Step:    81 /   793 Train loss: 0.03554662\r\n",
      "Epoch:  84 Step:    82 /   793 Train loss: 0.01441908\r\n",
      "Epoch:  84 Step:    83 /   793 Train loss: 0.01946801\r\n",
      "Epoch:  84 Step:    84 /   793 Train loss: 0.02673277\r\n",
      "Epoch:  84 Step:    85 /   793 Train loss: 0.03039260\r\n",
      "Epoch:  84 Step:    86 /   793 Train loss: 0.02350839\r\n",
      "Epoch:  84 Step:    87 /   793 Train loss: 0.02235149\r\n",
      "Epoch:  84 Step:    88 /   793 Train loss: 0.01793549\r\n",
      "Epoch:  84 Step:    89 /   793 Train loss: 0.02139047\r\n",
      "Epoch:  84 Step:    90 /   793 Train loss: 0.03802391\r\n",
      "Epoch:  84 Step:    91 /   793 Train loss: 0.03190232\r\n",
      "Epoch:  84 Step:    92 /   793 Train loss: 0.00781814\r\n",
      "Epoch:  84 Step:    93 /   793 Train loss: 0.02192047\r\n",
      "Epoch:  84 Step:    94 /   793 Train loss: 0.01749461\r\n",
      "Epoch:  84 Step:    95 /   793 Train loss: 0.01948964\r\n",
      "Epoch:  84 Step:    96 /   793 Train loss: 0.02108474\r\n",
      "Epoch:  84 Step:    97 /   793 Train loss: 0.02322682\r\n",
      "Epoch:  84 Step:    98 /   793 Train loss: 0.03337225\r\n",
      "Epoch:  84 Step:    99 /   793 Train loss: 0.02313286\r\n",
      "Epoch:  84 Step:   100 /   793 Train loss: 0.02085059\r\n",
      "Epoch:  84 Step:   101 /   793 Train loss: 0.02719172\r\n",
      "Epoch:  84 Step:   102 /   793 Train loss: 0.01958186\r\n",
      "Epoch:  84 Step:   103 /   793 Train loss: 0.01483491\r\n",
      "Epoch:  84 Step:   104 /   793 Train loss: 0.02760173\r\n",
      "Epoch:  84 Step:   105 /   793 Train loss: 0.02586092\r\n",
      "Epoch:  84 Step:   106 /   793 Train loss: 0.03232662\r\n",
      "Epoch:  84 Step:   107 /   793 Train loss: 0.01842325\r\n",
      "Epoch:  84 Step:   108 /   793 Train loss: 0.01842854\r\n",
      "Epoch:  84 Step:   109 /   793 Train loss: 0.01772683\r\n",
      "Epoch:  84 Step:   110 /   793 Train loss: 0.02546562\r\n",
      "Epoch:  84 Step:   111 /   793 Train loss: 0.02039890\r\n",
      "Epoch:  84 Step:   112 /   793 Train loss: 0.03095031\r\n",
      "Epoch:  84 Step:   113 /   793 Train loss: 0.03064451\r\n",
      "Epoch:  84 Step:   114 /   793 Train loss: 0.02107245\r\n",
      "Epoch:  84 Step:   115 /   793 Train loss: 0.02736558\r\n",
      "Epoch:  84 Step:   116 /   793 Train loss: 0.02233731\r\n",
      "Epoch:  84 Step:   117 /   793 Train loss: 0.02430610\r\n",
      "Epoch:  84 Step:   118 /   793 Train loss: 0.02726427\r\n",
      "Epoch:  84 Step:   119 /   793 Train loss: 0.02180378\r\n",
      "Epoch:  84 Step:   120 /   793 Train loss: 0.02271832\r\n",
      "Epoch:  84 Step:   121 /   793 Train loss: 0.01830218\r\n",
      "Epoch:  84 Step:   122 /   793 Train loss: 0.02813311\r\n",
      "Epoch:  84 Step:   123 /   793 Train loss: 0.02584760\r\n",
      "Epoch:  84 Step:   124 /   793 Train loss: 0.02040688\r\n",
      "Epoch:  84 Step:   125 /   793 Train loss: 0.01204088\r\n",
      "Epoch:  84 Step:   126 /   793 Train loss: 0.01147534\r\n",
      "Epoch:  84 Step:   127 /   793 Train loss: 0.02446120\r\n",
      "Epoch:  84 Step:   128 /   793 Train loss: 0.02099970\r\n",
      "Epoch:  84 Step:   129 /   793 Train loss: 0.03087968\r\n",
      "Epoch:  84 Step:   130 /   793 Train loss: 0.02774448\r\n",
      "Epoch:  84 Step:   131 /   793 Train loss: 0.01827294\r\n",
      "Epoch:  84 Step:   132 /   793 Train loss: 0.01890624\r\n",
      "Epoch:  84 Step:   133 /   793 Train loss: 0.01903845\r\n",
      "Epoch:  84 Step:   134 /   793 Train loss: 0.01511355\r\n",
      "Epoch:  84 Step:   135 /   793 Train loss: 0.02380665\r\n",
      "Epoch:  84 Step:   136 /   793 Train loss: 0.01800864\r\n",
      "Epoch:  84 Step:   137 /   793 Train loss: 0.02256614\r\n",
      "Epoch:  84 Step:   138 /   793 Train loss: 0.02721994\r\n",
      "Epoch:  84 Step:   139 /   793 Train loss: 0.01588038\r\n",
      "Epoch:  84 Step:   140 /   793 Train loss: 0.02275664\r\n",
      "Epoch:  84 Step:   141 /   793 Train loss: 0.01162814\r\n",
      "Epoch:  84 Step:   142 /   793 Train loss: 0.02645315\r\n",
      "Epoch:  84 Step:   143 /   793 Train loss: 0.02761184\r\n",
      "Epoch:  84 Step:   144 /   793 Train loss: 0.02515771\r\n",
      "Epoch:  84 Step:   145 /   793 Train loss: 0.03940923\r\n",
      "Epoch:  84 Step:   146 /   793 Train loss: 0.02392088\r\n",
      "Epoch:  84 Step:   147 /   793 Train loss: 0.03171466\r\n",
      "Epoch:  84 Step:   148 /   793 Train loss: 0.01939549\r\n",
      "Epoch:  84 Step:   149 /   793 Train loss: 0.02455889\r\n",
      "Epoch:  84 Step:   150 /   793 Train loss: 0.02137967\r\n",
      "Epoch:  84 Step:   151 /   793 Train loss: 0.01415957\r\n",
      "Epoch:  84 Step:   152 /   793 Train loss: 0.02457246\r\n",
      "Epoch:  84 Step:   153 /   793 Train loss: 0.01324218\r\n",
      "Epoch:  84 Step:   154 /   793 Train loss: 0.01295234\r\n",
      "Epoch:  84 Step:   155 /   793 Train loss: 0.02697621\r\n",
      "Epoch:  84 Step:   156 /   793 Train loss: 0.02553954\r\n",
      "Epoch:  84 Step:   157 /   793 Train loss: 0.03221184\r\n",
      "Epoch:  84 Step:   158 /   793 Train loss: 0.02532373\r\n",
      "Epoch:  84 Step:   159 /   793 Train loss: 0.02607803\r\n",
      "Epoch:  84 Step:   160 /   793 Train loss: 0.01581424\r\n",
      "Epoch:  84 Step:   161 /   793 Train loss: 0.02134678\r\n",
      "Epoch:  84 Step:   162 /   793 Train loss: 0.02438486\r\n",
      "Epoch:  84 Step:   163 /   793 Train loss: 0.04062874\r\n",
      "Epoch:  84 Step:   164 /   793 Train loss: 0.01991985\r\n",
      "Epoch:  84 Step:   165 /   793 Train loss: 0.02665027\r\n",
      "Epoch:  84 Step:   166 /   793 Train loss: 0.02597782\r\n",
      "Epoch:  84 Step:   167 /   793 Train loss: 0.02210787\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  84 Step:   168 /   793 Train loss: 0.01702497\r\n",
      "Epoch:  84 Step:   169 /   793 Train loss: 0.01414386\r\n",
      "Epoch:  84 Step:   170 /   793 Train loss: 0.02080381\r\n",
      "Epoch:  84 Step:   171 /   793 Train loss: 0.02436228\r\n",
      "Epoch:  84 Step:   172 /   793 Train loss: 0.02120500\r\n",
      "Epoch:  84 Step:   173 /   793 Train loss: 0.02490079\r\n",
      "Epoch:  84 Step:   174 /   793 Train loss: 0.01342433\r\n",
      "Epoch:  84 Step:   175 /   793 Train loss: 0.02101101\r\n",
      "Epoch:  84 Step:   176 /   793 Train loss: 0.03547594\r\n",
      "Epoch:  84 Step:   177 /   793 Train loss: 0.02848416\r\n",
      "Epoch:  84 Step:   178 /   793 Train loss: 0.03806955\r\n",
      "Epoch:  84 Step:   179 /   793 Train loss: 0.01901269\r\n",
      "Epoch:  84 Step:   180 /   793 Train loss: 0.02182431\r\n",
      "Epoch:  84 Step:   181 /   793 Train loss: 0.02043890\r\n",
      "Epoch:  84 Step:   182 /   793 Train loss: 0.02202628\r\n",
      "Epoch:  84 Step:   183 /   793 Train loss: 0.02505288\r\n",
      "Epoch:  84 Step:   184 /   793 Train loss: 0.01921863\r\n",
      "Epoch:  84 Step:   185 /   793 Train loss: 0.03644143\r\n",
      "Epoch:  84 Step:   186 /   793 Train loss: 0.01956948\r\n",
      "Epoch:  84 Step:   187 /   793 Train loss: 0.03493024\r\n",
      "Epoch:  84 Step:   188 /   793 Train loss: 0.01714668\r\n",
      "Epoch:  84 Step:   189 /   793 Train loss: 0.01246033\r\n",
      "Epoch:  84 Step:   190 /   793 Train loss: 0.02106741\r\n",
      "Epoch:  84 Step:   191 /   793 Train loss: 0.02415622\r\n",
      "Epoch:  84 Step:   192 /   793 Train loss: 0.02711152\r\n",
      "Epoch:  84 Step:   193 /   793 Train loss: 0.01950020\r\n",
      "Epoch:  84 Step:   194 /   793 Train loss: 0.01826637\r\n",
      "Epoch:  84 Step:   195 /   793 Train loss: 0.02029300\r\n",
      "Epoch:  84 Step:   196 /   793 Train loss: 0.03470172\r\n",
      "Epoch:  84 Step:   197 /   793 Train loss: 0.01686160\r\n",
      "Epoch:  84 Step:   198 /   793 Train loss: 0.02848448\r\n",
      "Epoch:  84 Step:   199 /   793 Train loss: 0.03479592\r\n",
      "Epoch:  84 Step:   200 /   793 Train loss: 0.01592894\r\n",
      "Epoch:  84 Step:   201 /   793 Train loss: 0.02030658\r\n",
      "Epoch:  84 Step:   202 /   793 Train loss: 0.02138617\r\n",
      "Epoch:  84 Step:   203 /   793 Train loss: 0.02544731\r\n",
      "Epoch:  84 Step:   204 /   793 Train loss: 0.02021787\r\n",
      "Epoch:  84 Step:   205 /   793 Train loss: 0.02860319\r\n",
      "Epoch:  84 Step:   206 /   793 Train loss: 0.04556306\r\n",
      "Epoch:  84 Step:   207 /   793 Train loss: 0.02758337\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  84 Step:   208 /   793 Train loss: 0.03235125\r\n",
      "Epoch:  84 Step:   209 /   793 Train loss: 0.01026743\r\n",
      "Epoch:  84 Step:   210 /   793 Train loss: 0.02703327\r\n",
      "Epoch:  84 Step:   211 /   793 Train loss: 0.03845203\r\n",
      "Epoch:  84 Step:   212 /   793 Train loss: 0.02329774\r\n",
      "Epoch:  84 Step:   213 /   793 Train loss: 0.01691252\r\n",
      "Epoch:  84 Step:   214 /   793 Train loss: 0.02960846\r\n",
      "Epoch:  84 Step:   215 /   793 Train loss: 0.02839926\r\n",
      "Epoch:  84 Step:   216 /   793 Train loss: 0.01278458\r\n",
      "Epoch:  84 Step:   217 /   793 Train loss: 0.01863749\r\n",
      "Epoch:  84 Step:   218 /   793 Train loss: 0.03657899\r\n",
      "Epoch:  84 Step:   219 /   793 Train loss: 0.01909736\r\n",
      "Epoch:  84 Step:   220 /   793 Train loss: 0.02058888\r\n",
      "Epoch:  84 Step:   221 /   793 Train loss: 0.01574360\r\n",
      "Epoch:  84 Step:   222 /   793 Train loss: 0.02580301\r\n",
      "Epoch:  84 Step:   223 /   793 Train loss: 0.04231548\r\n",
      "Epoch:  84 Step:   224 /   793 Train loss: 0.02729925\r\n",
      "Epoch:  84 Step:   225 /   793 Train loss: 0.01798671\r\n",
      "Epoch:  84 Step:   226 /   793 Train loss: 0.02092247\r\n",
      "Epoch:  84 Step:   227 /   793 Train loss: 0.02750562\r\n",
      "Epoch:  84 Step:   228 /   793 Train loss: 0.02213263\r\n",
      "Epoch:  84 Step:   229 /   793 Train loss: 0.02147791\r\n",
      "Epoch:  84 Step:   230 /   793 Train loss: 0.01889909\r\n",
      "Epoch:  84 Step:   231 /   793 Train loss: 0.02096583\r\n",
      "Epoch:  84 Step:   232 /   793 Train loss: 0.02650098\r\n",
      "Epoch:  84 Step:   233 /   793 Train loss: 0.02077886\r\n",
      "Epoch:  84 Step:   234 /   793 Train loss: 0.02544423\r\n",
      "Epoch:  84 Step:   235 /   793 Train loss: 0.02361164\r\n",
      "Epoch:  84 Step:   236 /   793 Train loss: 0.02011608\r\n",
      "Epoch:  84 Step:   237 /   793 Train loss: 0.02146530\r\n",
      "Epoch:  84 Step:   238 /   793 Train loss: 0.03634251\r\n",
      "Epoch:  84 Step:   239 /   793 Train loss: 0.03058992\r\n",
      "Epoch:  84 Step:   240 /   793 Train loss: 0.02593354\r\n",
      "Epoch:  84 Step:   241 /   793 Train loss: 0.01831895\r\n",
      "Epoch:  84 Step:   242 /   793 Train loss: 0.02950031\r\n",
      "Epoch:  84 Step:   243 /   793 Train loss: 0.01563401\r\n",
      "Epoch:  84 Step:   244 /   793 Train loss: 0.02217081\r\n",
      "Epoch:  84 Step:   245 /   793 Train loss: 0.02643875\r\n",
      "Epoch:  84 Step:   246 /   793 Train loss: 0.03273481\r\n",
      "Epoch:  84 Step:   247 /   793 Train loss: 0.01856330\r\n",
      "Epoch:  84 Step:   248 /   793 Train loss: 0.02943637\r\n",
      "Epoch:  84 Step:   249 /   793 Train loss: 0.03440379\r\n",
      "Epoch:  84 Step:   250 /   793 Train loss: 0.01270831\r\n",
      "Epoch:  84 Step:   251 /   793 Train loss: 0.02058065\r\n",
      "Epoch:  84 Step:   252 /   793 Train loss: 0.02764203\r\n",
      "Epoch:  84 Step:   253 /   793 Train loss: 0.00912947\r\n",
      "Epoch:  84 Step:   254 /   793 Train loss: 0.01371440\r\n",
      "Epoch:  84 Step:   255 /   793 Train loss: 0.03186570\r\n",
      "Epoch:  84 Step:   256 /   793 Train loss: 0.02862858\r\n",
      "Epoch:  84 Step:   257 /   793 Train loss: 0.02275147\r\n",
      "Epoch:  84 Step:   258 /   793 Train loss: 0.01829543\r\n",
      "Epoch:  84 Step:   259 /   793 Train loss: 0.03513285\r\n",
      "Epoch:  84 Step:   260 /   793 Train loss: 0.02759157\r\n",
      "Epoch:  84 Step:   261 /   793 Train loss: 0.02067326\r\n",
      "Epoch:  84 Step:   262 /   793 Train loss: 0.03045792\r\n",
      "Epoch:  84 Step:   263 /   793 Train loss: 0.02443574\r\n",
      "Epoch:  84 Step:   264 /   793 Train loss: 0.03777334\r\n",
      "Epoch:  84 Step:   265 /   793 Train loss: 0.02480088\r\n",
      "Epoch:  84 Step:   266 /   793 Train loss: 0.02075649\r\n",
      "Epoch:  84 Step:   267 /   793 Train loss: 0.01738312\r\n",
      "Epoch:  84 Step:   268 /   793 Train loss: 0.01410192\r\n",
      "Epoch:  84 Step:   269 /   793 Train loss: 0.03228151\r\n",
      "Epoch:  84 Step:   270 /   793 Train loss: 0.03332300\r\n",
      "Epoch:  84 Step:   271 /   793 Train loss: 0.01608865\r\n",
      "Epoch:  84 Step:   272 /   793 Train loss: 0.01935612\r\n",
      "Epoch:  84 Step:   273 /   793 Train loss: 0.00965387\r\n",
      "Epoch:  84 Step:   274 /   793 Train loss: 0.02330900\r\n",
      "Epoch:  84 Step:   275 /   793 Train loss: 0.02884455\r\n",
      "Epoch:  84 Step:   276 /   793 Train loss: 0.03525680\r\n",
      "Epoch:  84 Step:   277 /   793 Train loss: 0.02528208\r\n",
      "Epoch:  84 Step:   278 /   793 Train loss: 0.02867913\r\n",
      "Epoch:  84 Step:   279 /   793 Train loss: 0.02112318\r\n",
      "Epoch:  84 Step:   280 /   793 Train loss: 0.02245119\r\n",
      "Epoch:  84 Step:   281 /   793 Train loss: 0.02004228\r\n",
      "Epoch:  84 Step:   282 /   793 Train loss: 0.02370045\r\n",
      "Epoch:  84 Step:   283 /   793 Train loss: 0.02206388\r\n",
      "Epoch:  84 Step:   284 /   793 Train loss: 0.02542423\r\n",
      "Epoch:  84 Step:   285 /   793 Train loss: 0.01944900\r\n",
      "Epoch:  84 Step:   286 /   793 Train loss: 0.01437864\r\n",
      "Epoch:  84 Step:   287 /   793 Train loss: 0.02438428\r\n",
      "Epoch:  84 Step:   288 /   793 Train loss: 0.01947625\r\n",
      "Epoch:  84 Step:   289 /   793 Train loss: 0.02538036\r\n",
      "Epoch:  84 Step:   290 /   793 Train loss: 0.04313533\r\n",
      "Epoch:  84 Step:   291 /   793 Train loss: 0.01483813\r\n",
      "Epoch:  84 Step:   292 /   793 Train loss: 0.01743709\r\n",
      "Epoch:  84 Step:   293 /   793 Train loss: 0.02140620\r\n",
      "Epoch:  84 Step:   294 /   793 Train loss: 0.02416413\r\n",
      "Epoch:  84 Step:   295 /   793 Train loss: 0.03590714\r\n",
      "Epoch:  84 Step:   296 /   793 Train loss: 0.01531656\r\n",
      "Epoch:  84 Step:   297 /   793 Train loss: 0.02838425\r\n",
      "Epoch:  84 Step:   298 /   793 Train loss: 0.02666597\r\n",
      "Epoch:  84 Step:   299 /   793 Train loss: 0.02157736\r\n",
      "Epoch:  84 Step:   300 /   793 Train loss: 0.03127871\r\n",
      "Epoch:  84 Step:   301 /   793 Train loss: 0.02347620\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  84 Step:   302 /   793 Train loss: 0.00939105\r\n",
      "Epoch:  84 Step:   303 /   793 Train loss: 0.02704572\r\n",
      "Epoch:  84 Step:   304 /   793 Train loss: 0.02242109\r\n",
      "Epoch:  84 Step:   305 /   793 Train loss: 0.03658370\r\n",
      "Epoch:  84 Step:   306 /   793 Train loss: 0.02642147\r\n",
      "Epoch:  84 Step:   307 /   793 Train loss: 0.02223914\r\n",
      "Epoch:  84 Step:   308 /   793 Train loss: 0.01932995\r\n",
      "Epoch:  84 Step:   309 /   793 Train loss: 0.02054254\r\n",
      "Epoch:  84 Step:   310 /   793 Train loss: 0.02067911\r\n",
      "Epoch:  84 Step:   311 /   793 Train loss: 0.02625371\r\n",
      "Epoch:  84 Step:   312 /   793 Train loss: 0.01397206\r\n",
      "Epoch:  84 Step:   313 /   793 Train loss: 0.01401348\r\n",
      "Epoch:  84 Step:   314 /   793 Train loss: 0.03397972\r\n",
      "Epoch:  84 Step:   315 /   793 Train loss: 0.02671978\r\n",
      "Epoch:  84 Step:   316 /   793 Train loss: 0.02752923\r\n",
      "Epoch:  84 Step:   317 /   793 Train loss: 0.02851542\r\n",
      "Epoch:  84 Step:   318 /   793 Train loss: 0.02176895\r\n",
      "Epoch:  84 Step:   319 /   793 Train loss: 0.01572285\r\n",
      "Epoch:  84 Step:   320 /   793 Train loss: 0.03206419\r\n",
      "Epoch:  84 Step:   321 /   793 Train loss: 0.02234051\r\n",
      "Epoch:  84 Step:   322 /   793 Train loss: 0.01081143\r\n",
      "Epoch:  84 Step:   323 /   793 Train loss: 0.03181575\r\n",
      "Epoch:  84 Step:   324 /   793 Train loss: 0.01520436\r\n",
      "Epoch:  84 Step:   325 /   793 Train loss: 0.01686816\r\n",
      "Epoch:  84 Step:   326 /   793 Train loss: 0.02439026\r\n",
      "Epoch:  84 Step:   327 /   793 Train loss: 0.03114272\r\n",
      "Epoch:  84 Step:   328 /   793 Train loss: 0.03396566\r\n",
      "Epoch:  84 Step:   329 /   793 Train loss: 0.02985633\r\n",
      "Epoch:  84 Step:   330 /   793 Train loss: 0.01251310\r\n",
      "Epoch:  84 Step:   331 /   793 Train loss: 0.04198087\r\n",
      "Epoch:  84 Step:   332 /   793 Train loss: 0.02290989\r\n",
      "Epoch:  84 Step:   333 /   793 Train loss: 0.02130647\r\n",
      "Epoch:  84 Step:   334 /   793 Train loss: 0.02112214\r\n",
      "Epoch:  84 Step:   335 /   793 Train loss: 0.02045392\r\n",
      "Epoch:  84 Step:   336 /   793 Train loss: 0.01635683\r\n",
      "Epoch:  84 Step:   337 /   793 Train loss: 0.02428915\r\n",
      "Epoch:  84 Step:   338 /   793 Train loss: 0.02528500\r\n",
      "Epoch:  84 Step:   339 /   793 Train loss: 0.02487532\r\n",
      "Epoch:  84 Step:   340 /   793 Train loss: 0.01790071\r\n",
      "Epoch:  84 Step:   341 /   793 Train loss: 0.01446098\r\n",
      "Epoch:  84 Step:   342 /   793 Train loss: 0.01806105\r\n",
      "Epoch:  84 Step:   343 /   793 Train loss: 0.02610598\r\n",
      "Epoch:  84 Step:   344 /   793 Train loss: 0.03945163\r\n",
      "Epoch:  84 Step:   345 /   793 Train loss: 0.03201864\r\n",
      "Epoch:  84 Step:   346 /   793 Train loss: 0.03232621\r\n",
      "Epoch:  84 Step:   347 /   793 Train loss: 0.03250635\r\n",
      "Epoch:  84 Step:   348 /   793 Train loss: 0.02533445\r\n",
      "Epoch:  84 Step:   349 /   793 Train loss: 0.03430834\r\n",
      "Epoch:  84 Step:   350 /   793 Train loss: 0.02097660\r\n",
      "Epoch:  84 Step:   351 /   793 Train loss: 0.01834986\r\n",
      "Epoch:  84 Step:   352 /   793 Train loss: 0.01842791\r\n",
      "Epoch:  84 Step:   353 /   793 Train loss: 0.02074263\r\n",
      "Epoch:  84 Step:   354 /   793 Train loss: 0.02364537\r\n",
      "Epoch:  84 Step:   355 /   793 Train loss: 0.03116853\r\n",
      "Epoch:  84 Step:   356 /   793 Train loss: 0.03459246\r\n",
      "Epoch:  84 Step:   357 /   793 Train loss: 0.04050574\r\n",
      "Epoch:  84 Step:   358 /   793 Train loss: 0.01990191\r\n",
      "Epoch:  84 Step:   359 /   793 Train loss: 0.02970991\r\n",
      "Epoch:  84 Step:   360 /   793 Train loss: 0.02698222\r\n",
      "Epoch:  84 Step:   361 /   793 Train loss: 0.02459914\r\n",
      "Epoch:  84 Step:   362 /   793 Train loss: 0.01635636\r\n",
      "Epoch:  84 Step:   363 /   793 Train loss: 0.02665604\r\n",
      "Epoch:  84 Step:   364 /   793 Train loss: 0.01534679\r\n",
      "Epoch:  84 Step:   365 /   793 Train loss: 0.03659530\r\n",
      "Epoch:  84 Step:   366 /   793 Train loss: 0.01756921\r\n",
      "Epoch:  84 Step:   367 /   793 Train loss: 0.03285189\r\n",
      "Epoch:  84 Step:   368 /   793 Train loss: 0.02750138\r\n",
      "Epoch:  84 Step:   369 /   793 Train loss: 0.02390040\r\n",
      "Epoch:  84 Step:   370 /   793 Train loss: 0.01716986\r\n",
      "Epoch:  84 Step:   371 /   793 Train loss: 0.02641428\r\n",
      "Epoch:  84 Step:   372 /   793 Train loss: 0.01722745\r\n",
      "Epoch:  84 Step:   373 /   793 Train loss: 0.02163475\r\n",
      "Epoch:  84 Step:   374 /   793 Train loss: 0.01626800\r\n",
      "Epoch:  84 Step:   375 /   793 Train loss: 0.03575133\r\n",
      "Epoch:  84 Step:   376 /   793 Train loss: 0.03092299\r\n",
      "Epoch:  84 Step:   377 /   793 Train loss: 0.03384169\r\n",
      "Epoch:  84 Step:   378 /   793 Train loss: 0.02908074\r\n",
      "Epoch:  84 Step:   379 /   793 Train loss: 0.01996443\r\n",
      "Epoch:  84 Step:   380 /   793 Train loss: 0.02275336\r\n",
      "Epoch:  84 Step:   381 /   793 Train loss: 0.02684895\r\n",
      "Epoch:  84 Step:   382 /   793 Train loss: 0.01686502\r\n",
      "Epoch:  84 Step:   383 /   793 Train loss: 0.03371805\r\n",
      "Epoch:  84 Step:   384 /   793 Train loss: 0.03374883\r\n",
      "Epoch:  84 Step:   385 /   793 Train loss: 0.02334919\r\n",
      "Epoch:  84 Step:   386 /   793 Train loss: 0.02817040\r\n",
      "Epoch:  84 Step:   387 /   793 Train loss: 0.02106804\r\n",
      "Epoch:  84 Step:   388 /   793 Train loss: 0.04648516\r\n",
      "Epoch:  84 Step:   389 /   793 Train loss: 0.01776297\r\n",
      "Epoch:  84 Step:   390 /   793 Train loss: 0.02158740\r\n",
      "Epoch:  84 Step:   391 /   793 Train loss: 0.01822973\r\n",
      "Epoch:  84 Step:   392 /   793 Train loss: 0.01675295\r\n",
      "Epoch:  84 Step:   393 /   793 Train loss: 0.02837346\r\n",
      "Epoch:  84 Step:   394 /   793 Train loss: 0.01865035\r\n",
      "Epoch:  84 Step:   395 /   793 Train loss: 0.03070839\r\n",
      "Epoch:  84 Step:   396 /   793 Train loss: 0.02097662\r\n",
      "Epoch:  84 Step:   397 /   793 Train loss: 0.01512268\r\n",
      "Epoch:  84 Step:   398 /   793 Train loss: 0.02283595\r\n",
      "Epoch:  84 Step:   399 /   793 Train loss: 0.01427046\r\n",
      "Epoch:  84 Step:   400 /   793 Train loss: 0.01736815\r\n",
      "Epoch:  84 Step:   401 /   793 Train loss: 0.01696140\r\n",
      "Epoch:  84 Step:   402 /   793 Train loss: 0.02587351\r\n",
      "Epoch:  84 Step:   403 /   793 Train loss: 0.01722217\r\n",
      "Epoch:  84 Step:   404 /   793 Train loss: 0.01415420\r\n",
      "Epoch:  84 Step:   405 /   793 Train loss: 0.02026155\r\n",
      "Epoch:  84 Step:   406 /   793 Train loss: 0.01589954\r\n",
      "Epoch:  84 Step:   407 /   793 Train loss: 0.01882794\r\n",
      "Epoch:  84 Step:   408 /   793 Train loss: 0.03140622\r\n",
      "Epoch:  84 Step:   409 /   793 Train loss: 0.01934995\r\n",
      "Epoch:  84 Step:   410 /   793 Train loss: 0.02116021\r\n",
      "Epoch:  84 Step:   411 /   793 Train loss: 0.02773041\r\n",
      "Epoch:  84 Step:   412 /   793 Train loss: 0.01770996\r\n",
      "Epoch:  84 Step:   413 /   793 Train loss: 0.02623363\r\n",
      "Epoch:  84 Step:   414 /   793 Train loss: 0.02183229\r\n",
      "Epoch:  84 Step:   415 /   793 Train loss: 0.02078037\r\n",
      "Epoch:  84 Step:   416 /   793 Train loss: 0.03209988\r\n",
      "Epoch:  84 Step:   417 /   793 Train loss: 0.02707109\r\n",
      "Epoch:  84 Step:   418 /   793 Train loss: 0.02608498\r\n",
      "Epoch:  84 Step:   419 /   793 Train loss: 0.02073812\r\n",
      "Epoch:  84 Step:   420 /   793 Train loss: 0.04138871\r\n",
      "Epoch:  84 Step:   421 /   793 Train loss: 0.02050500\r\n",
      "Epoch:  84 Step:   422 /   793 Train loss: 0.02599372\r\n",
      "Epoch:  84 Step:   423 /   793 Train loss: 0.01527919\r\n",
      "Epoch:  84 Step:   424 /   793 Train loss: 0.02870045\r\n",
      "Epoch:  84 Step:   425 /   793 Train loss: 0.02561067\r\n",
      "Epoch:  84 Step:   426 /   793 Train loss: 0.02184759\r\n",
      "Epoch:  84 Step:   427 /   793 Train loss: 0.02433717\r\n",
      "Epoch:  84 Step:   428 /   793 Train loss: 0.01697245\r\n",
      "Epoch:  84 Step:   429 /   793 Train loss: 0.02383912\r\n",
      "Epoch:  84 Step:   430 /   793 Train loss: 0.02910792\r\n",
      "Epoch:  84 Step:   431 /   793 Train loss: 0.02225254\r\n",
      "Epoch:  84 Step:   432 /   793 Train loss: 0.01475975\r\n",
      "Epoch:  84 Step:   433 /   793 Train loss: 0.02781151\r\n",
      "Epoch:  84 Step:   434 /   793 Train loss: 0.02640038\r\n",
      "Epoch:  84 Step:   435 /   793 Train loss: 0.02772551\r\n",
      "Epoch:  84 Step:   436 /   793 Train loss: 0.02275469\r\n",
      "Epoch:  84 Step:   437 /   793 Train loss: 0.02154261\r\n",
      "Epoch:  84 Step:   438 /   793 Train loss: 0.03125403\r\n",
      "Epoch:  84 Step:   439 /   793 Train loss: 0.04242264\r\n",
      "Epoch:  84 Step:   440 /   793 Train loss: 0.01632646\r\n",
      "Epoch:  84 Step:   441 /   793 Train loss: 0.02943361\r\n",
      "Epoch:  84 Step:   442 /   793 Train loss: 0.02504613\r\n",
      "Epoch:  84 Step:   443 /   793 Train loss: 0.01987443\r\n",
      "Epoch:  84 Step:   444 /   793 Train loss: 0.02349298\r\n",
      "Epoch:  84 Step:   445 /   793 Train loss: 0.02572340\r\n",
      "Epoch:  84 Step:   446 /   793 Train loss: 0.02595474\r\n",
      "Epoch:  84 Step:   447 /   793 Train loss: 0.01810425\r\n",
      "Epoch:  84 Step:   448 /   793 Train loss: 0.02749094\r\n",
      "Epoch:  84 Step:   449 /   793 Train loss: 0.01367079\r\n",
      "Epoch:  84 Step:   450 /   793 Train loss: 0.01031708\r\n",
      "Epoch:  84 Step:   451 /   793 Train loss: 0.03158359\r\n",
      "Epoch:  84 Step:   452 /   793 Train loss: 0.02554512\r\n",
      "Epoch:  84 Step:   453 /   793 Train loss: 0.03702100\r\n",
      "Epoch:  84 Step:   454 /   793 Train loss: 0.01734973\r\n",
      "Epoch:  84 Step:   455 /   793 Train loss: 0.02274460\r\n",
      "Epoch:  84 Step:   456 /   793 Train loss: 0.02171585\r\n",
      "Epoch:  84 Step:   457 /   793 Train loss: 0.02896266\r\n",
      "Epoch:  84 Step:   458 /   793 Train loss: 0.02889445\r\n",
      "Epoch:  84 Step:   459 /   793 Train loss: 0.02522347\r\n",
      "Epoch:  84 Step:   460 /   793 Train loss: 0.02515199\r\n",
      "Epoch:  84 Step:   461 /   793 Train loss: 0.02388208\r\n",
      "Epoch:  84 Step:   462 /   793 Train loss: 0.03509070\r\n",
      "Epoch:  84 Step:   463 /   793 Train loss: 0.03531089\r\n",
      "Epoch:  84 Step:   464 /   793 Train loss: 0.01606192\r\n",
      "Epoch:  84 Step:   465 /   793 Train loss: 0.02595850\r\n",
      "Epoch:  84 Step:   466 /   793 Train loss: 0.03326093\r\n",
      "Epoch:  84 Step:   467 /   793 Train loss: 0.03046254\r\n",
      "Epoch:  84 Step:   468 /   793 Train loss: 0.02916135\r\n",
      "Epoch:  84 Step:   469 /   793 Train loss: 0.02831166\r\n",
      "Epoch:  84 Step:   470 /   793 Train loss: 0.01929178\r\n",
      "Epoch:  84 Step:   471 /   793 Train loss: 0.02744346\r\n",
      "Epoch:  84 Step:   472 /   793 Train loss: 0.03244819\r\n",
      "Epoch:  84 Step:   473 /   793 Train loss: 0.02273928\r\n",
      "Epoch:  84 Step:   474 /   793 Train loss: 0.01944207\r\n",
      "Epoch:  84 Step:   475 /   793 Train loss: 0.02631697\r\n",
      "Epoch:  84 Step:   476 /   793 Train loss: 0.02047886\r\n",
      "Epoch:  84 Step:   477 /   793 Train loss: 0.02432052\r\n",
      "Epoch:  84 Step:   478 /   793 Train loss: 0.02720995\r\n",
      "Epoch:  84 Step:   479 /   793 Train loss: 0.02084360\r\n",
      "Epoch:  84 Step:   480 /   793 Train loss: 0.02712349\r\n",
      "Epoch:  84 Step:   481 /   793 Train loss: 0.01878185\r\n",
      "Epoch:  84 Step:   482 /   793 Train loss: 0.01951135\r\n",
      "Epoch:  84 Step:   483 /   793 Train loss: 0.01680415\r\n",
      "Epoch:  84 Step:   484 /   793 Train loss: 0.02051595\r\n",
      "Epoch:  84 Step:   485 /   793 Train loss: 0.02155053\r\n",
      "Epoch:  84 Step:   486 /   793 Train loss: 0.01314088\r\n",
      "Epoch:  84 Step:   487 /   793 Train loss: 0.01445198\r\n",
      "Epoch:  84 Step:   488 /   793 Train loss: 0.02594952\r\n",
      "Epoch:  84 Step:   489 /   793 Train loss: 0.01655404\r\n",
      "Epoch:  84 Step:   490 /   793 Train loss: 0.03562997\r\n",
      "Epoch:  84 Step:   491 /   793 Train loss: 0.02893463\r\n",
      "Epoch:  84 Step:   492 /   793 Train loss: 0.02862173\r\n",
      "Epoch:  84 Step:   493 /   793 Train loss: 0.01067984\r\n",
      "Epoch:  84 Step:   494 /   793 Train loss: 0.03021330\r\n",
      "Epoch:  84 Step:   495 /   793 Train loss: 0.03493538\r\n",
      "Epoch:  84 Step:   496 /   793 Train loss: 0.03015725\r\n",
      "Epoch:  84 Step:   497 /   793 Train loss: 0.02195732\r\n",
      "Epoch:  84 Step:   498 /   793 Train loss: 0.02487815\r\n",
      "Epoch:  84 Step:   499 /   793 Train loss: 0.03550225\r\n",
      "Epoch:  84 Step:   500 /   793 Train loss: 0.03091833\r\n",
      "Epoch:  84 Step:   501 /   793 Train loss: 0.01500394\r\n",
      "Epoch:  84 Step:   502 /   793 Train loss: 0.01389237\r\n",
      "Epoch:  84 Step:   503 /   793 Train loss: 0.03107076\r\n",
      "Epoch:  84 Step:   504 /   793 Train loss: 0.03200284\r\n",
      "Epoch:  84 Step:   505 /   793 Train loss: 0.02603335\r\n",
      "Epoch:  84 Step:   506 /   793 Train loss: 0.02002712\r\n",
      "Epoch:  84 Step:   507 /   793 Train loss: 0.03806082\r\n",
      "Epoch:  84 Step:   508 /   793 Train loss: 0.01613864\r\n",
      "Epoch:  84 Step:   509 /   793 Train loss: 0.02612927\r\n",
      "Epoch:  84 Step:   510 /   793 Train loss: 0.02734280\r\n",
      "Epoch:  84 Step:   511 /   793 Train loss: 0.02216602\r\n",
      "Epoch:  84 Step:   512 /   793 Train loss: 0.02536062\r\n",
      "Epoch:  84 Step:   513 /   793 Train loss: 0.01727379\r\n",
      "Epoch:  84 Step:   514 /   793 Train loss: 0.03223582\r\n",
      "Epoch:  84 Step:   515 /   793 Train loss: 0.01793932\r\n",
      "Epoch:  84 Step:   516 /   793 Train loss: 0.03343182\r\n",
      "Epoch:  84 Step:   517 /   793 Train loss: 0.01689426\r\n",
      "Epoch:  84 Step:   518 /   793 Train loss: 0.03514545\r\n",
      "Epoch:  84 Step:   519 /   793 Train loss: 0.01581660\r\n",
      "Epoch:  84 Step:   520 /   793 Train loss: 0.04693655\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  84 Step:   521 /   793 Train loss: 0.02199323\r\n",
      "Epoch:  84 Step:   522 /   793 Train loss: 0.01476758\r\n",
      "Epoch:  84 Step:   523 /   793 Train loss: 0.02391119\r\n",
      "Epoch:  84 Step:   524 /   793 Train loss: 0.03339531\r\n",
      "Epoch:  84 Step:   525 /   793 Train loss: 0.03095657\r\n",
      "Epoch:  84 Step:   526 /   793 Train loss: 0.02628054\r\n",
      "Epoch:  84 Step:   527 /   793 Train loss: 0.02569326\r\n",
      "Epoch:  84 Step:   528 /   793 Train loss: 0.01237043\r\n",
      "Epoch:  84 Step:   529 /   793 Train loss: 0.03053810\r\n",
      "Epoch:  84 Step:   530 /   793 Train loss: 0.02490231\r\n",
      "Epoch:  84 Step:   531 /   793 Train loss: 0.02690430\r\n",
      "Epoch:  84 Step:   532 /   793 Train loss: 0.03212662\r\n",
      "Epoch:  84 Step:   533 /   793 Train loss: 0.02359647\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  84 Step:   534 /   793 Train loss: 0.03211579\r\n",
      "Epoch:  84 Step:   535 /   793 Train loss: 0.02584470\r\n",
      "Epoch:  84 Step:   536 /   793 Train loss: 0.02105592\r\n",
      "Epoch:  84 Step:   537 /   793 Train loss: 0.02264534\r\n",
      "Epoch:  84 Step:   538 /   793 Train loss: 0.01686505\r\n",
      "Epoch:  84 Step:   539 /   793 Train loss: 0.02013260\r\n",
      "Epoch:  84 Step:   540 /   793 Train loss: 0.03261837\r\n",
      "Epoch:  84 Step:   541 /   793 Train loss: 0.02903529\r\n",
      "Epoch:  84 Step:   542 /   793 Train loss: 0.02357638\r\n",
      "Epoch:  84 Step:   543 /   793 Train loss: 0.02236617\r\n",
      "Epoch:  84 Step:   544 /   793 Train loss: 0.01750918\r\n",
      "Epoch:  84 Step:   545 /   793 Train loss: 0.01858182\r\n",
      "Epoch:  84 Step:   546 /   793 Train loss: 0.02150782\r\n",
      "Epoch:  84 Step:   547 /   793 Train loss: 0.02119233\r\n",
      "Epoch:  84 Step:   548 /   793 Train loss: 0.02399858\r\n",
      "Epoch:  84 Step:   549 /   793 Train loss: 0.02439856\r\n",
      "Epoch:  84 Step:   550 /   793 Train loss: 0.03198743\r\n",
      "Epoch:  84 Step:   551 /   793 Train loss: 0.02423553\r\n",
      "Epoch:  84 Step:   552 /   793 Train loss: 0.01776853\r\n",
      "Epoch:  84 Step:   553 /   793 Train loss: 0.02489407\r\n",
      "Epoch:  84 Step:   554 /   793 Train loss: 0.02766895\r\n",
      "Epoch:  84 Step:   555 /   793 Train loss: 0.02170688\r\n",
      "Epoch:  84 Step:   556 /   793 Train loss: 0.02231550\r\n",
      "Epoch:  84 Step:   557 /   793 Train loss: 0.03337572\r\n",
      "Epoch:  84 Step:   558 /   793 Train loss: 0.02107226\r\n",
      "Epoch:  84 Step:   559 /   793 Train loss: 0.01324212\r\n",
      "Epoch:  84 Step:   560 /   793 Train loss: 0.03467216\r\n",
      "Epoch:  84 Step:   561 /   793 Train loss: 0.03081722\r\n",
      "Epoch:  84 Step:   562 /   793 Train loss: 0.01846746\r\n",
      "Epoch:  84 Step:   563 /   793 Train loss: 0.02558016\r\n",
      "Epoch:  84 Step:   564 /   793 Train loss: 0.01705652\r\n",
      "Epoch:  84 Step:   565 /   793 Train loss: 0.01840425\r\n",
      "Epoch:  84 Step:   566 /   793 Train loss: 0.03808638\r\n",
      "Epoch:  84 Step:   567 /   793 Train loss: 0.01821084\r\n",
      "Epoch:  84 Step:   568 /   793 Train loss: 0.02141101\r\n",
      "Epoch:  84 Step:   569 /   793 Train loss: 0.02269965\r\n",
      "Epoch:  84 Step:   570 /   793 Train loss: 0.02273240\r\n",
      "Epoch:  84 Step:   571 /   793 Train loss: 0.03917962\r\n",
      "Epoch:  84 Step:   572 /   793 Train loss: 0.01868596\r\n",
      "Epoch:  84 Step:   573 /   793 Train loss: 0.01990911\r\n",
      "Epoch:  84 Step:   574 /   793 Train loss: 0.02302347\r\n",
      "Epoch:  84 Step:   575 /   793 Train loss: 0.01748231\r\n",
      "Epoch:  84 Step:   576 /   793 Train loss: 0.02071393\r\n",
      "Epoch:  84 Step:   577 /   793 Train loss: 0.01941699\r\n",
      "Epoch:  84 Step:   578 /   793 Train loss: 0.01647040\r\n",
      "Epoch:  84 Step:   579 /   793 Train loss: 0.02928311\r\n",
      "Epoch:  84 Step:   580 /   793 Train loss: 0.02065632\r\n",
      "Epoch:  84 Step:   581 /   793 Train loss: 0.02099409\r\n",
      "Epoch:  84 Step:   582 /   793 Train loss: 0.02027736\r\n",
      "Epoch:  84 Step:   583 /   793 Train loss: 0.01157418\r\n",
      "Epoch:  84 Step:   584 /   793 Train loss: 0.02623794\r\n",
      "Epoch:  84 Step:   585 /   793 Train loss: 0.03476661\r\n",
      "Epoch:  84 Step:   586 /   793 Train loss: 0.02791719\r\n",
      "Epoch:  84 Step:   587 /   793 Train loss: 0.01207990\r\n",
      "Epoch:  84 Step:   588 /   793 Train loss: 0.03033187\r\n",
      "Epoch:  84 Step:   589 /   793 Train loss: 0.01678442\r\n",
      "Epoch:  84 Step:   590 /   793 Train loss: 0.02651277\r\n",
      "Epoch:  84 Step:   591 /   793 Train loss: 0.03712071\r\n",
      "Epoch:  84 Step:   592 /   793 Train loss: 0.02846837\r\n",
      "Epoch:  84 Step:   593 /   793 Train loss: 0.02651830\r\n",
      "Epoch:  84 Step:   594 /   793 Train loss: 0.02211260\r\n",
      "Epoch:  84 Step:   595 /   793 Train loss: 0.01897636\r\n",
      "Epoch:  84 Step:   596 /   793 Train loss: 0.02272926\r\n",
      "Epoch:  84 Step:   597 /   793 Train loss: 0.02066169\r\n",
      "Epoch:  84 Step:   598 /   793 Train loss: 0.01864766\r\n",
      "Epoch:  84 Step:   599 /   793 Train loss: 0.02686130\r\n",
      "Epoch:  84 Step:   600 /   793 Train loss: 0.01064979\r\n",
      "Epoch:  84 Step:   601 /   793 Train loss: 0.01836757\r\n",
      "Epoch:  84 Step:   602 /   793 Train loss: 0.02953875\r\n",
      "Epoch:  84 Step:   603 /   793 Train loss: 0.02012314\r\n",
      "Epoch:  84 Step:   604 /   793 Train loss: 0.01660464\r\n",
      "Epoch:  84 Step:   605 /   793 Train loss: 0.03234882\r\n",
      "Epoch:  84 Step:   606 /   793 Train loss: 0.03019598\r\n",
      "Epoch:  84 Step:   607 /   793 Train loss: 0.02561945\r\n",
      "Epoch:  84 Step:   608 /   793 Train loss: 0.03112731\r\n",
      "Epoch:  84 Step:   609 /   793 Train loss: 0.01695140\r\n",
      "Epoch:  84 Step:   610 /   793 Train loss: 0.03438864\r\n",
      "Epoch:  84 Step:   611 /   793 Train loss: 0.02287956\r\n",
      "Epoch:  84 Step:   612 /   793 Train loss: 0.01996855\r\n",
      "Epoch:  84 Step:   613 /   793 Train loss: 0.01822255\r\n",
      "Epoch:  84 Step:   614 /   793 Train loss: 0.01347783\r\n",
      "Epoch:  84 Step:   615 /   793 Train loss: 0.02038597\r\n",
      "Epoch:  84 Step:   616 /   793 Train loss: 0.02629298\r\n",
      "Epoch:  84 Step:   617 /   793 Train loss: 0.02063208\r\n",
      "Epoch:  84 Step:   618 /   793 Train loss: 0.02853716\r\n",
      "Epoch:  84 Step:   619 /   793 Train loss: 0.03001196\r\n",
      "Epoch:  84 Step:   620 /   793 Train loss: 0.02167414\r\n",
      "Epoch:  84 Step:   621 /   793 Train loss: 0.02453493\r\n",
      "Epoch:  84 Step:   622 /   793 Train loss: 0.01888388\r\n",
      "Epoch:  84 Step:   623 /   793 Train loss: 0.02204590\r\n",
      "Epoch:  84 Step:   624 /   793 Train loss: 0.02508520\r\n",
      "Epoch:  84 Step:   625 /   793 Train loss: 0.02644708\r\n",
      "Epoch:  84 Step:   626 /   793 Train loss: 0.02536695\r\n",
      "Epoch:  84 Step:   627 /   793 Train loss: 0.02079114\r\n",
      "Epoch:  84 Step:   628 /   793 Train loss: 0.02410712\r\n",
      "Epoch:  84 Step:   629 /   793 Train loss: 0.02026974\r\n",
      "Epoch:  84 Step:   630 /   793 Train loss: 0.02661234\r\n",
      "Epoch:  84 Step:   631 /   793 Train loss: 0.01707295\r\n",
      "Epoch:  84 Step:   632 /   793 Train loss: 0.01077094\r\n",
      "Epoch:  84 Step:   633 /   793 Train loss: 0.03286700\r\n",
      "Epoch:  84 Step:   634 /   793 Train loss: 0.01977194\r\n",
      "Epoch:  84 Step:   635 /   793 Train loss: 0.01274490\r\n",
      "Epoch:  84 Step:   636 /   793 Train loss: 0.02147157\r\n",
      "Epoch:  84 Step:   637 /   793 Train loss: 0.03798418\r\n",
      "Epoch:  84 Step:   638 /   793 Train loss: 0.02220504\r\n",
      "Epoch:  84 Step:   639 /   793 Train loss: 0.02704461\r\n",
      "Epoch:  84 Step:   640 /   793 Train loss: 0.03003775\r\n",
      "Epoch:  84 Step:   641 /   793 Train loss: 0.01862217\r\n",
      "Epoch:  84 Step:   642 /   793 Train loss: 0.03518167\r\n",
      "Epoch:  84 Step:   643 /   793 Train loss: 0.03474554\r\n",
      "Epoch:  84 Step:   644 /   793 Train loss: 0.02123207\r\n",
      "Epoch:  84 Step:   645 /   793 Train loss: 0.03183954\r\n",
      "Epoch:  84 Step:   646 /   793 Train loss: 0.03697373\r\n",
      "Epoch:  84 Step:   647 /   793 Train loss: 0.02454213\r\n",
      "Epoch:  84 Step:   648 /   793 Train loss: 0.02402274\r\n",
      "Epoch:  84 Step:   649 /   793 Train loss: 0.01981096\r\n",
      "Epoch:  84 Step:   650 /   793 Train loss: 0.01669153\r\n",
      "Epoch:  84 Step:   651 /   793 Train loss: 0.02126370\r\n",
      "Epoch:  84 Step:   652 /   793 Train loss: 0.02598785\r\n",
      "Epoch:  84 Step:   653 /   793 Train loss: 0.02789877\r\n",
      "Epoch:  84 Step:   654 /   793 Train loss: 0.01842631\r\n",
      "Epoch:  84 Step:   655 /   793 Train loss: 0.03142491\r\n",
      "Epoch:  84 Step:   656 /   793 Train loss: 0.01985779\r\n",
      "Epoch:  84 Step:   657 /   793 Train loss: 0.04707894\r\n",
      "Epoch:  84 Step:   658 /   793 Train loss: 0.02597479\r\n",
      "Epoch:  84 Step:   659 /   793 Train loss: 0.03351006\r\n",
      "Epoch:  84 Step:   660 /   793 Train loss: 0.02491833\r\n",
      "Epoch:  84 Step:   661 /   793 Train loss: 0.02578609\r\n",
      "Epoch:  84 Step:   662 /   793 Train loss: 0.01489878\r\n",
      "Epoch:  84 Step:   663 /   793 Train loss: 0.02143992\r\n",
      "Epoch:  84 Step:   664 /   793 Train loss: 0.02406674\r\n",
      "Epoch:  84 Step:   665 /   793 Train loss: 0.02783585\r\n",
      "Epoch:  84 Step:   666 /   793 Train loss: 0.02459030\r\n",
      "Epoch:  84 Step:   667 /   793 Train loss: 0.03188908\r\n",
      "Epoch:  84 Step:   668 /   793 Train loss: 0.03700008\r\n",
      "Epoch:  84 Step:   669 /   793 Train loss: 0.02753538\r\n",
      "Epoch:  84 Step:   670 /   793 Train loss: 0.03016645\r\n",
      "Epoch:  84 Step:   671 /   793 Train loss: 0.02821886\r\n",
      "Epoch:  84 Step:   672 /   793 Train loss: 0.02091442\r\n",
      "Epoch:  84 Step:   673 /   793 Train loss: 0.02168425\r\n",
      "Epoch:  84 Step:   674 /   793 Train loss: 0.03401216\r\n",
      "Epoch:  84 Step:   675 /   793 Train loss: 0.01731201\r\n",
      "Epoch:  84 Step:   676 /   793 Train loss: 0.01990388\r\n",
      "Epoch:  84 Step:   677 /   793 Train loss: 0.01950618\r\n",
      "Epoch:  84 Step:   678 /   793 Train loss: 0.02034508\r\n",
      "Epoch:  84 Step:   679 /   793 Train loss: 0.03727875\r\n",
      "Epoch:  84 Step:   680 /   793 Train loss: 0.02334206\r\n",
      "Epoch:  84 Step:   681 /   793 Train loss: 0.01479172\r\n",
      "Epoch:  84 Step:   682 /   793 Train loss: 0.03186124\r\n",
      "Epoch:  84 Step:   683 /   793 Train loss: 0.02146383\r\n",
      "Epoch:  84 Step:   684 /   793 Train loss: 0.02527517\r\n",
      "Epoch:  84 Step:   685 /   793 Train loss: 0.01930233\r\n",
      "Epoch:  84 Step:   686 /   793 Train loss: 0.01667987\r\n",
      "Epoch:  84 Step:   687 /   793 Train loss: 0.02585745\r\n",
      "Epoch:  84 Step:   688 /   793 Train loss: 0.01989288\r\n",
      "Epoch:  84 Step:   689 /   793 Train loss: 0.01399891\r\n",
      "Epoch:  84 Step:   690 /   793 Train loss: 0.03442107\r\n",
      "Epoch:  84 Step:   691 /   793 Train loss: 0.02353166\r\n",
      "Epoch:  84 Step:   692 /   793 Train loss: 0.03128765\r\n",
      "Epoch:  84 Step:   693 /   793 Train loss: 0.01792677\r\n",
      "Epoch:  84 Step:   694 /   793 Train loss: 0.02384355\r\n",
      "Epoch:  84 Step:   695 /   793 Train loss: 0.03016960\r\n",
      "Epoch:  84 Step:   696 /   793 Train loss: 0.03133415\r\n",
      "Epoch:  84 Step:   697 /   793 Train loss: 0.02510319\r\n",
      "Epoch:  84 Step:   698 /   793 Train loss: 0.02321693\r\n",
      "Epoch:  84 Step:   699 /   793 Train loss: 0.02685550\r\n",
      "Epoch:  84 Step:   700 /   793 Train loss: 0.02608438\r\n",
      "Epoch:  84 Step:   701 /   793 Train loss: 0.02334275\r\n",
      "Epoch:  84 Step:   702 /   793 Train loss: 0.02991099\r\n",
      "Epoch:  84 Step:   703 /   793 Train loss: 0.03433795\r\n",
      "Epoch:  84 Step:   704 /   793 Train loss: 0.02831169\r\n",
      "Epoch:  84 Step:   705 /   793 Train loss: 0.02524687\r\n",
      "Epoch:  84 Step:   706 /   793 Train loss: 0.01226385\r\n",
      "Epoch:  84 Step:   707 /   793 Train loss: 0.01761112\r\n",
      "Epoch:  84 Step:   708 /   793 Train loss: 0.02200539\r\n",
      "Epoch:  84 Step:   709 /   793 Train loss: 0.03617620\r\n",
      "Epoch:  84 Step:   710 /   793 Train loss: 0.02236919\r\n",
      "Epoch:  84 Step:   711 /   793 Train loss: 0.02809214\r\n",
      "Epoch:  84 Step:   712 /   793 Train loss: 0.01648095\r\n",
      "Epoch:  84 Step:   713 /   793 Train loss: 0.02851271\r\n",
      "Epoch:  84 Step:   714 /   793 Train loss: 0.02699429\r\n",
      "Epoch:  84 Step:   715 /   793 Train loss: 0.02849831\r\n",
      "Epoch:  84 Step:   716 /   793 Train loss: 0.02102574\r\n",
      "Epoch:  84 Step:   717 /   793 Train loss: 0.03892895\r\n",
      "Epoch:  84 Step:   718 /   793 Train loss: 0.02147534\r\n",
      "Epoch:  84 Step:   719 /   793 Train loss: 0.01676768\r\n",
      "Epoch:  84 Step:   720 /   793 Train loss: 0.03486311\r\n",
      "Epoch:  84 Step:   721 /   793 Train loss: 0.03221753\r\n",
      "Epoch:  84 Step:   722 /   793 Train loss: 0.01899185\r\n",
      "Epoch:  84 Step:   723 /   793 Train loss: 0.02112430\r\n",
      "Epoch:  84 Step:   724 /   793 Train loss: 0.02215825\r\n",
      "Epoch:  84 Step:   725 /   793 Train loss: 0.03361157\r\n",
      "Epoch:  84 Step:   726 /   793 Train loss: 0.02524567\r\n",
      "Epoch:  84 Step:   727 /   793 Train loss: 0.02235373\r\n",
      "Epoch:  84 Step:   728 /   793 Train loss: 0.01950872\r\n",
      "Epoch:  84 Step:   729 /   793 Train loss: 0.02395724\r\n",
      "Epoch:  84 Step:   730 /   793 Train loss: 0.01989028\r\n",
      "Epoch:  84 Step:   731 /   793 Train loss: 0.02861573\r\n",
      "Epoch:  84 Step:   732 /   793 Train loss: 0.02380319\r\n",
      "Epoch:  84 Step:   733 /   793 Train loss: 0.01451685\r\n",
      "Epoch:  84 Step:   734 /   793 Train loss: 0.03619536\r\n",
      "Epoch:  84 Step:   735 /   793 Train loss: 0.03257232\r\n",
      "Epoch:  84 Step:   736 /   793 Train loss: 0.02968671\r\n",
      "Epoch:  84 Step:   737 /   793 Train loss: 0.03233458\r\n",
      "Epoch:  84 Step:   738 /   793 Train loss: 0.01936619\r\n",
      "Epoch:  84 Step:   739 /   793 Train loss: 0.01943466\r\n",
      "Epoch:  84 Step:   740 /   793 Train loss: 0.02847203\r\n",
      "Epoch:  84 Step:   741 /   793 Train loss: 0.02753450\r\n",
      "Epoch:  84 Step:   742 /   793 Train loss: 0.01765975\r\n",
      "Epoch:  84 Step:   743 /   793 Train loss: 0.01371227\r\n",
      "Epoch:  84 Step:   744 /   793 Train loss: 0.03870643\r\n",
      "Epoch:  84 Step:   745 /   793 Train loss: 0.01416993\r\n",
      "Epoch:  84 Step:   746 /   793 Train loss: 0.02485620\r\n",
      "Epoch:  84 Step:   747 /   793 Train loss: 0.01854387\r\n",
      "Epoch:  84 Step:   748 /   793 Train loss: 0.01818268\r\n",
      "Epoch:  84 Step:   749 /   793 Train loss: 0.01448975\r\n",
      "Epoch:  84 Step:   750 /   793 Train loss: 0.02396558\r\n",
      "Epoch:  84 Step:   751 /   793 Train loss: 0.02995560\r\n",
      "Epoch:  84 Step:   752 /   793 Train loss: 0.02842656\r\n",
      "Epoch:  84 Step:   753 /   793 Train loss: 0.03282207\r\n",
      "Epoch:  84 Step:   754 /   793 Train loss: 0.02873284\r\n",
      "Epoch:  84 Step:   755 /   793 Train loss: 0.02719121\r\n",
      "Epoch:  84 Step:   756 /   793 Train loss: 0.03385880\r\n",
      "Epoch:  84 Step:   757 /   793 Train loss: 0.01846201\r\n",
      "Epoch:  84 Step:   758 /   793 Train loss: 0.02077340\r\n",
      "Epoch:  84 Step:   759 /   793 Train loss: 0.02194812\r\n",
      "Epoch:  84 Step:   760 /   793 Train loss: 0.02111428\r\n",
      "Epoch:  84 Step:   761 /   793 Train loss: 0.03684970\r\n",
      "Epoch:  84 Step:   762 /   793 Train loss: 0.02455113\r\n",
      "Epoch:  84 Step:   763 /   793 Train loss: 0.01474305\r\n",
      "Epoch:  84 Step:   764 /   793 Train loss: 0.02903942\r\n",
      "Epoch:  84 Step:   765 /   793 Train loss: 0.01688274\r\n",
      "Epoch:  84 Step:   766 /   793 Train loss: 0.02124285\r\n",
      "Epoch:  84 Step:   767 /   793 Train loss: 0.03059269\r\n",
      "Epoch:  84 Step:   768 /   793 Train loss: 0.02348787\r\n",
      "Epoch:  84 Step:   769 /   793 Train loss: 0.02203356\r\n",
      "Epoch:  84 Step:   770 /   793 Train loss: 0.01958426\r\n",
      "Epoch:  84 Step:   771 /   793 Train loss: 0.02294012\r\n",
      "Epoch:  84 Step:   772 /   793 Train loss: 0.03057830\r\n",
      "Epoch:  84 Step:   773 /   793 Train loss: 0.03157989\r\n",
      "Epoch:  84 Step:   774 /   793 Train loss: 0.04156320\r\n",
      "Epoch:  84 Step:   775 /   793 Train loss: 0.02019008\r\n",
      "Epoch:  84 Step:   776 /   793 Train loss: 0.03375863\r\n",
      "Epoch:  84 Step:   777 /   793 Train loss: 0.01436988\r\n",
      "Epoch:  84 Step:   778 /   793 Train loss: 0.02610281\r\n",
      "Epoch:  84 Step:   779 /   793 Train loss: 0.02141964\r\n",
      "Epoch:  84 Step:   780 /   793 Train loss: 0.02631886\r\n",
      "Epoch:  84 Step:   781 /   793 Train loss: 0.02458502\r\n",
      "Epoch:  84 Step:   782 /   793 Train loss: 0.01979405\r\n",
      "Epoch:  84 Step:   783 /   793 Train loss: 0.01928542\r\n",
      "Epoch:  84 Step:   784 /   793 Train loss: 0.02680548\r\n",
      "Epoch:  84 Step:   785 /   793 Train loss: 0.01865983\r\n",
      "Epoch:  84 Step:   786 /   793 Train loss: 0.02560422\r\n",
      "Epoch:  84 Step:   787 /   793 Train loss: 0.02478876\r\n",
      "Epoch:  84 Step:   788 /   793 Train loss: 0.00877651\r\n",
      "Epoch:  84 Step:   789 /   793 Train loss: 0.01556449\r\n",
      "Epoch:  84 Step:   790 /   793 Train loss: 0.01401595\r\n",
      "Epoch:  84 Step:   791 /   793 Train loss: 0.02554314\r\n",
      "Epoch:  84 Step:   792 /   793 Train loss: 0.02156262\r\n",
      "Epoch:  85 Step:     0 /   793 Train loss: 0.03014440\r\n",
      "Epoch:  85 Step:     1 /   793 Train loss: 0.02617116\r\n",
      "Epoch:  85 Step:     2 /   793 Train loss: 0.02729192\r\n",
      "Epoch:  85 Step:     3 /   793 Train loss: 0.01776870\r\n",
      "Epoch:  85 Step:     4 /   793 Train loss: 0.03369432\r\n",
      "Epoch:  85 Step:     5 /   793 Train loss: 0.02379777\r\n",
      "Epoch:  85 Step:     6 /   793 Train loss: 0.02992648\r\n",
      "Epoch:  85 Step:     7 /   793 Train loss: 0.02557413\r\n",
      "Epoch:  85 Step:     8 /   793 Train loss: 0.02064724\r\n",
      "Epoch:  85 Step:     9 /   793 Train loss: 0.01608577\r\n",
      "Epoch:  85 Step:    10 /   793 Train loss: 0.03145077\r\n",
      "Epoch:  85 Step:    11 /   793 Train loss: 0.01953315\r\n",
      "Epoch:  85 Step:    12 /   793 Train loss: 0.02285542\r\n",
      "Epoch:  85 Step:    13 /   793 Train loss: 0.02260947\r\n",
      "Epoch:  85 Step:    14 /   793 Train loss: 0.01840969\r\n",
      "Epoch:  85 Step:    15 /   793 Train loss: 0.01379072\r\n",
      "Epoch:  85 Step:    16 /   793 Train loss: 0.02622924\r\n",
      "Epoch:  85 Step:    17 /   793 Train loss: 0.03808506\r\n",
      "Epoch:  85 Step:    18 /   793 Train loss: 0.02474598\r\n",
      "Epoch:  85 Step:    19 /   793 Train loss: 0.02569160\r\n",
      "Epoch:  85 Step:    20 /   793 Train loss: 0.01592416\r\n",
      "Epoch:  85 Step:    21 /   793 Train loss: 0.02601775\r\n",
      "Epoch:  85 Step:    22 /   793 Train loss: 0.01663287\r\n",
      "Epoch:  85 Step:    23 /   793 Train loss: 0.02525008\r\n",
      "Epoch:  85 Step:    24 /   793 Train loss: 0.02424758\r\n",
      "Epoch:  85 Step:    25 /   793 Train loss: 0.03241815\r\n",
      "Epoch:  85 Step:    26 /   793 Train loss: 0.02589225\r\n",
      "Epoch:  85 Step:    27 /   793 Train loss: 0.02688200\r\n",
      "Epoch:  85 Step:    28 /   793 Train loss: 0.02045891\r\n",
      "Epoch:  85 Step:    29 /   793 Train loss: 0.02396906\r\n",
      "Epoch:  85 Step:    30 /   793 Train loss: 0.02894393\r\n",
      "Epoch:  85 Step:    31 /   793 Train loss: 0.02411834\r\n",
      "Epoch:  85 Step:    32 /   793 Train loss: 0.01846936\r\n",
      "Epoch:  85 Step:    33 /   793 Train loss: 0.02108843\r\n",
      "Epoch:  85 Step:    34 /   793 Train loss: 0.03342074\r\n",
      "Epoch:  85 Step:    35 /   793 Train loss: 0.02853962\r\n",
      "Epoch:  85 Step:    36 /   793 Train loss: 0.02620451\r\n",
      "Epoch:  85 Step:    37 /   793 Train loss: 0.03037107\r\n",
      "Epoch:  85 Step:    38 /   793 Train loss: 0.03161725\r\n",
      "Epoch:  85 Step:    39 /   793 Train loss: 0.02735585\r\n",
      "Epoch:  85 Step:    40 /   793 Train loss: 0.02481521\r\n",
      "Epoch:  85 Step:    41 /   793 Train loss: 0.02122703\r\n",
      "Epoch:  85 Step:    42 /   793 Train loss: 0.01960694\r\n",
      "Epoch:  85 Step:    43 /   793 Train loss: 0.02584315\r\n",
      "Epoch:  85 Step:    44 /   793 Train loss: 0.01673612\r\n",
      "Epoch:  85 Step:    45 /   793 Train loss: 0.02340767\r\n",
      "Epoch:  85 Step:    46 /   793 Train loss: 0.02189399\r\n",
      "Epoch:  85 Step:    47 /   793 Train loss: 0.01329999\r\n",
      "Epoch:  85 Step:    48 /   793 Train loss: 0.01621352\r\n",
      "Epoch:  85 Step:    49 /   793 Train loss: 0.02481094\r\n",
      "Epoch:  85 Step:    50 /   793 Train loss: 0.03597388\r\n",
      "Epoch:  85 Step:    51 /   793 Train loss: 0.03327702\r\n",
      "Epoch:  85 Step:    52 /   793 Train loss: 0.02180097\r\n",
      "Epoch:  85 Step:    53 /   793 Train loss: 0.03199429\r\n",
      "Epoch:  85 Step:    54 /   793 Train loss: 0.01754305\r\n",
      "Epoch:  85 Step:    55 /   793 Train loss: 0.01642094\r\n",
      "Epoch:  85 Step:    56 /   793 Train loss: 0.02455007\r\n",
      "Epoch:  85 Step:    57 /   793 Train loss: 0.02640237\r\n",
      "Epoch:  85 Step:    58 /   793 Train loss: 0.02460630\r\n",
      "Epoch:  85 Step:    59 /   793 Train loss: 0.02119636\r\n",
      "Epoch:  85 Step:    60 /   793 Train loss: 0.04101741\r\n",
      "Epoch:  85 Step:    61 /   793 Train loss: 0.01722333\r\n",
      "Epoch:  85 Step:    62 /   793 Train loss: 0.02137015\r\n",
      "Epoch:  85 Step:    63 /   793 Train loss: 0.01643344\r\n",
      "Epoch:  85 Step:    64 /   793 Train loss: 0.02401596\r\n",
      "Epoch:  85 Step:    65 /   793 Train loss: 0.02656898\r\n",
      "Epoch:  85 Step:    66 /   793 Train loss: 0.03360239\r\n",
      "Epoch:  85 Step:    67 /   793 Train loss: 0.02747487\r\n",
      "Epoch:  85 Step:    68 /   793 Train loss: 0.01070180\r\n",
      "Epoch:  85 Step:    69 /   793 Train loss: 0.02961640\r\n",
      "Epoch:  85 Step:    70 /   793 Train loss: 0.01949047\r\n",
      "Epoch:  85 Step:    71 /   793 Train loss: 0.02930745\r\n",
      "Epoch:  85 Step:    72 /   793 Train loss: 0.02117141\r\n",
      "Epoch:  85 Step:    73 /   793 Train loss: 0.02523667\r\n",
      "Epoch:  85 Step:    74 /   793 Train loss: 0.01670453\r\n",
      "Epoch:  85 Step:    75 /   793 Train loss: 0.02026471\r\n",
      "Epoch:  85 Step:    76 /   793 Train loss: 0.03541624\r\n",
      "Epoch:  85 Step:    77 /   793 Train loss: 0.02800094\r\n",
      "Epoch:  85 Step:    78 /   793 Train loss: 0.03436262\r\n",
      "Epoch:  85 Step:    79 /   793 Train loss: 0.02834465\r\n",
      "Epoch:  85 Step:    80 /   793 Train loss: 0.02951497\r\n",
      "Epoch:  85 Step:    81 /   793 Train loss: 0.02805962\r\n",
      "Epoch:  85 Step:    82 /   793 Train loss: 0.01707002\r\n",
      "Epoch:  85 Step:    83 /   793 Train loss: 0.02741025\r\n",
      "Epoch:  85 Step:    84 /   793 Train loss: 0.02611654\r\n",
      "Epoch:  85 Step:    85 /   793 Train loss: 0.02707632\r\n",
      "Epoch:  85 Step:    86 /   793 Train loss: 0.01211302\r\n",
      "Epoch:  85 Step:    87 /   793 Train loss: 0.01994265\r\n",
      "Epoch:  85 Step:    88 /   793 Train loss: 0.02680453\r\n",
      "Epoch:  85 Step:    89 /   793 Train loss: 0.00925584\r\n",
      "Epoch:  85 Step:    90 /   793 Train loss: 0.01877739\r\n",
      "Epoch:  85 Step:    91 /   793 Train loss: 0.02296136\r\n",
      "Epoch:  85 Step:    92 /   793 Train loss: 0.01758451\r\n",
      "Epoch:  85 Step:    93 /   793 Train loss: 0.02138323\r\n",
      "Epoch:  85 Step:    94 /   793 Train loss: 0.01737963\r\n",
      "Epoch:  85 Step:    95 /   793 Train loss: 0.03714903\r\n",
      "Epoch:  85 Step:    96 /   793 Train loss: 0.03540714\r\n",
      "Epoch:  85 Step:    97 /   793 Train loss: 0.02136871\r\n",
      "Epoch:  85 Step:    98 /   793 Train loss: 0.03088725\r\n",
      "Epoch:  85 Step:    99 /   793 Train loss: 0.02754629\r\n",
      "Epoch:  85 Step:   100 /   793 Train loss: 0.02977147\r\n",
      "Epoch:  85 Step:   101 /   793 Train loss: 0.02551459\r\n",
      "Epoch:  85 Step:   102 /   793 Train loss: 0.01643016\r\n",
      "Epoch:  85 Step:   103 /   793 Train loss: 0.02097928\r\n",
      "Epoch:  85 Step:   104 /   793 Train loss: 0.03080341\r\n",
      "Epoch:  85 Step:   105 /   793 Train loss: 0.02223995\r\n",
      "Epoch:  85 Step:   106 /   793 Train loss: 0.02319377\r\n",
      "Epoch:  85 Step:   107 /   793 Train loss: 0.00913874\r\n",
      "Epoch:  85 Step:   108 /   793 Train loss: 0.01967064\r\n",
      "Epoch:  85 Step:   109 /   793 Train loss: 0.01797302\r\n",
      "Epoch:  85 Step:   110 /   793 Train loss: 0.02833603\r\n",
      "Epoch:  85 Step:   111 /   793 Train loss: 0.02069656\r\n",
      "Epoch:  85 Step:   112 /   793 Train loss: 0.01818221\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  85 Step:   113 /   793 Train loss: 0.02437687\r\n",
      "Epoch:  85 Step:   114 /   793 Train loss: 0.02492785\r\n",
      "Epoch:  85 Step:   115 /   793 Train loss: 0.02523693\r\n",
      "Epoch:  85 Step:   116 /   793 Train loss: 0.01173158\r\n",
      "Epoch:  85 Step:   117 /   793 Train loss: 0.02043664\r\n",
      "Epoch:  85 Step:   118 /   793 Train loss: 0.03163124\r\n",
      "Epoch:  85 Step:   119 /   793 Train loss: 0.04652966\r\n",
      "Epoch:  85 Step:   120 /   793 Train loss: 0.02378407\r\n",
      "Epoch:  85 Step:   121 /   793 Train loss: 0.02011560\r\n",
      "Epoch:  85 Step:   122 /   793 Train loss: 0.02800052\r\n",
      "Epoch:  85 Step:   123 /   793 Train loss: 0.01820602\r\n",
      "Epoch:  85 Step:   124 /   793 Train loss: 0.02008840\r\n",
      "Epoch:  85 Step:   125 /   793 Train loss: 0.01997482\r\n",
      "Epoch:  85 Step:   126 /   793 Train loss: 0.02559172\r\n",
      "Epoch:  85 Step:   127 /   793 Train loss: 0.02190208\r\n",
      "Epoch:  85 Step:   128 /   793 Train loss: 0.02269689\r\n",
      "Epoch:  85 Step:   129 /   793 Train loss: 0.01686367\r\n",
      "Epoch:  85 Step:   130 /   793 Train loss: 0.01413060\r\n",
      "Epoch:  85 Step:   131 /   793 Train loss: 0.02436470\r\n",
      "Epoch:  85 Step:   132 /   793 Train loss: 0.02830280\r\n",
      "Epoch:  85 Step:   133 /   793 Train loss: 0.03361661\r\n",
      "Epoch:  85 Step:   134 /   793 Train loss: 0.02076760\r\n",
      "Epoch:  85 Step:   135 /   793 Train loss: 0.03237348\r\n",
      "Epoch:  85 Step:   136 /   793 Train loss: 0.03111740\r\n",
      "Epoch:  85 Step:   137 /   793 Train loss: 0.02365975\r\n",
      "Epoch:  85 Step:   138 /   793 Train loss: 0.01577880\r\n",
      "Epoch:  85 Step:   139 /   793 Train loss: 0.02068405\r\n",
      "Epoch:  85 Step:   140 /   793 Train loss: 0.03149498\r\n",
      "Epoch:  85 Step:   141 /   793 Train loss: 0.02921329\r\n",
      "Epoch:  85 Step:   142 /   793 Train loss: 0.01233553\r\n",
      "Epoch:  85 Step:   143 /   793 Train loss: 0.02540870\r\n",
      "Epoch:  85 Step:   144 /   793 Train loss: 0.01843176\r\n",
      "Epoch:  85 Step:   145 /   793 Train loss: 0.02748225\r\n",
      "Epoch:  85 Step:   146 /   793 Train loss: 0.01514851\r\n",
      "Epoch:  85 Step:   147 /   793 Train loss: 0.01455018\r\n",
      "Epoch:  85 Step:   148 /   793 Train loss: 0.02229860\r\n",
      "Epoch:  85 Step:   149 /   793 Train loss: 0.02737354\r\n",
      "Epoch:  85 Step:   150 /   793 Train loss: 0.03154364\r\n",
      "Epoch:  85 Step:   151 /   793 Train loss: 0.02286790\r\n",
      "Epoch:  85 Step:   152 /   793 Train loss: 0.02998057\r\n",
      "Epoch:  85 Step:   153 /   793 Train loss: 0.03038635\r\n",
      "Epoch:  85 Step:   154 /   793 Train loss: 0.01988654\r\n",
      "Epoch:  85 Step:   155 /   793 Train loss: 0.02693817\r\n",
      "Epoch:  85 Step:   156 /   793 Train loss: 0.02886748\r\n",
      "Epoch:  85 Step:   157 /   793 Train loss: 0.01632599\r\n",
      "Epoch:  85 Step:   158 /   793 Train loss: 0.01662292\r\n",
      "Epoch:  85 Step:   159 /   793 Train loss: 0.01988528\r\n",
      "Epoch:  85 Step:   160 /   793 Train loss: 0.01688283\r\n",
      "Epoch:  85 Step:   161 /   793 Train loss: 0.01468246\r\n",
      "Epoch:  85 Step:   162 /   793 Train loss: 0.01672776\r\n",
      "Epoch:  85 Step:   163 /   793 Train loss: 0.03603407\r\n",
      "Epoch:  85 Step:   164 /   793 Train loss: 0.02478319\r\n",
      "Epoch:  85 Step:   165 /   793 Train loss: 0.02754332\r\n",
      "Epoch:  85 Step:   166 /   793 Train loss: 0.03258096\r\n",
      "Epoch:  85 Step:   167 /   793 Train loss: 0.02565645\r\n",
      "Epoch:  85 Step:   168 /   793 Train loss: 0.02496318\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  85 Step:   169 /   793 Train loss: 0.03784836\r\n",
      "Epoch:  85 Step:   170 /   793 Train loss: 0.01974186\r\n",
      "Epoch:  85 Step:   171 /   793 Train loss: 0.02650769\r\n",
      "Epoch:  85 Step:   172 /   793 Train loss: 0.01812943\r\n",
      "Epoch:  85 Step:   173 /   793 Train loss: 0.04208285\r\n",
      "Epoch:  85 Step:   174 /   793 Train loss: 0.02171156\r\n",
      "Epoch:  85 Step:   175 /   793 Train loss: 0.02418851\r\n",
      "Epoch:  85 Step:   176 /   793 Train loss: 0.02540444\r\n",
      "Epoch:  85 Step:   177 /   793 Train loss: 0.02484351\r\n",
      "Epoch:  85 Step:   178 /   793 Train loss: 0.01570718\r\n",
      "Epoch:  85 Step:   179 /   793 Train loss: 0.03463098\r\n",
      "Epoch:  85 Step:   180 /   793 Train loss: 0.02838326\r\n",
      "Epoch:  85 Step:   181 /   793 Train loss: 0.02807344\r\n",
      "Epoch:  85 Step:   182 /   793 Train loss: 0.02012173\r\n",
      "Epoch:  85 Step:   183 /   793 Train loss: 0.03918184\r\n",
      "Epoch:  85 Step:   184 /   793 Train loss: 0.02413565\r\n",
      "Epoch:  85 Step:   185 /   793 Train loss: 0.02080466\r\n",
      "Epoch:  85 Step:   186 /   793 Train loss: 0.01634779\r\n",
      "Epoch:  85 Step:   187 /   793 Train loss: 0.02249623\r\n",
      "Epoch:  85 Step:   188 /   793 Train loss: 0.02865191\r\n",
      "Epoch:  85 Step:   189 /   793 Train loss: 0.02601588\r\n",
      "Epoch:  85 Step:   190 /   793 Train loss: 0.03347452\r\n",
      "Epoch:  85 Step:   191 /   793 Train loss: 0.03441321\r\n",
      "Epoch:  85 Step:   192 /   793 Train loss: 0.04106863\r\n",
      "Epoch:  85 Step:   193 /   793 Train loss: 0.02236701\r\n",
      "Epoch:  85 Step:   194 /   793 Train loss: 0.01543630\r\n",
      "Epoch:  85 Step:   195 /   793 Train loss: 0.01899754\r\n",
      "Epoch:  85 Step:   196 /   793 Train loss: 0.02876525\r\n",
      "Epoch:  85 Step:   197 /   793 Train loss: 0.02918046\r\n",
      "Epoch:  85 Step:   198 /   793 Train loss: 0.01866972\r\n",
      "Epoch:  85 Step:   199 /   793 Train loss: 0.02691073\r\n",
      "Epoch:  85 Step:   200 /   793 Train loss: 0.02104025\r\n",
      "Epoch:  85 Step:   201 /   793 Train loss: 0.02829136\r\n",
      "Epoch:  85 Step:   202 /   793 Train loss: 0.02102868\r\n",
      "Epoch:  85 Step:   203 /   793 Train loss: 0.01894748\r\n",
      "Epoch:  85 Step:   204 /   793 Train loss: 0.02213757\r\n",
      "Epoch:  85 Step:   205 /   793 Train loss: 0.01739085\r\n",
      "Epoch:  85 Step:   206 /   793 Train loss: 0.01739110\r\n",
      "Epoch:  85 Step:   207 /   793 Train loss: 0.02624905\r\n",
      "Epoch:  85 Step:   208 /   793 Train loss: 0.03346721\r\n",
      "Epoch:  85 Step:   209 /   793 Train loss: 0.01541056\r\n",
      "Epoch:  85 Step:   210 /   793 Train loss: 0.02094169\r\n",
      "Epoch:  85 Step:   211 /   793 Train loss: 0.01600197\r\n",
      "Epoch:  85 Step:   212 /   793 Train loss: 0.03962496\r\n",
      "Epoch:  85 Step:   213 /   793 Train loss: 0.02508873\r\n",
      "Epoch:  85 Step:   214 /   793 Train loss: 0.02046652\r\n",
      "Epoch:  85 Step:   215 /   793 Train loss: 0.02578988\r\n",
      "Epoch:  85 Step:   216 /   793 Train loss: 0.02046615\r\n",
      "Epoch:  85 Step:   217 /   793 Train loss: 0.03079018\r\n",
      "Epoch:  85 Step:   218 /   793 Train loss: 0.02046783\r\n",
      "Epoch:  85 Step:   219 /   793 Train loss: 0.03013834\r\n",
      "Epoch:  85 Step:   220 /   793 Train loss: 0.01923158\r\n",
      "Epoch:  85 Step:   221 /   793 Train loss: 0.02828110\r\n",
      "Epoch:  85 Step:   222 /   793 Train loss: 0.02419614\r\n",
      "Epoch:  85 Step:   223 /   793 Train loss: 0.02142524\r\n",
      "Epoch:  85 Step:   224 /   793 Train loss: 0.02523704\r\n",
      "Epoch:  85 Step:   225 /   793 Train loss: 0.02600458\r\n",
      "Epoch:  85 Step:   226 /   793 Train loss: 0.02883053\r\n",
      "Epoch:  85 Step:   227 /   793 Train loss: 0.02508505\r\n",
      "Epoch:  85 Step:   228 /   793 Train loss: 0.01652482\r\n",
      "Epoch:  85 Step:   229 /   793 Train loss: 0.02013119\r\n",
      "Epoch:  85 Step:   230 /   793 Train loss: 0.02264356\r\n",
      "Epoch:  85 Step:   231 /   793 Train loss: 0.03268088\r\n",
      "Epoch:  85 Step:   232 /   793 Train loss: 0.01615644\r\n",
      "Epoch:  85 Step:   233 /   793 Train loss: 0.02477358\r\n",
      "Epoch:  85 Step:   234 /   793 Train loss: 0.03381366\r\n",
      "Epoch:  85 Step:   235 /   793 Train loss: 0.03094760\r\n",
      "Epoch:  85 Step:   236 /   793 Train loss: 0.01852389\r\n",
      "Epoch:  85 Step:   237 /   793 Train loss: 0.01876548\r\n",
      "Epoch:  85 Step:   238 /   793 Train loss: 0.01868459\r\n",
      "Epoch:  85 Step:   239 /   793 Train loss: 0.02841977\r\n",
      "Epoch:  85 Step:   240 /   793 Train loss: 0.00934252\r\n",
      "Epoch:  85 Step:   241 /   793 Train loss: 0.01713277\r\n",
      "Epoch:  85 Step:   242 /   793 Train loss: 0.03660090\r\n",
      "Epoch:  85 Step:   243 /   793 Train loss: 0.01919834\r\n",
      "Epoch:  85 Step:   244 /   793 Train loss: 0.02192586\r\n",
      "Epoch:  85 Step:   245 /   793 Train loss: 0.02761443\r\n",
      "Epoch:  85 Step:   246 /   793 Train loss: 0.03024591\r\n",
      "Epoch:  85 Step:   247 /   793 Train loss: 0.02005256\r\n",
      "Epoch:  85 Step:   248 /   793 Train loss: 0.02174238\r\n",
      "Epoch:  85 Step:   249 /   793 Train loss: 0.03701840\r\n",
      "Epoch:  85 Step:   250 /   793 Train loss: 0.02126180\r\n",
      "Epoch:  85 Step:   251 /   793 Train loss: 0.02209755\r\n",
      "Epoch:  85 Step:   252 /   793 Train loss: 0.04070261\r\n",
      "Epoch:  85 Step:   253 /   793 Train loss: 0.02763271\r\n",
      "Epoch:  85 Step:   254 /   793 Train loss: 0.01334795\r\n",
      "Epoch:  85 Step:   255 /   793 Train loss: 0.03433148\r\n",
      "Epoch:  85 Step:   256 /   793 Train loss: 0.04086110\r\n",
      "Epoch:  85 Step:   257 /   793 Train loss: 0.01739443\r\n",
      "Epoch:  85 Step:   258 /   793 Train loss: 0.02468279\r\n",
      "Epoch:  85 Step:   259 /   793 Train loss: 0.01891481\r\n",
      "Epoch:  85 Step:   260 /   793 Train loss: 0.02322138\r\n",
      "Epoch:  85 Step:   261 /   793 Train loss: 0.02588685\r\n",
      "Epoch:  85 Step:   262 /   793 Train loss: 0.03786700\r\n",
      "Epoch:  85 Step:   263 /   793 Train loss: 0.02948313\r\n",
      "Epoch:  85 Step:   264 /   793 Train loss: 0.02275783\r\n",
      "Epoch:  85 Step:   265 /   793 Train loss: 0.03160977\r\n",
      "Epoch:  85 Step:   266 /   793 Train loss: 0.02682041\r\n",
      "Epoch:  85 Step:   267 /   793 Train loss: 0.03164163\r\n",
      "Epoch:  85 Step:   268 /   793 Train loss: 0.02717043\r\n",
      "Epoch:  85 Step:   269 /   793 Train loss: 0.03179844\r\n",
      "Epoch:  85 Step:   270 /   793 Train loss: 0.02338608\r\n",
      "Epoch:  85 Step:   271 /   793 Train loss: 0.02003046\r\n",
      "Epoch:  85 Step:   272 /   793 Train loss: 0.02980746\r\n",
      "Epoch:  85 Step:   273 /   793 Train loss: 0.02602000\r\n",
      "Epoch:  85 Step:   274 /   793 Train loss: 0.01870715\r\n",
      "Epoch:  85 Step:   275 /   793 Train loss: 0.02583430\r\n",
      "Epoch:  85 Step:   276 /   793 Train loss: 0.03015929\r\n",
      "Epoch:  85 Step:   277 /   793 Train loss: 0.01784108\r\n",
      "Epoch:  85 Step:   278 /   793 Train loss: 0.03259574\r\n",
      "Epoch:  85 Step:   279 /   793 Train loss: 0.01687261\r\n",
      "Epoch:  85 Step:   280 /   793 Train loss: 0.02378756\r\n",
      "Epoch:  85 Step:   281 /   793 Train loss: 0.01638471\r\n",
      "Epoch:  85 Step:   282 /   793 Train loss: 0.03188106\r\n",
      "Epoch:  85 Step:   283 /   793 Train loss: 0.01077659\r\n",
      "Epoch:  85 Step:   284 /   793 Train loss: 0.03375129\r\n",
      "Epoch:  85 Step:   285 /   793 Train loss: 0.01163718\r\n",
      "Epoch:  85 Step:   286 /   793 Train loss: 0.02388470\r\n",
      "Epoch:  85 Step:   287 /   793 Train loss: 0.02060186\r\n",
      "Epoch:  85 Step:   288 /   793 Train loss: 0.01844077\r\n",
      "Epoch:  85 Step:   289 /   793 Train loss: 0.01940833\r\n",
      "Epoch:  85 Step:   290 /   793 Train loss: 0.02389912\r\n",
      "Epoch:  85 Step:   291 /   793 Train loss: 0.02373341\r\n",
      "Epoch:  85 Step:   292 /   793 Train loss: 0.01246062\r\n",
      "Epoch:  85 Step:   293 /   793 Train loss: 0.02216546\r\n",
      "Epoch:  85 Step:   294 /   793 Train loss: 0.02055109\r\n",
      "Epoch:  85 Step:   295 /   793 Train loss: 0.02451288\r\n",
      "Epoch:  85 Step:   296 /   793 Train loss: 0.02417145\r\n",
      "Epoch:  85 Step:   297 /   793 Train loss: 0.02730313\r\n",
      "Epoch:  85 Step:   298 /   793 Train loss: 0.02386037\r\n",
      "Epoch:  85 Step:   299 /   793 Train loss: 0.02321190\r\n",
      "Epoch:  85 Step:   300 /   793 Train loss: 0.02218359\r\n",
      "Epoch:  85 Step:   301 /   793 Train loss: 0.03090806\r\n",
      "Epoch:  85 Step:   302 /   793 Train loss: 0.02196378\r\n",
      "Epoch:  85 Step:   303 /   793 Train loss: 0.01528096\r\n",
      "Epoch:  85 Step:   304 /   793 Train loss: 0.01793169\r\n",
      "Epoch:  85 Step:   305 /   793 Train loss: 0.01598679\r\n",
      "Epoch:  85 Step:   306 /   793 Train loss: 0.03111805\r\n",
      "Epoch:  85 Step:   307 /   793 Train loss: 0.01726128\r\n",
      "Epoch:  85 Step:   308 /   793 Train loss: 0.00919919\r\n",
      "Epoch:  85 Step:   309 /   793 Train loss: 0.03260101\r\n",
      "Epoch:  85 Step:   310 /   793 Train loss: 0.03748247\r\n",
      "Epoch:  85 Step:   311 /   793 Train loss: 0.03234147\r\n",
      "Epoch:  85 Step:   312 /   793 Train loss: 0.02381702\r\n",
      "Epoch:  85 Step:   313 /   793 Train loss: 0.02209298\r\n",
      "Epoch:  85 Step:   314 /   793 Train loss: 0.03885998\r\n",
      "Epoch:  85 Step:   315 /   793 Train loss: 0.02570936\r\n",
      "Epoch:  85 Step:   316 /   793 Train loss: 0.02598352\r\n",
      "Epoch:  85 Step:   317 /   793 Train loss: 0.01783189\r\n",
      "Epoch:  85 Step:   318 /   793 Train loss: 0.03190193\r\n",
      "Epoch:  85 Step:   319 /   793 Train loss: 0.01849977\r\n",
      "Epoch:  85 Step:   320 /   793 Train loss: 0.01674308\r\n",
      "Epoch:  85 Step:   321 /   793 Train loss: 0.02794539\r\n",
      "Epoch:  85 Step:   322 /   793 Train loss: 0.01373176\r\n",
      "Epoch:  85 Step:   323 /   793 Train loss: 0.03028337\r\n",
      "Epoch:  85 Step:   324 /   793 Train loss: 0.01527607\r\n",
      "Epoch:  85 Step:   325 /   793 Train loss: 0.01778410\r\n",
      "Epoch:  85 Step:   326 /   793 Train loss: 0.02172530\r\n",
      "Epoch:  85 Step:   327 /   793 Train loss: 0.02847040\r\n",
      "Epoch:  85 Step:   328 /   793 Train loss: 0.02025246\r\n",
      "Epoch:  85 Step:   329 /   793 Train loss: 0.04807441\r\n",
      "Epoch:  85 Step:   330 /   793 Train loss: 0.02499759\r\n",
      "Epoch:  85 Step:   331 /   793 Train loss: 0.02085130\r\n",
      "Epoch:  85 Step:   332 /   793 Train loss: 0.02626714\r\n",
      "Epoch:  85 Step:   333 /   793 Train loss: 0.03254160\r\n",
      "Epoch:  85 Step:   334 /   793 Train loss: 0.02495021\r\n",
      "Epoch:  85 Step:   335 /   793 Train loss: 0.02135929\r\n",
      "Epoch:  85 Step:   336 /   793 Train loss: 0.02494622\r\n",
      "Epoch:  85 Step:   337 /   793 Train loss: 0.02112038\r\n",
      "Epoch:  85 Step:   338 /   793 Train loss: 0.03438945\r\n",
      "Epoch:  85 Step:   339 /   793 Train loss: 0.03539839\r\n",
      "Epoch:  85 Step:   340 /   793 Train loss: 0.02394824\r\n",
      "Epoch:  85 Step:   341 /   793 Train loss: 0.02724583\r\n",
      "Epoch:  85 Step:   342 /   793 Train loss: 0.02020724\r\n",
      "Epoch:  85 Step:   343 /   793 Train loss: 0.02731946\r\n",
      "Epoch:  85 Step:   344 /   793 Train loss: 0.02730601\r\n",
      "Epoch:  85 Step:   345 /   793 Train loss: 0.02671837\r\n",
      "Epoch:  85 Step:   346 /   793 Train loss: 0.01615001\r\n",
      "Epoch:  85 Step:   347 /   793 Train loss: 0.02683008\r\n",
      "Epoch:  85 Step:   348 /   793 Train loss: 0.02754227\r\n",
      "Epoch:  85 Step:   349 /   793 Train loss: 0.02388991\r\n",
      "Epoch:  85 Step:   350 /   793 Train loss: 0.03158343\r\n",
      "Epoch:  85 Step:   351 /   793 Train loss: 0.01137440\r\n",
      "Epoch:  85 Step:   352 /   793 Train loss: 0.02511015\r\n",
      "Epoch:  85 Step:   353 /   793 Train loss: 0.01923432\r\n",
      "Epoch:  85 Step:   354 /   793 Train loss: 0.02684587\r\n",
      "Epoch:  85 Step:   355 /   793 Train loss: 0.01940088\r\n",
      "Epoch:  85 Step:   356 /   793 Train loss: 0.04099576\r\n",
      "Epoch:  85 Step:   357 /   793 Train loss: 0.01691428\r\n",
      "Epoch:  85 Step:   358 /   793 Train loss: 0.02231375\r\n",
      "Epoch:  85 Step:   359 /   793 Train loss: 0.02817431\r\n",
      "Epoch:  85 Step:   360 /   793 Train loss: 0.01531791\r\n",
      "Epoch:  85 Step:   361 /   793 Train loss: 0.03632223\r\n",
      "Epoch:  85 Step:   362 /   793 Train loss: 0.02318458\r\n",
      "Epoch:  85 Step:   363 /   793 Train loss: 0.02094936\r\n",
      "Epoch:  85 Step:   364 /   793 Train loss: 0.04230632\r\n",
      "Epoch:  85 Step:   365 /   793 Train loss: 0.01478813\r\n",
      "Epoch:  85 Step:   366 /   793 Train loss: 0.01641266\r\n",
      "Epoch:  85 Step:   367 /   793 Train loss: 0.02202137\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  85 Step:   368 /   793 Train loss: 0.03089708\r\n",
      "Epoch:  85 Step:   369 /   793 Train loss: 0.03935678\r\n",
      "Epoch:  85 Step:   370 /   793 Train loss: 0.02837988\r\n",
      "Epoch:  85 Step:   371 /   793 Train loss: 0.01615090\r\n",
      "Epoch:  85 Step:   372 /   793 Train loss: 0.01700531\r\n",
      "Epoch:  85 Step:   373 /   793 Train loss: 0.02382592\r\n",
      "Epoch:  85 Step:   374 /   793 Train loss: 0.01679221\r\n",
      "Epoch:  85 Step:   375 /   793 Train loss: 0.02326602\r\n",
      "Epoch:  85 Step:   376 /   793 Train loss: 0.02296468\r\n",
      "Epoch:  85 Step:   377 /   793 Train loss: 0.03105850\r\n",
      "Epoch:  85 Step:   378 /   793 Train loss: 0.01812655\r\n",
      "Epoch:  85 Step:   379 /   793 Train loss: 0.01885219\r\n",
      "Epoch:  85 Step:   380 /   793 Train loss: 0.01647712\r\n",
      "Epoch:  85 Step:   381 /   793 Train loss: 0.02147408\r\n",
      "Epoch:  85 Step:   382 /   793 Train loss: 0.02702560\r\n",
      "Epoch:  85 Step:   383 /   793 Train loss: 0.01630492\r\n",
      "Epoch:  85 Step:   384 /   793 Train loss: 0.02632554\r\n",
      "Epoch:  85 Step:   385 /   793 Train loss: 0.01968820\r\n",
      "Epoch:  85 Step:   386 /   793 Train loss: 0.03314254\r\n",
      "Epoch:  85 Step:   387 /   793 Train loss: 0.03038706\r\n",
      "Epoch:  85 Step:   388 /   793 Train loss: 0.02595379\r\n",
      "Epoch:  85 Step:   389 /   793 Train loss: 0.02936920\r\n",
      "Epoch:  85 Step:   390 /   793 Train loss: 0.01804950\r\n",
      "Epoch:  85 Step:   391 /   793 Train loss: 0.03689768\r\n",
      "Epoch:  85 Step:   392 /   793 Train loss: 0.03609335\r\n",
      "Epoch:  85 Step:   393 /   793 Train loss: 0.01719924\r\n",
      "Epoch:  85 Step:   394 /   793 Train loss: 0.02936758\r\n",
      "Epoch:  85 Step:   395 /   793 Train loss: 0.02913699\r\n",
      "Epoch:  85 Step:   396 /   793 Train loss: 0.01995124\r\n",
      "Epoch:  85 Step:   397 /   793 Train loss: 0.01949228\r\n",
      "Epoch:  85 Step:   398 /   793 Train loss: 0.02410351\r\n",
      "Epoch:  85 Step:   399 /   793 Train loss: 0.02092607\r\n",
      "Epoch:  85 Step:   400 /   793 Train loss: 0.02540580\r\n",
      "Epoch:  85 Step:   401 /   793 Train loss: 0.01668645\r\n",
      "Epoch:  85 Step:   402 /   793 Train loss: 0.03232690\r\n",
      "Epoch:  85 Step:   403 /   793 Train loss: 0.02305124\r\n",
      "Epoch:  85 Step:   404 /   793 Train loss: 0.01934448\r\n",
      "Epoch:  85 Step:   405 /   793 Train loss: 0.03723653\r\n",
      "Epoch:  85 Step:   406 /   793 Train loss: 0.01508842\r\n",
      "Epoch:  85 Step:   407 /   793 Train loss: 0.02227430\r\n",
      "Epoch:  85 Step:   408 /   793 Train loss: 0.02552199\r\n",
      "Epoch:  85 Step:   409 /   793 Train loss: 0.02770822\r\n",
      "Epoch:  85 Step:   410 /   793 Train loss: 0.02659179\r\n",
      "Epoch:  85 Step:   411 /   793 Train loss: 0.01771569\r\n",
      "Epoch:  85 Step:   412 /   793 Train loss: 0.01835465\r\n",
      "Epoch:  85 Step:   413 /   793 Train loss: 0.02091988\r\n",
      "Epoch:  85 Step:   414 /   793 Train loss: 0.02266044\r\n",
      "Epoch:  85 Step:   415 /   793 Train loss: 0.02323780\r\n",
      "Epoch:  85 Step:   416 /   793 Train loss: 0.02664406\r\n",
      "Epoch:  85 Step:   417 /   793 Train loss: 0.03577030\r\n",
      "Epoch:  85 Step:   418 /   793 Train loss: 0.01580308\r\n",
      "Epoch:  85 Step:   419 /   793 Train loss: 0.02964649\r\n",
      "Epoch:  85 Step:   420 /   793 Train loss: 0.02127618\r\n",
      "Epoch:  85 Step:   421 /   793 Train loss: 0.02816043\r\n",
      "Epoch:  85 Step:   422 /   793 Train loss: 0.02842117\r\n",
      "Epoch:  85 Step:   423 /   793 Train loss: 0.02523608\r\n",
      "Epoch:  85 Step:   424 /   793 Train loss: 0.01957627\r\n",
      "Epoch:  85 Step:   425 /   793 Train loss: 0.02106936\r\n",
      "Epoch:  85 Step:   426 /   793 Train loss: 0.03218499\r\n",
      "Epoch:  85 Step:   427 /   793 Train loss: 0.03285154\r\n",
      "Epoch:  85 Step:   428 /   793 Train loss: 0.01666591\r\n",
      "Epoch:  85 Step:   429 /   793 Train loss: 0.03279823\r\n",
      "Epoch:  85 Step:   430 /   793 Train loss: 0.02425496\r\n",
      "Epoch:  85 Step:   431 /   793 Train loss: 0.02795244\r\n",
      "Epoch:  85 Step:   432 /   793 Train loss: 0.00913622\r\n",
      "Epoch:  85 Step:   433 /   793 Train loss: 0.02072708\r\n",
      "Epoch:  85 Step:   434 /   793 Train loss: 0.01595134\r\n",
      "Epoch:  85 Step:   435 /   793 Train loss: 0.02845154\r\n",
      "Epoch:  85 Step:   436 /   793 Train loss: 0.01796799\r\n",
      "Epoch:  85 Step:   437 /   793 Train loss: 0.03403987\r\n",
      "Epoch:  85 Step:   438 /   793 Train loss: 0.02172032\r\n",
      "Epoch:  85 Step:   439 /   793 Train loss: 0.02663715\r\n",
      "Epoch:  85 Step:   440 /   793 Train loss: 0.02742026\r\n",
      "Epoch:  85 Step:   441 /   793 Train loss: 0.02069303\r\n",
      "Epoch:  85 Step:   442 /   793 Train loss: 0.02681891\r\n",
      "Epoch:  85 Step:   443 /   793 Train loss: 0.02269230\r\n",
      "Epoch:  85 Step:   444 /   793 Train loss: 0.02740963\r\n",
      "Epoch:  85 Step:   445 /   793 Train loss: 0.03689832\r\n",
      "Epoch:  85 Step:   446 /   793 Train loss: 0.02230674\r\n",
      "Epoch:  85 Step:   447 /   793 Train loss: 0.02119203\r\n",
      "Epoch:  85 Step:   448 /   793 Train loss: 0.01895685\r\n",
      "Epoch:  85 Step:   449 /   793 Train loss: 0.03073583\r\n",
      "Epoch:  85 Step:   450 /   793 Train loss: 0.02069853\r\n",
      "Epoch:  85 Step:   451 /   793 Train loss: 0.02613681\r\n",
      "Epoch:  85 Step:   452 /   793 Train loss: 0.02479912\r\n",
      "Epoch:  85 Step:   453 /   793 Train loss: 0.03548662\r\n",
      "Epoch:  85 Step:   454 /   793 Train loss: 0.01390328\r\n",
      "Epoch:  85 Step:   455 /   793 Train loss: 0.02453983\r\n",
      "Epoch:  85 Step:   456 /   793 Train loss: 0.01617738\r\n",
      "Epoch:  85 Step:   457 /   793 Train loss: 0.01645285\r\n",
      "Epoch:  85 Step:   458 /   793 Train loss: 0.03521661\r\n",
      "Epoch:  85 Step:   459 /   793 Train loss: 0.04382848\r\n",
      "Epoch:  85 Step:   460 /   793 Train loss: 0.01951174\r\n",
      "Epoch:  85 Step:   461 /   793 Train loss: 0.02961191\r\n",
      "Epoch:  85 Step:   462 /   793 Train loss: 0.01586855\r\n",
      "Epoch:  85 Step:   463 /   793 Train loss: 0.02901408\r\n",
      "Epoch:  85 Step:   464 /   793 Train loss: 0.02704957\r\n",
      "Epoch:  85 Step:   465 /   793 Train loss: 0.01871436\r\n",
      "Epoch:  85 Step:   466 /   793 Train loss: 0.01727135\r\n",
      "Epoch:  85 Step:   467 /   793 Train loss: 0.01148659\r\n",
      "Epoch:  85 Step:   468 /   793 Train loss: 0.01469568\r\n",
      "Epoch:  85 Step:   469 /   793 Train loss: 0.02297038\r\n",
      "Epoch:  85 Step:   470 /   793 Train loss: 0.02243334\r\n",
      "Epoch:  85 Step:   471 /   793 Train loss: 0.01999079\r\n",
      "Epoch:  85 Step:   472 /   793 Train loss: 0.01018306\r\n",
      "Epoch:  85 Step:   473 /   793 Train loss: 0.03020425\r\n",
      "Epoch:  85 Step:   474 /   793 Train loss: 0.02857699\r\n",
      "Epoch:  85 Step:   475 /   793 Train loss: 0.02033845\r\n",
      "Epoch:  85 Step:   476 /   793 Train loss: 0.02407334\r\n",
      "Epoch:  85 Step:   477 /   793 Train loss: 0.01379768\r\n",
      "Epoch:  85 Step:   478 /   793 Train loss: 0.02161633\r\n",
      "Epoch:  85 Step:   479 /   793 Train loss: 0.02592449\r\n",
      "Epoch:  85 Step:   480 /   793 Train loss: 0.02465403\r\n",
      "Epoch:  85 Step:   481 /   793 Train loss: 0.02643864\r\n",
      "Epoch:  85 Step:   482 /   793 Train loss: 0.02135932\r\n",
      "Epoch:  85 Step:   483 /   793 Train loss: 0.01636181\r\n",
      "Epoch:  85 Step:   484 /   793 Train loss: 0.00919107\r\n",
      "Epoch:  85 Step:   485 /   793 Train loss: 0.02545622\r\n",
      "Epoch:  85 Step:   486 /   793 Train loss: 0.02945934\r\n",
      "Epoch:  85 Step:   487 /   793 Train loss: 0.01632733\r\n",
      "Epoch:  85 Step:   488 /   793 Train loss: 0.02764760\r\n",
      "Epoch:  85 Step:   489 /   793 Train loss: 0.02731569\r\n",
      "Epoch:  85 Step:   490 /   793 Train loss: 0.01971848\r\n",
      "Epoch:  85 Step:   491 /   793 Train loss: 0.03929262\r\n",
      "Epoch:  85 Step:   492 /   793 Train loss: 0.02824920\r\n",
      "Epoch:  85 Step:   493 /   793 Train loss: 0.01937690\r\n",
      "Epoch:  85 Step:   494 /   793 Train loss: 0.01504351\r\n",
      "Epoch:  85 Step:   495 /   793 Train loss: 0.02663949\r\n",
      "Epoch:  85 Step:   496 /   793 Train loss: 0.03202887\r\n",
      "Epoch:  85 Step:   497 /   793 Train loss: 0.04410832\r\n",
      "Epoch:  85 Step:   498 /   793 Train loss: 0.02830624\r\n",
      "Epoch:  85 Step:   499 /   793 Train loss: 0.02722399\r\n",
      "Epoch:  85 Step:   500 /   793 Train loss: 0.02812884\r\n",
      "Epoch:  85 Step:   501 /   793 Train loss: 0.02102217\r\n",
      "Epoch:  85 Step:   502 /   793 Train loss: 0.01491809\r\n",
      "Epoch:  85 Step:   503 /   793 Train loss: 0.02839897\r\n",
      "Epoch:  85 Step:   504 /   793 Train loss: 0.03794231\r\n",
      "Epoch:  85 Step:   505 /   793 Train loss: 0.01498375\r\n",
      "Epoch:  85 Step:   506 /   793 Train loss: 0.02467617\r\n",
      "Epoch:  85 Step:   507 /   793 Train loss: 0.03706905\r\n",
      "Epoch:  85 Step:   508 /   793 Train loss: 0.02781767\r\n",
      "Epoch:  85 Step:   509 /   793 Train loss: 0.01488243\r\n",
      "Epoch:  85 Step:   510 /   793 Train loss: 0.02372238\r\n",
      "Epoch:  85 Step:   511 /   793 Train loss: 0.01666314\r\n",
      "Epoch:  85 Step:   512 /   793 Train loss: 0.02967845\r\n",
      "Epoch:  85 Step:   513 /   793 Train loss: 0.02909521\r\n",
      "Epoch:  85 Step:   514 /   793 Train loss: 0.02869277\r\n",
      "Epoch:  85 Step:   515 /   793 Train loss: 0.03411198\r\n",
      "Epoch:  85 Step:   516 /   793 Train loss: 0.02825234\r\n",
      "Epoch:  85 Step:   517 /   793 Train loss: 0.02687048\r\n",
      "Epoch:  85 Step:   518 /   793 Train loss: 0.02912650\r\n",
      "Epoch:  85 Step:   519 /   793 Train loss: 0.02928469\r\n",
      "Epoch:  85 Step:   520 /   793 Train loss: 0.02710548\r\n",
      "Epoch:  85 Step:   521 /   793 Train loss: 0.01010368\r\n",
      "Epoch:  85 Step:   522 /   793 Train loss: 0.02321183\r\n",
      "Epoch:  85 Step:   523 /   793 Train loss: 0.01628186\r\n",
      "Epoch:  85 Step:   524 /   793 Train loss: 0.02608225\r\n",
      "Epoch:  85 Step:   525 /   793 Train loss: 0.02392050\r\n",
      "Epoch:  85 Step:   526 /   793 Train loss: 0.01330380\r\n",
      "Epoch:  85 Step:   527 /   793 Train loss: 0.02033908\r\n",
      "Epoch:  85 Step:   528 /   793 Train loss: 0.02548090\r\n",
      "Epoch:  85 Step:   529 /   793 Train loss: 0.01476310\r\n",
      "Epoch:  85 Step:   530 /   793 Train loss: 0.02288939\r\n",
      "Epoch:  85 Step:   531 /   793 Train loss: 0.01841654\r\n",
      "Epoch:  85 Step:   532 /   793 Train loss: 0.03183523\r\n",
      "Epoch:  85 Step:   533 /   793 Train loss: 0.02426519\r\n",
      "Epoch:  85 Step:   534 /   793 Train loss: 0.03008897\r\n",
      "Epoch:  85 Step:   535 /   793 Train loss: 0.02030351\r\n",
      "Epoch:  85 Step:   536 /   793 Train loss: 0.01498962\r\n",
      "Epoch:  85 Step:   537 /   793 Train loss: 0.02262088\r\n",
      "Epoch:  85 Step:   538 /   793 Train loss: 0.03085162\r\n",
      "Epoch:  85 Step:   539 /   793 Train loss: 0.02870971\r\n",
      "Epoch:  85 Step:   540 /   793 Train loss: 0.01285516\r\n",
      "Epoch:  85 Step:   541 /   793 Train loss: 0.02333643\r\n",
      "Epoch:  85 Step:   542 /   793 Train loss: 0.04192093\r\n",
      "Epoch:  85 Step:   543 /   793 Train loss: 0.01342707\r\n",
      "Epoch:  85 Step:   544 /   793 Train loss: 0.02445734\r\n",
      "Epoch:  85 Step:   545 /   793 Train loss: 0.02802579\r\n",
      "Epoch:  85 Step:   546 /   793 Train loss: 0.02832910\r\n",
      "Epoch:  85 Step:   547 /   793 Train loss: 0.02201482\r\n",
      "Epoch:  85 Step:   548 /   793 Train loss: 0.03264727\r\n",
      "Epoch:  85 Step:   549 /   793 Train loss: 0.02342792\r\n",
      "Epoch:  85 Step:   550 /   793 Train loss: 0.02290737\r\n",
      "Epoch:  85 Step:   551 /   793 Train loss: 0.02620874\r\n",
      "Epoch:  85 Step:   552 /   793 Train loss: 0.02483461\r\n",
      "Epoch:  85 Step:   553 /   793 Train loss: 0.02017182\r\n",
      "Epoch:  85 Step:   554 /   793 Train loss: 0.02292839\r\n",
      "Epoch:  85 Step:   555 /   793 Train loss: 0.02754122\r\n",
      "Epoch:  85 Step:   556 /   793 Train loss: 0.02260626\r\n",
      "Epoch:  85 Step:   557 /   793 Train loss: 0.01876501\r\n",
      "Epoch:  85 Step:   558 /   793 Train loss: 0.02164776\r\n",
      "Epoch:  85 Step:   559 /   793 Train loss: 0.02478377\r\n",
      "Epoch:  85 Step:   560 /   793 Train loss: 0.02165914\r\n",
      "Epoch:  85 Step:   561 /   793 Train loss: 0.02274265\r\n",
      "Epoch:  85 Step:   562 /   793 Train loss: 0.02895901\r\n",
      "Epoch:  85 Step:   563 /   793 Train loss: 0.01996903\r\n",
      "Epoch:  85 Step:   564 /   793 Train loss: 0.03283292\r\n",
      "Epoch:  85 Step:   565 /   793 Train loss: 0.02628138\r\n",
      "Epoch:  85 Step:   566 /   793 Train loss: 0.01686383\r\n",
      "Epoch:  85 Step:   567 /   793 Train loss: 0.01278778\r\n",
      "Epoch:  85 Step:   568 /   793 Train loss: 0.02347514\r\n",
      "Epoch:  85 Step:   569 /   793 Train loss: 0.03426068\r\n",
      "Epoch:  85 Step:   570 /   793 Train loss: 0.02133492\r\n",
      "Epoch:  85 Step:   571 /   793 Train loss: 0.01746065\r\n",
      "Epoch:  85 Step:   572 /   793 Train loss: 0.02088931\r\n",
      "Epoch:  85 Step:   573 /   793 Train loss: 0.03760119\r\n",
      "Epoch:  85 Step:   574 /   793 Train loss: 0.02585101\r\n",
      "Epoch:  85 Step:   575 /   793 Train loss: 0.02077715\r\n",
      "Epoch:  85 Step:   576 /   793 Train loss: 0.02504344\r\n",
      "Epoch:  85 Step:   577 /   793 Train loss: 0.02461695\r\n",
      "Epoch:  85 Step:   578 /   793 Train loss: 0.01782555\r\n",
      "Epoch:  85 Step:   579 /   793 Train loss: 0.01892732\r\n",
      "Epoch:  85 Step:   580 /   793 Train loss: 0.02417650\r\n",
      "Epoch:  85 Step:   581 /   793 Train loss: 0.02891043\r\n",
      "Epoch:  85 Step:   582 /   793 Train loss: 0.03563492\r\n",
      "Epoch:  85 Step:   583 /   793 Train loss: 0.03778903\r\n",
      "Epoch:  85 Step:   584 /   793 Train loss: 0.02491122\r\n",
      "Epoch:  85 Step:   585 /   793 Train loss: 0.01368384\r\n",
      "Epoch:  85 Step:   586 /   793 Train loss: 0.02262260\r\n",
      "Epoch:  85 Step:   587 /   793 Train loss: 0.01953951\r\n",
      "Epoch:  85 Step:   588 /   793 Train loss: 0.03155662\r\n",
      "Epoch:  85 Step:   589 /   793 Train loss: 0.03127186\r\n",
      "Epoch:  85 Step:   590 /   793 Train loss: 0.01856271\r\n",
      "Epoch:  85 Step:   591 /   793 Train loss: 0.01711927\r\n",
      "Epoch:  85 Step:   592 /   793 Train loss: 0.02815941\r\n",
      "Epoch:  85 Step:   593 /   793 Train loss: 0.02327842\r\n",
      "Epoch:  85 Step:   594 /   793 Train loss: 0.02514793\r\n",
      "Epoch:  85 Step:   595 /   793 Train loss: 0.03693886\r\n",
      "Epoch:  85 Step:   596 /   793 Train loss: 0.02184257\r\n",
      "Epoch:  85 Step:   597 /   793 Train loss: 0.02747822\r\n",
      "Epoch:  85 Step:   598 /   793 Train loss: 0.02200364\r\n",
      "Epoch:  85 Step:   599 /   793 Train loss: 0.02169021\r\n",
      "Epoch:  85 Step:   600 /   793 Train loss: 0.01777814\r\n",
      "Epoch:  85 Step:   601 /   793 Train loss: 0.02813121\r\n",
      "Epoch:  85 Step:   602 /   793 Train loss: 0.02143207\r\n",
      "Epoch:  85 Step:   603 /   793 Train loss: 0.02242829\r\n",
      "Epoch:  85 Step:   604 /   793 Train loss: 0.01286050\r\n",
      "Epoch:  85 Step:   605 /   793 Train loss: 0.02615392\r\n",
      "Epoch:  85 Step:   606 /   793 Train loss: 0.01821829\r\n",
      "Epoch:  85 Step:   607 /   793 Train loss: 0.03595152\r\n",
      "Epoch:  85 Step:   608 /   793 Train loss: 0.02169057\r\n",
      "Epoch:  85 Step:   609 /   793 Train loss: 0.02634444\r\n",
      "Epoch:  85 Step:   610 /   793 Train loss: 0.01137521\r\n",
      "Epoch:  85 Step:   611 /   793 Train loss: 0.01799066\r\n",
      "Epoch:  85 Step:   612 /   793 Train loss: 0.02972235\r\n",
      "Epoch:  85 Step:   613 /   793 Train loss: 0.02093489\r\n",
      "Epoch:  85 Step:   614 /   793 Train loss: 0.02689028\r\n",
      "Epoch:  85 Step:   615 /   793 Train loss: 0.01507501\r\n",
      "Epoch:  85 Step:   616 /   793 Train loss: 0.01785767\r\n",
      "Epoch:  85 Step:   617 /   793 Train loss: 0.03368461\r\n",
      "Epoch:  85 Step:   618 /   793 Train loss: 0.02327983\r\n",
      "Epoch:  85 Step:   619 /   793 Train loss: 0.02923667\r\n",
      "Epoch:  85 Step:   620 /   793 Train loss: 0.01641666\r\n",
      "Epoch:  85 Step:   621 /   793 Train loss: 0.01911027\r\n",
      "Epoch:  85 Step:   622 /   793 Train loss: 0.04527938\r\n",
      "Epoch:  85 Step:   623 /   793 Train loss: 0.02899094\r\n",
      "Epoch:  85 Step:   624 /   793 Train loss: 0.03057635\r\n",
      "Epoch:  85 Step:   625 /   793 Train loss: 0.03232551\r\n",
      "Epoch:  85 Step:   626 /   793 Train loss: 0.01560623\r\n",
      "Epoch:  85 Step:   627 /   793 Train loss: 0.01615577\r\n",
      "Epoch:  85 Step:   628 /   793 Train loss: 0.02367310\r\n",
      "Epoch:  85 Step:   629 /   793 Train loss: 0.02125988\r\n",
      "Epoch:  85 Step:   630 /   793 Train loss: 0.01756650\r\n",
      "Epoch:  85 Step:   631 /   793 Train loss: 0.02490265\r\n",
      "Epoch:  85 Step:   632 /   793 Train loss: 0.02444216\r\n",
      "Epoch:  85 Step:   633 /   793 Train loss: 0.02364651\r\n",
      "Epoch:  85 Step:   634 /   793 Train loss: 0.02559431\r\n",
      "Epoch:  85 Step:   635 /   793 Train loss: 0.02829272\r\n",
      "Epoch:  85 Step:   636 /   793 Train loss: 0.03255925\r\n",
      "Epoch:  85 Step:   637 /   793 Train loss: 0.01922823\r\n",
      "Epoch:  85 Step:   638 /   793 Train loss: 0.03419495\r\n",
      "Epoch:  85 Step:   639 /   793 Train loss: 0.02532952\r\n",
      "Epoch:  85 Step:   640 /   793 Train loss: 0.03028117\r\n",
      "Epoch:  85 Step:   641 /   793 Train loss: 0.02174932\r\n",
      "Epoch:  85 Step:   642 /   793 Train loss: 0.01530954\r\n",
      "Epoch:  85 Step:   643 /   793 Train loss: 0.03210007\r\n",
      "Epoch:  85 Step:   644 /   793 Train loss: 0.03740676\r\n",
      "Epoch:  85 Step:   645 /   793 Train loss: 0.02519045\r\n",
      "Epoch:  85 Step:   646 /   793 Train loss: 0.02360203\r\n",
      "Epoch:  85 Step:   647 /   793 Train loss: 0.03568202\r\n",
      "Epoch:  85 Step:   648 /   793 Train loss: 0.01591832\r\n",
      "Epoch:  85 Step:   649 /   793 Train loss: 0.02012016\r\n",
      "Epoch:  85 Step:   650 /   793 Train loss: 0.01999716\r\n",
      "Epoch:  85 Step:   651 /   793 Train loss: 0.01761521\r\n",
      "Epoch:  85 Step:   652 /   793 Train loss: 0.03194747\r\n",
      "Epoch:  85 Step:   653 /   793 Train loss: 0.01429482\r\n",
      "Epoch:  85 Step:   654 /   793 Train loss: 0.03260577\r\n",
      "Epoch:  85 Step:   655 /   793 Train loss: 0.03108417\r\n",
      "Epoch:  85 Step:   656 /   793 Train loss: 0.01547621\r\n",
      "Epoch:  85 Step:   657 /   793 Train loss: 0.01737398\r\n",
      "Epoch:  85 Step:   658 /   793 Train loss: 0.03392648\r\n",
      "Epoch:  85 Step:   659 /   793 Train loss: 0.02852786\r\n",
      "Epoch:  85 Step:   660 /   793 Train loss: 0.02535729\r\n",
      "Epoch:  85 Step:   661 /   793 Train loss: 0.02781028\r\n",
      "Epoch:  85 Step:   662 /   793 Train loss: 0.02172220\r\n",
      "Epoch:  85 Step:   663 /   793 Train loss: 0.02034422\r\n",
      "Epoch:  85 Step:   664 /   793 Train loss: 0.01916683\r\n",
      "Epoch:  85 Step:   665 /   793 Train loss: 0.01415485\r\n",
      "Epoch:  85 Step:   666 /   793 Train loss: 0.02732221\r\n",
      "Epoch:  85 Step:   667 /   793 Train loss: 0.02642966\r\n",
      "Epoch:  85 Step:   668 /   793 Train loss: 0.02928731\r\n",
      "Epoch:  85 Step:   669 /   793 Train loss: 0.01580785\r\n",
      "Epoch:  85 Step:   670 /   793 Train loss: 0.02078116\r\n",
      "Epoch:  85 Step:   671 /   793 Train loss: 0.02836027\r\n",
      "Epoch:  85 Step:   672 /   793 Train loss: 0.01559371\r\n",
      "Epoch:  85 Step:   673 /   793 Train loss: 0.02570708\r\n",
      "Epoch:  85 Step:   674 /   793 Train loss: 0.02983013\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  85 Step:   675 /   793 Train loss: 0.03942540\r\n",
      "Epoch:  85 Step:   676 /   793 Train loss: 0.02045088\r\n",
      "Epoch:  85 Step:   677 /   793 Train loss: 0.02303930\r\n",
      "Epoch:  85 Step:   678 /   793 Train loss: 0.01948915\r\n",
      "Epoch:  85 Step:   679 /   793 Train loss: 0.02191132\r\n",
      "Epoch:  85 Step:   680 /   793 Train loss: 0.01962912\r\n",
      "Epoch:  85 Step:   681 /   793 Train loss: 0.03000534\r\n",
      "Epoch:  85 Step:   682 /   793 Train loss: 0.02132940\r\n",
      "Epoch:  85 Step:   683 /   793 Train loss: 0.01946206\r\n",
      "Epoch:  85 Step:   684 /   793 Train loss: 0.01444153\r\n",
      "Epoch:  85 Step:   685 /   793 Train loss: 0.02169996\r\n",
      "Epoch:  85 Step:   686 /   793 Train loss: 0.02485167\r\n",
      "Epoch:  85 Step:   687 /   793 Train loss: 0.02587920\r\n",
      "Epoch:  85 Step:   688 /   793 Train loss: 0.01524356\r\n",
      "Epoch:  85 Step:   689 /   793 Train loss: 0.02596745\r\n",
      "Epoch:  85 Step:   690 /   793 Train loss: 0.03421678\r\n",
      "Epoch:  85 Step:   691 /   793 Train loss: 0.01813305\r\n",
      "Epoch:  85 Step:   692 /   793 Train loss: 0.02350050\r\n",
      "Epoch:  85 Step:   693 /   793 Train loss: 0.02146555\r\n",
      "Epoch:  85 Step:   694 /   793 Train loss: 0.02033371\r\n",
      "Epoch:  85 Step:   695 /   793 Train loss: 0.01278234\r\n",
      "Epoch:  85 Step:   696 /   793 Train loss: 0.01950490\r\n",
      "Epoch:  85 Step:   697 /   793 Train loss: 0.01899383\r\n",
      "Epoch:  85 Step:   698 /   793 Train loss: 0.03228030\r\n",
      "Epoch:  85 Step:   699 /   793 Train loss: 0.02861626\r\n",
      "Epoch:  85 Step:   700 /   793 Train loss: 0.02995043\r\n",
      "Epoch:  85 Step:   701 /   793 Train loss: 0.02488335\r\n",
      "Epoch:  85 Step:   702 /   793 Train loss: 0.02506942\r\n",
      "Epoch:  85 Step:   703 /   793 Train loss: 0.03982846\r\n",
      "Epoch:  85 Step:   704 /   793 Train loss: 0.03360595\r\n",
      "Epoch:  85 Step:   705 /   793 Train loss: 0.02070184\r\n",
      "Epoch:  85 Step:   706 /   793 Train loss: 0.00965236\r\n",
      "Epoch:  85 Step:   707 /   793 Train loss: 0.02848985\r\n",
      "Epoch:  85 Step:   708 /   793 Train loss: 0.03469639\r\n",
      "Epoch:  85 Step:   709 /   793 Train loss: 0.02661286\r\n",
      "Epoch:  85 Step:   710 /   793 Train loss: 0.03160907\r\n",
      "Epoch:  85 Step:   711 /   793 Train loss: 0.02973384\r\n",
      "Epoch:  85 Step:   712 /   793 Train loss: 0.02811834\r\n",
      "Epoch:  85 Step:   713 /   793 Train loss: 0.01857602\r\n",
      "Epoch:  85 Step:   714 /   793 Train loss: 0.02916015\r\n",
      "Epoch:  85 Step:   715 /   793 Train loss: 0.03005441\r\n",
      "Epoch:  85 Step:   716 /   793 Train loss: 0.02210656\r\n",
      "Epoch:  85 Step:   717 /   793 Train loss: 0.01742860\r\n",
      "Epoch:  85 Step:   718 /   793 Train loss: 0.02334633\r\n",
      "Epoch:  85 Step:   719 /   793 Train loss: 0.02004522\r\n",
      "Epoch:  85 Step:   720 /   793 Train loss: 0.01039083\r\n",
      "Epoch:  85 Step:   721 /   793 Train loss: 0.02689233\r\n",
      "Epoch:  85 Step:   722 /   793 Train loss: 0.01333991\r\n",
      "Epoch:  85 Step:   723 /   793 Train loss: 0.01485987\r\n",
      "Epoch:  85 Step:   724 /   793 Train loss: 0.01693323\r\n",
      "Epoch:  85 Step:   725 /   793 Train loss: 0.01145718\r\n",
      "Epoch:  85 Step:   726 /   793 Train loss: 0.02353247\r\n",
      "Epoch:  85 Step:   727 /   793 Train loss: 0.02869459\r\n",
      "Epoch:  85 Step:   728 /   793 Train loss: 0.03178737\r\n",
      "Epoch:  85 Step:   729 /   793 Train loss: 0.02024875\r\n",
      "Epoch:  85 Step:   730 /   793 Train loss: 0.01430704\r\n",
      "Epoch:  85 Step:   731 /   793 Train loss: 0.02840009\r\n",
      "Epoch:  85 Step:   732 /   793 Train loss: 0.02023693\r\n",
      "Epoch:  85 Step:   733 /   793 Train loss: 0.02707342\r\n",
      "Epoch:  85 Step:   734 /   793 Train loss: 0.01604399\r\n",
      "Epoch:  85 Step:   735 /   793 Train loss: 0.02997677\r\n",
      "Epoch:  85 Step:   736 /   793 Train loss: 0.02097876\r\n",
      "Epoch:  85 Step:   737 /   793 Train loss: 0.02616494\r\n",
      "Epoch:  85 Step:   738 /   793 Train loss: 0.04581458\r\n",
      "Epoch:  85 Step:   739 /   793 Train loss: 0.03057252\r\n",
      "Epoch:  85 Step:   740 /   793 Train loss: 0.01955333\r\n",
      "Epoch:  85 Step:   741 /   793 Train loss: 0.02563001\r\n",
      "Epoch:  85 Step:   742 /   793 Train loss: 0.02035925\r\n",
      "Epoch:  85 Step:   743 /   793 Train loss: 0.03675095\r\n",
      "Epoch:  85 Step:   744 /   793 Train loss: 0.02452068\r\n",
      "Epoch:  85 Step:   745 /   793 Train loss: 0.02756587\r\n",
      "Epoch:  85 Step:   746 /   793 Train loss: 0.03344969\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  85 Step:   747 /   793 Train loss: 0.02099820\r\n",
      "Epoch:  85 Step:   748 /   793 Train loss: 0.01174026\r\n",
      "Epoch:  85 Step:   749 /   793 Train loss: 0.03334557\r\n",
      "Epoch:  85 Step:   750 /   793 Train loss: 0.01937762\r\n",
      "Epoch:  85 Step:   751 /   793 Train loss: 0.03071705\r\n",
      "Epoch:  85 Step:   752 /   793 Train loss: 0.02838144\r\n",
      "Epoch:  85 Step:   753 /   793 Train loss: 0.01758386\r\n",
      "Epoch:  85 Step:   754 /   793 Train loss: 0.01296587\r\n",
      "Epoch:  85 Step:   755 /   793 Train loss: 0.01649499\r\n",
      "Epoch:  85 Step:   756 /   793 Train loss: 0.02179106\r\n",
      "Epoch:  85 Step:   757 /   793 Train loss: 0.02192434\r\n",
      "Epoch:  85 Step:   758 /   793 Train loss: 0.01913587\r\n",
      "Epoch:  85 Step:   759 /   793 Train loss: 0.03002499\r\n",
      "Epoch:  85 Step:   760 /   793 Train loss: 0.02363578\r\n",
      "Epoch:  85 Step:   761 /   793 Train loss: 0.03936625\r\n",
      "Epoch:  85 Step:   762 /   793 Train loss: 0.02018010\r\n",
      "Epoch:  85 Step:   763 /   793 Train loss: 0.02966012\r\n",
      "Epoch:  85 Step:   764 /   793 Train loss: 0.01520255\r\n",
      "Epoch:  85 Step:   765 /   793 Train loss: 0.01921986\r\n",
      "Epoch:  85 Step:   766 /   793 Train loss: 0.01872205\r\n",
      "Epoch:  85 Step:   767 /   793 Train loss: 0.02418975\r\n",
      "Epoch:  85 Step:   768 /   793 Train loss: 0.02544589\r\n",
      "Epoch:  85 Step:   769 /   793 Train loss: 0.02687708\r\n",
      "Epoch:  85 Step:   770 /   793 Train loss: 0.02313957\r\n",
      "Epoch:  85 Step:   771 /   793 Train loss: 0.02680826\r\n",
      "Epoch:  85 Step:   772 /   793 Train loss: 0.02603897\r\n",
      "Epoch:  85 Step:   773 /   793 Train loss: 0.01330701\r\n",
      "Epoch:  85 Step:   774 /   793 Train loss: 0.01912599\r\n",
      "Epoch:  85 Step:   775 /   793 Train loss: 0.02618239\r\n",
      "Epoch:  85 Step:   776 /   793 Train loss: 0.02400120\r\n",
      "Epoch:  85 Step:   777 /   793 Train loss: 0.01462814\r\n",
      "Epoch:  85 Step:   778 /   793 Train loss: 0.02222769\r\n",
      "Epoch:  85 Step:   779 /   793 Train loss: 0.01974849\r\n",
      "Epoch:  85 Step:   780 /   793 Train loss: 0.02613274\r\n",
      "Epoch:  85 Step:   781 /   793 Train loss: 0.02511874\r\n",
      "Epoch:  85 Step:   782 /   793 Train loss: 0.01678175\r\n",
      "Epoch:  85 Step:   783 /   793 Train loss: 0.02514823\r\n",
      "Epoch:  85 Step:   784 /   793 Train loss: 0.02309730\r\n",
      "Epoch:  85 Step:   785 /   793 Train loss: 0.02457660\r\n",
      "Epoch:  85 Step:   786 /   793 Train loss: 0.02459972\r\n",
      "Epoch:  85 Step:   787 /   793 Train loss: 0.03525899\r\n",
      "Epoch:  85 Step:   788 /   793 Train loss: 0.02364627\r\n",
      "Epoch:  85 Step:   789 /   793 Train loss: 0.02215935\r\n",
      "Epoch:  85 Step:   790 /   793 Train loss: 0.01468387\r\n",
      "Epoch:  85 Step:   791 /   793 Train loss: 0.01940139\r\n",
      "Epoch:  85 Step:   792 /   793 Train loss: 0.03725579\r\n",
      "Epoch:  85 Validation loss: 0.01408243\r\n",
      "Epoch:  86 Step:     0 /   793 Train loss: 0.03622035\r\n",
      "Epoch:  86 Step:     1 /   793 Train loss: 0.01952770\r\n",
      "Epoch:  86 Step:     2 /   793 Train loss: 0.02022262\r\n",
      "Epoch:  86 Step:     3 /   793 Train loss: 0.02293353\r\n",
      "Epoch:  86 Step:     4 /   793 Train loss: 0.02089415\r\n",
      "Epoch:  86 Step:     5 /   793 Train loss: 0.01310492\r\n",
      "Epoch:  86 Step:     6 /   793 Train loss: 0.02253168\r\n",
      "Epoch:  86 Step:     7 /   793 Train loss: 0.01582123\r\n",
      "Epoch:  86 Step:     8 /   793 Train loss: 0.02989838\r\n",
      "Epoch:  86 Step:     9 /   793 Train loss: 0.01507970\r\n",
      "Epoch:  86 Step:    10 /   793 Train loss: 0.01658974\r\n",
      "Epoch:  86 Step:    11 /   793 Train loss: 0.02622081\r\n",
      "Epoch:  86 Step:    12 /   793 Train loss: 0.01867006\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  86 Step:    13 /   793 Train loss: 0.02980127\r\n",
      "Epoch:  86 Step:    14 /   793 Train loss: 0.02654377\r\n",
      "Epoch:  86 Step:    15 /   793 Train loss: 0.02604947\r\n",
      "Epoch:  86 Step:    16 /   793 Train loss: 0.03099054\r\n",
      "Epoch:  86 Step:    17 /   793 Train loss: 0.01910423\r\n",
      "Epoch:  86 Step:    18 /   793 Train loss: 0.01631794\r\n",
      "Epoch:  86 Step:    19 /   793 Train loss: 0.02864971\r\n",
      "Epoch:  86 Step:    20 /   793 Train loss: 0.02225557\r\n",
      "Epoch:  86 Step:    21 /   793 Train loss: 0.02959127\r\n",
      "Epoch:  86 Step:    22 /   793 Train loss: 0.01699296\r\n",
      "Epoch:  86 Step:    23 /   793 Train loss: 0.03453979\r\n",
      "Epoch:  86 Step:    24 /   793 Train loss: 0.03540210\r\n",
      "Epoch:  86 Step:    25 /   793 Train loss: 0.02913115\r\n",
      "Epoch:  86 Step:    26 /   793 Train loss: 0.04505065\r\n",
      "Epoch:  86 Step:    27 /   793 Train loss: 0.02063925\r\n",
      "Epoch:  86 Step:    28 /   793 Train loss: 0.02021484\r\n",
      "Epoch:  86 Step:    29 /   793 Train loss: 0.02955097\r\n",
      "Epoch:  86 Step:    30 /   793 Train loss: 0.01876429\r\n",
      "Epoch:  86 Step:    31 /   793 Train loss: 0.02087964\r\n",
      "Epoch:  86 Step:    32 /   793 Train loss: 0.02327945\r\n",
      "Epoch:  86 Step:    33 /   793 Train loss: 0.03281653\r\n",
      "Epoch:  86 Step:    34 /   793 Train loss: 0.02646255\r\n",
      "Epoch:  86 Step:    35 /   793 Train loss: 0.03117263\r\n",
      "Epoch:  86 Step:    36 /   793 Train loss: 0.02031883\r\n",
      "Epoch:  86 Step:    37 /   793 Train loss: 0.02238438\r\n",
      "Epoch:  86 Step:    38 /   793 Train loss: 0.01717461\r\n",
      "Epoch:  86 Step:    39 /   793 Train loss: 0.02977186\r\n",
      "Epoch:  86 Step:    40 /   793 Train loss: 0.02286229\r\n",
      "Epoch:  86 Step:    41 /   793 Train loss: 0.01747919\r\n",
      "Epoch:  86 Step:    42 /   793 Train loss: 0.02142762\r\n",
      "Epoch:  86 Step:    43 /   793 Train loss: 0.03164121\r\n",
      "Epoch:  86 Step:    44 /   793 Train loss: 0.02045417\r\n",
      "Epoch:  86 Step:    45 /   793 Train loss: 0.02067070\r\n",
      "Epoch:  86 Step:    46 /   793 Train loss: 0.02576772\r\n",
      "Epoch:  86 Step:    47 /   793 Train loss: 0.02972716\r\n",
      "Epoch:  86 Step:    48 /   793 Train loss: 0.02009534\r\n",
      "Epoch:  86 Step:    49 /   793 Train loss: 0.01405913\r\n",
      "Epoch:  86 Step:    50 /   793 Train loss: 0.01702040\r\n",
      "Epoch:  86 Step:    51 /   793 Train loss: 0.02514593\r\n",
      "Epoch:  86 Step:    52 /   793 Train loss: 0.03542930\r\n",
      "Epoch:  86 Step:    53 /   793 Train loss: 0.02681465\r\n",
      "Epoch:  86 Step:    54 /   793 Train loss: 0.02240330\r\n",
      "Epoch:  86 Step:    55 /   793 Train loss: 0.02525903\r\n",
      "Epoch:  86 Step:    56 /   793 Train loss: 0.01959016\r\n",
      "Epoch:  86 Step:    57 /   793 Train loss: 0.02522969\r\n",
      "Epoch:  86 Step:    58 /   793 Train loss: 0.03563085\r\n",
      "Epoch:  86 Step:    59 /   793 Train loss: 0.02706095\r\n",
      "Epoch:  86 Step:    60 /   793 Train loss: 0.01982429\r\n",
      "Epoch:  86 Step:    61 /   793 Train loss: 0.02162111\r\n",
      "Epoch:  86 Step:    62 /   793 Train loss: 0.03182728\r\n",
      "Epoch:  86 Step:    63 /   793 Train loss: 0.02241811\r\n",
      "Epoch:  86 Step:    64 /   793 Train loss: 0.03223528\r\n",
      "Epoch:  86 Step:    65 /   793 Train loss: 0.01110824\r\n",
      "Epoch:  86 Step:    66 /   793 Train loss: 0.02791440\r\n",
      "Epoch:  86 Step:    67 /   793 Train loss: 0.01280230\r\n",
      "Epoch:  86 Step:    68 /   793 Train loss: 0.02376690\r\n",
      "Epoch:  86 Step:    69 /   793 Train loss: 0.01790184\r\n",
      "Epoch:  86 Step:    70 /   793 Train loss: 0.02725879\r\n",
      "Epoch:  86 Step:    71 /   793 Train loss: 0.03205720\r\n",
      "Epoch:  86 Step:    72 /   793 Train loss: 0.01694245\r\n",
      "Epoch:  86 Step:    73 /   793 Train loss: 0.02438361\r\n",
      "Epoch:  86 Step:    74 /   793 Train loss: 0.02393327\r\n",
      "Epoch:  86 Step:    75 /   793 Train loss: 0.02039345\r\n",
      "Epoch:  86 Step:    76 /   793 Train loss: 0.01251083\r\n",
      "Epoch:  86 Step:    77 /   793 Train loss: 0.02561353\r\n",
      "Epoch:  86 Step:    78 /   793 Train loss: 0.01958806\r\n",
      "Epoch:  86 Step:    79 /   793 Train loss: 0.01818403\r\n",
      "Epoch:  86 Step:    80 /   793 Train loss: 0.02417550\r\n",
      "Epoch:  86 Step:    81 /   793 Train loss: 0.04376382\r\n",
      "Epoch:  86 Step:    82 /   793 Train loss: 0.02927140\r\n",
      "Epoch:  86 Step:    83 /   793 Train loss: 0.01818274\r\n",
      "Epoch:  86 Step:    84 /   793 Train loss: 0.02126903\r\n",
      "Epoch:  86 Step:    85 /   793 Train loss: 0.02574133\r\n",
      "Epoch:  86 Step:    86 /   793 Train loss: 0.01194326\r\n",
      "Epoch:  86 Step:    87 /   793 Train loss: 0.02576678\r\n",
      "Epoch:  86 Step:    88 /   793 Train loss: 0.02942614\r\n",
      "Epoch:  86 Step:    89 /   793 Train loss: 0.02351023\r\n",
      "Epoch:  86 Step:    90 /   793 Train loss: 0.02593920\r\n",
      "Epoch:  86 Step:    91 /   793 Train loss: 0.02055732\r\n",
      "Epoch:  86 Step:    92 /   793 Train loss: 0.02342165\r\n",
      "Epoch:  86 Step:    93 /   793 Train loss: 0.03442407\r\n",
      "Epoch:  86 Step:    94 /   793 Train loss: 0.04093910\r\n",
      "Epoch:  86 Step:    95 /   793 Train loss: 0.02388718\r\n",
      "Epoch:  86 Step:    96 /   793 Train loss: 0.01712123\r\n",
      "Epoch:  86 Step:    97 /   793 Train loss: 0.01975446\r\n",
      "Epoch:  86 Step:    98 /   793 Train loss: 0.03741322\r\n",
      "Epoch:  86 Step:    99 /   793 Train loss: 0.03576222\r\n",
      "Epoch:  86 Step:   100 /   793 Train loss: 0.01859616\r\n",
      "Epoch:  86 Step:   101 /   793 Train loss: 0.02297181\r\n",
      "Epoch:  86 Step:   102 /   793 Train loss: 0.01808184\r\n",
      "Epoch:  86 Step:   103 /   793 Train loss: 0.01508935\r\n",
      "Epoch:  86 Step:   104 /   793 Train loss: 0.01774497\r\n",
      "Epoch:  86 Step:   105 /   793 Train loss: 0.01238219\r\n",
      "Epoch:  86 Step:   106 /   793 Train loss: 0.02727958\r\n",
      "Epoch:  86 Step:   107 /   793 Train loss: 0.02138993\r\n",
      "Epoch:  86 Step:   108 /   793 Train loss: 0.02564258\r\n",
      "Epoch:  86 Step:   109 /   793 Train loss: 0.02793329\r\n",
      "Epoch:  86 Step:   110 /   793 Train loss: 0.02522047\r\n",
      "Epoch:  86 Step:   111 /   793 Train loss: 0.04203990\r\n",
      "Epoch:  86 Step:   112 /   793 Train loss: 0.02746395\r\n",
      "Epoch:  86 Step:   113 /   793 Train loss: 0.02540097\r\n",
      "Epoch:  86 Step:   114 /   793 Train loss: 0.02415263\r\n",
      "Epoch:  86 Step:   115 /   793 Train loss: 0.03165598\r\n",
      "Epoch:  86 Step:   116 /   793 Train loss: 0.02870747\r\n",
      "Epoch:  86 Step:   117 /   793 Train loss: 0.02348761\r\n",
      "Epoch:  86 Step:   118 /   793 Train loss: 0.01469843\r\n",
      "Epoch:  86 Step:   119 /   793 Train loss: 0.04332646\r\n",
      "Epoch:  86 Step:   120 /   793 Train loss: 0.02484466\r\n",
      "Epoch:  86 Step:   121 /   793 Train loss: 0.01976677\r\n",
      "Epoch:  86 Step:   122 /   793 Train loss: 0.02515979\r\n",
      "Epoch:  86 Step:   123 /   793 Train loss: 0.02382335\r\n",
      "Epoch:  86 Step:   124 /   793 Train loss: 0.01899793\r\n",
      "Epoch:  86 Step:   125 /   793 Train loss: 0.02947981\r\n",
      "Epoch:  86 Step:   126 /   793 Train loss: 0.02414640\r\n",
      "Epoch:  86 Step:   127 /   793 Train loss: 0.02619664\r\n",
      "Epoch:  86 Step:   128 /   793 Train loss: 0.01606448\r\n",
      "Epoch:  86 Step:   129 /   793 Train loss: 0.02188912\r\n",
      "Epoch:  86 Step:   130 /   793 Train loss: 0.01931160\r\n",
      "Epoch:  86 Step:   131 /   793 Train loss: 0.01885938\r\n",
      "Epoch:  86 Step:   132 /   793 Train loss: 0.01726535\r\n",
      "Epoch:  86 Step:   133 /   793 Train loss: 0.03069709\r\n",
      "Epoch:  86 Step:   134 /   793 Train loss: 0.00988858\r\n",
      "Epoch:  86 Step:   135 /   793 Train loss: 0.02123699\r\n",
      "Epoch:  86 Step:   136 /   793 Train loss: 0.01638968\r\n",
      "Epoch:  86 Step:   137 /   793 Train loss: 0.02065380\r\n",
      "Epoch:  86 Step:   138 /   793 Train loss: 0.01970357\r\n",
      "Epoch:  86 Step:   139 /   793 Train loss: 0.01904239\r\n",
      "Epoch:  86 Step:   140 /   793 Train loss: 0.01749510\r\n",
      "Epoch:  86 Step:   141 /   793 Train loss: 0.01772668\r\n",
      "Epoch:  86 Step:   142 /   793 Train loss: 0.02220169\r\n",
      "Epoch:  86 Step:   143 /   793 Train loss: 0.01334898\r\n",
      "Epoch:  86 Step:   144 /   793 Train loss: 0.02999562\r\n",
      "Epoch:  86 Step:   145 /   793 Train loss: 0.01366690\r\n",
      "Epoch:  86 Step:   146 /   793 Train loss: 0.02265707\r\n",
      "Epoch:  86 Step:   147 /   793 Train loss: 0.02722927\r\n",
      "Epoch:  86 Step:   148 /   793 Train loss: 0.02491879\r\n",
      "Epoch:  86 Step:   149 /   793 Train loss: 0.02219385\r\n",
      "Epoch:  86 Step:   150 /   793 Train loss: 0.02439454\r\n",
      "Epoch:  86 Step:   151 /   793 Train loss: 0.02664908\r\n",
      "Epoch:  86 Step:   152 /   793 Train loss: 0.03263826\r\n",
      "Epoch:  86 Step:   153 /   793 Train loss: 0.04038025\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  86 Step:   154 /   793 Train loss: 0.01920660\r\n",
      "Epoch:  86 Step:   155 /   793 Train loss: 0.03186342\r\n",
      "Epoch:  86 Step:   156 /   793 Train loss: 0.02553472\r\n",
      "Epoch:  86 Step:   157 /   793 Train loss: 0.02081857\r\n",
      "Epoch:  86 Step:   158 /   793 Train loss: 0.02546315\r\n",
      "Epoch:  86 Step:   159 /   793 Train loss: 0.02100371\r\n",
      "Epoch:  86 Step:   160 /   793 Train loss: 0.02644228\r\n",
      "Epoch:  86 Step:   161 /   793 Train loss: 0.02181659\r\n",
      "Epoch:  86 Step:   162 /   793 Train loss: 0.02572040\r\n",
      "Epoch:  86 Step:   163 /   793 Train loss: 0.03414407\r\n",
      "Epoch:  86 Step:   164 /   793 Train loss: 0.01828339\r\n",
      "Epoch:  86 Step:   165 /   793 Train loss: 0.01944705\r\n",
      "Epoch:  86 Step:   166 /   793 Train loss: 0.04358348\r\n",
      "Epoch:  86 Step:   167 /   793 Train loss: 0.02380830\r\n",
      "Epoch:  86 Step:   168 /   793 Train loss: 0.02205511\r\n",
      "Epoch:  86 Step:   169 /   793 Train loss: 0.02165463\r\n",
      "Epoch:  86 Step:   170 /   793 Train loss: 0.02127440\r\n",
      "Epoch:  86 Step:   171 /   793 Train loss: 0.02750865\r\n",
      "Epoch:  86 Step:   172 /   793 Train loss: 0.02204762\r\n",
      "Epoch:  86 Step:   173 /   793 Train loss: 0.01854658\r\n",
      "Epoch:  86 Step:   174 /   793 Train loss: 0.02447159\r\n",
      "Epoch:  86 Step:   175 /   793 Train loss: 0.02193753\r\n",
      "Epoch:  86 Step:   176 /   793 Train loss: 0.02930509\r\n",
      "Epoch:  86 Step:   177 /   793 Train loss: 0.03963033\r\n",
      "Epoch:  86 Step:   178 /   793 Train loss: 0.02450343\r\n",
      "Epoch:  86 Step:   179 /   793 Train loss: 0.01964358\r\n",
      "Epoch:  86 Step:   180 /   793 Train loss: 0.02836935\r\n",
      "Epoch:  86 Step:   181 /   793 Train loss: 0.03305992\r\n",
      "Epoch:  86 Step:   182 /   793 Train loss: 0.01481252\r\n",
      "Epoch:  86 Step:   183 /   793 Train loss: 0.03004035\r\n",
      "Epoch:  86 Step:   184 /   793 Train loss: 0.02636081\r\n",
      "Epoch:  86 Step:   185 /   793 Train loss: 0.02000846\r\n",
      "Epoch:  86 Step:   186 /   793 Train loss: 0.04205279\r\n",
      "Epoch:  86 Step:   187 /   793 Train loss: 0.03117888\r\n",
      "Epoch:  86 Step:   188 /   793 Train loss: 0.02804365\r\n",
      "Epoch:  86 Step:   189 /   793 Train loss: 0.02139277\r\n",
      "Epoch:  86 Step:   190 /   793 Train loss: 0.02031740\r\n",
      "Epoch:  86 Step:   191 /   793 Train loss: 0.02752649\r\n",
      "Epoch:  86 Step:   192 /   793 Train loss: 0.01322531\r\n",
      "Epoch:  86 Step:   193 /   793 Train loss: 0.03656249\r\n",
      "Epoch:  86 Step:   194 /   793 Train loss: 0.03243459\r\n",
      "Epoch:  86 Step:   195 /   793 Train loss: 0.03219539\r\n",
      "Epoch:  86 Step:   196 /   793 Train loss: 0.01744840\r\n",
      "Epoch:  86 Step:   197 /   793 Train loss: 0.02117413\r\n",
      "Epoch:  86 Step:   198 /   793 Train loss: 0.02731748\r\n",
      "Epoch:  86 Step:   199 /   793 Train loss: 0.02298721\r\n",
      "Epoch:  86 Step:   200 /   793 Train loss: 0.02473431\r\n",
      "Epoch:  86 Step:   201 /   793 Train loss: 0.02853489\r\n",
      "Epoch:  86 Step:   202 /   793 Train loss: 0.03111860\r\n",
      "Epoch:  86 Step:   203 /   793 Train loss: 0.04577035\r\n",
      "Epoch:  86 Step:   204 /   793 Train loss: 0.01788890\r\n",
      "Epoch:  86 Step:   205 /   793 Train loss: 0.03963431\r\n",
      "Epoch:  86 Step:   206 /   793 Train loss: 0.02828335\r\n",
      "Epoch:  86 Step:   207 /   793 Train loss: 0.03822291\r\n",
      "Epoch:  86 Step:   208 /   793 Train loss: 0.02884836\r\n",
      "Epoch:  86 Step:   209 /   793 Train loss: 0.02300659\r\n",
      "Epoch:  86 Step:   210 /   793 Train loss: 0.02118206\r\n",
      "Epoch:  86 Step:   211 /   793 Train loss: 0.01683293\r\n",
      "Epoch:  86 Step:   212 /   793 Train loss: 0.02745921\r\n",
      "Epoch:  86 Step:   213 /   793 Train loss: 0.01778884\r\n",
      "Epoch:  86 Step:   214 /   793 Train loss: 0.02180479\r\n",
      "Epoch:  86 Step:   215 /   793 Train loss: 0.02078138\r\n",
      "Epoch:  86 Step:   216 /   793 Train loss: 0.02819352\r\n",
      "Epoch:  86 Step:   217 /   793 Train loss: 0.04255789\r\n",
      "Epoch:  86 Step:   218 /   793 Train loss: 0.03249466\r\n",
      "Epoch:  86 Step:   219 /   793 Train loss: 0.03476589\r\n",
      "Epoch:  86 Step:   220 /   793 Train loss: 0.03555032\r\n",
      "Epoch:  86 Step:   221 /   793 Train loss: 0.01410708\r\n",
      "Epoch:  86 Step:   222 /   793 Train loss: 0.02479775\r\n",
      "Epoch:  86 Step:   223 /   793 Train loss: 0.03346938\r\n",
      "Epoch:  86 Step:   224 /   793 Train loss: 0.02093416\r\n",
      "Epoch:  86 Step:   225 /   793 Train loss: 0.02052020\r\n",
      "Epoch:  86 Step:   226 /   793 Train loss: 0.01736391\r\n",
      "Epoch:  86 Step:   227 /   793 Train loss: 0.01444369\r\n",
      "Epoch:  86 Step:   228 /   793 Train loss: 0.01792436\r\n",
      "Epoch:  86 Step:   229 /   793 Train loss: 0.01759791\r\n",
      "Epoch:  86 Step:   230 /   793 Train loss: 0.02775829\r\n",
      "Epoch:  86 Step:   231 /   793 Train loss: 0.01650771\r\n",
      "Epoch:  86 Step:   232 /   793 Train loss: 0.02111043\r\n",
      "Epoch:  86 Step:   233 /   793 Train loss: 0.01703201\r\n",
      "Epoch:  86 Step:   234 /   793 Train loss: 0.01572727\r\n",
      "Epoch:  86 Step:   235 /   793 Train loss: 0.01186038\r\n",
      "Epoch:  86 Step:   236 /   793 Train loss: 0.03971918\r\n",
      "Epoch:  86 Step:   237 /   793 Train loss: 0.02422992\r\n",
      "Epoch:  86 Step:   238 /   793 Train loss: 0.02280327\r\n",
      "Epoch:  86 Step:   239 /   793 Train loss: 0.02811834\r\n",
      "Epoch:  86 Step:   240 /   793 Train loss: 0.01778480\r\n",
      "Epoch:  86 Step:   241 /   793 Train loss: 0.03268488\r\n",
      "Epoch:  86 Step:   242 /   793 Train loss: 0.01697990\r\n",
      "Epoch:  86 Step:   243 /   793 Train loss: 0.02711674\r\n",
      "Epoch:  86 Step:   244 /   793 Train loss: 0.02230094\r\n",
      "Epoch:  86 Step:   245 /   793 Train loss: 0.02199633\r\n",
      "Epoch:  86 Step:   246 /   793 Train loss: 0.01515628\r\n",
      "Epoch:  86 Step:   247 /   793 Train loss: 0.02175460\r\n",
      "Epoch:  86 Step:   248 /   793 Train loss: 0.01576169\r\n",
      "Epoch:  86 Step:   249 /   793 Train loss: 0.02032370\r\n",
      "Epoch:  86 Step:   250 /   793 Train loss: 0.03358907\r\n",
      "Epoch:  86 Step:   251 /   793 Train loss: 0.02883241\r\n",
      "Epoch:  86 Step:   252 /   793 Train loss: 0.01729500\r\n",
      "Epoch:  86 Step:   253 /   793 Train loss: 0.02869896\r\n",
      "Epoch:  86 Step:   254 /   793 Train loss: 0.02284921\r\n",
      "Epoch:  86 Step:   255 /   793 Train loss: 0.01388477\r\n",
      "Epoch:  86 Step:   256 /   793 Train loss: 0.02601724\r\n",
      "Epoch:  86 Step:   257 /   793 Train loss: 0.02409438\r\n",
      "Epoch:  86 Step:   258 /   793 Train loss: 0.03070857\r\n",
      "Epoch:  86 Step:   259 /   793 Train loss: 0.02414691\r\n",
      "Epoch:  86 Step:   260 /   793 Train loss: 0.01484930\r\n",
      "Epoch:  86 Step:   261 /   793 Train loss: 0.01572301\r\n",
      "Epoch:  86 Step:   262 /   793 Train loss: 0.01474855\r\n",
      "Epoch:  86 Step:   263 /   793 Train loss: 0.02133330\r\n",
      "Epoch:  86 Step:   264 /   793 Train loss: 0.02215870\r\n",
      "Epoch:  86 Step:   265 /   793 Train loss: 0.02189886\r\n",
      "Epoch:  86 Step:   266 /   793 Train loss: 0.04173339\r\n",
      "Epoch:  86 Step:   267 /   793 Train loss: 0.03515369\r\n",
      "Epoch:  86 Step:   268 /   793 Train loss: 0.01134501\r\n",
      "Epoch:  86 Step:   269 /   793 Train loss: 0.02941909\r\n",
      "Epoch:  86 Step:   270 /   793 Train loss: 0.04108518\r\n",
      "Epoch:  86 Step:   271 /   793 Train loss: 0.01578639\r\n",
      "Epoch:  86 Step:   272 /   793 Train loss: 0.02498398\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  86 Step:   273 /   793 Train loss: 0.03512065\r\n",
      "Epoch:  86 Step:   274 /   793 Train loss: 0.02189770\r\n",
      "Epoch:  86 Step:   275 /   793 Train loss: 0.02773893\r\n",
      "Epoch:  86 Step:   276 /   793 Train loss: 0.01440593\r\n",
      "Epoch:  86 Step:   277 /   793 Train loss: 0.02653735\r\n",
      "Epoch:  86 Step:   278 /   793 Train loss: 0.02254552\r\n",
      "Epoch:  86 Step:   279 /   793 Train loss: 0.03376103\r\n",
      "Epoch:  86 Step:   280 /   793 Train loss: 0.01383419\r\n",
      "Epoch:  86 Step:   281 /   793 Train loss: 0.03698393\r\n",
      "Epoch:  86 Step:   282 /   793 Train loss: 0.01660594\r\n",
      "Epoch:  86 Step:   283 /   793 Train loss: 0.01394068\r\n",
      "Epoch:  86 Step:   284 /   793 Train loss: 0.01777578\r\n",
      "Epoch:  86 Step:   285 /   793 Train loss: 0.02037977\r\n",
      "Epoch:  86 Step:   286 /   793 Train loss: 0.02903363\r\n",
      "Epoch:  86 Step:   287 /   793 Train loss: 0.01274314\r\n",
      "Epoch:  86 Step:   288 /   793 Train loss: 0.01886673\r\n",
      "Epoch:  86 Step:   289 /   793 Train loss: 0.03008493\r\n",
      "Epoch:  86 Step:   290 /   793 Train loss: 0.02601441\r\n",
      "Epoch:  86 Step:   291 /   793 Train loss: 0.02377321\r\n",
      "Epoch:  86 Step:   292 /   793 Train loss: 0.02605079\r\n",
      "Epoch:  86 Step:   293 /   793 Train loss: 0.03208315\r\n",
      "Epoch:  86 Step:   294 /   793 Train loss: 0.01572113\r\n",
      "Epoch:  86 Step:   295 /   793 Train loss: 0.02729719\r\n",
      "Epoch:  86 Step:   296 /   793 Train loss: 0.02633102\r\n",
      "Epoch:  86 Step:   297 /   793 Train loss: 0.02516184\r\n",
      "Epoch:  86 Step:   298 /   793 Train loss: 0.02880218\r\n",
      "Epoch:  86 Step:   299 /   793 Train loss: 0.01498120\r\n",
      "Epoch:  86 Step:   300 /   793 Train loss: 0.01736917\r\n",
      "Epoch:  86 Step:   301 /   793 Train loss: 0.03606641\r\n",
      "Epoch:  86 Step:   302 /   793 Train loss: 0.03679495\r\n",
      "Epoch:  86 Step:   303 /   793 Train loss: 0.03126585\r\n",
      "Epoch:  86 Step:   304 /   793 Train loss: 0.02401887\r\n",
      "Epoch:  86 Step:   305 /   793 Train loss: 0.02740588\r\n",
      "Epoch:  86 Step:   306 /   793 Train loss: 0.03435749\r\n",
      "Epoch:  86 Step:   307 /   793 Train loss: 0.02741916\r\n",
      "Epoch:  86 Step:   308 /   793 Train loss: 0.03401962\r\n",
      "Epoch:  86 Step:   309 /   793 Train loss: 0.01731924\r\n",
      "Epoch:  86 Step:   310 /   793 Train loss: 0.02287389\r\n",
      "Epoch:  86 Step:   311 /   793 Train loss: 0.01299957\r\n",
      "Epoch:  86 Step:   312 /   793 Train loss: 0.01845422\r\n",
      "Epoch:  86 Step:   313 /   793 Train loss: 0.01953205\r\n",
      "Epoch:  86 Step:   314 /   793 Train loss: 0.01082356\r\n",
      "Epoch:  86 Step:   315 /   793 Train loss: 0.03468850\r\n",
      "Epoch:  86 Step:   316 /   793 Train loss: 0.02304120\r\n",
      "Epoch:  86 Step:   317 /   793 Train loss: 0.02890217\r\n",
      "Epoch:  86 Step:   318 /   793 Train loss: 0.03267043\r\n",
      "Epoch:  86 Step:   319 /   793 Train loss: 0.01463607\r\n",
      "Epoch:  86 Step:   320 /   793 Train loss: 0.02745046\r\n",
      "Epoch:  86 Step:   321 /   793 Train loss: 0.02496405\r\n",
      "Epoch:  86 Step:   322 /   793 Train loss: 0.01241506\r\n",
      "Epoch:  86 Step:   323 /   793 Train loss: 0.02774789\r\n",
      "Epoch:  86 Step:   324 /   793 Train loss: 0.03195555\r\n",
      "Epoch:  86 Step:   325 /   793 Train loss: 0.00967601\r\n",
      "Epoch:  86 Step:   326 /   793 Train loss: 0.02879212\r\n",
      "Epoch:  86 Step:   327 /   793 Train loss: 0.03145415\r\n",
      "Epoch:  86 Step:   328 /   793 Train loss: 0.01963235\r\n",
      "Epoch:  86 Step:   329 /   793 Train loss: 0.02364737\r\n",
      "Epoch:  86 Step:   330 /   793 Train loss: 0.03045865\r\n",
      "Epoch:  86 Step:   331 /   793 Train loss: 0.01546017\r\n",
      "Epoch:  86 Step:   332 /   793 Train loss: 0.02070418\r\n",
      "Epoch:  86 Step:   333 /   793 Train loss: 0.04217329\r\n",
      "Epoch:  86 Step:   334 /   793 Train loss: 0.03852800\r\n",
      "Epoch:  86 Step:   335 /   793 Train loss: 0.02273408\r\n",
      "Epoch:  86 Step:   336 /   793 Train loss: 0.01253629\r\n",
      "Epoch:  86 Step:   337 /   793 Train loss: 0.02624023\r\n",
      "Epoch:  86 Step:   338 /   793 Train loss: 0.01990994\r\n",
      "Epoch:  86 Step:   339 /   793 Train loss: 0.02268266\r\n",
      "Epoch:  86 Step:   340 /   793 Train loss: 0.02145743\r\n",
      "Epoch:  86 Step:   341 /   793 Train loss: 0.03541776\r\n",
      "Epoch:  86 Step:   342 /   793 Train loss: 0.01692862\r\n",
      "Epoch:  86 Step:   343 /   793 Train loss: 0.03438133\r\n",
      "Epoch:  86 Step:   344 /   793 Train loss: 0.03024796\r\n",
      "Epoch:  86 Step:   345 /   793 Train loss: 0.03664971\r\n",
      "Epoch:  86 Step:   346 /   793 Train loss: 0.02746817\r\n",
      "Epoch:  86 Step:   347 /   793 Train loss: 0.02125288\r\n",
      "Epoch:  86 Step:   348 /   793 Train loss: 0.02148303\r\n",
      "Epoch:  86 Step:   349 /   793 Train loss: 0.02766857\r\n",
      "Epoch:  86 Step:   350 /   793 Train loss: 0.04272825\r\n",
      "Epoch:  86 Step:   351 /   793 Train loss: 0.01947991\r\n",
      "Epoch:  86 Step:   352 /   793 Train loss: 0.01840657\r\n",
      "Epoch:  86 Step:   353 /   793 Train loss: 0.02393145\r\n",
      "Epoch:  86 Step:   354 /   793 Train loss: 0.02022958\r\n",
      "Epoch:  86 Step:   355 /   793 Train loss: 0.02428081\r\n",
      "Epoch:  86 Step:   356 /   793 Train loss: 0.02047137\r\n",
      "Epoch:  86 Step:   357 /   793 Train loss: 0.01971663\r\n",
      "Epoch:  86 Step:   358 /   793 Train loss: 0.02719632\r\n",
      "Epoch:  86 Step:   359 /   793 Train loss: 0.02690380\r\n",
      "Epoch:  86 Step:   360 /   793 Train loss: 0.03739048\r\n",
      "Epoch:  86 Step:   361 /   793 Train loss: 0.02769028\r\n",
      "Epoch:  86 Step:   362 /   793 Train loss: 0.02315190\r\n",
      "Epoch:  86 Step:   363 /   793 Train loss: 0.02514616\r\n",
      "Epoch:  86 Step:   364 /   793 Train loss: 0.03162679\r\n",
      "Epoch:  86 Step:   365 /   793 Train loss: 0.01677842\r\n",
      "Epoch:  86 Step:   366 /   793 Train loss: 0.02040959\r\n",
      "Epoch:  86 Step:   367 /   793 Train loss: 0.02612098\r\n",
      "Epoch:  86 Step:   368 /   793 Train loss: 0.02628011\r\n",
      "Epoch:  86 Step:   369 /   793 Train loss: 0.01079367\r\n",
      "Epoch:  86 Step:   370 /   793 Train loss: 0.02088942\r\n",
      "Epoch:  86 Step:   371 /   793 Train loss: 0.02642684\r\n",
      "Epoch:  86 Step:   372 /   793 Train loss: 0.03370816\r\n",
      "Epoch:  86 Step:   373 /   793 Train loss: 0.03257939\r\n",
      "Epoch:  86 Step:   374 /   793 Train loss: 0.03501258\r\n",
      "Epoch:  86 Step:   375 /   793 Train loss: 0.03218275\r\n",
      "Epoch:  86 Step:   376 /   793 Train loss: 0.03211809\r\n",
      "Epoch:  86 Step:   377 /   793 Train loss: 0.02770337\r\n",
      "Epoch:  86 Step:   378 /   793 Train loss: 0.03793623\r\n",
      "Epoch:  86 Step:   379 /   793 Train loss: 0.02348712\r\n",
      "Epoch:  86 Step:   380 /   793 Train loss: 0.01945225\r\n",
      "Epoch:  86 Step:   381 /   793 Train loss: 0.00925094\r\n",
      "Epoch:  86 Step:   382 /   793 Train loss: 0.02221269\r\n",
      "Epoch:  86 Step:   383 /   793 Train loss: 0.02750906\r\n",
      "Epoch:  86 Step:   384 /   793 Train loss: 0.02203461\r\n",
      "Epoch:  86 Step:   385 /   793 Train loss: 0.02435685\r\n",
      "Epoch:  86 Step:   386 /   793 Train loss: 0.01373916\r\n",
      "Epoch:  86 Step:   387 /   793 Train loss: 0.03073248\r\n",
      "Epoch:  86 Step:   388 /   793 Train loss: 0.02814442\r\n",
      "Epoch:  86 Step:   389 /   793 Train loss: 0.03089610\r\n",
      "Epoch:  86 Step:   390 /   793 Train loss: 0.03034277\r\n",
      "Epoch:  86 Step:   391 /   793 Train loss: 0.02520391\r\n",
      "Epoch:  86 Step:   392 /   793 Train loss: 0.02475105\r\n",
      "Epoch:  86 Step:   393 /   793 Train loss: 0.02027823\r\n",
      "Epoch:  86 Step:   394 /   793 Train loss: 0.02944871\r\n",
      "Epoch:  86 Step:   395 /   793 Train loss: 0.02925835\r\n",
      "Epoch:  86 Step:   396 /   793 Train loss: 0.02273561\r\n",
      "Epoch:  86 Step:   397 /   793 Train loss: 0.01412201\r\n",
      "Epoch:  86 Step:   398 /   793 Train loss: 0.02418837\r\n",
      "Epoch:  86 Step:   399 /   793 Train loss: 0.02041189\r\n",
      "Epoch:  86 Step:   400 /   793 Train loss: 0.02815662\r\n",
      "Epoch:  86 Step:   401 /   793 Train loss: 0.02274995\r\n",
      "Epoch:  86 Step:   402 /   793 Train loss: 0.02825121\r\n",
      "Epoch:  86 Step:   403 /   793 Train loss: 0.02244434\r\n",
      "Epoch:  86 Step:   404 /   793 Train loss: 0.01937385\r\n",
      "Epoch:  86 Step:   405 /   793 Train loss: 0.03044645\r\n",
      "Epoch:  86 Step:   406 /   793 Train loss: 0.02455425\r\n",
      "Epoch:  86 Step:   407 /   793 Train loss: 0.02338102\r\n",
      "Epoch:  86 Step:   408 /   793 Train loss: 0.02752459\r\n",
      "Epoch:  86 Step:   409 /   793 Train loss: 0.00945021\r\n",
      "Epoch:  86 Step:   410 /   793 Train loss: 0.02647691\r\n",
      "Epoch:  86 Step:   411 /   793 Train loss: 0.02568294\r\n",
      "Epoch:  86 Step:   412 /   793 Train loss: 0.02959031\r\n",
      "Epoch:  86 Step:   413 /   793 Train loss: 0.02858699\r\n",
      "Epoch:  86 Step:   414 /   793 Train loss: 0.01924735\r\n",
      "Epoch:  86 Step:   415 /   793 Train loss: 0.02483614\r\n",
      "Epoch:  86 Step:   416 /   793 Train loss: 0.02578407\r\n",
      "Epoch:  86 Step:   417 /   793 Train loss: 0.01590234\r\n",
      "Epoch:  86 Step:   418 /   793 Train loss: 0.04125936\r\n",
      "Epoch:  86 Step:   419 /   793 Train loss: 0.01856629\r\n",
      "Epoch:  86 Step:   420 /   793 Train loss: 0.02430624\r\n",
      "Epoch:  86 Step:   421 /   793 Train loss: 0.01954274\r\n",
      "Epoch:  86 Step:   422 /   793 Train loss: 0.03561332\r\n",
      "Epoch:  86 Step:   423 /   793 Train loss: 0.02796967\r\n",
      "Epoch:  86 Step:   424 /   793 Train loss: 0.01703937\r\n",
      "Epoch:  86 Step:   425 /   793 Train loss: 0.03833367\r\n",
      "Epoch:  86 Step:   426 /   793 Train loss: 0.01582093\r\n",
      "Epoch:  86 Step:   427 /   793 Train loss: 0.02274231\r\n",
      "Epoch:  86 Step:   428 /   793 Train loss: 0.02652271\r\n",
      "Epoch:  86 Step:   429 /   793 Train loss: 0.02399417\r\n",
      "Epoch:  86 Step:   430 /   793 Train loss: 0.02005278\r\n",
      "Epoch:  86 Step:   431 /   793 Train loss: 0.01630120\r\n",
      "Epoch:  86 Step:   432 /   793 Train loss: 0.02192104\r\n",
      "Epoch:  86 Step:   433 /   793 Train loss: 0.02537866\r\n",
      "Epoch:  86 Step:   434 /   793 Train loss: 0.02608781\r\n",
      "Epoch:  86 Step:   435 /   793 Train loss: 0.02304690\r\n",
      "Epoch:  86 Step:   436 /   793 Train loss: 0.02291824\r\n",
      "Epoch:  86 Step:   437 /   793 Train loss: 0.02655558\r\n",
      "Epoch:  86 Step:   438 /   793 Train loss: 0.01546141\r\n",
      "Epoch:  86 Step:   439 /   793 Train loss: 0.02544212\r\n",
      "Epoch:  86 Step:   440 /   793 Train loss: 0.01347841\r\n",
      "Epoch:  86 Step:   441 /   793 Train loss: 0.02977351\r\n",
      "Epoch:  86 Step:   442 /   793 Train loss: 0.02957284\r\n",
      "Epoch:  86 Step:   443 /   793 Train loss: 0.01763151\r\n",
      "Epoch:  86 Step:   444 /   793 Train loss: 0.01354599\r\n",
      "Epoch:  86 Step:   445 /   793 Train loss: 0.02277063\r\n",
      "Epoch:  86 Step:   446 /   793 Train loss: 0.02071675\r\n",
      "Epoch:  86 Step:   447 /   793 Train loss: 0.02428762\r\n",
      "Epoch:  86 Step:   448 /   793 Train loss: 0.03016942\r\n",
      "Epoch:  86 Step:   449 /   793 Train loss: 0.01980140\r\n",
      "Epoch:  86 Step:   450 /   793 Train loss: 0.02440194\r\n",
      "Epoch:  86 Step:   451 /   793 Train loss: 0.02330216\r\n",
      "Epoch:  86 Step:   452 /   793 Train loss: 0.02036108\r\n",
      "Epoch:  86 Step:   453 /   793 Train loss: 0.03991754\r\n",
      "Epoch:  86 Step:   454 /   793 Train loss: 0.03185086\r\n",
      "Epoch:  86 Step:   455 /   793 Train loss: 0.03219702\r\n",
      "Epoch:  86 Step:   456 /   793 Train loss: 0.02988584\r\n",
      "Epoch:  86 Step:   457 /   793 Train loss: 0.02578636\r\n",
      "Epoch:  86 Step:   458 /   793 Train loss: 0.02002178\r\n",
      "Epoch:  86 Step:   459 /   793 Train loss: 0.02788647\r\n",
      "Epoch:  86 Step:   460 /   793 Train loss: 0.02206344\r\n",
      "Epoch:  86 Step:   461 /   793 Train loss: 0.02176654\r\n",
      "Epoch:  86 Step:   462 /   793 Train loss: 0.01300086\r\n",
      "Epoch:  86 Step:   463 /   793 Train loss: 0.02423744\r\n",
      "Epoch:  86 Step:   464 /   793 Train loss: 0.02415441\r\n",
      "Epoch:  86 Step:   465 /   793 Train loss: 0.02908142\r\n",
      "Epoch:  86 Step:   466 /   793 Train loss: 0.00793393\r\n",
      "Epoch:  86 Step:   467 /   793 Train loss: 0.02730499\r\n",
      "Epoch:  86 Step:   468 /   793 Train loss: 0.01422491\r\n",
      "Epoch:  86 Step:   469 /   793 Train loss: 0.03468737\r\n",
      "Epoch:  86 Step:   470 /   793 Train loss: 0.03224952\r\n",
      "Epoch:  86 Step:   471 /   793 Train loss: 0.03863505\r\n",
      "Epoch:  86 Step:   472 /   793 Train loss: 0.02061347\r\n",
      "Epoch:  86 Step:   473 /   793 Train loss: 0.02219294\r\n",
      "Epoch:  86 Step:   474 /   793 Train loss: 0.03003687\r\n",
      "Epoch:  86 Step:   475 /   793 Train loss: 0.02243455\r\n",
      "Epoch:  86 Step:   476 /   793 Train loss: 0.01963614\r\n",
      "Epoch:  86 Step:   477 /   793 Train loss: 0.02684543\r\n",
      "Epoch:  86 Step:   478 /   793 Train loss: 0.01282513\r\n",
      "Epoch:  86 Step:   479 /   793 Train loss: 0.03300219\r\n",
      "Epoch:  86 Step:   480 /   793 Train loss: 0.02421403\r\n",
      "Epoch:  86 Step:   481 /   793 Train loss: 0.02274900\r\n",
      "Epoch:  86 Step:   482 /   793 Train loss: 0.03061857\r\n",
      "Epoch:  86 Step:   483 /   793 Train loss: 0.02197993\r\n",
      "Epoch:  86 Step:   484 /   793 Train loss: 0.00664788\r\n",
      "Epoch:  86 Step:   485 /   793 Train loss: 0.02120969\r\n",
      "Epoch:  86 Step:   486 /   793 Train loss: 0.03964458\r\n",
      "Epoch:  86 Step:   487 /   793 Train loss: 0.01681367\r\n",
      "Epoch:  86 Step:   488 /   793 Train loss: 0.02246549\r\n",
      "Epoch:  86 Step:   489 /   793 Train loss: 0.01986881\r\n",
      "Epoch:  86 Step:   490 /   793 Train loss: 0.02181572\r\n",
      "Epoch:  86 Step:   491 /   793 Train loss: 0.01608377\r\n",
      "Epoch:  86 Step:   492 /   793 Train loss: 0.01724956\r\n",
      "Epoch:  86 Step:   493 /   793 Train loss: 0.01885901\r\n",
      "Epoch:  86 Step:   494 /   793 Train loss: 0.02522238\r\n",
      "Epoch:  86 Step:   495 /   793 Train loss: 0.03071381\r\n",
      "Epoch:  86 Step:   496 /   793 Train loss: 0.02831957\r\n",
      "Epoch:  86 Step:   497 /   793 Train loss: 0.01480372\r\n",
      "Epoch:  86 Step:   498 /   793 Train loss: 0.01548462\r\n",
      "Epoch:  86 Step:   499 /   793 Train loss: 0.01549493\r\n",
      "Epoch:  86 Step:   500 /   793 Train loss: 0.02623431\r\n",
      "Epoch:  86 Step:   501 /   793 Train loss: 0.01823230\r\n",
      "Epoch:  86 Step:   502 /   793 Train loss: 0.01815493\r\n",
      "Epoch:  86 Step:   503 /   793 Train loss: 0.02608444\r\n",
      "Epoch:  86 Step:   504 /   793 Train loss: 0.02328205\r\n",
      "Epoch:  86 Step:   505 /   793 Train loss: 0.02185759\r\n",
      "Epoch:  86 Step:   506 /   793 Train loss: 0.02734822\r\n",
      "Epoch:  86 Step:   507 /   793 Train loss: 0.02292578\r\n",
      "Epoch:  86 Step:   508 /   793 Train loss: 0.02792726\r\n",
      "Epoch:  86 Step:   509 /   793 Train loss: 0.02504319\r\n",
      "Epoch:  86 Step:   510 /   793 Train loss: 0.01086563\r\n",
      "Epoch:  86 Step:   511 /   793 Train loss: 0.02628697\r\n",
      "Epoch:  86 Step:   512 /   793 Train loss: 0.01965114\r\n",
      "Epoch:  86 Step:   513 /   793 Train loss: 0.02043487\r\n",
      "Epoch:  86 Step:   514 /   793 Train loss: 0.02850123\r\n",
      "Epoch:  86 Step:   515 /   793 Train loss: 0.01977168\r\n",
      "Epoch:  86 Step:   516 /   793 Train loss: 0.03092773\r\n",
      "Epoch:  86 Step:   517 /   793 Train loss: 0.02124862\r\n",
      "Epoch:  86 Step:   518 /   793 Train loss: 0.02555528\r\n",
      "Epoch:  86 Step:   519 /   793 Train loss: 0.03152893\r\n",
      "Epoch:  86 Step:   520 /   793 Train loss: 0.02474454\r\n",
      "Epoch:  86 Step:   521 /   793 Train loss: 0.01919340\r\n",
      "Epoch:  86 Step:   522 /   793 Train loss: 0.02556357\r\n",
      "Epoch:  86 Step:   523 /   793 Train loss: 0.02007899\r\n",
      "Epoch:  86 Step:   524 /   793 Train loss: 0.02361904\r\n",
      "Epoch:  86 Step:   525 /   793 Train loss: 0.01858085\r\n",
      "Epoch:  86 Step:   526 /   793 Train loss: 0.03233698\r\n",
      "Epoch:  86 Step:   527 /   793 Train loss: 0.03358556\r\n",
      "Epoch:  86 Step:   528 /   793 Train loss: 0.03492563\r\n",
      "Epoch:  86 Step:   529 /   793 Train loss: 0.02350263\r\n",
      "Epoch:  86 Step:   530 /   793 Train loss: 0.02241543\r\n",
      "Epoch:  86 Step:   531 /   793 Train loss: 0.02631679\r\n",
      "Epoch:  86 Step:   532 /   793 Train loss: 0.02894712\r\n",
      "Epoch:  86 Step:   533 /   793 Train loss: 0.03112685\r\n",
      "Epoch:  86 Step:   534 /   793 Train loss: 0.01685565\r\n",
      "Epoch:  86 Step:   535 /   793 Train loss: 0.01852199\r\n",
      "Epoch:  86 Step:   536 /   793 Train loss: 0.02354409\r\n",
      "Epoch:  86 Step:   537 /   793 Train loss: 0.01398226\r\n",
      "Epoch:  86 Step:   538 /   793 Train loss: 0.02086530\r\n",
      "Epoch:  86 Step:   539 /   793 Train loss: 0.04042298\r\n",
      "Epoch:  86 Step:   540 /   793 Train loss: 0.02502476\r\n",
      "Epoch:  86 Step:   541 /   793 Train loss: 0.02443228\r\n",
      "Epoch:  86 Step:   542 /   793 Train loss: 0.02714155\r\n",
      "Epoch:  86 Step:   543 /   793 Train loss: 0.02443339\r\n",
      "Epoch:  86 Step:   544 /   793 Train loss: 0.01466787\r\n",
      "Epoch:  86 Step:   545 /   793 Train loss: 0.02526136\r\n",
      "Epoch:  86 Step:   546 /   793 Train loss: 0.02436746\r\n",
      "Epoch:  86 Step:   547 /   793 Train loss: 0.03238610\r\n",
      "Epoch:  86 Step:   548 /   793 Train loss: 0.03026183\r\n",
      "Epoch:  86 Step:   549 /   793 Train loss: 0.01987196\r\n",
      "Epoch:  86 Step:   550 /   793 Train loss: 0.01651679\r\n",
      "Epoch:  86 Step:   551 /   793 Train loss: 0.02931510\r\n",
      "Epoch:  86 Step:   552 /   793 Train loss: 0.02109865\r\n",
      "Epoch:  86 Step:   553 /   793 Train loss: 0.01058354\r\n",
      "Epoch:  86 Step:   554 /   793 Train loss: 0.01858649\r\n",
      "Epoch:  86 Step:   555 /   793 Train loss: 0.02101845\r\n",
      "Epoch:  86 Step:   556 /   793 Train loss: 0.02895351\r\n",
      "Epoch:  86 Step:   557 /   793 Train loss: 0.02508158\r\n",
      "Epoch:  86 Step:   558 /   793 Train loss: 0.01748056\r\n",
      "Epoch:  86 Step:   559 /   793 Train loss: 0.02280239\r\n",
      "Epoch:  86 Step:   560 /   793 Train loss: 0.03833189\r\n",
      "Epoch:  86 Step:   561 /   793 Train loss: 0.02268901\r\n",
      "Epoch:  86 Step:   562 /   793 Train loss: 0.03495395\r\n",
      "Epoch:  86 Step:   563 /   793 Train loss: 0.02506730\r\n",
      "Epoch:  86 Step:   564 /   793 Train loss: 0.04177974\r\n",
      "Epoch:  86 Step:   565 /   793 Train loss: 0.01234797\r\n",
      "Epoch:  86 Step:   566 /   793 Train loss: 0.02251683\r\n",
      "Epoch:  86 Step:   567 /   793 Train loss: 0.01444472\r\n",
      "Epoch:  86 Step:   568 /   793 Train loss: 0.02359694\r\n",
      "Epoch:  86 Step:   569 /   793 Train loss: 0.02556568\r\n",
      "Epoch:  86 Step:   570 /   793 Train loss: 0.03022708\r\n",
      "Epoch:  86 Step:   571 /   793 Train loss: 0.02052419\r\n",
      "Epoch:  86 Step:   572 /   793 Train loss: 0.02230624\r\n",
      "Epoch:  86 Step:   573 /   793 Train loss: 0.01420671\r\n",
      "Epoch:  86 Step:   574 /   793 Train loss: 0.02653132\r\n",
      "Epoch:  86 Step:   575 /   793 Train loss: 0.03181316\r\n",
      "Epoch:  86 Step:   576 /   793 Train loss: 0.02701592\r\n",
      "Epoch:  86 Step:   577 /   793 Train loss: 0.01608694\r\n",
      "Epoch:  86 Step:   578 /   793 Train loss: 0.02095607\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  86 Step:   579 /   793 Train loss: 0.01716506\r\n",
      "Epoch:  86 Step:   580 /   793 Train loss: 0.01928953\r\n",
      "Epoch:  86 Step:   581 /   793 Train loss: 0.01982124\r\n",
      "Epoch:  86 Step:   582 /   793 Train loss: 0.02682181\r\n",
      "Epoch:  86 Step:   583 /   793 Train loss: 0.01766757\r\n",
      "Epoch:  86 Step:   584 /   793 Train loss: 0.01668501\r\n",
      "Epoch:  86 Step:   585 /   793 Train loss: 0.03699366\r\n",
      "Epoch:  86 Step:   586 /   793 Train loss: 0.02641969\r\n",
      "Epoch:  86 Step:   587 /   793 Train loss: 0.03426285\r\n",
      "Epoch:  86 Step:   588 /   793 Train loss: 0.02537876\r\n",
      "Epoch:  86 Step:   589 /   793 Train loss: 0.01926550\r\n",
      "Epoch:  86 Step:   590 /   793 Train loss: 0.03113928\r\n",
      "Epoch:  86 Step:   591 /   793 Train loss: 0.02046060\r\n",
      "Epoch:  86 Step:   592 /   793 Train loss: 0.01763410\r\n",
      "Epoch:  86 Step:   593 /   793 Train loss: 0.01787084\r\n",
      "Epoch:  86 Step:   594 /   793 Train loss: 0.02811762\r\n",
      "Epoch:  86 Step:   595 /   793 Train loss: 0.02078131\r\n",
      "Epoch:  86 Step:   596 /   793 Train loss: 0.01432015\r\n",
      "Epoch:  86 Step:   597 /   793 Train loss: 0.02247244\r\n",
      "Epoch:  86 Step:   598 /   793 Train loss: 0.01161699\r\n",
      "Epoch:  86 Step:   599 /   793 Train loss: 0.03415531\r\n",
      "Epoch:  86 Step:   600 /   793 Train loss: 0.01650875\r\n",
      "Epoch:  86 Step:   601 /   793 Train loss: 0.04385687\r\n",
      "Epoch:  86 Step:   602 /   793 Train loss: 0.01725315\r\n",
      "Epoch:  86 Step:   603 /   793 Train loss: 0.02416284\r\n",
      "Epoch:  86 Step:   604 /   793 Train loss: 0.01604425\r\n",
      "Epoch:  86 Step:   605 /   793 Train loss: 0.02011884\r\n",
      "Epoch:  86 Step:   606 /   793 Train loss: 0.02675905\r\n",
      "Epoch:  86 Step:   607 /   793 Train loss: 0.01113641\r\n",
      "Epoch:  86 Step:   608 /   793 Train loss: 0.01724853\r\n",
      "Epoch:  86 Step:   609 /   793 Train loss: 0.01210207\r\n",
      "Epoch:  86 Step:   610 /   793 Train loss: 0.01519888\r\n",
      "Epoch:  86 Step:   611 /   793 Train loss: 0.02693631\r\n",
      "Epoch:  86 Step:   612 /   793 Train loss: 0.01801073\r\n",
      "Epoch:  86 Step:   613 /   793 Train loss: 0.02004442\r\n",
      "Epoch:  86 Step:   614 /   793 Train loss: 0.01609201\r\n",
      "Epoch:  86 Step:   615 /   793 Train loss: 0.01578803\r\n",
      "Epoch:  86 Step:   616 /   793 Train loss: 0.02338581\r\n",
      "Epoch:  86 Step:   617 /   793 Train loss: 0.02297285\r\n",
      "Epoch:  86 Step:   618 /   793 Train loss: 0.01490457\r\n",
      "Epoch:  86 Step:   619 /   793 Train loss: 0.01896339\r\n",
      "Epoch:  86 Step:   620 /   793 Train loss: 0.02973127\r\n",
      "Epoch:  86 Step:   621 /   793 Train loss: 0.03795692\r\n",
      "Epoch:  86 Step:   622 /   793 Train loss: 0.02099269\r\n",
      "Epoch:  86 Step:   623 /   793 Train loss: 0.02800455\r\n",
      "Epoch:  86 Step:   624 /   793 Train loss: 0.02010408\r\n",
      "Epoch:  86 Step:   625 /   793 Train loss: 0.02797217\r\n",
      "Epoch:  86 Step:   626 /   793 Train loss: 0.01549003\r\n",
      "Epoch:  86 Step:   627 /   793 Train loss: 0.02876323\r\n",
      "Epoch:  86 Step:   628 /   793 Train loss: 0.02693811\r\n",
      "Epoch:  86 Step:   629 /   793 Train loss: 0.01087091\r\n",
      "Epoch:  86 Step:   630 /   793 Train loss: 0.02884951\r\n",
      "Epoch:  86 Step:   631 /   793 Train loss: 0.02469688\r\n",
      "Epoch:  86 Step:   632 /   793 Train loss: 0.02012575\r\n",
      "Epoch:  86 Step:   633 /   793 Train loss: 0.02661895\r\n",
      "Epoch:  86 Step:   634 /   793 Train loss: 0.01249636\r\n",
      "Epoch:  86 Step:   635 /   793 Train loss: 0.03557275\r\n",
      "Epoch:  86 Step:   636 /   793 Train loss: 0.03365847\r\n",
      "Epoch:  86 Step:   637 /   793 Train loss: 0.01897076\r\n",
      "Epoch:  86 Step:   638 /   793 Train loss: 0.02837687\r\n",
      "Epoch:  86 Step:   639 /   793 Train loss: 0.02830588\r\n",
      "Epoch:  86 Step:   640 /   793 Train loss: 0.02688883\r\n",
      "Epoch:  86 Step:   641 /   793 Train loss: 0.01645866\r\n",
      "Epoch:  86 Step:   642 /   793 Train loss: 0.02227831\r\n",
      "Epoch:  86 Step:   643 /   793 Train loss: 0.01427386\r\n",
      "Epoch:  86 Step:   644 /   793 Train loss: 0.02700775\r\n",
      "Epoch:  86 Step:   645 /   793 Train loss: 0.01733575\r\n",
      "Epoch:  86 Step:   646 /   793 Train loss: 0.01846357\r\n",
      "Epoch:  86 Step:   647 /   793 Train loss: 0.02164226\r\n",
      "Epoch:  86 Step:   648 /   793 Train loss: 0.03240715\r\n",
      "Epoch:  86 Step:   649 /   793 Train loss: 0.02408113\r\n",
      "Epoch:  86 Step:   650 /   793 Train loss: 0.02143800\r\n",
      "Epoch:  86 Step:   651 /   793 Train loss: 0.02681117\r\n",
      "Epoch:  86 Step:   652 /   793 Train loss: 0.02310154\r\n",
      "Epoch:  86 Step:   653 /   793 Train loss: 0.02824694\r\n",
      "Epoch:  86 Step:   654 /   793 Train loss: 0.02242800\r\n",
      "Epoch:  86 Step:   655 /   793 Train loss: 0.01806016\r\n",
      "Epoch:  86 Step:   656 /   793 Train loss: 0.04418005\r\n",
      "Epoch:  86 Step:   657 /   793 Train loss: 0.03570016\r\n",
      "Epoch:  86 Step:   658 /   793 Train loss: 0.02171312\r\n",
      "Epoch:  86 Step:   659 /   793 Train loss: 0.03166590\r\n",
      "Epoch:  86 Step:   660 /   793 Train loss: 0.03041709\r\n",
      "Epoch:  86 Step:   661 /   793 Train loss: 0.01740003\r\n",
      "Epoch:  86 Step:   662 /   793 Train loss: 0.01954730\r\n",
      "Epoch:  86 Step:   663 /   793 Train loss: 0.02845101\r\n",
      "Epoch:  86 Step:   664 /   793 Train loss: 0.02485346\r\n",
      "Epoch:  86 Step:   665 /   793 Train loss: 0.02090750\r\n",
      "Epoch:  86 Step:   666 /   793 Train loss: 0.03157851\r\n",
      "Epoch:  86 Step:   667 /   793 Train loss: 0.02162733\r\n",
      "Epoch:  86 Step:   668 /   793 Train loss: 0.02473667\r\n",
      "Epoch:  86 Step:   669 /   793 Train loss: 0.02770249\r\n",
      "Epoch:  86 Step:   670 /   793 Train loss: 0.02089963\r\n",
      "Epoch:  86 Step:   671 /   793 Train loss: 0.02327988\r\n",
      "Epoch:  86 Step:   672 /   793 Train loss: 0.03552666\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  86 Step:   673 /   793 Train loss: 0.01783510\r\n",
      "Epoch:  86 Step:   674 /   793 Train loss: 0.03121104\r\n",
      "Epoch:  86 Step:   675 /   793 Train loss: 0.01563459\r\n",
      "Epoch:  86 Step:   676 /   793 Train loss: 0.03699620\r\n",
      "Epoch:  86 Step:   677 /   793 Train loss: 0.02641083\r\n",
      "Epoch:  86 Step:   678 /   793 Train loss: 0.02606188\r\n",
      "Epoch:  86 Step:   679 /   793 Train loss: 0.03219232\r\n",
      "Epoch:  86 Step:   680 /   793 Train loss: 0.02366212\r\n",
      "Epoch:  86 Step:   681 /   793 Train loss: 0.03895075\r\n",
      "Epoch:  86 Step:   682 /   793 Train loss: 0.01755967\r\n",
      "Epoch:  86 Step:   683 /   793 Train loss: 0.04139191\r\n",
      "Epoch:  86 Step:   684 /   793 Train loss: 0.03456930\r\n",
      "Epoch:  86 Step:   685 /   793 Train loss: 0.01645736\r\n",
      "Epoch:  86 Step:   686 /   793 Train loss: 0.01807325\r\n",
      "Epoch:  86 Step:   687 /   793 Train loss: 0.01450083\r\n",
      "Epoch:  86 Step:   688 /   793 Train loss: 0.01884015\r\n",
      "Epoch:  86 Step:   689 /   793 Train loss: 0.02144815\r\n",
      "Epoch:  86 Step:   690 /   793 Train loss: 0.02941516\r\n",
      "Epoch:  86 Step:   691 /   793 Train loss: 0.01634539\r\n",
      "Epoch:  86 Step:   692 /   793 Train loss: 0.02267842\r\n",
      "Epoch:  86 Step:   693 /   793 Train loss: 0.02318078\r\n",
      "Epoch:  86 Step:   694 /   793 Train loss: 0.02465129\r\n",
      "Epoch:  86 Step:   695 /   793 Train loss: 0.02147687\r\n",
      "Epoch:  86 Step:   696 /   793 Train loss: 0.01507604\r\n",
      "Epoch:  86 Step:   697 /   793 Train loss: 0.02290984\r\n",
      "Epoch:  86 Step:   698 /   793 Train loss: 0.01976482\r\n",
      "Epoch:  86 Step:   699 /   793 Train loss: 0.02232912\r\n",
      "Epoch:  86 Step:   700 /   793 Train loss: 0.02114065\r\n",
      "Epoch:  86 Step:   701 /   793 Train loss: 0.01860107\r\n",
      "Epoch:  86 Step:   702 /   793 Train loss: 0.02323156\r\n",
      "Epoch:  86 Step:   703 /   793 Train loss: 0.02024616\r\n",
      "Epoch:  86 Step:   704 /   793 Train loss: 0.01334231\r\n",
      "Epoch:  86 Step:   705 /   793 Train loss: 0.03151934\r\n",
      "Epoch:  86 Step:   706 /   793 Train loss: 0.02453199\r\n",
      "Epoch:  86 Step:   707 /   793 Train loss: 0.02404376\r\n",
      "Epoch:  86 Step:   708 /   793 Train loss: 0.02755142\r\n",
      "Epoch:  86 Step:   709 /   793 Train loss: 0.02057408\r\n",
      "Epoch:  86 Step:   710 /   793 Train loss: 0.02007105\r\n",
      "Epoch:  86 Step:   711 /   793 Train loss: 0.02999798\r\n",
      "Epoch:  86 Step:   712 /   793 Train loss: 0.02523411\r\n",
      "Epoch:  86 Step:   713 /   793 Train loss: 0.02224963\r\n",
      "Epoch:  86 Step:   714 /   793 Train loss: 0.03275440\r\n",
      "Epoch:  86 Step:   715 /   793 Train loss: 0.01861364\r\n",
      "Epoch:  86 Step:   716 /   793 Train loss: 0.01465027\r\n",
      "Epoch:  86 Step:   717 /   793 Train loss: 0.01942992\r\n",
      "Epoch:  86 Step:   718 /   793 Train loss: 0.02240814\r\n",
      "Epoch:  86 Step:   719 /   793 Train loss: 0.02596768\r\n",
      "Epoch:  86 Step:   720 /   793 Train loss: 0.03209839\r\n",
      "Epoch:  86 Step:   721 /   793 Train loss: 0.02196901\r\n",
      "Epoch:  86 Step:   722 /   793 Train loss: 0.02774357\r\n",
      "Epoch:  86 Step:   723 /   793 Train loss: 0.03614444\r\n",
      "Epoch:  86 Step:   724 /   793 Train loss: 0.02267804\r\n",
      "Epoch:  86 Step:   725 /   793 Train loss: 0.02135150\r\n",
      "Epoch:  86 Step:   726 /   793 Train loss: 0.03171723\r\n",
      "Epoch:  86 Step:   727 /   793 Train loss: 0.01236083\r\n",
      "Epoch:  86 Step:   728 /   793 Train loss: 0.01966528\r\n",
      "Epoch:  86 Step:   729 /   793 Train loss: 0.02201290\r\n",
      "Epoch:  86 Step:   730 /   793 Train loss: 0.01419243\r\n",
      "Epoch:  86 Step:   731 /   793 Train loss: 0.01593602\r\n",
      "Epoch:  86 Step:   732 /   793 Train loss: 0.02575327\r\n",
      "Epoch:  86 Step:   733 /   793 Train loss: 0.04038770\r\n",
      "Epoch:  86 Step:   734 /   793 Train loss: 0.03370862\r\n",
      "Epoch:  86 Step:   735 /   793 Train loss: 0.01486801\r\n",
      "Epoch:  86 Step:   736 /   793 Train loss: 0.01803191\r\n",
      "Epoch:  86 Step:   737 /   793 Train loss: 0.01929362\r\n",
      "Epoch:  86 Step:   738 /   793 Train loss: 0.01726324\r\n",
      "Epoch:  86 Step:   739 /   793 Train loss: 0.00909011\r\n",
      "Epoch:  86 Step:   740 /   793 Train loss: 0.02171465\r\n",
      "Epoch:  86 Step:   741 /   793 Train loss: 0.02265672\r\n",
      "Epoch:  86 Step:   742 /   793 Train loss: 0.04413223\r\n",
      "Epoch:  86 Step:   743 /   793 Train loss: 0.01894286\r\n",
      "Epoch:  86 Step:   744 /   793 Train loss: 0.02314128\r\n",
      "Epoch:  86 Step:   745 /   793 Train loss: 0.03008283\r\n",
      "Epoch:  86 Step:   746 /   793 Train loss: 0.02468373\r\n",
      "Epoch:  86 Step:   747 /   793 Train loss: 0.02126301\r\n",
      "Epoch:  86 Step:   748 /   793 Train loss: 0.02758675\r\n",
      "Epoch:  86 Step:   749 /   793 Train loss: 0.03325232\r\n",
      "Epoch:  86 Step:   750 /   793 Train loss: 0.02346482\r\n",
      "Epoch:  86 Step:   751 /   793 Train loss: 0.01515097\r\n",
      "Epoch:  86 Step:   752 /   793 Train loss: 0.01998825\r\n",
      "Epoch:  86 Step:   753 /   793 Train loss: 0.02045579\r\n",
      "Epoch:  86 Step:   754 /   793 Train loss: 0.02839820\r\n",
      "Epoch:  86 Step:   755 /   793 Train loss: 0.01897032\r\n",
      "Epoch:  86 Step:   756 /   793 Train loss: 0.03012873\r\n",
      "Epoch:  86 Step:   757 /   793 Train loss: 0.01702492\r\n",
      "Epoch:  86 Step:   758 /   793 Train loss: 0.02523060\r\n",
      "Epoch:  86 Step:   759 /   793 Train loss: 0.01592263\r\n",
      "Epoch:  86 Step:   760 /   793 Train loss: 0.02477600\r\n",
      "Epoch:  86 Step:   761 /   793 Train loss: 0.03043466\r\n",
      "Epoch:  86 Step:   762 /   793 Train loss: 0.01912928\r\n",
      "Epoch:  86 Step:   763 /   793 Train loss: 0.02089926\r\n",
      "Epoch:  86 Step:   764 /   793 Train loss: 0.03087769\r\n",
      "Epoch:  86 Step:   765 /   793 Train loss: 0.03685577\r\n",
      "Epoch:  86 Step:   766 /   793 Train loss: 0.01708069\r\n",
      "Epoch:  86 Step:   767 /   793 Train loss: 0.01966351\r\n",
      "Epoch:  86 Step:   768 /   793 Train loss: 0.02524966\r\n",
      "Epoch:  86 Step:   769 /   793 Train loss: 0.01415194\r\n",
      "Epoch:  86 Step:   770 /   793 Train loss: 0.02918073\r\n",
      "Epoch:  86 Step:   771 /   793 Train loss: 0.01916438\r\n",
      "Epoch:  86 Step:   772 /   793 Train loss: 0.01549473\r\n",
      "Epoch:  86 Step:   773 /   793 Train loss: 0.02745798\r\n",
      "Epoch:  86 Step:   774 /   793 Train loss: 0.03210160\r\n",
      "Epoch:  86 Step:   775 /   793 Train loss: 0.04091492\r\n",
      "Epoch:  86 Step:   776 /   793 Train loss: 0.02913356\r\n",
      "Epoch:  86 Step:   777 /   793 Train loss: 0.02332332\r\n",
      "Epoch:  86 Step:   778 /   793 Train loss: 0.03310043\r\n",
      "Epoch:  86 Step:   779 /   793 Train loss: 0.01940897\r\n",
      "Epoch:  86 Step:   780 /   793 Train loss: 0.02758504\r\n",
      "Epoch:  86 Step:   781 /   793 Train loss: 0.02901337\r\n",
      "Epoch:  86 Step:   782 /   793 Train loss: 0.03045124\r\n",
      "Epoch:  86 Step:   783 /   793 Train loss: 0.03107013\r\n",
      "Epoch:  86 Step:   784 /   793 Train loss: 0.03039199\r\n",
      "Epoch:  86 Step:   785 /   793 Train loss: 0.02200044\r\n",
      "Epoch:  86 Step:   786 /   793 Train loss: 0.03277038\r\n",
      "Epoch:  86 Step:   787 /   793 Train loss: 0.02637913\r\n",
      "Epoch:  86 Step:   788 /   793 Train loss: 0.02742512\r\n",
      "Epoch:  86 Step:   789 /   793 Train loss: 0.01934522\r\n",
      "Epoch:  86 Step:   790 /   793 Train loss: 0.02382765\r\n",
      "Epoch:  86 Step:   791 /   793 Train loss: 0.01158508\r\n",
      "Epoch:  86 Step:   792 /   793 Train loss: 0.03755904\r\n",
      "Epoch:  87 Step:     0 /   793 Train loss: 0.02668466\r\n",
      "Epoch:  87 Step:     1 /   793 Train loss: 0.02399751\r\n",
      "Epoch:  87 Step:     2 /   793 Train loss: 0.02051060\r\n",
      "Epoch:  87 Step:     3 /   793 Train loss: 0.02505718\r\n",
      "Epoch:  87 Step:     4 /   793 Train loss: 0.02560540\r\n",
      "Epoch:  87 Step:     5 /   793 Train loss: 0.02917171\r\n",
      "Epoch:  87 Step:     6 /   793 Train loss: 0.02008484\r\n",
      "Epoch:  87 Step:     7 /   793 Train loss: 0.01935545\r\n",
      "Epoch:  87 Step:     8 /   793 Train loss: 0.02299490\r\n",
      "Epoch:  87 Step:     9 /   793 Train loss: 0.02274820\r\n",
      "Epoch:  87 Step:    10 /   793 Train loss: 0.01851196\r\n",
      "Epoch:  87 Step:    11 /   793 Train loss: 0.02420482\r\n",
      "Epoch:  87 Step:    12 /   793 Train loss: 0.02694784\r\n",
      "Epoch:  87 Step:    13 /   793 Train loss: 0.02677393\r\n",
      "Epoch:  87 Step:    14 /   793 Train loss: 0.02196350\r\n",
      "Epoch:  87 Step:    15 /   793 Train loss: 0.04038530\r\n",
      "Epoch:  87 Step:    16 /   793 Train loss: 0.02009835\r\n",
      "Epoch:  87 Step:    17 /   793 Train loss: 0.01583570\r\n",
      "Epoch:  87 Step:    18 /   793 Train loss: 0.01971730\r\n",
      "Epoch:  87 Step:    19 /   793 Train loss: 0.02959305\r\n",
      "Epoch:  87 Step:    20 /   793 Train loss: 0.02262188\r\n",
      "Epoch:  87 Step:    21 /   793 Train loss: 0.03265131\r\n",
      "Epoch:  87 Step:    22 /   793 Train loss: 0.02977940\r\n",
      "Epoch:  87 Step:    23 /   793 Train loss: 0.02070521\r\n",
      "Epoch:  87 Step:    24 /   793 Train loss: 0.03034150\r\n",
      "Epoch:  87 Step:    25 /   793 Train loss: 0.02605386\r\n",
      "Epoch:  87 Step:    26 /   793 Train loss: 0.02290851\r\n",
      "Epoch:  87 Step:    27 /   793 Train loss: 0.01913021\r\n",
      "Epoch:  87 Step:    28 /   793 Train loss: 0.02168069\r\n",
      "Epoch:  87 Step:    29 /   793 Train loss: 0.01817755\r\n",
      "Epoch:  87 Step:    30 /   793 Train loss: 0.02826426\r\n",
      "Epoch:  87 Step:    31 /   793 Train loss: 0.02536449\r\n",
      "Epoch:  87 Step:    32 /   793 Train loss: 0.02329127\r\n",
      "Epoch:  87 Step:    33 /   793 Train loss: 0.02062077\r\n",
      "Epoch:  87 Step:    34 /   793 Train loss: 0.02543779\r\n",
      "Epoch:  87 Step:    35 /   793 Train loss: 0.02746701\r\n",
      "Epoch:  87 Step:    36 /   793 Train loss: 0.02558735\r\n",
      "Epoch:  87 Step:    37 /   793 Train loss: 0.02426201\r\n",
      "Epoch:  87 Step:    38 /   793 Train loss: 0.02373089\r\n",
      "Epoch:  87 Step:    39 /   793 Train loss: 0.02908042\r\n",
      "Epoch:  87 Step:    40 /   793 Train loss: 0.01844496\r\n",
      "Epoch:  87 Step:    41 /   793 Train loss: 0.02805422\r\n",
      "Epoch:  87 Step:    42 /   793 Train loss: 0.01663365\r\n",
      "Epoch:  87 Step:    43 /   793 Train loss: 0.02454820\r\n",
      "Epoch:  87 Step:    44 /   793 Train loss: 0.02407719\r\n",
      "Epoch:  87 Step:    45 /   793 Train loss: 0.02675312\r\n",
      "Epoch:  87 Step:    46 /   793 Train loss: 0.02660820\r\n",
      "Epoch:  87 Step:    47 /   793 Train loss: 0.02886911\r\n",
      "Epoch:  87 Step:    48 /   793 Train loss: 0.02177516\r\n",
      "Epoch:  87 Step:    49 /   793 Train loss: 0.02536926\r\n",
      "Epoch:  87 Step:    50 /   793 Train loss: 0.01472571\r\n",
      "Epoch:  87 Step:    51 /   793 Train loss: 0.03472891\r\n",
      "Epoch:  87 Step:    52 /   793 Train loss: 0.02465948\r\n",
      "Epoch:  87 Step:    53 /   793 Train loss: 0.02560330\r\n",
      "Epoch:  87 Step:    54 /   793 Train loss: 0.03146332\r\n",
      "Epoch:  87 Step:    55 /   793 Train loss: 0.02653603\r\n",
      "Epoch:  87 Step:    56 /   793 Train loss: 0.02992104\r\n",
      "Epoch:  87 Step:    57 /   793 Train loss: 0.03168726\r\n",
      "Epoch:  87 Step:    58 /   793 Train loss: 0.03427644\r\n",
      "Epoch:  87 Step:    59 /   793 Train loss: 0.01456082\r\n",
      "Epoch:  87 Step:    60 /   793 Train loss: 0.01476046\r\n",
      "Epoch:  87 Step:    61 /   793 Train loss: 0.02394243\r\n",
      "Epoch:  87 Step:    62 /   793 Train loss: 0.01916606\r\n",
      "Epoch:  87 Step:    63 /   793 Train loss: 0.02842531\r\n",
      "Epoch:  87 Step:    64 /   793 Train loss: 0.02892160\r\n",
      "Epoch:  87 Step:    65 /   793 Train loss: 0.03345264\r\n",
      "Epoch:  87 Step:    66 /   793 Train loss: 0.02861803\r\n",
      "Epoch:  87 Step:    67 /   793 Train loss: 0.02334407\r\n",
      "Epoch:  87 Step:    68 /   793 Train loss: 0.01914636\r\n",
      "Epoch:  87 Step:    69 /   793 Train loss: 0.02020174\r\n",
      "Epoch:  87 Step:    70 /   793 Train loss: 0.01758023\r\n",
      "Epoch:  87 Step:    71 /   793 Train loss: 0.02457734\r\n",
      "Epoch:  87 Step:    72 /   793 Train loss: 0.01890472\r\n",
      "Epoch:  87 Step:    73 /   793 Train loss: 0.01433377\r\n",
      "Epoch:  87 Step:    74 /   793 Train loss: 0.01198689\r\n",
      "Epoch:  87 Step:    75 /   793 Train loss: 0.02092972\r\n",
      "Epoch:  87 Step:    76 /   793 Train loss: 0.01753306\r\n",
      "Epoch:  87 Step:    77 /   793 Train loss: 0.02869470\r\n",
      "Epoch:  87 Step:    78 /   793 Train loss: 0.02577831\r\n",
      "Epoch:  87 Step:    79 /   793 Train loss: 0.01324021\r\n",
      "Epoch:  87 Step:    80 /   793 Train loss: 0.01791629\r\n",
      "Epoch:  87 Step:    81 /   793 Train loss: 0.02339968\r\n",
      "Epoch:  87 Step:    82 /   793 Train loss: 0.02111642\r\n",
      "Epoch:  87 Step:    83 /   793 Train loss: 0.03386767\r\n",
      "Epoch:  87 Step:    84 /   793 Train loss: 0.03138873\r\n",
      "Epoch:  87 Step:    85 /   793 Train loss: 0.02602984\r\n",
      "Epoch:  87 Step:    86 /   793 Train loss: 0.03092965\r\n",
      "Epoch:  87 Step:    87 /   793 Train loss: 0.04275019\r\n",
      "Epoch:  87 Step:    88 /   793 Train loss: 0.03276643\r\n",
      "Epoch:  87 Step:    89 /   793 Train loss: 0.02603815\r\n",
      "Epoch:  87 Step:    90 /   793 Train loss: 0.03090850\r\n",
      "Epoch:  87 Step:    91 /   793 Train loss: 0.03373110\r\n",
      "Epoch:  87 Step:    92 /   793 Train loss: 0.02705152\r\n",
      "Epoch:  87 Step:    93 /   793 Train loss: 0.02890064\r\n",
      "Epoch:  87 Step:    94 /   793 Train loss: 0.02281972\r\n",
      "Epoch:  87 Step:    95 /   793 Train loss: 0.01758247\r\n",
      "Epoch:  87 Step:    96 /   793 Train loss: 0.02116317\r\n",
      "Epoch:  87 Step:    97 /   793 Train loss: 0.01896389\r\n",
      "Epoch:  87 Step:    98 /   793 Train loss: 0.03379696\r\n",
      "Epoch:  87 Step:    99 /   793 Train loss: 0.01561044\r\n",
      "Epoch:  87 Step:   100 /   793 Train loss: 0.02980393\r\n",
      "Epoch:  87 Step:   101 /   793 Train loss: 0.01981257\r\n",
      "Epoch:  87 Step:   102 /   793 Train loss: 0.02139760\r\n",
      "Epoch:  87 Step:   103 /   793 Train loss: 0.02762289\r\n",
      "Epoch:  87 Step:   104 /   793 Train loss: 0.02894732\r\n",
      "Epoch:  87 Step:   105 /   793 Train loss: 0.02948570\r\n",
      "Epoch:  87 Step:   106 /   793 Train loss: 0.03335632\r\n",
      "Epoch:  87 Step:   107 /   793 Train loss: 0.02394396\r\n",
      "Epoch:  87 Step:   108 /   793 Train loss: 0.03266408\r\n",
      "Epoch:  87 Step:   109 /   793 Train loss: 0.02802188\r\n",
      "Epoch:  87 Step:   110 /   793 Train loss: 0.02022053\r\n",
      "Epoch:  87 Step:   111 /   793 Train loss: 0.02447091\r\n",
      "Epoch:  87 Step:   112 /   793 Train loss: 0.01507381\r\n",
      "Epoch:  87 Step:   113 /   793 Train loss: 0.01190665\r\n",
      "Epoch:  87 Step:   114 /   793 Train loss: 0.01475321\r\n",
      "Epoch:  87 Step:   115 /   793 Train loss: 0.02675324\r\n",
      "Epoch:  87 Step:   116 /   793 Train loss: 0.02744379\r\n",
      "Epoch:  87 Step:   117 /   793 Train loss: 0.01603923\r\n",
      "Epoch:  87 Step:   118 /   793 Train loss: 0.02136693\r\n",
      "Epoch:  87 Step:   119 /   793 Train loss: 0.02724184\r\n",
      "Epoch:  87 Step:   120 /   793 Train loss: 0.02063207\r\n",
      "Epoch:  87 Step:   121 /   793 Train loss: 0.01533429\r\n",
      "Epoch:  87 Step:   122 /   793 Train loss: 0.01441942\r\n",
      "Epoch:  87 Step:   123 /   793 Train loss: 0.01069905\r\n",
      "Epoch:  87 Step:   124 /   793 Train loss: 0.02496122\r\n",
      "Epoch:  87 Step:   125 /   793 Train loss: 0.02108246\r\n",
      "Epoch:  87 Step:   126 /   793 Train loss: 0.02077990\r\n",
      "Epoch:  87 Step:   127 /   793 Train loss: 0.02328731\r\n",
      "Epoch:  87 Step:   128 /   793 Train loss: 0.02943885\r\n",
      "Epoch:  87 Step:   129 /   793 Train loss: 0.02181778\r\n",
      "Epoch:  87 Step:   130 /   793 Train loss: 0.01409375\r\n",
      "Epoch:  87 Step:   131 /   793 Train loss: 0.02743448\r\n",
      "Epoch:  87 Step:   132 /   793 Train loss: 0.03993227\r\n",
      "Epoch:  87 Step:   133 /   793 Train loss: 0.01817148\r\n",
      "Epoch:  87 Step:   134 /   793 Train loss: 0.03317422\r\n",
      "Epoch:  87 Step:   135 /   793 Train loss: 0.02165098\r\n",
      "Epoch:  87 Step:   136 /   793 Train loss: 0.03206217\r\n",
      "Epoch:  87 Step:   137 /   793 Train loss: 0.02063129\r\n",
      "Epoch:  87 Step:   138 /   793 Train loss: 0.02073386\r\n",
      "Epoch:  87 Step:   139 /   793 Train loss: 0.04016552\r\n",
      "Epoch:  87 Step:   140 /   793 Train loss: 0.02534483\r\n",
      "Epoch:  87 Step:   141 /   793 Train loss: 0.01312516\r\n",
      "Epoch:  87 Step:   142 /   793 Train loss: 0.02429361\r\n",
      "Epoch:  87 Step:   143 /   793 Train loss: 0.03237895\r\n",
      "Epoch:  87 Step:   144 /   793 Train loss: 0.02274098\r\n",
      "Epoch:  87 Step:   145 /   793 Train loss: 0.04677956\r\n",
      "Epoch:  87 Step:   146 /   793 Train loss: 0.02832652\r\n",
      "Epoch:  87 Step:   147 /   793 Train loss: 0.01820279\r\n",
      "Epoch:  87 Step:   148 /   793 Train loss: 0.03358345\r\n",
      "Epoch:  87 Step:   149 /   793 Train loss: 0.02442237\r\n",
      "Epoch:  87 Step:   150 /   793 Train loss: 0.03176109\r\n",
      "Epoch:  87 Step:   151 /   793 Train loss: 0.01532139\r\n",
      "Epoch:  87 Step:   152 /   793 Train loss: 0.02790793\r\n",
      "Epoch:  87 Step:   153 /   793 Train loss: 0.01424634\r\n",
      "Epoch:  87 Step:   154 /   793 Train loss: 0.02767969\r\n",
      "Epoch:  87 Step:   155 /   793 Train loss: 0.03187396\r\n",
      "Epoch:  87 Step:   156 /   793 Train loss: 0.01740787\r\n",
      "Epoch:  87 Step:   157 /   793 Train loss: 0.02116816\r\n",
      "Epoch:  87 Step:   158 /   793 Train loss: 0.02442831\r\n",
      "Epoch:  87 Step:   159 /   793 Train loss: 0.02065611\r\n",
      "Epoch:  87 Step:   160 /   793 Train loss: 0.01653882\r\n",
      "Epoch:  87 Step:   161 /   793 Train loss: 0.03371875\r\n",
      "Epoch:  87 Step:   162 /   793 Train loss: 0.01844067\r\n",
      "Epoch:  87 Step:   163 /   793 Train loss: 0.01985570\r\n",
      "Epoch:  87 Step:   164 /   793 Train loss: 0.01803388\r\n",
      "Epoch:  87 Step:   165 /   793 Train loss: 0.03110494\r\n",
      "Epoch:  87 Step:   166 /   793 Train loss: 0.02105736\r\n",
      "Epoch:  87 Step:   167 /   793 Train loss: 0.01456772\r\n",
      "Epoch:  87 Step:   168 /   793 Train loss: 0.02357174\r\n",
      "Epoch:  87 Step:   169 /   793 Train loss: 0.02354729\r\n",
      "Epoch:  87 Step:   170 /   793 Train loss: 0.03202578\r\n",
      "Epoch:  87 Step:   171 /   793 Train loss: 0.01751762\r\n",
      "Epoch:  87 Step:   172 /   793 Train loss: 0.02449371\r\n",
      "Epoch:  87 Step:   173 /   793 Train loss: 0.03061417\r\n",
      "Epoch:  87 Step:   174 /   793 Train loss: 0.01279003\r\n",
      "Epoch:  87 Step:   175 /   793 Train loss: 0.01451165\r\n",
      "Epoch:  87 Step:   176 /   793 Train loss: 0.02591641\r\n",
      "Epoch:  87 Step:   177 /   793 Train loss: 0.02624854\r\n",
      "Epoch:  87 Step:   178 /   793 Train loss: 0.02383077\r\n",
      "Epoch:  87 Step:   179 /   793 Train loss: 0.02287879\r\n",
      "Epoch:  87 Step:   180 /   793 Train loss: 0.02543659\r\n",
      "Epoch:  87 Step:   181 /   793 Train loss: 0.01496426\r\n",
      "Epoch:  87 Step:   182 /   793 Train loss: 0.02344224\r\n",
      "Epoch:  87 Step:   183 /   793 Train loss: 0.03791056\r\n",
      "Epoch:  87 Step:   184 /   793 Train loss: 0.01669263\r\n",
      "Epoch:  87 Step:   185 /   793 Train loss: 0.01583910\r\n",
      "Epoch:  87 Step:   186 /   793 Train loss: 0.02263036\r\n",
      "Epoch:  87 Step:   187 /   793 Train loss: 0.02317431\r\n",
      "Epoch:  87 Step:   188 /   793 Train loss: 0.01486009\r\n",
      "Epoch:  87 Step:   189 /   793 Train loss: 0.02972996\r\n",
      "Epoch:  87 Step:   190 /   793 Train loss: 0.04319150\r\n",
      "Epoch:  87 Step:   191 /   793 Train loss: 0.02645427\r\n",
      "Epoch:  87 Step:   192 /   793 Train loss: 0.02447688\r\n",
      "Epoch:  87 Step:   193 /   793 Train loss: 0.02157161\r\n",
      "Epoch:  87 Step:   194 /   793 Train loss: 0.03667626\r\n",
      "Epoch:  87 Step:   195 /   793 Train loss: 0.03424947\r\n",
      "Epoch:  87 Step:   196 /   793 Train loss: 0.03329168\r\n",
      "Epoch:  87 Step:   197 /   793 Train loss: 0.03454099\r\n",
      "Epoch:  87 Step:   198 /   793 Train loss: 0.01984296\r\n",
      "Epoch:  87 Step:   199 /   793 Train loss: 0.01280242\r\n",
      "Epoch:  87 Step:   200 /   793 Train loss: 0.02742185\r\n",
      "Epoch:  87 Step:   201 /   793 Train loss: 0.01915365\r\n",
      "Epoch:  87 Step:   202 /   793 Train loss: 0.01989822\r\n",
      "Epoch:  87 Step:   203 /   793 Train loss: 0.02484548\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  87 Step:   204 /   793 Train loss: 0.02772416\r\n",
      "Epoch:  87 Step:   205 /   793 Train loss: 0.02710603\r\n",
      "Epoch:  87 Step:   206 /   793 Train loss: 0.03014657\r\n",
      "Epoch:  87 Step:   207 /   793 Train loss: 0.02498783\r\n",
      "Epoch:  87 Step:   208 /   793 Train loss: 0.02384843\r\n",
      "Epoch:  87 Step:   209 /   793 Train loss: 0.02432436\r\n",
      "Epoch:  87 Step:   210 /   793 Train loss: 0.03180461\r\n",
      "Epoch:  87 Step:   211 /   793 Train loss: 0.02921640\r\n",
      "Epoch:  87 Step:   212 /   793 Train loss: 0.02122870\r\n",
      "Epoch:  87 Step:   213 /   793 Train loss: 0.02675358\r\n",
      "Epoch:  87 Step:   214 /   793 Train loss: 0.01943776\r\n",
      "Epoch:  87 Step:   215 /   793 Train loss: 0.02437140\r\n",
      "Epoch:  87 Step:   216 /   793 Train loss: 0.02652995\r\n",
      "Epoch:  87 Step:   217 /   793 Train loss: 0.02751148\r\n",
      "Epoch:  87 Step:   218 /   793 Train loss: 0.03079085\r\n",
      "Epoch:  87 Step:   219 /   793 Train loss: 0.02397141\r\n",
      "Epoch:  87 Step:   220 /   793 Train loss: 0.01502762\r\n",
      "Epoch:  87 Step:   221 /   793 Train loss: 0.02312440\r\n",
      "Epoch:  87 Step:   222 /   793 Train loss: 0.02142516\r\n",
      "Epoch:  87 Step:   223 /   793 Train loss: 0.03205971\r\n",
      "Epoch:  87 Step:   224 /   793 Train loss: 0.02259669\r\n",
      "Epoch:  87 Step:   225 /   793 Train loss: 0.01543101\r\n",
      "Epoch:  87 Step:   226 /   793 Train loss: 0.03008689\r\n",
      "Epoch:  87 Step:   227 /   793 Train loss: 0.03526521\r\n",
      "Epoch:  87 Step:   228 /   793 Train loss: 0.01288714\r\n",
      "Epoch:  87 Step:   229 /   793 Train loss: 0.03928443\r\n",
      "Epoch:  87 Step:   230 /   793 Train loss: 0.01833276\r\n",
      "Epoch:  87 Step:   231 /   793 Train loss: 0.02565043\r\n",
      "Epoch:  87 Step:   232 /   793 Train loss: 0.02478282\r\n",
      "Epoch:  87 Step:   233 /   793 Train loss: 0.01791343\r\n",
      "Epoch:  87 Step:   234 /   793 Train loss: 0.02297770\r\n",
      "Epoch:  87 Step:   235 /   793 Train loss: 0.01838505\r\n",
      "Epoch:  87 Step:   236 /   793 Train loss: 0.02481150\r\n",
      "Epoch:  87 Step:   237 /   793 Train loss: 0.01584890\r\n",
      "Epoch:  87 Step:   238 /   793 Train loss: 0.03282797\r\n",
      "Epoch:  87 Step:   239 /   793 Train loss: 0.02993513\r\n",
      "Epoch:  87 Step:   240 /   793 Train loss: 0.00849708\r\n",
      "Epoch:  87 Step:   241 /   793 Train loss: 0.01111119\r\n",
      "Epoch:  87 Step:   242 /   793 Train loss: 0.01753234\r\n",
      "Epoch:  87 Step:   243 /   793 Train loss: 0.02672624\r\n",
      "Epoch:  87 Step:   244 /   793 Train loss: 0.02875557\r\n",
      "Epoch:  87 Step:   245 /   793 Train loss: 0.02957428\r\n",
      "Epoch:  87 Step:   246 /   793 Train loss: 0.02485951\r\n",
      "Epoch:  87 Step:   247 /   793 Train loss: 0.02368567\r\n",
      "Epoch:  87 Step:   248 /   793 Train loss: 0.01544179\r\n",
      "Epoch:  87 Step:   249 /   793 Train loss: 0.01562611\r\n",
      "Epoch:  87 Step:   250 /   793 Train loss: 0.02129607\r\n",
      "Epoch:  87 Step:   251 /   793 Train loss: 0.02378562\r\n",
      "Epoch:  87 Step:   252 /   793 Train loss: 0.02202132\r\n",
      "Epoch:  87 Step:   253 /   793 Train loss: 0.03303464\r\n",
      "Epoch:  87 Step:   254 /   793 Train loss: 0.03378433\r\n",
      "Epoch:  87 Step:   255 /   793 Train loss: 0.02123210\r\n",
      "Epoch:  87 Step:   256 /   793 Train loss: 0.02144582\r\n",
      "Epoch:  87 Step:   257 /   793 Train loss: 0.02768234\r\n",
      "Epoch:  87 Step:   258 /   793 Train loss: 0.01714724\r\n",
      "Epoch:  87 Step:   259 /   793 Train loss: 0.02679850\r\n",
      "Epoch:  87 Step:   260 /   793 Train loss: 0.01204342\r\n",
      "Epoch:  87 Step:   261 /   793 Train loss: 0.02730823\r\n",
      "Epoch:  87 Step:   262 /   793 Train loss: 0.03669222\r\n",
      "Epoch:  87 Step:   263 /   793 Train loss: 0.01938904\r\n",
      "Epoch:  87 Step:   264 /   793 Train loss: 0.03813647\r\n",
      "Epoch:  87 Step:   265 /   793 Train loss: 0.02573204\r\n",
      "Epoch:  87 Step:   266 /   793 Train loss: 0.02296764\r\n",
      "Epoch:  87 Step:   267 /   793 Train loss: 0.01995589\r\n",
      "Epoch:  87 Step:   268 /   793 Train loss: 0.01873720\r\n",
      "Epoch:  87 Step:   269 /   793 Train loss: 0.02456650\r\n",
      "Epoch:  87 Step:   270 /   793 Train loss: 0.02109886\r\n",
      "Epoch:  87 Step:   271 /   793 Train loss: 0.01497948\r\n",
      "Epoch:  87 Step:   272 /   793 Train loss: 0.01700263\r\n",
      "Epoch:  87 Step:   273 /   793 Train loss: 0.03362522\r\n",
      "Epoch:  87 Step:   274 /   793 Train loss: 0.01420683\r\n",
      "Epoch:  87 Step:   275 /   793 Train loss: 0.03616288\r\n",
      "Epoch:  87 Step:   276 /   793 Train loss: 0.02156525\r\n",
      "Epoch:  87 Step:   277 /   793 Train loss: 0.02222859\r\n",
      "Epoch:  87 Step:   278 /   793 Train loss: 0.01491921\r\n",
      "Epoch:  87 Step:   279 /   793 Train loss: 0.01563257\r\n",
      "Epoch:  87 Step:   280 /   793 Train loss: 0.01847805\r\n",
      "Epoch:  87 Step:   281 /   793 Train loss: 0.02997609\r\n",
      "Epoch:  87 Step:   282 /   793 Train loss: 0.02599062\r\n",
      "Epoch:  87 Step:   283 /   793 Train loss: 0.02115767\r\n",
      "Epoch:  87 Step:   284 /   793 Train loss: 0.02871518\r\n",
      "Epoch:  87 Step:   285 /   793 Train loss: 0.03572413\r\n",
      "Epoch:  87 Step:   286 /   793 Train loss: 0.02896471\r\n",
      "Epoch:  87 Step:   287 /   793 Train loss: 0.02755717\r\n",
      "Epoch:  87 Step:   288 /   793 Train loss: 0.01882723\r\n",
      "Epoch:  87 Step:   289 /   793 Train loss: 0.02430052\r\n",
      "Epoch:  87 Step:   290 /   793 Train loss: 0.02442932\r\n",
      "Epoch:  87 Step:   291 /   793 Train loss: 0.02210233\r\n",
      "Epoch:  87 Step:   292 /   793 Train loss: 0.02189070\r\n",
      "Epoch:  87 Step:   293 /   793 Train loss: 0.01965702\r\n",
      "Epoch:  87 Step:   294 /   793 Train loss: 0.01494131\r\n",
      "Epoch:  87 Step:   295 /   793 Train loss: 0.01934395\r\n",
      "Epoch:  87 Step:   296 /   793 Train loss: 0.02383440\r\n",
      "Epoch:  87 Step:   297 /   793 Train loss: 0.03079848\r\n",
      "Epoch:  87 Step:   298 /   793 Train loss: 0.02380037\r\n",
      "Epoch:  87 Step:   299 /   793 Train loss: 0.02966427\r\n",
      "Epoch:  87 Step:   300 /   793 Train loss: 0.02340705\r\n",
      "Epoch:  87 Step:   301 /   793 Train loss: 0.02690217\r\n",
      "Epoch:  87 Step:   302 /   793 Train loss: 0.03417816\r\n",
      "Epoch:  87 Step:   303 /   793 Train loss: 0.01521899\r\n",
      "Epoch:  87 Step:   304 /   793 Train loss: 0.02529174\r\n",
      "Epoch:  87 Step:   305 /   793 Train loss: 0.01599879\r\n",
      "Epoch:  87 Step:   306 /   793 Train loss: 0.03362025\r\n",
      "Epoch:  87 Step:   307 /   793 Train loss: 0.01208731\r\n",
      "Epoch:  87 Step:   308 /   793 Train loss: 0.01787368\r\n",
      "Epoch:  87 Step:   309 /   793 Train loss: 0.01713208\r\n",
      "Epoch:  87 Step:   310 /   793 Train loss: 0.03305203\r\n",
      "Epoch:  87 Step:   311 /   793 Train loss: 0.02678046\r\n",
      "Epoch:  87 Step:   312 /   793 Train loss: 0.04383434\r\n",
      "Epoch:  87 Step:   313 /   793 Train loss: 0.01788817\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  87 Step:   314 /   793 Train loss: 0.02188086\r\n",
      "Epoch:  87 Step:   315 /   793 Train loss: 0.02719536\r\n",
      "Epoch:  87 Step:   316 /   793 Train loss: 0.02323880\r\n",
      "Epoch:  87 Step:   317 /   793 Train loss: 0.02765107\r\n",
      "Epoch:  87 Step:   318 /   793 Train loss: 0.02132144\r\n",
      "Epoch:  87 Step:   319 /   793 Train loss: 0.02642842\r\n",
      "Epoch:  87 Step:   320 /   793 Train loss: 0.03878142\r\n",
      "Epoch:  87 Step:   321 /   793 Train loss: 0.03365101\r\n",
      "Epoch:  87 Step:   322 /   793 Train loss: 0.04155385\r\n",
      "Epoch:  87 Step:   323 /   793 Train loss: 0.03078328\r\n",
      "Epoch:  87 Step:   324 /   793 Train loss: 0.01908400\r\n",
      "Epoch:  87 Step:   325 /   793 Train loss: 0.02446310\r\n",
      "Epoch:  87 Step:   326 /   793 Train loss: 0.01456053\r\n",
      "Epoch:  87 Step:   327 /   793 Train loss: 0.01875041\r\n",
      "Epoch:  87 Step:   328 /   793 Train loss: 0.01913682\r\n",
      "Epoch:  87 Step:   329 /   793 Train loss: 0.02795799\r\n",
      "Epoch:  87 Step:   330 /   793 Train loss: 0.01876728\r\n",
      "Epoch:  87 Step:   331 /   793 Train loss: 0.02124259\r\n",
      "Epoch:  87 Step:   332 /   793 Train loss: 0.02729424\r\n",
      "Epoch:  87 Step:   333 /   793 Train loss: 0.02594044\r\n",
      "Epoch:  87 Step:   334 /   793 Train loss: 0.02022816\r\n",
      "Epoch:  87 Step:   335 /   793 Train loss: 0.01529880\r\n",
      "Epoch:  87 Step:   336 /   793 Train loss: 0.02237971\r\n",
      "Epoch:  87 Step:   337 /   793 Train loss: 0.02171123\r\n",
      "Epoch:  87 Step:   338 /   793 Train loss: 0.02002326\r\n",
      "Epoch:  87 Step:   339 /   793 Train loss: 0.01568932\r\n",
      "Epoch:  87 Step:   340 /   793 Train loss: 0.01381471\r\n",
      "Epoch:  87 Step:   341 /   793 Train loss: 0.02337280\r\n",
      "Epoch:  87 Step:   342 /   793 Train loss: 0.02043749\r\n",
      "Epoch:  87 Step:   343 /   793 Train loss: 0.02462346\r\n",
      "Epoch:  87 Step:   344 /   793 Train loss: 0.02365012\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  87 Step:   345 /   793 Train loss: 0.01992890\r\n",
      "Epoch:  87 Step:   346 /   793 Train loss: 0.02423919\r\n",
      "Epoch:  87 Step:   347 /   793 Train loss: 0.02323502\r\n",
      "Epoch:  87 Step:   348 /   793 Train loss: 0.02335000\r\n",
      "Epoch:  87 Step:   349 /   793 Train loss: 0.03027894\r\n",
      "Epoch:  87 Step:   350 /   793 Train loss: 0.01159401\r\n",
      "Epoch:  87 Step:   351 /   793 Train loss: 0.03090601\r\n",
      "Epoch:  87 Step:   352 /   793 Train loss: 0.03356954\r\n",
      "Epoch:  87 Step:   353 /   793 Train loss: 0.01394729\r\n",
      "Epoch:  87 Step:   354 /   793 Train loss: 0.02281703\r\n",
      "Epoch:  87 Step:   355 /   793 Train loss: 0.02374075\r\n",
      "Epoch:  87 Step:   356 /   793 Train loss: 0.01647523\r\n",
      "Epoch:  87 Step:   357 /   793 Train loss: 0.01239603\r\n",
      "Epoch:  87 Step:   358 /   793 Train loss: 0.03296193\r\n",
      "Epoch:  87 Step:   359 /   793 Train loss: 0.02457022\r\n",
      "Epoch:  87 Step:   360 /   793 Train loss: 0.03345071\r\n",
      "Epoch:  87 Step:   361 /   793 Train loss: 0.02312241\r\n",
      "Epoch:  87 Step:   362 /   793 Train loss: 0.04229801\r\n",
      "Epoch:  87 Step:   363 /   793 Train loss: 0.01615233\r\n",
      "Epoch:  87 Step:   364 /   793 Train loss: 0.02964114\r\n",
      "Epoch:  87 Step:   365 /   793 Train loss: 0.02873989\r\n",
      "Epoch:  87 Step:   366 /   793 Train loss: 0.01857808\r\n",
      "Epoch:  87 Step:   367 /   793 Train loss: 0.02770130\r\n",
      "Epoch:  87 Step:   368 /   793 Train loss: 0.02239415\r\n",
      "Epoch:  87 Step:   369 /   793 Train loss: 0.02546670\r\n",
      "Epoch:  87 Step:   370 /   793 Train loss: 0.02906375\r\n",
      "Epoch:  87 Step:   371 /   793 Train loss: 0.01744155\r\n",
      "Epoch:  87 Step:   372 /   793 Train loss: 0.03474815\r\n",
      "Epoch:  87 Step:   373 /   793 Train loss: 0.02903249\r\n",
      "Epoch:  87 Step:   374 /   793 Train loss: 0.02857261\r\n",
      "Epoch:  87 Step:   375 /   793 Train loss: 0.03262574\r\n",
      "Epoch:  87 Step:   376 /   793 Train loss: 0.02518880\r\n",
      "Epoch:  87 Step:   377 /   793 Train loss: 0.02003733\r\n",
      "Epoch:  87 Step:   378 /   793 Train loss: 0.01475314\r\n",
      "Epoch:  87 Step:   379 /   793 Train loss: 0.02032970\r\n",
      "Epoch:  87 Step:   380 /   793 Train loss: 0.02804516\r\n",
      "Epoch:  87 Step:   381 /   793 Train loss: 0.02330137\r\n",
      "Epoch:  87 Step:   382 /   793 Train loss: 0.02911832\r\n",
      "Epoch:  87 Step:   383 /   793 Train loss: 0.01189932\r\n",
      "Epoch:  87 Step:   384 /   793 Train loss: 0.01581297\r\n",
      "Epoch:  87 Step:   385 /   793 Train loss: 0.02189767\r\n",
      "Epoch:  87 Step:   386 /   793 Train loss: 0.02495458\r\n",
      "Epoch:  87 Step:   387 /   793 Train loss: 0.01826056\r\n",
      "Epoch:  87 Step:   388 /   793 Train loss: 0.01633486\r\n",
      "Epoch:  87 Step:   389 /   793 Train loss: 0.02612033\r\n",
      "Epoch:  87 Step:   390 /   793 Train loss: 0.02711875\r\n",
      "Epoch:  87 Step:   391 /   793 Train loss: 0.03522956\r\n",
      "Epoch:  87 Step:   392 /   793 Train loss: 0.02598479\r\n",
      "Epoch:  87 Step:   393 /   793 Train loss: 0.01625964\r\n",
      "Epoch:  87 Step:   394 /   793 Train loss: 0.03070895\r\n",
      "Epoch:  87 Step:   395 /   793 Train loss: 0.01346959\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  87 Step:   396 /   793 Train loss: 0.02024015\r\n",
      "Epoch:  87 Step:   397 /   793 Train loss: 0.02263982\r\n",
      "Epoch:  87 Step:   398 /   793 Train loss: 0.03001175\r\n",
      "Epoch:  87 Step:   399 /   793 Train loss: 0.01448065\r\n",
      "Epoch:  87 Step:   400 /   793 Train loss: 0.02038443\r\n",
      "Epoch:  87 Step:   401 /   793 Train loss: 0.03044322\r\n",
      "Epoch:  87 Step:   402 /   793 Train loss: 0.02034499\r\n",
      "Epoch:  87 Step:   403 /   793 Train loss: 0.01704172\r\n",
      "Epoch:  87 Step:   404 /   793 Train loss: 0.02954435\r\n",
      "Epoch:  87 Step:   405 /   793 Train loss: 0.03256969\r\n",
      "Epoch:  87 Step:   406 /   793 Train loss: 0.03257953\r\n",
      "Epoch:  87 Step:   407 /   793 Train loss: 0.01980051\r\n",
      "Epoch:  87 Step:   408 /   793 Train loss: 0.04527843\r\n",
      "Epoch:  87 Step:   409 /   793 Train loss: 0.01662924\r\n",
      "Epoch:  87 Step:   410 /   793 Train loss: 0.01797772\r\n",
      "Epoch:  87 Step:   411 /   793 Train loss: 0.02561389\r\n",
      "Epoch:  87 Step:   412 /   793 Train loss: 0.02025126\r\n",
      "Epoch:  87 Step:   413 /   793 Train loss: 0.02285429\r\n",
      "Epoch:  87 Step:   414 /   793 Train loss: 0.02985641\r\n",
      "Epoch:  87 Step:   415 /   793 Train loss: 0.02018967\r\n",
      "Epoch:  87 Step:   416 /   793 Train loss: 0.01045432\r\n",
      "Epoch:  87 Step:   417 /   793 Train loss: 0.02704226\r\n",
      "Epoch:  87 Step:   418 /   793 Train loss: 0.01623921\r\n",
      "Epoch:  87 Step:   419 /   793 Train loss: 0.01739266\r\n",
      "Epoch:  87 Step:   420 /   793 Train loss: 0.02764942\r\n",
      "Epoch:  87 Step:   421 /   793 Train loss: 0.02921597\r\n",
      "Epoch:  87 Step:   422 /   793 Train loss: 0.02348425\r\n",
      "Epoch:  87 Step:   423 /   793 Train loss: 0.01911730\r\n",
      "Epoch:  87 Step:   424 /   793 Train loss: 0.01399689\r\n",
      "Epoch:  87 Step:   425 /   793 Train loss: 0.02562466\r\n",
      "Epoch:  87 Step:   426 /   793 Train loss: 0.03118535\r\n",
      "Epoch:  87 Step:   427 /   793 Train loss: 0.01438229\r\n",
      "Epoch:  87 Step:   428 /   793 Train loss: 0.01688116\r\n",
      "Epoch:  87 Step:   429 /   793 Train loss: 0.02511027\r\n",
      "Epoch:  87 Step:   430 /   793 Train loss: 0.02537796\r\n",
      "Epoch:  87 Step:   431 /   793 Train loss: 0.02267350\r\n",
      "Epoch:  87 Step:   432 /   793 Train loss: 0.02840364\r\n",
      "Epoch:  87 Step:   433 /   793 Train loss: 0.03452149\r\n",
      "Epoch:  87 Step:   434 /   793 Train loss: 0.02790234\r\n",
      "Epoch:  87 Step:   435 /   793 Train loss: 0.02926496\r\n",
      "Epoch:  87 Step:   436 /   793 Train loss: 0.02495778\r\n",
      "Epoch:  87 Step:   437 /   793 Train loss: 0.02196011\r\n",
      "Epoch:  87 Step:   438 /   793 Train loss: 0.02082824\r\n",
      "Epoch:  87 Step:   439 /   793 Train loss: 0.01816349\r\n",
      "Epoch:  87 Step:   440 /   793 Train loss: 0.02698627\r\n",
      "Epoch:  87 Step:   441 /   793 Train loss: 0.03288056\r\n",
      "Epoch:  87 Step:   442 /   793 Train loss: 0.04353421\r\n",
      "Epoch:  87 Step:   443 /   793 Train loss: 0.02161996\r\n",
      "Epoch:  87 Step:   444 /   793 Train loss: 0.02793532\r\n",
      "Epoch:  87 Step:   445 /   793 Train loss: 0.02818591\r\n",
      "Epoch:  87 Step:   446 /   793 Train loss: 0.02296251\r\n",
      "Epoch:  87 Step:   447 /   793 Train loss: 0.01950998\r\n",
      "Epoch:  87 Step:   448 /   793 Train loss: 0.02035398\r\n",
      "Epoch:  87 Step:   449 /   793 Train loss: 0.01585426\r\n",
      "Epoch:  87 Step:   450 /   793 Train loss: 0.02445681\r\n",
      "Epoch:  87 Step:   451 /   793 Train loss: 0.02390284\r\n",
      "Epoch:  87 Step:   452 /   793 Train loss: 0.02710322\r\n",
      "Epoch:  87 Step:   453 /   793 Train loss: 0.02195923\r\n",
      "Epoch:  87 Step:   454 /   793 Train loss: 0.00952771\r\n",
      "Epoch:  87 Step:   455 /   793 Train loss: 0.01270566\r\n",
      "Epoch:  87 Step:   456 /   793 Train loss: 0.02211668\r\n",
      "Epoch:  87 Step:   457 /   793 Train loss: 0.02288149\r\n",
      "Epoch:  87 Step:   458 /   793 Train loss: 0.03486123\r\n",
      "Epoch:  87 Step:   459 /   793 Train loss: 0.01597592\r\n",
      "Epoch:  87 Step:   460 /   793 Train loss: 0.02793209\r\n",
      "Epoch:  87 Step:   461 /   793 Train loss: 0.02749047\r\n",
      "Epoch:  87 Step:   462 /   793 Train loss: 0.01913324\r\n",
      "Epoch:  87 Step:   463 /   793 Train loss: 0.02280246\r\n",
      "Epoch:  87 Step:   464 /   793 Train loss: 0.04219025\r\n",
      "Epoch:  87 Step:   465 /   793 Train loss: 0.01299724\r\n",
      "Epoch:  87 Step:   466 /   793 Train loss: 0.01909444\r\n",
      "Epoch:  87 Step:   467 /   793 Train loss: 0.03730403\r\n",
      "Epoch:  87 Step:   468 /   793 Train loss: 0.01933279\r\n",
      "Epoch:  87 Step:   469 /   793 Train loss: 0.01913475\r\n",
      "Epoch:  87 Step:   470 /   793 Train loss: 0.02064425\r\n",
      "Epoch:  87 Step:   471 /   793 Train loss: 0.02348913\r\n",
      "Epoch:  87 Step:   472 /   793 Train loss: 0.02294017\r\n",
      "Epoch:  87 Step:   473 /   793 Train loss: 0.03698932\r\n",
      "Epoch:  87 Step:   474 /   793 Train loss: 0.02524581\r\n",
      "Epoch:  87 Step:   475 /   793 Train loss: 0.01901496\r\n",
      "Epoch:  87 Step:   476 /   793 Train loss: 0.02800426\r\n",
      "Epoch:  87 Step:   477 /   793 Train loss: 0.02759318\r\n",
      "Epoch:  87 Step:   478 /   793 Train loss: 0.02316857\r\n",
      "Epoch:  87 Step:   479 /   793 Train loss: 0.02459803\r\n",
      "Epoch:  87 Step:   480 /   793 Train loss: 0.02014539\r\n",
      "Epoch:  87 Step:   481 /   793 Train loss: 0.02915744\r\n",
      "Epoch:  87 Step:   482 /   793 Train loss: 0.02999845\r\n",
      "Epoch:  87 Step:   483 /   793 Train loss: 0.02823924\r\n",
      "Epoch:  87 Step:   484 /   793 Train loss: 0.02073116\r\n",
      "Epoch:  87 Step:   485 /   793 Train loss: 0.02267447\r\n",
      "Epoch:  87 Step:   486 /   793 Train loss: 0.02619011\r\n",
      "Epoch:  87 Step:   487 /   793 Train loss: 0.02272199\r\n",
      "Epoch:  87 Step:   488 /   793 Train loss: 0.01811738\r\n",
      "Epoch:  87 Step:   489 /   793 Train loss: 0.02411741\r\n",
      "Epoch:  87 Step:   490 /   793 Train loss: 0.01757159\r\n",
      "Epoch:  87 Step:   491 /   793 Train loss: 0.01631821\r\n",
      "Epoch:  87 Step:   492 /   793 Train loss: 0.00993560\r\n",
      "Epoch:  87 Step:   493 /   793 Train loss: 0.01718732\r\n",
      "Epoch:  87 Step:   494 /   793 Train loss: 0.03389169\r\n",
      "Epoch:  87 Step:   495 /   793 Train loss: 0.01870173\r\n",
      "Epoch:  87 Step:   496 /   793 Train loss: 0.03124284\r\n",
      "Epoch:  87 Step:   497 /   793 Train loss: 0.04720487\r\n",
      "Epoch:  87 Step:   498 /   793 Train loss: 0.01992814\r\n",
      "Epoch:  87 Step:   499 /   793 Train loss: 0.00961133\r\n",
      "Epoch:  87 Step:   500 /   793 Train loss: 0.03755810\r\n",
      "Epoch:  87 Step:   501 /   793 Train loss: 0.02405386\r\n",
      "Epoch:  87 Step:   502 /   793 Train loss: 0.01470576\r\n",
      "Epoch:  87 Step:   503 /   793 Train loss: 0.01940119\r\n",
      "Epoch:  87 Step:   504 /   793 Train loss: 0.04063903\r\n",
      "Epoch:  87 Step:   505 /   793 Train loss: 0.01665665\r\n",
      "Epoch:  87 Step:   506 /   793 Train loss: 0.02188725\r\n",
      "Epoch:  87 Step:   507 /   793 Train loss: 0.02424701\r\n",
      "Epoch:  87 Step:   508 /   793 Train loss: 0.02242263\r\n",
      "Epoch:  87 Step:   509 /   793 Train loss: 0.01909098\r\n",
      "Epoch:  87 Step:   510 /   793 Train loss: 0.02381692\r\n",
      "Epoch:  87 Step:   511 /   793 Train loss: 0.01346326\r\n",
      "Epoch:  87 Step:   512 /   793 Train loss: 0.03141032\r\n",
      "Epoch:  87 Step:   513 /   793 Train loss: 0.02645754\r\n",
      "Epoch:  87 Step:   514 /   793 Train loss: 0.02325358\r\n",
      "Epoch:  87 Step:   515 /   793 Train loss: 0.03440995\r\n",
      "Epoch:  87 Step:   516 /   793 Train loss: 0.02027937\r\n",
      "Epoch:  87 Step:   517 /   793 Train loss: 0.02863739\r\n",
      "Epoch:  87 Step:   518 /   793 Train loss: 0.02959445\r\n",
      "Epoch:  87 Step:   519 /   793 Train loss: 0.01919573\r\n",
      "Epoch:  87 Step:   520 /   793 Train loss: 0.00946637\r\n",
      "Epoch:  87 Step:   521 /   793 Train loss: 0.02211017\r\n",
      "Epoch:  87 Step:   522 /   793 Train loss: 0.02130281\r\n",
      "Epoch:  87 Step:   523 /   793 Train loss: 0.01941899\r\n",
      "Epoch:  87 Step:   524 /   793 Train loss: 0.01870970\r\n",
      "Epoch:  87 Step:   525 /   793 Train loss: 0.02616507\r\n",
      "Epoch:  87 Step:   526 /   793 Train loss: 0.01267054\r\n",
      "Epoch:  87 Step:   527 /   793 Train loss: 0.01281009\r\n",
      "Epoch:  87 Step:   528 /   793 Train loss: 0.02356902\r\n",
      "Epoch:  87 Step:   529 /   793 Train loss: 0.02864208\r\n",
      "Epoch:  87 Step:   530 /   793 Train loss: 0.01951353\r\n",
      "Epoch:  87 Step:   531 /   793 Train loss: 0.02864882\r\n",
      "Epoch:  87 Step:   532 /   793 Train loss: 0.02191965\r\n",
      "Epoch:  87 Step:   533 /   793 Train loss: 0.02970799\r\n",
      "Epoch:  87 Step:   534 /   793 Train loss: 0.02322307\r\n",
      "Epoch:  87 Step:   535 /   793 Train loss: 0.01354024\r\n",
      "Epoch:  87 Step:   536 /   793 Train loss: 0.02217558\r\n",
      "Epoch:  87 Step:   537 /   793 Train loss: 0.01940440\r\n",
      "Epoch:  87 Step:   538 /   793 Train loss: 0.02622642\r\n",
      "Epoch:  87 Step:   539 /   793 Train loss: 0.02282703\r\n",
      "Epoch:  87 Step:   540 /   793 Train loss: 0.02771957\r\n",
      "Epoch:  87 Step:   541 /   793 Train loss: 0.02825244\r\n",
      "Epoch:  87 Step:   542 /   793 Train loss: 0.01449259\r\n",
      "Epoch:  87 Step:   543 /   793 Train loss: 0.03048348\r\n",
      "Epoch:  87 Step:   544 /   793 Train loss: 0.04308551\r\n",
      "Epoch:  87 Step:   545 /   793 Train loss: 0.01729302\r\n",
      "Epoch:  87 Step:   546 /   793 Train loss: 0.01968563\r\n",
      "Epoch:  87 Step:   547 /   793 Train loss: 0.03226982\r\n",
      "Epoch:  87 Step:   548 /   793 Train loss: 0.03212211\r\n",
      "Epoch:  87 Step:   549 /   793 Train loss: 0.03169218\r\n",
      "Epoch:  87 Step:   550 /   793 Train loss: 0.02551558\r\n",
      "Epoch:  87 Step:   551 /   793 Train loss: 0.02706035\r\n",
      "Epoch:  87 Step:   552 /   793 Train loss: 0.02799571\r\n",
      "Epoch:  87 Step:   553 /   793 Train loss: 0.02299369\r\n",
      "Epoch:  87 Step:   554 /   793 Train loss: 0.02999844\r\n",
      "Epoch:  87 Step:   555 /   793 Train loss: 0.02394132\r\n",
      "Epoch:  87 Step:   556 /   793 Train loss: 0.02557087\r\n",
      "Epoch:  87 Step:   557 /   793 Train loss: 0.01132803\r\n",
      "Epoch:  87 Step:   558 /   793 Train loss: 0.03205890\r\n",
      "Epoch:  87 Step:   559 /   793 Train loss: 0.03244193\r\n",
      "Epoch:  87 Step:   560 /   793 Train loss: 0.02227267\r\n",
      "Epoch:  87 Step:   561 /   793 Train loss: 0.03031701\r\n",
      "Epoch:  87 Step:   562 /   793 Train loss: 0.02349725\r\n",
      "Epoch:  87 Step:   563 /   793 Train loss: 0.01583092\r\n",
      "Epoch:  87 Step:   564 /   793 Train loss: 0.01731524\r\n",
      "Epoch:  87 Step:   565 /   793 Train loss: 0.01676502\r\n",
      "Epoch:  87 Step:   566 /   793 Train loss: 0.01534061\r\n",
      "Epoch:  87 Step:   567 /   793 Train loss: 0.01695522\r\n",
      "Epoch:  87 Step:   568 /   793 Train loss: 0.03669156\r\n",
      "Epoch:  87 Step:   569 /   793 Train loss: 0.04086920\r\n",
      "Epoch:  87 Step:   570 /   793 Train loss: 0.01655745\r\n",
      "Epoch:  87 Step:   571 /   793 Train loss: 0.02183037\r\n",
      "Epoch:  87 Step:   572 /   793 Train loss: 0.03888856\r\n",
      "Epoch:  87 Step:   573 /   793 Train loss: 0.02625266\r\n",
      "Epoch:  87 Step:   574 /   793 Train loss: 0.02946567\r\n",
      "Epoch:  87 Step:   575 /   793 Train loss: 0.02320905\r\n",
      "Epoch:  87 Step:   576 /   793 Train loss: 0.02594189\r\n",
      "Epoch:  87 Step:   577 /   793 Train loss: 0.02482317\r\n",
      "Epoch:  87 Step:   578 /   793 Train loss: 0.02264901\r\n",
      "Epoch:  87 Step:   579 /   793 Train loss: 0.03503298\r\n",
      "Epoch:  87 Step:   580 /   793 Train loss: 0.02349678\r\n",
      "Epoch:  87 Step:   581 /   793 Train loss: 0.01629793\r\n",
      "Epoch:  87 Step:   582 /   793 Train loss: 0.02580079\r\n",
      "Epoch:  87 Step:   583 /   793 Train loss: 0.04094298\r\n",
      "Epoch:  87 Step:   584 /   793 Train loss: 0.01146670\r\n",
      "Epoch:  87 Step:   585 /   793 Train loss: 0.01405734\r\n",
      "Epoch:  87 Step:   586 /   793 Train loss: 0.02629182\r\n",
      "Epoch:  87 Step:   587 /   793 Train loss: 0.03043051\r\n",
      "Epoch:  87 Step:   588 /   793 Train loss: 0.02578761\r\n",
      "Epoch:  87 Step:   589 /   793 Train loss: 0.02749581\r\n",
      "Epoch:  87 Step:   590 /   793 Train loss: 0.02154639\r\n",
      "Epoch:  87 Step:   591 /   793 Train loss: 0.03223455\r\n",
      "Epoch:  87 Step:   592 /   793 Train loss: 0.02383888\r\n",
      "Epoch:  87 Step:   593 /   793 Train loss: 0.02335501\r\n",
      "Epoch:  87 Step:   594 /   793 Train loss: 0.02076825\r\n",
      "Epoch:  87 Step:   595 /   793 Train loss: 0.01840807\r\n",
      "Epoch:  87 Step:   596 /   793 Train loss: 0.02541745\r\n",
      "Epoch:  87 Step:   597 /   793 Train loss: 0.02598406\r\n",
      "Epoch:  87 Step:   598 /   793 Train loss: 0.02859560\r\n",
      "Epoch:  87 Step:   599 /   793 Train loss: 0.02525290\r\n",
      "Epoch:  87 Step:   600 /   793 Train loss: 0.02952202\r\n",
      "Epoch:  87 Step:   601 /   793 Train loss: 0.02737627\r\n",
      "Epoch:  87 Step:   602 /   793 Train loss: 0.02792514\r\n",
      "Epoch:  87 Step:   603 /   793 Train loss: 0.02393686\r\n",
      "Epoch:  87 Step:   604 /   793 Train loss: 0.01334734\r\n",
      "Epoch:  87 Step:   605 /   793 Train loss: 0.02776065\r\n",
      "Epoch:  87 Step:   606 /   793 Train loss: 0.01618232\r\n",
      "Epoch:  87 Step:   607 /   793 Train loss: 0.02819471\r\n",
      "Epoch:  87 Step:   608 /   793 Train loss: 0.01636309\r\n",
      "Epoch:  87 Step:   609 /   793 Train loss: 0.02683878\r\n",
      "Epoch:  87 Step:   610 /   793 Train loss: 0.03466680\r\n",
      "Epoch:  87 Step:   611 /   793 Train loss: 0.01887421\r\n",
      "Epoch:  87 Step:   612 /   793 Train loss: 0.02688869\r\n",
      "Epoch:  87 Step:   613 /   793 Train loss: 0.03514496\r\n",
      "Epoch:  87 Step:   614 /   793 Train loss: 0.02026293\r\n",
      "Epoch:  87 Step:   615 /   793 Train loss: 0.02710118\r\n",
      "Epoch:  87 Step:   616 /   793 Train loss: 0.01981540\r\n",
      "Epoch:  87 Step:   617 /   793 Train loss: 0.03742592\r\n",
      "Epoch:  87 Step:   618 /   793 Train loss: 0.02309247\r\n",
      "Epoch:  87 Step:   619 /   793 Train loss: 0.01705170\r\n",
      "Epoch:  87 Step:   620 /   793 Train loss: 0.02643465\r\n",
      "Epoch:  87 Step:   621 /   793 Train loss: 0.03911331\r\n",
      "Epoch:  87 Step:   622 /   793 Train loss: 0.01838093\r\n",
      "Epoch:  87 Step:   623 /   793 Train loss: 0.01333254\r\n",
      "Epoch:  87 Step:   624 /   793 Train loss: 0.02471262\r\n",
      "Epoch:  87 Step:   625 /   793 Train loss: 0.02008914\r\n",
      "Epoch:  87 Step:   626 /   793 Train loss: 0.01252003\r\n",
      "Epoch:  87 Step:   627 /   793 Train loss: 0.02706837\r\n",
      "Epoch:  87 Step:   628 /   793 Train loss: 0.02284432\r\n",
      "Epoch:  87 Step:   629 /   793 Train loss: 0.03037662\r\n",
      "Epoch:  87 Step:   630 /   793 Train loss: 0.03432112\r\n",
      "Epoch:  87 Step:   631 /   793 Train loss: 0.03009154\r\n",
      "Epoch:  87 Step:   632 /   793 Train loss: 0.02363714\r\n",
      "Epoch:  87 Step:   633 /   793 Train loss: 0.02799993\r\n",
      "Epoch:  87 Step:   634 /   793 Train loss: 0.03078215\r\n",
      "Epoch:  87 Step:   635 /   793 Train loss: 0.03376985\r\n",
      "Epoch:  87 Step:   636 /   793 Train loss: 0.02575169\r\n",
      "Epoch:  87 Step:   637 /   793 Train loss: 0.02647913\r\n",
      "Epoch:  87 Step:   638 /   793 Train loss: 0.03259262\r\n",
      "Epoch:  87 Step:   639 /   793 Train loss: 0.01671089\r\n",
      "Epoch:  87 Step:   640 /   793 Train loss: 0.02251558\r\n",
      "Epoch:  87 Step:   641 /   793 Train loss: 0.02605198\r\n",
      "Epoch:  87 Step:   642 /   793 Train loss: 0.03015914\r\n",
      "Epoch:  87 Step:   643 /   793 Train loss: 0.01538986\r\n",
      "Epoch:  87 Step:   644 /   793 Train loss: 0.02168203\r\n",
      "Epoch:  87 Step:   645 /   793 Train loss: 0.03484892\r\n",
      "Epoch:  87 Step:   646 /   793 Train loss: 0.02128064\r\n",
      "Epoch:  87 Step:   647 /   793 Train loss: 0.03305698\r\n",
      "Epoch:  87 Step:   648 /   793 Train loss: 0.02026016\r\n",
      "Epoch:  87 Step:   649 /   793 Train loss: 0.02727165\r\n",
      "Epoch:  87 Step:   650 /   793 Train loss: 0.02278876\r\n",
      "Epoch:  87 Step:   651 /   793 Train loss: 0.02592797\r\n",
      "Epoch:  87 Step:   652 /   793 Train loss: 0.02536481\r\n",
      "Epoch:  87 Step:   653 /   793 Train loss: 0.02696881\r\n",
      "Epoch:  87 Step:   654 /   793 Train loss: 0.01732837\r\n",
      "Epoch:  87 Step:   655 /   793 Train loss: 0.02196079\r\n",
      "Epoch:  87 Step:   656 /   793 Train loss: 0.01873560\r\n",
      "Epoch:  87 Step:   657 /   793 Train loss: 0.03932307\r\n",
      "Epoch:  87 Step:   658 /   793 Train loss: 0.01403791\r\n",
      "Epoch:  87 Step:   659 /   793 Train loss: 0.03017597\r\n",
      "Epoch:  87 Step:   660 /   793 Train loss: 0.03192230\r\n",
      "Epoch:  87 Step:   661 /   793 Train loss: 0.02244234\r\n",
      "Epoch:  87 Step:   662 /   793 Train loss: 0.02688846\r\n",
      "Epoch:  87 Step:   663 /   793 Train loss: 0.03230977\r\n",
      "Epoch:  87 Step:   664 /   793 Train loss: 0.02295291\r\n",
      "Epoch:  87 Step:   665 /   793 Train loss: 0.02083109\r\n",
      "Epoch:  87 Step:   666 /   793 Train loss: 0.01871864\r\n",
      "Epoch:  87 Step:   667 /   793 Train loss: 0.01324930\r\n",
      "Epoch:  87 Step:   668 /   793 Train loss: 0.01947259\r\n",
      "Epoch:  87 Step:   669 /   793 Train loss: 0.03239484\r\n",
      "Epoch:  87 Step:   670 /   793 Train loss: 0.01451666\r\n",
      "Epoch:  87 Step:   671 /   793 Train loss: 0.02565674\r\n",
      "Epoch:  87 Step:   672 /   793 Train loss: 0.02038288\r\n",
      "Epoch:  87 Step:   673 /   793 Train loss: 0.02122147\r\n",
      "Epoch:  87 Step:   674 /   793 Train loss: 0.01956627\r\n",
      "Epoch:  87 Step:   675 /   793 Train loss: 0.02661916\r\n",
      "Epoch:  87 Step:   676 /   793 Train loss: 0.02442760\r\n",
      "Epoch:  87 Step:   677 /   793 Train loss: 0.02573335\r\n",
      "Epoch:  87 Step:   678 /   793 Train loss: 0.01745558\r\n",
      "Epoch:  87 Step:   679 /   793 Train loss: 0.02203236\r\n",
      "Epoch:  87 Step:   680 /   793 Train loss: 0.02057834\r\n",
      "Epoch:  87 Step:   681 /   793 Train loss: 0.02994081\r\n",
      "Epoch:  87 Step:   682 /   793 Train loss: 0.02738160\r\n",
      "Epoch:  87 Step:   683 /   793 Train loss: 0.02162439\r\n",
      "Epoch:  87 Step:   684 /   793 Train loss: 0.03067992\r\n",
      "Epoch:  87 Step:   685 /   793 Train loss: 0.02146630\r\n",
      "Epoch:  87 Step:   686 /   793 Train loss: 0.02589552\r\n",
      "Epoch:  87 Step:   687 /   793 Train loss: 0.01526503\r\n",
      "Epoch:  87 Step:   688 /   793 Train loss: 0.02081831\r\n",
      "Epoch:  87 Step:   689 /   793 Train loss: 0.02747078\r\n",
      "Epoch:  87 Step:   690 /   793 Train loss: 0.02133936\r\n",
      "Epoch:  87 Step:   691 /   793 Train loss: 0.01407412\r\n",
      "Epoch:  87 Step:   692 /   793 Train loss: 0.02877507\r\n",
      "Epoch:  87 Step:   693 /   793 Train loss: 0.02409895\r\n",
      "Epoch:  87 Step:   694 /   793 Train loss: 0.02816335\r\n",
      "Epoch:  87 Step:   695 /   793 Train loss: 0.02516146\r\n",
      "Epoch:  87 Step:   696 /   793 Train loss: 0.02547343\r\n",
      "Epoch:  87 Step:   697 /   793 Train loss: 0.02488535\r\n",
      "Epoch:  87 Step:   698 /   793 Train loss: 0.02585443\r\n",
      "Epoch:  87 Step:   699 /   793 Train loss: 0.01466626\r\n",
      "Epoch:  87 Step:   700 /   793 Train loss: 0.02100224\r\n",
      "Epoch:  87 Step:   701 /   793 Train loss: 0.02229446\r\n",
      "Epoch:  87 Step:   702 /   793 Train loss: 0.02985429\r\n",
      "Epoch:  87 Step:   703 /   793 Train loss: 0.02604187\r\n",
      "Epoch:  87 Step:   704 /   793 Train loss: 0.01822573\r\n",
      "Epoch:  87 Step:   705 /   793 Train loss: 0.03289776\r\n",
      "Epoch:  87 Step:   706 /   793 Train loss: 0.01396196\r\n",
      "Epoch:  87 Step:   707 /   793 Train loss: 0.02675520\r\n",
      "Epoch:  87 Step:   708 /   793 Train loss: 0.01766607\r\n",
      "Epoch:  87 Step:   709 /   793 Train loss: 0.02601608\r\n",
      "Epoch:  87 Step:   710 /   793 Train loss: 0.02654089\r\n",
      "Epoch:  87 Step:   711 /   793 Train loss: 0.02590227\r\n",
      "Epoch:  87 Step:   712 /   793 Train loss: 0.03276793\r\n",
      "Epoch:  87 Step:   713 /   793 Train loss: 0.02472347\r\n",
      "Epoch:  87 Step:   714 /   793 Train loss: 0.02033847\r\n",
      "Epoch:  87 Step:   715 /   793 Train loss: 0.02044310\r\n",
      "Epoch:  87 Step:   716 /   793 Train loss: 0.02282992\r\n",
      "Epoch:  87 Step:   717 /   793 Train loss: 0.01311049\r\n",
      "Epoch:  87 Step:   718 /   793 Train loss: 0.01617507\r\n",
      "Epoch:  87 Step:   719 /   793 Train loss: 0.01801550\r\n",
      "Epoch:  87 Step:   720 /   793 Train loss: 0.01396366\r\n",
      "Epoch:  87 Step:   721 /   793 Train loss: 0.01841030\r\n",
      "Epoch:  87 Step:   722 /   793 Train loss: 0.02758383\r\n",
      "Epoch:  87 Step:   723 /   793 Train loss: 0.02396813\r\n",
      "Epoch:  87 Step:   724 /   793 Train loss: 0.01620425\r\n",
      "Epoch:  87 Step:   725 /   793 Train loss: 0.02396750\r\n",
      "Epoch:  87 Step:   726 /   793 Train loss: 0.02675582\r\n",
      "Epoch:  87 Step:   727 /   793 Train loss: 0.01762703\r\n",
      "Epoch:  87 Step:   728 /   793 Train loss: 0.01447721\r\n",
      "Epoch:  87 Step:   729 /   793 Train loss: 0.03677484\r\n",
      "Epoch:  87 Step:   730 /   793 Train loss: 0.02671106\r\n",
      "Epoch:  87 Step:   731 /   793 Train loss: 0.03541140\r\n",
      "Epoch:  87 Step:   732 /   793 Train loss: 0.03775874\r\n",
      "Epoch:  87 Step:   733 /   793 Train loss: 0.03020810\r\n",
      "Epoch:  87 Step:   734 /   793 Train loss: 0.02317202\r\n",
      "Epoch:  87 Step:   735 /   793 Train loss: 0.03333213\r\n",
      "Epoch:  87 Step:   736 /   793 Train loss: 0.03067311\r\n",
      "Epoch:  87 Step:   737 /   793 Train loss: 0.01967703\r\n",
      "Epoch:  87 Step:   738 /   793 Train loss: 0.02756366\r\n",
      "Epoch:  87 Step:   739 /   793 Train loss: 0.02647999\r\n",
      "Epoch:  87 Step:   740 /   793 Train loss: 0.01628020\r\n",
      "Epoch:  87 Step:   741 /   793 Train loss: 0.01759662\r\n",
      "Epoch:  87 Step:   742 /   793 Train loss: 0.02319149\r\n",
      "Epoch:  87 Step:   743 /   793 Train loss: 0.02015794\r\n",
      "Epoch:  87 Step:   744 /   793 Train loss: 0.01883188\r\n",
      "Epoch:  87 Step:   745 /   793 Train loss: 0.02382289\r\n",
      "Epoch:  87 Step:   746 /   793 Train loss: 0.03655187\r\n",
      "Epoch:  87 Step:   747 /   793 Train loss: 0.02050207\r\n",
      "Epoch:  87 Step:   748 /   793 Train loss: 0.02408932\r\n",
      "Epoch:  87 Step:   749 /   793 Train loss: 0.02545799\r\n",
      "Epoch:  87 Step:   750 /   793 Train loss: 0.02081758\r\n",
      "Epoch:  87 Step:   751 /   793 Train loss: 0.03005790\r\n",
      "Epoch:  87 Step:   752 /   793 Train loss: 0.02842393\r\n",
      "Epoch:  87 Step:   753 /   793 Train loss: 0.02516381\r\n",
      "Epoch:  87 Step:   754 /   793 Train loss: 0.01929009\r\n",
      "Epoch:  87 Step:   755 /   793 Train loss: 0.03404899\r\n",
      "Epoch:  87 Step:   756 /   793 Train loss: 0.02786776\r\n",
      "Epoch:  87 Step:   757 /   793 Train loss: 0.01355041\r\n",
      "Epoch:  87 Step:   758 /   793 Train loss: 0.02223906\r\n",
      "Epoch:  87 Step:   759 /   793 Train loss: 0.02143241\r\n",
      "Epoch:  87 Step:   760 /   793 Train loss: 0.02775004\r\n",
      "Epoch:  87 Step:   761 /   793 Train loss: 0.02877147\r\n",
      "Epoch:  87 Step:   762 /   793 Train loss: 0.02831678\r\n",
      "Epoch:  87 Step:   763 /   793 Train loss: 0.02435542\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  87 Step:   764 /   793 Train loss: 0.02722495\r\n",
      "Epoch:  87 Step:   765 /   793 Train loss: 0.01658595\r\n",
      "Epoch:  87 Step:   766 /   793 Train loss: 0.02165452\r\n",
      "Epoch:  87 Step:   767 /   793 Train loss: 0.03344634\r\n",
      "Epoch:  87 Step:   768 /   793 Train loss: 0.02328233\r\n",
      "Epoch:  87 Step:   769 /   793 Train loss: 0.02296247\r\n",
      "Epoch:  87 Step:   770 /   793 Train loss: 0.01664823\r\n",
      "Epoch:  87 Step:   771 /   793 Train loss: 0.03030051\r\n",
      "Epoch:  87 Step:   772 /   793 Train loss: 0.01771546\r\n",
      "Epoch:  87 Step:   773 /   793 Train loss: 0.03866598\r\n",
      "Epoch:  87 Step:   774 /   793 Train loss: 0.02173801\r\n",
      "Epoch:  87 Step:   775 /   793 Train loss: 0.03288421\r\n",
      "Epoch:  87 Step:   776 /   793 Train loss: 0.02424126\r\n",
      "Epoch:  87 Step:   777 /   793 Train loss: 0.02982463\r\n",
      "Epoch:  87 Step:   778 /   793 Train loss: 0.02048056\r\n",
      "Epoch:  87 Step:   779 /   793 Train loss: 0.02836235\r\n",
      "Epoch:  87 Step:   780 /   793 Train loss: 0.01709673\r\n",
      "Epoch:  87 Step:   781 /   793 Train loss: 0.01790351\r\n",
      "Epoch:  87 Step:   782 /   793 Train loss: 0.02452991\r\n",
      "Epoch:  87 Step:   783 /   793 Train loss: 0.02028158\r\n",
      "Epoch:  87 Step:   784 /   793 Train loss: 0.03181345\r\n",
      "Epoch:  87 Step:   785 /   793 Train loss: 0.02782631\r\n",
      "Epoch:  87 Step:   786 /   793 Train loss: 0.02595967\r\n",
      "Epoch:  87 Step:   787 /   793 Train loss: 0.02975772\r\n",
      "Epoch:  87 Step:   788 /   793 Train loss: 0.01531270\r\n",
      "Epoch:  87 Step:   789 /   793 Train loss: 0.03745196\r\n",
      "Epoch:  87 Step:   790 /   793 Train loss: 0.02898813\r\n",
      "Epoch:  87 Step:   791 /   793 Train loss: 0.00835558\r\n",
      "Epoch:  87 Step:   792 /   793 Train loss: 0.03049226\r\n",
      "Epoch:  87 Validation loss: 0.01424315\r\n",
      "Epoch:  88 Step:     0 /   793 Train loss: 0.02283219\r\n",
      "Epoch:  88 Step:     1 /   793 Train loss: 0.01922583\r\n",
      "Epoch:  88 Step:     2 /   793 Train loss: 0.02481560\r\n",
      "Epoch:  88 Step:     3 /   793 Train loss: 0.02837816\r\n",
      "Epoch:  88 Step:     4 /   793 Train loss: 0.01707690\r\n",
      "Epoch:  88 Step:     5 /   793 Train loss: 0.02258299\r\n",
      "Epoch:  88 Step:     6 /   793 Train loss: 0.01904266\r\n",
      "Epoch:  88 Step:     7 /   793 Train loss: 0.01965939\r\n",
      "Epoch:  88 Step:     8 /   793 Train loss: 0.02790449\r\n",
      "Epoch:  88 Step:     9 /   793 Train loss: 0.03378161\r\n",
      "Epoch:  88 Step:    10 /   793 Train loss: 0.01479935\r\n",
      "Epoch:  88 Step:    11 /   793 Train loss: 0.02417123\r\n",
      "Epoch:  88 Step:    12 /   793 Train loss: 0.00965125\r\n",
      "Epoch:  88 Step:    13 /   793 Train loss: 0.01934897\r\n",
      "Epoch:  88 Step:    14 /   793 Train loss: 0.03232585\r\n",
      "Epoch:  88 Step:    15 /   793 Train loss: 0.01684301\r\n",
      "Epoch:  88 Step:    16 /   793 Train loss: 0.02915921\r\n",
      "Epoch:  88 Step:    17 /   793 Train loss: 0.01576945\r\n",
      "Epoch:  88 Step:    18 /   793 Train loss: 0.02236301\r\n",
      "Epoch:  88 Step:    19 /   793 Train loss: 0.01443664\r\n",
      "Epoch:  88 Step:    20 /   793 Train loss: 0.03194539\r\n",
      "Epoch:  88 Step:    21 /   793 Train loss: 0.02518244\r\n",
      "Epoch:  88 Step:    22 /   793 Train loss: 0.03138151\r\n",
      "Epoch:  88 Step:    23 /   793 Train loss: 0.02773541\r\n",
      "Epoch:  88 Step:    24 /   793 Train loss: 0.02009358\r\n",
      "Epoch:  88 Step:    25 /   793 Train loss: 0.02737839\r\n",
      "Epoch:  88 Step:    26 /   793 Train loss: 0.02038694\r\n",
      "Epoch:  88 Step:    27 /   793 Train loss: 0.02163161\r\n",
      "Epoch:  88 Step:    28 /   793 Train loss: 0.02652411\r\n",
      "Epoch:  88 Step:    29 /   793 Train loss: 0.01485357\r\n",
      "Epoch:  88 Step:    30 /   793 Train loss: 0.01463733\r\n",
      "Epoch:  88 Step:    31 /   793 Train loss: 0.02029335\r\n",
      "Epoch:  88 Step:    32 /   793 Train loss: 0.02707814\r\n",
      "Epoch:  88 Step:    33 /   793 Train loss: 0.02105886\r\n",
      "Epoch:  88 Step:    34 /   793 Train loss: 0.02508496\r\n",
      "Epoch:  88 Step:    35 /   793 Train loss: 0.03031581\r\n",
      "Epoch:  88 Step:    36 /   793 Train loss: 0.02376372\r\n",
      "Epoch:  88 Step:    37 /   793 Train loss: 0.02705716\r\n",
      "Epoch:  88 Step:    38 /   793 Train loss: 0.01629942\r\n",
      "Epoch:  88 Step:    39 /   793 Train loss: 0.04000958\r\n",
      "Epoch:  88 Step:    40 /   793 Train loss: 0.02130137\r\n",
      "Epoch:  88 Step:    41 /   793 Train loss: 0.02411054\r\n",
      "Epoch:  88 Step:    42 /   793 Train loss: 0.02219528\r\n",
      "Epoch:  88 Step:    43 /   793 Train loss: 0.03352010\r\n",
      "Epoch:  88 Step:    44 /   793 Train loss: 0.01941592\r\n",
      "Epoch:  88 Step:    45 /   793 Train loss: 0.01918197\r\n",
      "Epoch:  88 Step:    46 /   793 Train loss: 0.03440489\r\n",
      "Epoch:  88 Step:    47 /   793 Train loss: 0.02850122\r\n",
      "Epoch:  88 Step:    48 /   793 Train loss: 0.02604846\r\n",
      "Epoch:  88 Step:    49 /   793 Train loss: 0.03561374\r\n",
      "Epoch:  88 Step:    50 /   793 Train loss: 0.02105695\r\n",
      "Epoch:  88 Step:    51 /   793 Train loss: 0.02687693\r\n",
      "Epoch:  88 Step:    52 /   793 Train loss: 0.03297403\r\n",
      "Epoch:  88 Step:    53 /   793 Train loss: 0.03349473\r\n",
      "Epoch:  88 Step:    54 /   793 Train loss: 0.02607521\r\n",
      "Epoch:  88 Step:    55 /   793 Train loss: 0.03482332\r\n",
      "Epoch:  88 Step:    56 /   793 Train loss: 0.02451137\r\n",
      "Epoch:  88 Step:    57 /   793 Train loss: 0.02786699\r\n",
      "Epoch:  88 Step:    58 /   793 Train loss: 0.02635898\r\n",
      "Epoch:  88 Step:    59 /   793 Train loss: 0.01530220\r\n",
      "Epoch:  88 Step:    60 /   793 Train loss: 0.02227736\r\n",
      "Epoch:  88 Step:    61 /   793 Train loss: 0.02616277\r\n",
      "Epoch:  88 Step:    62 /   793 Train loss: 0.01769254\r\n",
      "Epoch:  88 Step:    63 /   793 Train loss: 0.02466897\r\n",
      "Epoch:  88 Step:    64 /   793 Train loss: 0.02125913\r\n",
      "Epoch:  88 Step:    65 /   793 Train loss: 0.02813958\r\n",
      "Epoch:  88 Step:    66 /   793 Train loss: 0.02964630\r\n",
      "Epoch:  88 Step:    67 /   793 Train loss: 0.02583643\r\n",
      "Epoch:  88 Step:    68 /   793 Train loss: 0.02682496\r\n",
      "Epoch:  88 Step:    69 /   793 Train loss: 0.01601933\r\n",
      "Epoch:  88 Step:    70 /   793 Train loss: 0.03205046\r\n",
      "Epoch:  88 Step:    71 /   793 Train loss: 0.01760629\r\n",
      "Epoch:  88 Step:    72 /   793 Train loss: 0.04132239\r\n",
      "Epoch:  88 Step:    73 /   793 Train loss: 0.02372812\r\n",
      "Epoch:  88 Step:    74 /   793 Train loss: 0.02396144\r\n",
      "Epoch:  88 Step:    75 /   793 Train loss: 0.02737144\r\n",
      "Epoch:  88 Step:    76 /   793 Train loss: 0.02359752\r\n",
      "Epoch:  88 Step:    77 /   793 Train loss: 0.02212398\r\n",
      "Epoch:  88 Step:    78 /   793 Train loss: 0.01689081\r\n",
      "Epoch:  88 Step:    79 /   793 Train loss: 0.02411974\r\n",
      "Epoch:  88 Step:    80 /   793 Train loss: 0.02123363\r\n",
      "Epoch:  88 Step:    81 /   793 Train loss: 0.01855181\r\n",
      "Epoch:  88 Step:    82 /   793 Train loss: 0.01996200\r\n",
      "Epoch:  88 Step:    83 /   793 Train loss: 0.02555531\r\n",
      "Epoch:  88 Step:    84 /   793 Train loss: 0.04314229\r\n",
      "Epoch:  88 Step:    85 /   793 Train loss: 0.01727336\r\n",
      "Epoch:  88 Step:    86 /   793 Train loss: 0.01705214\r\n",
      "Epoch:  88 Step:    87 /   793 Train loss: 0.01693714\r\n",
      "Epoch:  88 Step:    88 /   793 Train loss: 0.01380869\r\n",
      "Epoch:  88 Step:    89 /   793 Train loss: 0.01827252\r\n",
      "Epoch:  88 Step:    90 /   793 Train loss: 0.04066860\r\n",
      "Epoch:  88 Step:    91 /   793 Train loss: 0.01871211\r\n",
      "Epoch:  88 Step:    92 /   793 Train loss: 0.02557293\r\n",
      "Epoch:  88 Step:    93 /   793 Train loss: 0.00851146\r\n",
      "Epoch:  88 Step:    94 /   793 Train loss: 0.02131324\r\n",
      "Epoch:  88 Step:    95 /   793 Train loss: 0.01256047\r\n",
      "Epoch:  88 Step:    96 /   793 Train loss: 0.03228950\r\n",
      "Epoch:  88 Step:    97 /   793 Train loss: 0.01883261\r\n",
      "Epoch:  88 Step:    98 /   793 Train loss: 0.02299168\r\n",
      "Epoch:  88 Step:    99 /   793 Train loss: 0.03127080\r\n",
      "Epoch:  88 Step:   100 /   793 Train loss: 0.02381480\r\n",
      "Epoch:  88 Step:   101 /   793 Train loss: 0.02234885\r\n",
      "Epoch:  88 Step:   102 /   793 Train loss: 0.01545311\r\n",
      "Epoch:  88 Step:   103 /   793 Train loss: 0.01603899\r\n",
      "Epoch:  88 Step:   104 /   793 Train loss: 0.03156403\r\n",
      "Epoch:  88 Step:   105 /   793 Train loss: 0.02854053\r\n",
      "Epoch:  88 Step:   106 /   793 Train loss: 0.03436068\r\n",
      "Epoch:  88 Step:   107 /   793 Train loss: 0.02867730\r\n",
      "Epoch:  88 Step:   108 /   793 Train loss: 0.03188635\r\n",
      "Epoch:  88 Step:   109 /   793 Train loss: 0.01758626\r\n",
      "Epoch:  88 Step:   110 /   793 Train loss: 0.01738875\r\n",
      "Epoch:  88 Step:   111 /   793 Train loss: 0.01870310\r\n",
      "Epoch:  88 Step:   112 /   793 Train loss: 0.02514320\r\n",
      "Epoch:  88 Step:   113 /   793 Train loss: 0.02816062\r\n",
      "Epoch:  88 Step:   114 /   793 Train loss: 0.01659451\r\n",
      "Epoch:  88 Step:   115 /   793 Train loss: 0.02150765\r\n",
      "Epoch:  88 Step:   116 /   793 Train loss: 0.02408481\r\n",
      "Epoch:  88 Step:   117 /   793 Train loss: 0.02599611\r\n",
      "Epoch:  88 Step:   118 /   793 Train loss: 0.02009789\r\n",
      "Epoch:  88 Step:   119 /   793 Train loss: 0.02833495\r\n",
      "Epoch:  88 Step:   120 /   793 Train loss: 0.01816085\r\n",
      "Epoch:  88 Step:   121 /   793 Train loss: 0.02525933\r\n",
      "Epoch:  88 Step:   122 /   793 Train loss: 0.03269537\r\n",
      "Epoch:  88 Step:   123 /   793 Train loss: 0.03060683\r\n",
      "Epoch:  88 Step:   124 /   793 Train loss: 0.01766577\r\n",
      "Epoch:  88 Step:   125 /   793 Train loss: 0.03031973\r\n",
      "Epoch:  88 Step:   126 /   793 Train loss: 0.02318855\r\n",
      "Epoch:  88 Step:   127 /   793 Train loss: 0.03012203\r\n",
      "Epoch:  88 Step:   128 /   793 Train loss: 0.02381827\r\n",
      "Epoch:  88 Step:   129 /   793 Train loss: 0.02802458\r\n",
      "Epoch:  88 Step:   130 /   793 Train loss: 0.02633431\r\n",
      "Epoch:  88 Step:   131 /   793 Train loss: 0.01904647\r\n",
      "Epoch:  88 Step:   132 /   793 Train loss: 0.03559800\r\n",
      "Epoch:  88 Step:   133 /   793 Train loss: 0.01585652\r\n",
      "Epoch:  88 Step:   134 /   793 Train loss: 0.02490065\r\n",
      "Epoch:  88 Step:   135 /   793 Train loss: 0.02398011\r\n",
      "Epoch:  88 Step:   136 /   793 Train loss: 0.02804310\r\n",
      "Epoch:  88 Step:   137 /   793 Train loss: 0.03128141\r\n",
      "Epoch:  88 Step:   138 /   793 Train loss: 0.01723127\r\n",
      "Epoch:  88 Step:   139 /   793 Train loss: 0.02290188\r\n",
      "Epoch:  88 Step:   140 /   793 Train loss: 0.02351033\r\n",
      "Epoch:  88 Step:   141 /   793 Train loss: 0.02209256\r\n",
      "Epoch:  88 Step:   142 /   793 Train loss: 0.01900882\r\n",
      "Epoch:  88 Step:   143 /   793 Train loss: 0.02352289\r\n",
      "Epoch:  88 Step:   144 /   793 Train loss: 0.03160052\r\n",
      "Epoch:  88 Step:   145 /   793 Train loss: 0.01501967\r\n",
      "Epoch:  88 Step:   146 /   793 Train loss: 0.02184539\r\n",
      "Epoch:  88 Step:   147 /   793 Train loss: 0.02827245\r\n",
      "Epoch:  88 Step:   148 /   793 Train loss: 0.02653480\r\n",
      "Epoch:  88 Step:   149 /   793 Train loss: 0.02546664\r\n",
      "Epoch:  88 Step:   150 /   793 Train loss: 0.02446812\r\n",
      "Epoch:  88 Step:   151 /   793 Train loss: 0.02251840\r\n",
      "Epoch:  88 Step:   152 /   793 Train loss: 0.01785747\r\n",
      "Epoch:  88 Step:   153 /   793 Train loss: 0.02105390\r\n",
      "Epoch:  88 Step:   154 /   793 Train loss: 0.02162041\r\n",
      "Epoch:  88 Step:   155 /   793 Train loss: 0.02346991\r\n",
      "Epoch:  88 Step:   156 /   793 Train loss: 0.02556530\r\n",
      "Epoch:  88 Step:   157 /   793 Train loss: 0.02700815\r\n",
      "Epoch:  88 Step:   158 /   793 Train loss: 0.02092016\r\n",
      "Epoch:  88 Step:   159 /   793 Train loss: 0.01672467\r\n",
      "Epoch:  88 Step:   160 /   793 Train loss: 0.02504109\r\n",
      "Epoch:  88 Step:   161 /   793 Train loss: 0.03413487\r\n",
      "Epoch:  88 Step:   162 /   793 Train loss: 0.03028233\r\n",
      "Epoch:  88 Step:   163 /   793 Train loss: 0.01950663\r\n",
      "Epoch:  88 Step:   164 /   793 Train loss: 0.02543800\r\n",
      "Epoch:  88 Step:   165 /   793 Train loss: 0.03967765\r\n",
      "Epoch:  88 Step:   166 /   793 Train loss: 0.03146722\r\n",
      "Epoch:  88 Step:   167 /   793 Train loss: 0.01622149\r\n",
      "Epoch:  88 Step:   168 /   793 Train loss: 0.03611031\r\n",
      "Epoch:  88 Step:   169 /   793 Train loss: 0.01126844\r\n",
      "Epoch:  88 Step:   170 /   793 Train loss: 0.03578207\r\n",
      "Epoch:  88 Step:   171 /   793 Train loss: 0.01877078\r\n",
      "Epoch:  88 Step:   172 /   793 Train loss: 0.02272061\r\n",
      "Epoch:  88 Step:   173 /   793 Train loss: 0.01210698\r\n",
      "Epoch:  88 Step:   174 /   793 Train loss: 0.03316217\r\n",
      "Epoch:  88 Step:   175 /   793 Train loss: 0.03682423\r\n",
      "Epoch:  88 Step:   176 /   793 Train loss: 0.02860060\r\n",
      "Epoch:  88 Step:   177 /   793 Train loss: 0.02391893\r\n",
      "Epoch:  88 Step:   178 /   793 Train loss: 0.03247169\r\n",
      "Epoch:  88 Step:   179 /   793 Train loss: 0.01365606\r\n",
      "Epoch:  88 Step:   180 /   793 Train loss: 0.01769933\r\n",
      "Epoch:  88 Step:   181 /   793 Train loss: 0.01435784\r\n",
      "Epoch:  88 Step:   182 /   793 Train loss: 0.02466264\r\n",
      "Epoch:  88 Step:   183 /   793 Train loss: 0.04014131\r\n",
      "Epoch:  88 Step:   184 /   793 Train loss: 0.03234298\r\n",
      "Epoch:  88 Step:   185 /   793 Train loss: 0.02574371\r\n",
      "Epoch:  88 Step:   186 /   793 Train loss: 0.01831789\r\n",
      "Epoch:  88 Step:   187 /   793 Train loss: 0.02094289\r\n",
      "Epoch:  88 Step:   188 /   793 Train loss: 0.02803970\r\n",
      "Epoch:  88 Step:   189 /   793 Train loss: 0.03375344\r\n",
      "Epoch:  88 Step:   190 /   793 Train loss: 0.03499952\r\n",
      "Epoch:  88 Step:   191 /   793 Train loss: 0.01718218\r\n",
      "Epoch:  88 Step:   192 /   793 Train loss: 0.04198517\r\n",
      "Epoch:  88 Step:   193 /   793 Train loss: 0.01217126\r\n",
      "Epoch:  88 Step:   194 /   793 Train loss: 0.02624281\r\n",
      "Epoch:  88 Step:   195 /   793 Train loss: 0.01586929\r\n",
      "Epoch:  88 Step:   196 /   793 Train loss: 0.04629866\r\n",
      "Epoch:  88 Step:   197 /   793 Train loss: 0.03484284\r\n",
      "Epoch:  88 Step:   198 /   793 Train loss: 0.02410205\r\n",
      "Epoch:  88 Step:   199 /   793 Train loss: 0.02444302\r\n",
      "Epoch:  88 Step:   200 /   793 Train loss: 0.02331421\r\n",
      "Epoch:  88 Step:   201 /   793 Train loss: 0.02846798\r\n",
      "Epoch:  88 Step:   202 /   793 Train loss: 0.03283281\r\n",
      "Epoch:  88 Step:   203 /   793 Train loss: 0.02697502\r\n",
      "Epoch:  88 Step:   204 /   793 Train loss: 0.02732902\r\n",
      "Epoch:  88 Step:   205 /   793 Train loss: 0.02036238\r\n",
      "Epoch:  88 Step:   206 /   793 Train loss: 0.03004039\r\n",
      "Epoch:  88 Step:   207 /   793 Train loss: 0.01815515\r\n",
      "Epoch:  88 Step:   208 /   793 Train loss: 0.03492223\r\n",
      "Epoch:  88 Step:   209 /   793 Train loss: 0.02041026\r\n",
      "Epoch:  88 Step:   210 /   793 Train loss: 0.02124588\r\n",
      "Epoch:  88 Step:   211 /   793 Train loss: 0.02066297\r\n",
      "Epoch:  88 Step:   212 /   793 Train loss: 0.03488583\r\n",
      "Epoch:  88 Step:   213 /   793 Train loss: 0.03141995\r\n",
      "Epoch:  88 Step:   214 /   793 Train loss: 0.03213952\r\n",
      "Epoch:  88 Step:   215 /   793 Train loss: 0.01398648\r\n",
      "Epoch:  88 Step:   216 /   793 Train loss: 0.02001320\r\n",
      "Epoch:  88 Step:   217 /   793 Train loss: 0.02488555\r\n",
      "Epoch:  88 Step:   218 /   793 Train loss: 0.01540322\r\n",
      "Epoch:  88 Step:   219 /   793 Train loss: 0.01202437\r\n",
      "Epoch:  88 Step:   220 /   793 Train loss: 0.01775400\r\n",
      "Epoch:  88 Step:   221 /   793 Train loss: 0.02566988\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  88 Step:   222 /   793 Train loss: 0.02763744\r\n",
      "Epoch:  88 Step:   223 /   793 Train loss: 0.03023817\r\n",
      "Epoch:  88 Step:   224 /   793 Train loss: 0.02819636\r\n",
      "Epoch:  88 Step:   225 /   793 Train loss: 0.02292051\r\n",
      "Epoch:  88 Step:   226 /   793 Train loss: 0.01981388\r\n",
      "Epoch:  88 Step:   227 /   793 Train loss: 0.02741249\r\n",
      "Epoch:  88 Step:   228 /   793 Train loss: 0.02185266\r\n",
      "Epoch:  88 Step:   229 /   793 Train loss: 0.03255267\r\n",
      "Epoch:  88 Step:   230 /   793 Train loss: 0.01873909\r\n",
      "Epoch:  88 Step:   231 /   793 Train loss: 0.03879081\r\n",
      "Epoch:  88 Step:   232 /   793 Train loss: 0.02097638\r\n",
      "Epoch:  88 Step:   233 /   793 Train loss: 0.02748436\r\n",
      "Epoch:  88 Step:   234 /   793 Train loss: 0.02428595\r\n",
      "Epoch:  88 Step:   235 /   793 Train loss: 0.01988946\r\n",
      "Epoch:  88 Step:   236 /   793 Train loss: 0.01335507\r\n",
      "Epoch:  88 Step:   237 /   793 Train loss: 0.03220535\r\n",
      "Epoch:  88 Step:   238 /   793 Train loss: 0.02132236\r\n",
      "Epoch:  88 Step:   239 /   793 Train loss: 0.02411425\r\n",
      "Epoch:  88 Step:   240 /   793 Train loss: 0.02129769\r\n",
      "Epoch:  88 Step:   241 /   793 Train loss: 0.02494004\r\n",
      "Epoch:  88 Step:   242 /   793 Train loss: 0.01522703\r\n",
      "Epoch:  88 Step:   243 /   793 Train loss: 0.02335462\r\n",
      "Epoch:  88 Step:   244 /   793 Train loss: 0.02877947\r\n",
      "Epoch:  88 Step:   245 /   793 Train loss: 0.02654454\r\n",
      "Epoch:  88 Step:   246 /   793 Train loss: 0.01958696\r\n",
      "Epoch:  88 Step:   247 /   793 Train loss: 0.02559010\r\n",
      "Epoch:  88 Step:   248 /   793 Train loss: 0.02237209\r\n",
      "Epoch:  88 Step:   249 /   793 Train loss: 0.02230844\r\n",
      "Epoch:  88 Step:   250 /   793 Train loss: 0.02387412\r\n",
      "Epoch:  88 Step:   251 /   793 Train loss: 0.02682773\r\n",
      "Epoch:  88 Step:   252 /   793 Train loss: 0.02327891\r\n",
      "Epoch:  88 Step:   253 /   793 Train loss: 0.02888683\r\n",
      "Epoch:  88 Step:   254 /   793 Train loss: 0.02232068\r\n",
      "Epoch:  88 Step:   255 /   793 Train loss: 0.02970102\r\n",
      "Epoch:  88 Step:   256 /   793 Train loss: 0.02496207\r\n",
      "Epoch:  88 Step:   257 /   793 Train loss: 0.02989398\r\n",
      "Epoch:  88 Step:   258 /   793 Train loss: 0.01591298\r\n",
      "Epoch:  88 Step:   259 /   793 Train loss: 0.01409757\r\n",
      "Epoch:  88 Step:   260 /   793 Train loss: 0.01900514\r\n",
      "Epoch:  88 Step:   261 /   793 Train loss: 0.02428901\r\n",
      "Epoch:  88 Step:   262 /   793 Train loss: 0.02655567\r\n",
      "Epoch:  88 Step:   263 /   793 Train loss: 0.01795924\r\n",
      "Epoch:  88 Step:   264 /   793 Train loss: 0.02353366\r\n",
      "Epoch:  88 Step:   265 /   793 Train loss: 0.01864977\r\n",
      "Epoch:  88 Step:   266 /   793 Train loss: 0.01989480\r\n",
      "Epoch:  88 Step:   267 /   793 Train loss: 0.02389996\r\n",
      "Epoch:  88 Step:   268 /   793 Train loss: 0.01789951\r\n",
      "Epoch:  88 Step:   269 /   793 Train loss: 0.02818562\r\n",
      "Epoch:  88 Step:   270 /   793 Train loss: 0.02121125\r\n",
      "Epoch:  88 Step:   271 /   793 Train loss: 0.02863174\r\n",
      "Epoch:  88 Step:   272 /   793 Train loss: 0.02640468\r\n",
      "Epoch:  88 Step:   273 /   793 Train loss: 0.01745778\r\n",
      "Epoch:  88 Step:   274 /   793 Train loss: 0.02909042\r\n",
      "Epoch:  88 Step:   275 /   793 Train loss: 0.01950462\r\n",
      "Epoch:  88 Step:   276 /   793 Train loss: 0.02217067\r\n",
      "Epoch:  88 Step:   277 /   793 Train loss: 0.04153941\r\n",
      "Epoch:  88 Step:   278 /   793 Train loss: 0.02516298\r\n",
      "Epoch:  88 Step:   279 /   793 Train loss: 0.03411399\r\n",
      "Epoch:  88 Step:   280 /   793 Train loss: 0.03114238\r\n",
      "Epoch:  88 Step:   281 /   793 Train loss: 0.02470700\r\n",
      "Epoch:  88 Step:   282 /   793 Train loss: 0.02304620\r\n",
      "Epoch:  88 Step:   283 /   793 Train loss: 0.02910893\r\n",
      "Epoch:  88 Step:   284 /   793 Train loss: 0.01050515\r\n",
      "Epoch:  88 Step:   285 /   793 Train loss: 0.02186195\r\n",
      "Epoch:  88 Step:   286 /   793 Train loss: 0.01983592\r\n",
      "Epoch:  88 Step:   287 /   793 Train loss: 0.02864349\r\n",
      "Epoch:  88 Step:   288 /   793 Train loss: 0.02029377\r\n",
      "Epoch:  88 Step:   289 /   793 Train loss: 0.01952999\r\n",
      "Epoch:  88 Step:   290 /   793 Train loss: 0.01881380\r\n",
      "Epoch:  88 Step:   291 /   793 Train loss: 0.01803301\r\n",
      "Epoch:  88 Step:   292 /   793 Train loss: 0.02978150\r\n",
      "Epoch:  88 Step:   293 /   793 Train loss: 0.03168039\r\n",
      "Epoch:  88 Step:   294 /   793 Train loss: 0.02906181\r\n",
      "Epoch:  88 Step:   295 /   793 Train loss: 0.02769437\r\n",
      "Epoch:  88 Step:   296 /   793 Train loss: 0.02438967\r\n",
      "Epoch:  88 Step:   297 /   793 Train loss: 0.02449508\r\n",
      "Epoch:  88 Step:   298 /   793 Train loss: 0.02768242\r\n",
      "Epoch:  88 Step:   299 /   793 Train loss: 0.03756348\r\n",
      "Epoch:  88 Step:   300 /   793 Train loss: 0.01203759\r\n",
      "Epoch:  88 Step:   301 /   793 Train loss: 0.02186581\r\n",
      "Epoch:  88 Step:   302 /   793 Train loss: 0.03344244\r\n",
      "Epoch:  88 Step:   303 /   793 Train loss: 0.01660773\r\n",
      "Epoch:  88 Step:   304 /   793 Train loss: 0.02441251\r\n",
      "Epoch:  88 Step:   305 /   793 Train loss: 0.01239621\r\n",
      "Epoch:  88 Step:   306 /   793 Train loss: 0.02441312\r\n",
      "Epoch:  88 Step:   307 /   793 Train loss: 0.02694730\r\n",
      "Epoch:  88 Step:   308 /   793 Train loss: 0.02685057\r\n",
      "Epoch:  88 Step:   309 /   793 Train loss: 0.01305925\r\n",
      "Epoch:  88 Step:   310 /   793 Train loss: 0.02237801\r\n",
      "Epoch:  88 Step:   311 /   793 Train loss: 0.01205316\r\n",
      "Epoch:  88 Step:   312 /   793 Train loss: 0.03370827\r\n",
      "Epoch:  88 Step:   313 /   793 Train loss: 0.01881664\r\n",
      "Epoch:  88 Step:   314 /   793 Train loss: 0.02762118\r\n",
      "Epoch:  88 Step:   315 /   793 Train loss: 0.02725014\r\n",
      "Epoch:  88 Step:   316 /   793 Train loss: 0.03345602\r\n",
      "Epoch:  88 Step:   317 /   793 Train loss: 0.02696488\r\n",
      "Epoch:  88 Step:   318 /   793 Train loss: 0.02743331\r\n",
      "Epoch:  88 Step:   319 /   793 Train loss: 0.03334621\r\n",
      "Epoch:  88 Step:   320 /   793 Train loss: 0.01275385\r\n",
      "Epoch:  88 Step:   321 /   793 Train loss: 0.02076498\r\n",
      "Epoch:  88 Step:   322 /   793 Train loss: 0.02574914\r\n",
      "Epoch:  88 Step:   323 /   793 Train loss: 0.02230299\r\n",
      "Epoch:  88 Step:   324 /   793 Train loss: 0.04269032\r\n",
      "Epoch:  88 Step:   325 /   793 Train loss: 0.01886415\r\n",
      "Epoch:  88 Step:   326 /   793 Train loss: 0.02402223\r\n",
      "Epoch:  88 Step:   327 /   793 Train loss: 0.01460380\r\n",
      "Epoch:  88 Step:   328 /   793 Train loss: 0.02717071\r\n",
      "Epoch:  88 Step:   329 /   793 Train loss: 0.03320978\r\n",
      "Epoch:  88 Step:   330 /   793 Train loss: 0.03225596\r\n",
      "Epoch:  88 Step:   331 /   793 Train loss: 0.03181692\r\n",
      "Epoch:  88 Step:   332 /   793 Train loss: 0.02119181\r\n",
      "Epoch:  88 Step:   333 /   793 Train loss: 0.02111204\r\n",
      "Epoch:  88 Step:   334 /   793 Train loss: 0.01081730\r\n",
      "Epoch:  88 Step:   335 /   793 Train loss: 0.01572274\r\n",
      "Epoch:  88 Step:   336 /   793 Train loss: 0.02549180\r\n",
      "Epoch:  88 Step:   337 /   793 Train loss: 0.03664324\r\n",
      "Epoch:  88 Step:   338 /   793 Train loss: 0.02248003\r\n",
      "Epoch:  88 Step:   339 /   793 Train loss: 0.02291266\r\n",
      "Epoch:  88 Step:   340 /   793 Train loss: 0.01969249\r\n",
      "Epoch:  88 Step:   341 /   793 Train loss: 0.02897607\r\n",
      "Epoch:  88 Step:   342 /   793 Train loss: 0.03349857\r\n",
      "Epoch:  88 Step:   343 /   793 Train loss: 0.02385436\r\n",
      "Epoch:  88 Step:   344 /   793 Train loss: 0.01687563\r\n",
      "Epoch:  88 Step:   345 /   793 Train loss: 0.02258880\r\n",
      "Epoch:  88 Step:   346 /   793 Train loss: 0.03100979\r\n",
      "Epoch:  88 Step:   347 /   793 Train loss: 0.03781093\r\n",
      "Epoch:  88 Step:   348 /   793 Train loss: 0.01758343\r\n",
      "Epoch:  88 Step:   349 /   793 Train loss: 0.03229259\r\n",
      "Epoch:  88 Step:   350 /   793 Train loss: 0.01630554\r\n",
      "Epoch:  88 Step:   351 /   793 Train loss: 0.02916697\r\n",
      "Epoch:  88 Step:   352 /   793 Train loss: 0.01444738\r\n",
      "Epoch:  88 Step:   353 /   793 Train loss: 0.01671273\r\n",
      "Epoch:  88 Step:   354 /   793 Train loss: 0.02477866\r\n",
      "Epoch:  88 Step:   355 /   793 Train loss: 0.01817956\r\n",
      "Epoch:  88 Step:   356 /   793 Train loss: 0.02621244\r\n",
      "Epoch:  88 Step:   357 /   793 Train loss: 0.01982509\r\n",
      "Epoch:  88 Step:   358 /   793 Train loss: 0.01533269\r\n",
      "Epoch:  88 Step:   359 /   793 Train loss: 0.01492371\r\n",
      "Epoch:  88 Step:   360 /   793 Train loss: 0.01875751\r\n",
      "Epoch:  88 Step:   361 /   793 Train loss: 0.02556578\r\n",
      "Epoch:  88 Step:   362 /   793 Train loss: 0.02075046\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  88 Step:   363 /   793 Train loss: 0.01639492\r\n",
      "Epoch:  88 Step:   364 /   793 Train loss: 0.01192071\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  88 Step:   365 /   793 Train loss: 0.01797828\r\n",
      "Epoch:  88 Step:   366 /   793 Train loss: 0.01508146\r\n",
      "Epoch:  88 Step:   367 /   793 Train loss: 0.02698025\r\n",
      "Epoch:  88 Step:   368 /   793 Train loss: 0.01406775\r\n",
      "Epoch:  88 Step:   369 /   793 Train loss: 0.03135233\r\n",
      "Epoch:  88 Step:   370 /   793 Train loss: 0.02167028\r\n",
      "Epoch:  88 Step:   371 /   793 Train loss: 0.01856680\r\n",
      "Epoch:  88 Step:   372 /   793 Train loss: 0.02660317\r\n",
      "Epoch:  88 Step:   373 /   793 Train loss: 0.03843553\r\n",
      "Epoch:  88 Step:   374 /   793 Train loss: 0.01689084\r\n",
      "Epoch:  88 Step:   375 /   793 Train loss: 0.02480575\r\n",
      "Epoch:  88 Step:   376 /   793 Train loss: 0.01311886\r\n",
      "Epoch:  88 Step:   377 /   793 Train loss: 0.02483926\r\n",
      "Epoch:  88 Step:   378 /   793 Train loss: 0.01912571\r\n",
      "Epoch:  88 Step:   379 /   793 Train loss: 0.02867064\r\n",
      "Epoch:  88 Step:   380 /   793 Train loss: 0.02013079\r\n",
      "Epoch:  88 Step:   381 /   793 Train loss: 0.01944592\r\n",
      "Epoch:  88 Step:   382 /   793 Train loss: 0.02705990\r\n",
      "Epoch:  88 Step:   383 /   793 Train loss: 0.03348240\r\n",
      "Epoch:  88 Step:   384 /   793 Train loss: 0.02205485\r\n",
      "Epoch:  88 Step:   385 /   793 Train loss: 0.01705224\r\n",
      "Epoch:  88 Step:   386 /   793 Train loss: 0.02744252\r\n",
      "Epoch:  88 Step:   387 /   793 Train loss: 0.02925473\r\n",
      "Epoch:  88 Step:   388 /   793 Train loss: 0.02010200\r\n",
      "Epoch:  88 Step:   389 /   793 Train loss: 0.03102769\r\n",
      "Epoch:  88 Step:   390 /   793 Train loss: 0.02391208\r\n",
      "Epoch:  88 Step:   391 /   793 Train loss: 0.01962012\r\n",
      "Epoch:  88 Step:   392 /   793 Train loss: 0.03857496\r\n",
      "Epoch:  88 Step:   393 /   793 Train loss: 0.02958152\r\n",
      "Epoch:  88 Step:   394 /   793 Train loss: 0.03888963\r\n",
      "Epoch:  88 Step:   395 /   793 Train loss: 0.02093094\r\n",
      "Epoch:  88 Step:   396 /   793 Train loss: 0.02713024\r\n",
      "Epoch:  88 Step:   397 /   793 Train loss: 0.01718737\r\n",
      "Epoch:  88 Step:   398 /   793 Train loss: 0.03420649\r\n",
      "Epoch:  88 Step:   399 /   793 Train loss: 0.02071245\r\n",
      "Epoch:  88 Step:   400 /   793 Train loss: 0.01921135\r\n",
      "Epoch:  88 Step:   401 /   793 Train loss: 0.02858228\r\n",
      "Epoch:  88 Step:   402 /   793 Train loss: 0.02097857\r\n",
      "Epoch:  88 Step:   403 /   793 Train loss: 0.03588493\r\n",
      "Epoch:  88 Step:   404 /   793 Train loss: 0.02084382\r\n",
      "Epoch:  88 Step:   405 /   793 Train loss: 0.02920062\r\n",
      "Epoch:  88 Step:   406 /   793 Train loss: 0.02935889\r\n",
      "Epoch:  88 Step:   407 /   793 Train loss: 0.03098551\r\n",
      "Epoch:  88 Step:   408 /   793 Train loss: 0.02263626\r\n",
      "Epoch:  88 Step:   409 /   793 Train loss: 0.01579207\r\n",
      "Epoch:  88 Step:   410 /   793 Train loss: 0.02635419\r\n",
      "Epoch:  88 Step:   411 /   793 Train loss: 0.01711328\r\n",
      "Epoch:  88 Step:   412 /   793 Train loss: 0.02115200\r\n",
      "Epoch:  88 Step:   413 /   793 Train loss: 0.01970108\r\n",
      "Epoch:  88 Step:   414 /   793 Train loss: 0.01532499\r\n",
      "Epoch:  88 Step:   415 /   793 Train loss: 0.02037918\r\n",
      "Epoch:  88 Step:   416 /   793 Train loss: 0.01162213\r\n",
      "Epoch:  88 Step:   417 /   793 Train loss: 0.01823670\r\n",
      "Epoch:  88 Step:   418 /   793 Train loss: 0.02115314\r\n",
      "Epoch:  88 Step:   419 /   793 Train loss: 0.01736396\r\n",
      "Epoch:  88 Step:   420 /   793 Train loss: 0.02249561\r\n",
      "Epoch:  88 Step:   421 /   793 Train loss: 0.02685798\r\n",
      "Epoch:  88 Step:   422 /   793 Train loss: 0.03100761\r\n",
      "Epoch:  88 Step:   423 /   793 Train loss: 0.02026465\r\n",
      "Epoch:  88 Step:   424 /   793 Train loss: 0.01857520\r\n",
      "Epoch:  88 Step:   425 /   793 Train loss: 0.02520289\r\n",
      "Epoch:  88 Step:   426 /   793 Train loss: 0.02747193\r\n",
      "Epoch:  88 Step:   427 /   793 Train loss: 0.02073688\r\n",
      "Epoch:  88 Step:   428 /   793 Train loss: 0.02607025\r\n",
      "Epoch:  88 Step:   429 /   793 Train loss: 0.01775832\r\n",
      "Epoch:  88 Step:   430 /   793 Train loss: 0.01867938\r\n",
      "Epoch:  88 Step:   431 /   793 Train loss: 0.02914529\r\n",
      "Epoch:  88 Step:   432 /   793 Train loss: 0.02634245\r\n",
      "Epoch:  88 Step:   433 /   793 Train loss: 0.01821605\r\n",
      "Epoch:  88 Step:   434 /   793 Train loss: 0.02767102\r\n",
      "Epoch:  88 Step:   435 /   793 Train loss: 0.02052814\r\n",
      "Epoch:  88 Step:   436 /   793 Train loss: 0.01681989\r\n",
      "Epoch:  88 Step:   437 /   793 Train loss: 0.02259809\r\n",
      "Epoch:  88 Step:   438 /   793 Train loss: 0.02191988\r\n",
      "Epoch:  88 Step:   439 /   793 Train loss: 0.02346781\r\n",
      "Epoch:  88 Step:   440 /   793 Train loss: 0.01598861\r\n",
      "Epoch:  88 Step:   441 /   793 Train loss: 0.01704782\r\n",
      "Epoch:  88 Step:   442 /   793 Train loss: 0.02139063\r\n",
      "Epoch:  88 Step:   443 /   793 Train loss: 0.02963469\r\n",
      "Epoch:  88 Step:   444 /   793 Train loss: 0.02872872\r\n",
      "Epoch:  88 Step:   445 /   793 Train loss: 0.02447648\r\n",
      "Epoch:  88 Step:   446 /   793 Train loss: 0.02831435\r\n",
      "Epoch:  88 Step:   447 /   793 Train loss: 0.02091102\r\n",
      "Epoch:  88 Step:   448 /   793 Train loss: 0.02073878\r\n",
      "Epoch:  88 Step:   449 /   793 Train loss: 0.03452786\r\n",
      "Epoch:  88 Step:   450 /   793 Train loss: 0.03730635\r\n",
      "Epoch:  88 Step:   451 /   793 Train loss: 0.03628420\r\n",
      "Epoch:  88 Step:   452 /   793 Train loss: 0.03314288\r\n",
      "Epoch:  88 Step:   453 /   793 Train loss: 0.01414411\r\n",
      "Epoch:  88 Step:   454 /   793 Train loss: 0.01855842\r\n",
      "Epoch:  88 Step:   455 /   793 Train loss: 0.02148124\r\n",
      "Epoch:  88 Step:   456 /   793 Train loss: 0.02067018\r\n",
      "Epoch:  88 Step:   457 /   793 Train loss: 0.03459286\r\n",
      "Epoch:  88 Step:   458 /   793 Train loss: 0.02488961\r\n",
      "Epoch:  88 Step:   459 /   793 Train loss: 0.02719991\r\n",
      "Epoch:  88 Step:   460 /   793 Train loss: 0.02733446\r\n",
      "Epoch:  88 Step:   461 /   793 Train loss: 0.01455057\r\n",
      "Epoch:  88 Step:   462 /   793 Train loss: 0.02374199\r\n",
      "Epoch:  88 Step:   463 /   793 Train loss: 0.01739107\r\n",
      "Epoch:  88 Step:   464 /   793 Train loss: 0.01766806\r\n",
      "Epoch:  88 Step:   465 /   793 Train loss: 0.01894693\r\n",
      "Epoch:  88 Step:   466 /   793 Train loss: 0.01464484\r\n",
      "Epoch:  88 Step:   467 /   793 Train loss: 0.01799719\r\n",
      "Epoch:  88 Step:   468 /   793 Train loss: 0.02129134\r\n",
      "Epoch:  88 Step:   469 /   793 Train loss: 0.02247782\r\n",
      "Epoch:  88 Step:   470 /   793 Train loss: 0.02667009\r\n",
      "Epoch:  88 Step:   471 /   793 Train loss: 0.02479429\r\n",
      "Epoch:  88 Step:   472 /   793 Train loss: 0.03075838\r\n",
      "Epoch:  88 Step:   473 /   793 Train loss: 0.02594895\r\n",
      "Epoch:  88 Step:   474 /   793 Train loss: 0.03586740\r\n",
      "Epoch:  88 Step:   475 /   793 Train loss: 0.03127669\r\n",
      "Epoch:  88 Step:   476 /   793 Train loss: 0.03348036\r\n",
      "Epoch:  88 Step:   477 /   793 Train loss: 0.02469370\r\n",
      "Epoch:  88 Step:   478 /   793 Train loss: 0.04060309\r\n",
      "Epoch:  88 Step:   479 /   793 Train loss: 0.02308359\r\n",
      "Epoch:  88 Step:   480 /   793 Train loss: 0.02557708\r\n",
      "Epoch:  88 Step:   481 /   793 Train loss: 0.02826141\r\n",
      "Epoch:  88 Step:   482 /   793 Train loss: 0.01986722\r\n",
      "Epoch:  88 Step:   483 /   793 Train loss: 0.02526262\r\n",
      "Epoch:  88 Step:   484 /   793 Train loss: 0.01859045\r\n",
      "Epoch:  88 Step:   485 /   793 Train loss: 0.01135841\r\n",
      "Epoch:  88 Step:   486 /   793 Train loss: 0.01604473\r\n",
      "Epoch:  88 Step:   487 /   793 Train loss: 0.01669462\r\n",
      "Epoch:  88 Step:   488 /   793 Train loss: 0.01781712\r\n",
      "Epoch:  88 Step:   489 /   793 Train loss: 0.01848718\r\n",
      "Epoch:  88 Step:   490 /   793 Train loss: 0.02278101\r\n",
      "Epoch:  88 Step:   491 /   793 Train loss: 0.02332387\r\n",
      "Epoch:  88 Step:   492 /   793 Train loss: 0.02155987\r\n",
      "Epoch:  88 Step:   493 /   793 Train loss: 0.02435885\r\n",
      "Epoch:  88 Step:   494 /   793 Train loss: 0.01917424\r\n",
      "Epoch:  88 Step:   495 /   793 Train loss: 0.01977873\r\n",
      "Epoch:  88 Step:   496 /   793 Train loss: 0.02178922\r\n",
      "Epoch:  88 Step:   497 /   793 Train loss: 0.01655256\r\n",
      "Epoch:  88 Step:   498 /   793 Train loss: 0.02263121\r\n",
      "Epoch:  88 Step:   499 /   793 Train loss: 0.01879945\r\n",
      "Epoch:  88 Step:   500 /   793 Train loss: 0.01768344\r\n",
      "Epoch:  88 Step:   501 /   793 Train loss: 0.03298416\r\n",
      "Epoch:  88 Step:   502 /   793 Train loss: 0.03203562\r\n",
      "Epoch:  88 Step:   503 /   793 Train loss: 0.04461443\r\n",
      "Epoch:  88 Step:   504 /   793 Train loss: 0.02355679\r\n",
      "Epoch:  88 Step:   505 /   793 Train loss: 0.02447065\r\n",
      "Epoch:  88 Step:   506 /   793 Train loss: 0.02474661\r\n",
      "Epoch:  88 Step:   507 /   793 Train loss: 0.03067986\r\n",
      "Epoch:  88 Step:   508 /   793 Train loss: 0.02560489\r\n",
      "Epoch:  88 Step:   509 /   793 Train loss: 0.02230079\r\n",
      "Epoch:  88 Step:   510 /   793 Train loss: 0.01835646\r\n",
      "Epoch:  88 Step:   511 /   793 Train loss: 0.02249781\r\n",
      "Epoch:  88 Step:   512 /   793 Train loss: 0.03444340\r\n",
      "Epoch:  88 Step:   513 /   793 Train loss: 0.02522814\r\n",
      "Epoch:  88 Step:   514 /   793 Train loss: 0.02959112\r\n",
      "Epoch:  88 Step:   515 /   793 Train loss: 0.02485884\r\n",
      "Epoch:  88 Step:   516 /   793 Train loss: 0.01863384\r\n",
      "Epoch:  88 Step:   517 /   793 Train loss: 0.02401938\r\n",
      "Epoch:  88 Step:   518 /   793 Train loss: 0.01410329\r\n",
      "Epoch:  88 Step:   519 /   793 Train loss: 0.01834308\r\n",
      "Epoch:  88 Step:   520 /   793 Train loss: 0.00819469\r\n",
      "Epoch:  88 Step:   521 /   793 Train loss: 0.02486662\r\n",
      "Epoch:  88 Step:   522 /   793 Train loss: 0.01625535\r\n",
      "Epoch:  88 Step:   523 /   793 Train loss: 0.02903529\r\n",
      "Epoch:  88 Step:   524 /   793 Train loss: 0.01829188\r\n",
      "Epoch:  88 Step:   525 /   793 Train loss: 0.01685675\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  88 Step:   526 /   793 Train loss: 0.02065130\r\n",
      "Epoch:  88 Step:   527 /   793 Train loss: 0.02008490\r\n",
      "Epoch:  88 Step:   528 /   793 Train loss: 0.02371181\r\n",
      "Epoch:  88 Step:   529 /   793 Train loss: 0.02302826\r\n",
      "Epoch:  88 Step:   530 /   793 Train loss: 0.02017459\r\n",
      "Epoch:  88 Step:   531 /   793 Train loss: 0.02962844\r\n",
      "Epoch:  88 Step:   532 /   793 Train loss: 0.01752032\r\n",
      "Epoch:  88 Step:   533 /   793 Train loss: 0.02992810\r\n",
      "Epoch:  88 Step:   534 /   793 Train loss: 0.02132265\r\n",
      "Epoch:  88 Step:   535 /   793 Train loss: 0.01983053\r\n",
      "Epoch:  88 Step:   536 /   793 Train loss: 0.02303072\r\n",
      "Epoch:  88 Step:   537 /   793 Train loss: 0.01692714\r\n",
      "Epoch:  88 Step:   538 /   793 Train loss: 0.01927379\r\n",
      "Epoch:  88 Step:   539 /   793 Train loss: 0.01165914\r\n",
      "Epoch:  88 Step:   540 /   793 Train loss: 0.03502228\r\n",
      "Epoch:  88 Step:   541 /   793 Train loss: 0.02830101\r\n",
      "Epoch:  88 Step:   542 /   793 Train loss: 0.04446859\r\n",
      "Epoch:  88 Step:   543 /   793 Train loss: 0.02950617\r\n",
      "Epoch:  88 Step:   544 /   793 Train loss: 0.02438873\r\n",
      "Epoch:  88 Step:   545 /   793 Train loss: 0.02485077\r\n",
      "Epoch:  88 Step:   546 /   793 Train loss: 0.01778863\r\n",
      "Epoch:  88 Step:   547 /   793 Train loss: 0.01831684\r\n",
      "Epoch:  88 Step:   548 /   793 Train loss: 0.02565655\r\n",
      "Epoch:  88 Step:   549 /   793 Train loss: 0.02835902\r\n",
      "Epoch:  88 Step:   550 /   793 Train loss: 0.02821446\r\n",
      "Epoch:  88 Step:   551 /   793 Train loss: 0.03082560\r\n",
      "Epoch:  88 Step:   552 /   793 Train loss: 0.03037208\r\n",
      "Epoch:  88 Step:   553 /   793 Train loss: 0.02308168\r\n",
      "Epoch:  88 Step:   554 /   793 Train loss: 0.01086706\r\n",
      "Epoch:  88 Step:   555 /   793 Train loss: 0.02575080\r\n",
      "Epoch:  88 Step:   556 /   793 Train loss: 0.01783591\r\n",
      "Epoch:  88 Step:   557 /   793 Train loss: 0.01673424\r\n",
      "Epoch:  88 Step:   558 /   793 Train loss: 0.02307517\r\n",
      "Epoch:  88 Step:   559 /   793 Train loss: 0.02458303\r\n",
      "Epoch:  88 Step:   560 /   793 Train loss: 0.02462973\r\n",
      "Epoch:  88 Step:   561 /   793 Train loss: 0.02011080\r\n",
      "Epoch:  88 Step:   562 /   793 Train loss: 0.02093810\r\n",
      "Epoch:  88 Step:   563 /   793 Train loss: 0.02470231\r\n",
      "Epoch:  88 Step:   564 /   793 Train loss: 0.01355592\r\n",
      "Epoch:  88 Step:   565 /   793 Train loss: 0.02060471\r\n",
      "Epoch:  88 Step:   566 /   793 Train loss: 0.02498145\r\n",
      "Epoch:  88 Step:   567 /   793 Train loss: 0.01612306\r\n",
      "Epoch:  88 Step:   568 /   793 Train loss: 0.01256571\r\n",
      "Epoch:  88 Step:   569 /   793 Train loss: 0.02430974\r\n",
      "Epoch:  88 Step:   570 /   793 Train loss: 0.02123983\r\n",
      "Epoch:  88 Step:   571 /   793 Train loss: 0.01890036\r\n",
      "Epoch:  88 Step:   572 /   793 Train loss: 0.01279330\r\n",
      "Epoch:  88 Step:   573 /   793 Train loss: 0.03116886\r\n",
      "Epoch:  88 Step:   574 /   793 Train loss: 0.02099718\r\n",
      "Epoch:  88 Step:   575 /   793 Train loss: 0.02821140\r\n",
      "Epoch:  88 Step:   576 /   793 Train loss: 0.02609348\r\n",
      "Epoch:  88 Step:   577 /   793 Train loss: 0.01756545\r\n",
      "Epoch:  88 Step:   578 /   793 Train loss: 0.03336231\r\n",
      "Epoch:  88 Step:   579 /   793 Train loss: 0.03120260\r\n",
      "Epoch:  88 Step:   580 /   793 Train loss: 0.01940366\r\n",
      "Epoch:  88 Step:   581 /   793 Train loss: 0.03502487\r\n",
      "Epoch:  88 Step:   582 /   793 Train loss: 0.02340562\r\n",
      "Epoch:  88 Step:   583 /   793 Train loss: 0.02586259\r\n",
      "Epoch:  88 Step:   584 /   793 Train loss: 0.01997432\r\n",
      "Epoch:  88 Step:   585 /   793 Train loss: 0.04026440\r\n",
      "Epoch:  88 Step:   586 /   793 Train loss: 0.02949094\r\n",
      "Epoch:  88 Step:   587 /   793 Train loss: 0.01277631\r\n",
      "Epoch:  88 Step:   588 /   793 Train loss: 0.01957942\r\n",
      "Epoch:  88 Step:   589 /   793 Train loss: 0.03046411\r\n",
      "Epoch:  88 Step:   590 /   793 Train loss: 0.01632386\r\n",
      "Epoch:  88 Step:   591 /   793 Train loss: 0.02503528\r\n",
      "Epoch:  88 Step:   592 /   793 Train loss: 0.03917608\r\n",
      "Epoch:  88 Step:   593 /   793 Train loss: 0.02136309\r\n",
      "Epoch:  88 Step:   594 /   793 Train loss: 0.04862751\r\n",
      "Epoch:  88 Step:   595 /   793 Train loss: 0.02183357\r\n",
      "Epoch:  88 Step:   596 /   793 Train loss: 0.02077705\r\n",
      "Epoch:  88 Step:   597 /   793 Train loss: 0.03885111\r\n",
      "Epoch:  88 Step:   598 /   793 Train loss: 0.02803576\r\n",
      "Epoch:  88 Step:   599 /   793 Train loss: 0.02388945\r\n",
      "Epoch:  88 Step:   600 /   793 Train loss: 0.00812909\r\n",
      "Epoch:  88 Step:   601 /   793 Train loss: 0.01406639\r\n",
      "Epoch:  88 Step:   602 /   793 Train loss: 0.01056598\r\n",
      "Epoch:  88 Step:   603 /   793 Train loss: 0.03706437\r\n",
      "Epoch:  88 Step:   604 /   793 Train loss: 0.02594828\r\n",
      "Epoch:  88 Step:   605 /   793 Train loss: 0.01917451\r\n",
      "Epoch:  88 Step:   606 /   793 Train loss: 0.03650004\r\n",
      "Epoch:  88 Step:   607 /   793 Train loss: 0.02392575\r\n",
      "Epoch:  88 Step:   608 /   793 Train loss: 0.02864799\r\n",
      "Epoch:  88 Step:   609 /   793 Train loss: 0.02420668\r\n",
      "Epoch:  88 Step:   610 /   793 Train loss: 0.02243376\r\n",
      "Epoch:  88 Step:   611 /   793 Train loss: 0.02638564\r\n",
      "Epoch:  88 Step:   612 /   793 Train loss: 0.01076656\r\n",
      "Epoch:  88 Step:   613 /   793 Train loss: 0.02107591\r\n",
      "Epoch:  88 Step:   614 /   793 Train loss: 0.02705724\r\n",
      "Epoch:  88 Step:   615 /   793 Train loss: 0.01953307\r\n",
      "Epoch:  88 Step:   616 /   793 Train loss: 0.03609706\r\n",
      "Epoch:  88 Step:   617 /   793 Train loss: 0.02472935\r\n",
      "Epoch:  88 Step:   618 /   793 Train loss: 0.02306759\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  88 Step:   619 /   793 Train loss: 0.02186863\r\n",
      "Epoch:  88 Step:   620 /   793 Train loss: 0.03736725\r\n",
      "Epoch:  88 Step:   621 /   793 Train loss: 0.02820158\r\n",
      "Epoch:  88 Step:   622 /   793 Train loss: 0.02527988\r\n",
      "Epoch:  88 Step:   623 /   793 Train loss: 0.02703458\r\n",
      "Epoch:  88 Step:   624 /   793 Train loss: 0.03750776\r\n",
      "Epoch:  88 Step:   625 /   793 Train loss: 0.02637607\r\n",
      "Epoch:  88 Step:   626 /   793 Train loss: 0.01491726\r\n",
      "Epoch:  88 Step:   627 /   793 Train loss: 0.02809946\r\n",
      "Epoch:  88 Step:   628 /   793 Train loss: 0.01908750\r\n",
      "Epoch:  88 Step:   629 /   793 Train loss: 0.02642364\r\n",
      "Epoch:  88 Step:   630 /   793 Train loss: 0.01603550\r\n",
      "Epoch:  88 Step:   631 /   793 Train loss: 0.03328308\r\n",
      "Epoch:  88 Step:   632 /   793 Train loss: 0.02349614\r\n",
      "Epoch:  88 Step:   633 /   793 Train loss: 0.02627818\r\n",
      "Epoch:  88 Step:   634 /   793 Train loss: 0.02131185\r\n",
      "Epoch:  88 Step:   635 /   793 Train loss: 0.02602317\r\n",
      "Epoch:  88 Step:   636 /   793 Train loss: 0.02336412\r\n",
      "Epoch:  88 Step:   637 /   793 Train loss: 0.01748877\r\n",
      "Epoch:  88 Step:   638 /   793 Train loss: 0.01908325\r\n",
      "Epoch:  88 Step:   639 /   793 Train loss: 0.01818016\r\n",
      "Epoch:  88 Step:   640 /   793 Train loss: 0.02143824\r\n",
      "Epoch:  88 Step:   641 /   793 Train loss: 0.03709864\r\n",
      "Epoch:  88 Step:   642 /   793 Train loss: 0.02275027\r\n",
      "Epoch:  88 Step:   643 /   793 Train loss: 0.02654039\r\n",
      "Epoch:  88 Step:   644 /   793 Train loss: 0.03708436\r\n",
      "Epoch:  88 Step:   645 /   793 Train loss: 0.01550424\r\n",
      "Epoch:  88 Step:   646 /   793 Train loss: 0.02300118\r\n",
      "Epoch:  88 Step:   647 /   793 Train loss: 0.01861089\r\n",
      "Epoch:  88 Step:   648 /   793 Train loss: 0.03041035\r\n",
      "Epoch:  88 Step:   649 /   793 Train loss: 0.01707021\r\n",
      "Epoch:  88 Step:   650 /   793 Train loss: 0.03027420\r\n",
      "Epoch:  88 Step:   651 /   793 Train loss: 0.01975291\r\n",
      "Epoch:  88 Step:   652 /   793 Train loss: 0.01654499\r\n",
      "Epoch:  88 Step:   653 /   793 Train loss: 0.02297409\r\n",
      "Epoch:  88 Step:   654 /   793 Train loss: 0.03076206\r\n",
      "Epoch:  88 Step:   655 /   793 Train loss: 0.02059689\r\n",
      "Epoch:  88 Step:   656 /   793 Train loss: 0.02400681\r\n",
      "Epoch:  88 Step:   657 /   793 Train loss: 0.02079359\r\n",
      "Epoch:  88 Step:   658 /   793 Train loss: 0.02247205\r\n",
      "Epoch:  88 Step:   659 /   793 Train loss: 0.02043598\r\n",
      "Epoch:  88 Step:   660 /   793 Train loss: 0.02202275\r\n",
      "Epoch:  88 Step:   661 /   793 Train loss: 0.02278807\r\n",
      "Epoch:  88 Step:   662 /   793 Train loss: 0.02815046\r\n",
      "Epoch:  88 Step:   663 /   793 Train loss: 0.04093088\r\n",
      "Epoch:  88 Step:   664 /   793 Train loss: 0.04734491\r\n",
      "Epoch:  88 Step:   665 /   793 Train loss: 0.01707115\r\n",
      "Epoch:  88 Step:   666 /   793 Train loss: 0.03091108\r\n",
      "Epoch:  88 Step:   667 /   793 Train loss: 0.02339676\r\n",
      "Epoch:  88 Step:   668 /   793 Train loss: 0.02232649\r\n",
      "Epoch:  88 Step:   669 /   793 Train loss: 0.01872748\r\n",
      "Epoch:  88 Step:   670 /   793 Train loss: 0.01857843\r\n",
      "Epoch:  88 Step:   671 /   793 Train loss: 0.02333340\r\n",
      "Epoch:  88 Step:   672 /   793 Train loss: 0.02187999\r\n",
      "Epoch:  88 Step:   673 /   793 Train loss: 0.02033483\r\n",
      "Epoch:  88 Step:   674 /   793 Train loss: 0.02293673\r\n",
      "Epoch:  88 Step:   675 /   793 Train loss: 0.02945708\r\n",
      "Epoch:  88 Step:   676 /   793 Train loss: 0.02653186\r\n",
      "Epoch:  88 Step:   677 /   793 Train loss: 0.01649740\r\n",
      "Epoch:  88 Step:   678 /   793 Train loss: 0.03133300\r\n",
      "Epoch:  88 Step:   679 /   793 Train loss: 0.03111459\r\n",
      "Epoch:  88 Step:   680 /   793 Train loss: 0.01940793\r\n",
      "Epoch:  88 Step:   681 /   793 Train loss: 0.02143822\r\n",
      "Epoch:  88 Step:   682 /   793 Train loss: 0.02770539\r\n",
      "Epoch:  88 Step:   683 /   793 Train loss: 0.01703427\r\n",
      "Epoch:  88 Step:   684 /   793 Train loss: 0.04516052\r\n",
      "Epoch:  88 Step:   685 /   793 Train loss: 0.02232197\r\n",
      "Epoch:  88 Step:   686 /   793 Train loss: 0.01929791\r\n",
      "Epoch:  88 Step:   687 /   793 Train loss: 0.02280513\r\n",
      "Epoch:  88 Step:   688 /   793 Train loss: 0.01653999\r\n",
      "Epoch:  88 Step:   689 /   793 Train loss: 0.02795481\r\n",
      "Epoch:  88 Step:   690 /   793 Train loss: 0.02906703\r\n",
      "Epoch:  88 Step:   691 /   793 Train loss: 0.03828956\r\n",
      "Epoch:  88 Step:   692 /   793 Train loss: 0.02367581\r\n",
      "Epoch:  88 Step:   693 /   793 Train loss: 0.03339413\r\n",
      "Epoch:  88 Step:   694 /   793 Train loss: 0.03499793\r\n",
      "Epoch:  88 Step:   695 /   793 Train loss: 0.03273181\r\n",
      "Epoch:  88 Step:   696 /   793 Train loss: 0.01840418\r\n",
      "Epoch:  88 Step:   697 /   793 Train loss: 0.02187475\r\n",
      "Epoch:  88 Step:   698 /   793 Train loss: 0.03680700\r\n",
      "Epoch:  88 Step:   699 /   793 Train loss: 0.04128918\r\n",
      "Epoch:  88 Step:   700 /   793 Train loss: 0.01415204\r\n",
      "Epoch:  88 Step:   701 /   793 Train loss: 0.03246156\r\n",
      "Epoch:  88 Step:   702 /   793 Train loss: 0.03292504\r\n",
      "Epoch:  88 Step:   703 /   793 Train loss: 0.02814055\r\n",
      "Epoch:  88 Step:   704 /   793 Train loss: 0.01851003\r\n",
      "Epoch:  88 Step:   705 /   793 Train loss: 0.03318238\r\n",
      "Epoch:  88 Step:   706 /   793 Train loss: 0.03033529\r\n",
      "Epoch:  88 Step:   707 /   793 Train loss: 0.02472525\r\n",
      "Epoch:  88 Step:   708 /   793 Train loss: 0.02389514\r\n",
      "Epoch:  88 Step:   709 /   793 Train loss: 0.01454683\r\n",
      "Epoch:  88 Step:   710 /   793 Train loss: 0.03335547\r\n",
      "Epoch:  88 Step:   711 /   793 Train loss: 0.02911101\r\n",
      "Epoch:  88 Step:   712 /   793 Train loss: 0.01305666\r\n",
      "Epoch:  88 Step:   713 /   793 Train loss: 0.02332423\r\n",
      "Epoch:  88 Step:   714 /   793 Train loss: 0.02220002\r\n",
      "Epoch:  88 Step:   715 /   793 Train loss: 0.02222173\r\n",
      "Epoch:  88 Step:   716 /   793 Train loss: 0.03336012\r\n",
      "Epoch:  88 Step:   717 /   793 Train loss: 0.02707658\r\n",
      "Epoch:  88 Step:   718 /   793 Train loss: 0.03115432\r\n",
      "Epoch:  88 Step:   719 /   793 Train loss: 0.02603799\r\n",
      "Epoch:  88 Step:   720 /   793 Train loss: 0.01812922\r\n",
      "Epoch:  88 Step:   721 /   793 Train loss: 0.02156451\r\n",
      "Epoch:  88 Step:   722 /   793 Train loss: 0.03103179\r\n",
      "Epoch:  88 Step:   723 /   793 Train loss: 0.02771794\r\n",
      "Epoch:  88 Step:   724 /   793 Train loss: 0.01850801\r\n",
      "Epoch:  88 Step:   725 /   793 Train loss: 0.01602586\r\n",
      "Epoch:  88 Step:   726 /   793 Train loss: 0.01986901\r\n",
      "Epoch:  88 Step:   727 /   793 Train loss: 0.02726275\r\n",
      "Epoch:  88 Step:   728 /   793 Train loss: 0.01507623\r\n",
      "Epoch:  88 Step:   729 /   793 Train loss: 0.03805504\r\n",
      "Epoch:  88 Step:   730 /   793 Train loss: 0.02439770\r\n",
      "Epoch:  88 Step:   731 /   793 Train loss: 0.01672304\r\n",
      "Epoch:  88 Step:   732 /   793 Train loss: 0.02279940\r\n",
      "Epoch:  88 Step:   733 /   793 Train loss: 0.02135443\r\n",
      "Epoch:  88 Step:   734 /   793 Train loss: 0.02463300\r\n",
      "Epoch:  88 Step:   735 /   793 Train loss: 0.03055380\r\n",
      "Epoch:  88 Step:   736 /   793 Train loss: 0.01605920\r\n",
      "Epoch:  88 Step:   737 /   793 Train loss: 0.02935684\r\n",
      "Epoch:  88 Step:   738 /   793 Train loss: 0.02122078\r\n",
      "Epoch:  88 Step:   739 /   793 Train loss: 0.03061358\r\n",
      "Epoch:  88 Step:   740 /   793 Train loss: 0.01378072\r\n",
      "Epoch:  88 Step:   741 /   793 Train loss: 0.02449353\r\n",
      "Epoch:  88 Step:   742 /   793 Train loss: 0.01521381\r\n",
      "Epoch:  88 Step:   743 /   793 Train loss: 0.02252761\r\n",
      "Epoch:  88 Step:   744 /   793 Train loss: 0.02464617\r\n",
      "Epoch:  88 Step:   745 /   793 Train loss: 0.01375069\r\n",
      "Epoch:  88 Step:   746 /   793 Train loss: 0.03046912\r\n",
      "Epoch:  88 Step:   747 /   793 Train loss: 0.03073503\r\n",
      "Epoch:  88 Step:   748 /   793 Train loss: 0.02339485\r\n",
      "Epoch:  88 Step:   749 /   793 Train loss: 0.02291992\r\n",
      "Epoch:  88 Step:   750 /   793 Train loss: 0.02716591\r\n",
      "Epoch:  88 Step:   751 /   793 Train loss: 0.04097380\r\n",
      "Epoch:  88 Step:   752 /   793 Train loss: 0.01914446\r\n",
      "Epoch:  88 Step:   753 /   793 Train loss: 0.03302307\r\n",
      "Epoch:  88 Step:   754 /   793 Train loss: 0.01470166\r\n",
      "Epoch:  88 Step:   755 /   793 Train loss: 0.02816409\r\n",
      "Epoch:  88 Step:   756 /   793 Train loss: 0.02560020\r\n",
      "Epoch:  88 Step:   757 /   793 Train loss: 0.01276284\r\n",
      "Epoch:  88 Step:   758 /   793 Train loss: 0.02548371\r\n",
      "Epoch:  88 Step:   759 /   793 Train loss: 0.02084841\r\n",
      "Epoch:  88 Step:   760 /   793 Train loss: 0.02926029\r\n",
      "Epoch:  88 Step:   761 /   793 Train loss: 0.02487928\r\n",
      "Epoch:  88 Step:   762 /   793 Train loss: 0.01840271\r\n",
      "Epoch:  88 Step:   763 /   793 Train loss: 0.02148307\r\n",
      "Epoch:  88 Step:   764 /   793 Train loss: 0.03156818\r\n",
      "Epoch:  88 Step:   765 /   793 Train loss: 0.01350847\r\n",
      "Epoch:  88 Step:   766 /   793 Train loss: 0.02283875\r\n",
      "Epoch:  88 Step:   767 /   793 Train loss: 0.02751670\r\n",
      "Epoch:  88 Step:   768 /   793 Train loss: 0.02534513\r\n",
      "Epoch:  88 Step:   769 /   793 Train loss: 0.03194086\r\n",
      "Epoch:  88 Step:   770 /   793 Train loss: 0.02558994\r\n",
      "Epoch:  88 Step:   771 /   793 Train loss: 0.01627635\r\n",
      "Epoch:  88 Step:   772 /   793 Train loss: 0.02223993\r\n",
      "Epoch:  88 Step:   773 /   793 Train loss: 0.02866264\r\n",
      "Epoch:  88 Step:   774 /   793 Train loss: 0.01282256\r\n",
      "Epoch:  88 Step:   775 /   793 Train loss: 0.02669391\r\n",
      "Epoch:  88 Step:   776 /   793 Train loss: 0.02369027\r\n",
      "Epoch:  88 Step:   777 /   793 Train loss: 0.01784110\r\n",
      "Epoch:  88 Step:   778 /   793 Train loss: 0.03378970\r\n",
      "Epoch:  88 Step:   779 /   793 Train loss: 0.03350842\r\n",
      "Epoch:  88 Step:   780 /   793 Train loss: 0.02178998\r\n",
      "Epoch:  88 Step:   781 /   793 Train loss: 0.02170096\r\n",
      "Epoch:  88 Step:   782 /   793 Train loss: 0.02407738\r\n",
      "Epoch:  88 Step:   783 /   793 Train loss: 0.02582350\r\n",
      "Epoch:  88 Step:   784 /   793 Train loss: 0.02936783\r\n",
      "Epoch:  88 Step:   785 /   793 Train loss: 0.02836332\r\n",
      "Epoch:  88 Step:   786 /   793 Train loss: 0.02029772\r\n",
      "Epoch:  88 Step:   787 /   793 Train loss: 0.02640620\r\n",
      "Epoch:  88 Step:   788 /   793 Train loss: 0.02734595\r\n",
      "Epoch:  88 Step:   789 /   793 Train loss: 0.01492307\r\n",
      "Epoch:  88 Step:   790 /   793 Train loss: 0.02401003\r\n",
      "Epoch:  88 Step:   791 /   793 Train loss: 0.01622720\r\n",
      "Epoch:  88 Step:   792 /   793 Train loss: 0.02637724\r\n",
      "Epoch:  89 Step:     0 /   793 Train loss: 0.02371627\r\n",
      "Epoch:  89 Step:     1 /   793 Train loss: 0.02173436\r\n",
      "Epoch:  89 Step:     2 /   793 Train loss: 0.02108437\r\n",
      "Epoch:  89 Step:     3 /   793 Train loss: 0.03091710\r\n",
      "Epoch:  89 Step:     4 /   793 Train loss: 0.02205765\r\n",
      "Epoch:  89 Step:     5 /   793 Train loss: 0.03565881\r\n",
      "Epoch:  89 Step:     6 /   793 Train loss: 0.02695504\r\n",
      "Epoch:  89 Step:     7 /   793 Train loss: 0.03146810\r\n",
      "Epoch:  89 Step:     8 /   793 Train loss: 0.02211294\r\n",
      "Epoch:  89 Step:     9 /   793 Train loss: 0.02632391\r\n",
      "Epoch:  89 Step:    10 /   793 Train loss: 0.01944636\r\n",
      "Epoch:  89 Step:    11 /   793 Train loss: 0.02381496\r\n",
      "Epoch:  89 Step:    12 /   793 Train loss: 0.03570043\r\n",
      "Epoch:  89 Step:    13 /   793 Train loss: 0.01749799\r\n",
      "Epoch:  89 Step:    14 /   793 Train loss: 0.01509559\r\n",
      "Epoch:  89 Step:    15 /   793 Train loss: 0.02882946\r\n",
      "Epoch:  89 Step:    16 /   793 Train loss: 0.02777569\r\n",
      "Epoch:  89 Step:    17 /   793 Train loss: 0.02454296\r\n",
      "Epoch:  89 Step:    18 /   793 Train loss: 0.01746726\r\n",
      "Epoch:  89 Step:    19 /   793 Train loss: 0.02271894\r\n",
      "Epoch:  89 Step:    20 /   793 Train loss: 0.01617225\r\n",
      "Epoch:  89 Step:    21 /   793 Train loss: 0.02264378\r\n",
      "Epoch:  89 Step:    22 /   793 Train loss: 0.01692293\r\n",
      "Epoch:  89 Step:    23 /   793 Train loss: 0.01782574\r\n",
      "Epoch:  89 Step:    24 /   793 Train loss: 0.01499229\r\n",
      "Epoch:  89 Step:    25 /   793 Train loss: 0.02201453\r\n",
      "Epoch:  89 Step:    26 /   793 Train loss: 0.02306553\r\n",
      "Epoch:  89 Step:    27 /   793 Train loss: 0.03146309\r\n",
      "Epoch:  89 Step:    28 /   793 Train loss: 0.02826348\r\n",
      "Epoch:  89 Step:    29 /   793 Train loss: 0.02315543\r\n",
      "Epoch:  89 Step:    30 /   793 Train loss: 0.02264697\r\n",
      "Epoch:  89 Step:    31 /   793 Train loss: 0.03032867\r\n",
      "Epoch:  89 Step:    32 /   793 Train loss: 0.01683090\r\n",
      "Epoch:  89 Step:    33 /   793 Train loss: 0.01731205\r\n",
      "Epoch:  89 Step:    34 /   793 Train loss: 0.01527627\r\n",
      "Epoch:  89 Step:    35 /   793 Train loss: 0.02222698\r\n",
      "Epoch:  89 Step:    36 /   793 Train loss: 0.02086245\r\n",
      "Epoch:  89 Step:    37 /   793 Train loss: 0.02401891\r\n",
      "Epoch:  89 Step:    38 /   793 Train loss: 0.03627350\r\n",
      "Epoch:  89 Step:    39 /   793 Train loss: 0.02121630\r\n",
      "Epoch:  89 Step:    40 /   793 Train loss: 0.03123777\r\n",
      "Epoch:  89 Step:    41 /   793 Train loss: 0.02603053\r\n",
      "Epoch:  89 Step:    42 /   793 Train loss: 0.02533863\r\n",
      "Epoch:  89 Step:    43 /   793 Train loss: 0.01831762\r\n",
      "Epoch:  89 Step:    44 /   793 Train loss: 0.02097343\r\n",
      "Epoch:  89 Step:    45 /   793 Train loss: 0.01693914\r\n",
      "Epoch:  89 Step:    46 /   793 Train loss: 0.04426145\r\n",
      "Epoch:  89 Step:    47 /   793 Train loss: 0.02493683\r\n",
      "Epoch:  89 Step:    48 /   793 Train loss: 0.02909938\r\n",
      "Epoch:  89 Step:    49 /   793 Train loss: 0.03322940\r\n",
      "Epoch:  89 Step:    50 /   793 Train loss: 0.03388425\r\n",
      "Epoch:  89 Step:    51 /   793 Train loss: 0.02637018\r\n",
      "Epoch:  89 Step:    52 /   793 Train loss: 0.02337435\r\n",
      "Epoch:  89 Step:    53 /   793 Train loss: 0.02756367\r\n",
      "Epoch:  89 Step:    54 /   793 Train loss: 0.01959517\r\n",
      "Epoch:  89 Step:    55 /   793 Train loss: 0.02512154\r\n",
      "Epoch:  89 Step:    56 /   793 Train loss: 0.02073564\r\n",
      "Epoch:  89 Step:    57 /   793 Train loss: 0.01702902\r\n",
      "Epoch:  89 Step:    58 /   793 Train loss: 0.02954494\r\n",
      "Epoch:  89 Step:    59 /   793 Train loss: 0.03002752\r\n",
      "Epoch:  89 Step:    60 /   793 Train loss: 0.02451818\r\n",
      "Epoch:  89 Step:    61 /   793 Train loss: 0.01826785\r\n",
      "Epoch:  89 Step:    62 /   793 Train loss: 0.01973515\r\n",
      "Epoch:  89 Step:    63 /   793 Train loss: 0.02533170\r\n",
      "Epoch:  89 Step:    64 /   793 Train loss: 0.02433087\r\n",
      "Epoch:  89 Step:    65 /   793 Train loss: 0.02225758\r\n",
      "Epoch:  89 Step:    66 /   793 Train loss: 0.02300684\r\n",
      "Epoch:  89 Step:    67 /   793 Train loss: 0.03603301\r\n",
      "Epoch:  89 Step:    68 /   793 Train loss: 0.01727918\r\n",
      "Epoch:  89 Step:    69 /   793 Train loss: 0.01801166\r\n",
      "Epoch:  89 Step:    70 /   793 Train loss: 0.02053321\r\n",
      "Epoch:  89 Step:    71 /   793 Train loss: 0.03274210\r\n",
      "Epoch:  89 Step:    72 /   793 Train loss: 0.02164820\r\n",
      "Epoch:  89 Step:    73 /   793 Train loss: 0.01994150\r\n",
      "Epoch:  89 Step:    74 /   793 Train loss: 0.02814868\r\n",
      "Epoch:  89 Step:    75 /   793 Train loss: 0.01985821\r\n",
      "Epoch:  89 Step:    76 /   793 Train loss: 0.02266724\r\n",
      "Epoch:  89 Step:    77 /   793 Train loss: 0.01688166\r\n",
      "Epoch:  89 Step:    78 /   793 Train loss: 0.02226201\r\n",
      "Epoch:  89 Step:    79 /   793 Train loss: 0.02878246\r\n",
      "Epoch:  89 Step:    80 /   793 Train loss: 0.03126805\r\n",
      "Epoch:  89 Step:    81 /   793 Train loss: 0.01997064\r\n",
      "Epoch:  89 Step:    82 /   793 Train loss: 0.01889224\r\n",
      "Epoch:  89 Step:    83 /   793 Train loss: 0.03064100\r\n",
      "Epoch:  89 Step:    84 /   793 Train loss: 0.01689825\r\n",
      "Epoch:  89 Step:    85 /   793 Train loss: 0.02783747\r\n",
      "Epoch:  89 Step:    86 /   793 Train loss: 0.02274839\r\n",
      "Epoch:  89 Step:    87 /   793 Train loss: 0.01436310\r\n",
      "Epoch:  89 Step:    88 /   793 Train loss: 0.01703684\r\n",
      "Epoch:  89 Step:    89 /   793 Train loss: 0.02162368\r\n",
      "Epoch:  89 Step:    90 /   793 Train loss: 0.03103187\r\n",
      "Epoch:  89 Step:    91 /   793 Train loss: 0.03715465\r\n",
      "Epoch:  89 Step:    92 /   793 Train loss: 0.02996923\r\n",
      "Epoch:  89 Step:    93 /   793 Train loss: 0.03286519\r\n",
      "Epoch:  89 Step:    94 /   793 Train loss: 0.03269085\r\n",
      "Epoch:  89 Step:    95 /   793 Train loss: 0.03008192\r\n",
      "Epoch:  89 Step:    96 /   793 Train loss: 0.02241513\r\n",
      "Epoch:  89 Step:    97 /   793 Train loss: 0.03074938\r\n",
      "Epoch:  89 Step:    98 /   793 Train loss: 0.02113275\r\n",
      "Epoch:  89 Step:    99 /   793 Train loss: 0.02478473\r\n",
      "Epoch:  89 Step:   100 /   793 Train loss: 0.03254783\r\n",
      "Epoch:  89 Step:   101 /   793 Train loss: 0.03342392\r\n",
      "Epoch:  89 Step:   102 /   793 Train loss: 0.03265110\r\n",
      "Epoch:  89 Step:   103 /   793 Train loss: 0.01137039\r\n",
      "Epoch:  89 Step:   104 /   793 Train loss: 0.02459764\r\n",
      "Epoch:  89 Step:   105 /   793 Train loss: 0.01900512\r\n",
      "Epoch:  89 Step:   106 /   793 Train loss: 0.03366878\r\n",
      "Epoch:  89 Step:   107 /   793 Train loss: 0.03185914\r\n",
      "Epoch:  89 Step:   108 /   793 Train loss: 0.01690768\r\n",
      "Epoch:  89 Step:   109 /   793 Train loss: 0.02146405\r\n",
      "Epoch:  89 Step:   110 /   793 Train loss: 0.02106445\r\n",
      "Epoch:  89 Step:   111 /   793 Train loss: 0.02659819\r\n",
      "Epoch:  89 Step:   112 /   793 Train loss: 0.02169982\r\n",
      "Epoch:  89 Step:   113 /   793 Train loss: 0.01775427\r\n",
      "Epoch:  89 Step:   114 /   793 Train loss: 0.02604560\r\n",
      "Epoch:  89 Step:   115 /   793 Train loss: 0.02478237\r\n",
      "Epoch:  89 Step:   116 /   793 Train loss: 0.03065506\r\n",
      "Epoch:  89 Step:   117 /   793 Train loss: 0.03733481\r\n",
      "Epoch:  89 Step:   118 /   793 Train loss: 0.04247536\r\n",
      "Epoch:  89 Step:   119 /   793 Train loss: 0.03158938\r\n",
      "Epoch:  89 Step:   120 /   793 Train loss: 0.02713905\r\n",
      "Epoch:  89 Step:   121 /   793 Train loss: 0.02284675\r\n",
      "Epoch:  89 Step:   122 /   793 Train loss: 0.02592235\r\n",
      "Epoch:  89 Step:   123 /   793 Train loss: 0.01430807\r\n",
      "Epoch:  89 Step:   124 /   793 Train loss: 0.02071475\r\n",
      "Epoch:  89 Step:   125 /   793 Train loss: 0.02312391\r\n",
      "Epoch:  89 Step:   126 /   793 Train loss: 0.02245183\r\n",
      "Epoch:  89 Step:   127 /   793 Train loss: 0.02811616\r\n",
      "Epoch:  89 Step:   128 /   793 Train loss: 0.02989567\r\n",
      "Epoch:  89 Step:   129 /   793 Train loss: 0.02097271\r\n",
      "Epoch:  89 Step:   130 /   793 Train loss: 0.03420937\r\n",
      "Epoch:  89 Step:   131 /   793 Train loss: 0.03452893\r\n",
      "Epoch:  89 Step:   132 /   793 Train loss: 0.02569314\r\n",
      "Epoch:  89 Step:   133 /   793 Train loss: 0.02376521\r\n",
      "Epoch:  89 Step:   134 /   793 Train loss: 0.01668276\r\n",
      "Epoch:  89 Step:   135 /   793 Train loss: 0.00738024\r\n",
      "Epoch:  89 Step:   136 /   793 Train loss: 0.02613742\r\n",
      "Epoch:  89 Step:   137 /   793 Train loss: 0.03041482\r\n",
      "Epoch:  89 Step:   138 /   793 Train loss: 0.03850564\r\n",
      "Epoch:  89 Step:   139 /   793 Train loss: 0.02042975\r\n",
      "Epoch:  89 Step:   140 /   793 Train loss: 0.02989812\r\n",
      "Epoch:  89 Step:   141 /   793 Train loss: 0.02888743\r\n",
      "Epoch:  89 Step:   142 /   793 Train loss: 0.01582990\r\n",
      "Epoch:  89 Step:   143 /   793 Train loss: 0.02649899\r\n",
      "Epoch:  89 Step:   144 /   793 Train loss: 0.01988141\r\n",
      "Epoch:  89 Step:   145 /   793 Train loss: 0.01843403\r\n",
      "Epoch:  89 Step:   146 /   793 Train loss: 0.02600760\r\n",
      "Epoch:  89 Step:   147 /   793 Train loss: 0.01035463\r\n",
      "Epoch:  89 Step:   148 /   793 Train loss: 0.01804738\r\n",
      "Epoch:  89 Step:   149 /   793 Train loss: 0.02606434\r\n",
      "Epoch:  89 Step:   150 /   793 Train loss: 0.01357705\r\n",
      "Epoch:  89 Step:   151 /   793 Train loss: 0.02478273\r\n",
      "Epoch:  89 Step:   152 /   793 Train loss: 0.01141874\r\n",
      "Epoch:  89 Step:   153 /   793 Train loss: 0.04770681\r\n",
      "Epoch:  89 Step:   154 /   793 Train loss: 0.01959774\r\n",
      "Epoch:  89 Step:   155 /   793 Train loss: 0.02045106\r\n",
      "Epoch:  89 Step:   156 /   793 Train loss: 0.02226531\r\n",
      "Epoch:  89 Step:   157 /   793 Train loss: 0.02512878\r\n",
      "Epoch:  89 Step:   158 /   793 Train loss: 0.03257658\r\n",
      "Epoch:  89 Step:   159 /   793 Train loss: 0.01544554\r\n",
      "Epoch:  89 Step:   160 /   793 Train loss: 0.02402046\r\n",
      "Epoch:  89 Step:   161 /   793 Train loss: 0.02730929\r\n",
      "Epoch:  89 Step:   162 /   793 Train loss: 0.02352219\r\n",
      "Epoch:  89 Step:   163 /   793 Train loss: 0.01677792\r\n",
      "Epoch:  89 Step:   164 /   793 Train loss: 0.02347136\r\n",
      "Epoch:  89 Step:   165 /   793 Train loss: 0.02399150\r\n",
      "Epoch:  89 Step:   166 /   793 Train loss: 0.03884908\r\n",
      "Epoch:  89 Step:   167 /   793 Train loss: 0.02273387\r\n",
      "Epoch:  89 Step:   168 /   793 Train loss: 0.02209637\r\n",
      "Epoch:  89 Step:   169 /   793 Train loss: 0.02393315\r\n",
      "Epoch:  89 Step:   170 /   793 Train loss: 0.01888862\r\n",
      "Epoch:  89 Step:   171 /   793 Train loss: 0.02271821\r\n",
      "Epoch:  89 Step:   172 /   793 Train loss: 0.02584871\r\n",
      "Epoch:  89 Step:   173 /   793 Train loss: 0.02590506\r\n",
      "Epoch:  89 Step:   174 /   793 Train loss: 0.01894341\r\n",
      "Epoch:  89 Step:   175 /   793 Train loss: 0.01762113\r\n",
      "Epoch:  89 Step:   176 /   793 Train loss: 0.01589203\r\n",
      "Epoch:  89 Step:   177 /   793 Train loss: 0.02353785\r\n",
      "Epoch:  89 Step:   178 /   793 Train loss: 0.02412177\r\n",
      "Epoch:  89 Step:   179 /   793 Train loss: 0.03223065\r\n",
      "Epoch:  89 Step:   180 /   793 Train loss: 0.03750569\r\n",
      "Epoch:  89 Step:   181 /   793 Train loss: 0.02952607\r\n",
      "Epoch:  89 Step:   182 /   793 Train loss: 0.02940528\r\n",
      "Epoch:  89 Step:   183 /   793 Train loss: 0.02546744\r\n",
      "Epoch:  89 Step:   184 /   793 Train loss: 0.02202082\r\n",
      "Epoch:  89 Step:   185 /   793 Train loss: 0.01926310\r\n",
      "Epoch:  89 Step:   186 /   793 Train loss: 0.02879124\r\n",
      "Epoch:  89 Step:   187 /   793 Train loss: 0.02366725\r\n",
      "Epoch:  89 Step:   188 /   793 Train loss: 0.02690888\r\n",
      "Epoch:  89 Step:   189 /   793 Train loss: 0.03201773\r\n",
      "Epoch:  89 Step:   190 /   793 Train loss: 0.02685080\r\n",
      "Epoch:  89 Step:   191 /   793 Train loss: 0.03585329\r\n",
      "Epoch:  89 Step:   192 /   793 Train loss: 0.02931570\r\n",
      "Epoch:  89 Step:   193 /   793 Train loss: 0.01319596\r\n",
      "Epoch:  89 Step:   194 /   793 Train loss: 0.02182046\r\n",
      "Epoch:  89 Step:   195 /   793 Train loss: 0.03003827\r\n",
      "Epoch:  89 Step:   196 /   793 Train loss: 0.02086253\r\n",
      "Epoch:  89 Step:   197 /   793 Train loss: 0.03006926\r\n",
      "Epoch:  89 Step:   198 /   793 Train loss: 0.02487711\r\n",
      "Epoch:  89 Step:   199 /   793 Train loss: 0.02369351\r\n",
      "Epoch:  89 Step:   200 /   793 Train loss: 0.02457668\r\n",
      "Epoch:  89 Step:   201 /   793 Train loss: 0.03220695\r\n",
      "Epoch:  89 Step:   202 /   793 Train loss: 0.02453512\r\n",
      "Epoch:  89 Step:   203 /   793 Train loss: 0.02695918\r\n",
      "Epoch:  89 Step:   204 /   793 Train loss: 0.02005323\r\n",
      "Epoch:  89 Step:   205 /   793 Train loss: 0.03269007\r\n",
      "Epoch:  89 Step:   206 /   793 Train loss: 0.03265232\r\n",
      "Epoch:  89 Step:   207 /   793 Train loss: 0.01808791\r\n",
      "Epoch:  89 Step:   208 /   793 Train loss: 0.03782240\r\n",
      "Epoch:  89 Step:   209 /   793 Train loss: 0.01951955\r\n",
      "Epoch:  89 Step:   210 /   793 Train loss: 0.01961705\r\n",
      "Epoch:  89 Step:   211 /   793 Train loss: 0.02590265\r\n",
      "Epoch:  89 Step:   212 /   793 Train loss: 0.02663083\r\n",
      "Epoch:  89 Step:   213 /   793 Train loss: 0.01533003\r\n",
      "Epoch:  89 Step:   214 /   793 Train loss: 0.02084923\r\n",
      "Epoch:  89 Step:   215 /   793 Train loss: 0.02074522\r\n",
      "Epoch:  89 Step:   216 /   793 Train loss: 0.03335045\r\n",
      "Epoch:  89 Step:   217 /   793 Train loss: 0.03394284\r\n",
      "Epoch:  89 Step:   218 /   793 Train loss: 0.02074766\r\n",
      "Epoch:  89 Step:   219 /   793 Train loss: 0.01675788\r\n",
      "Epoch:  89 Step:   220 /   793 Train loss: 0.02534487\r\n",
      "Epoch:  89 Step:   221 /   793 Train loss: 0.02266032\r\n",
      "Epoch:  89 Step:   222 /   793 Train loss: 0.01129941\r\n",
      "Epoch:  89 Step:   223 /   793 Train loss: 0.01544082\r\n",
      "Epoch:  89 Step:   224 /   793 Train loss: 0.01944868\r\n",
      "Epoch:  89 Step:   225 /   793 Train loss: 0.02120327\r\n",
      "Epoch:  89 Step:   226 /   793 Train loss: 0.03235441\r\n",
      "Epoch:  89 Step:   227 /   793 Train loss: 0.02391237\r\n",
      "Epoch:  89 Step:   228 /   793 Train loss: 0.01850789\r\n",
      "Epoch:  89 Step:   229 /   793 Train loss: 0.02834076\r\n",
      "Epoch:  89 Step:   230 /   793 Train loss: 0.01903331\r\n",
      "Epoch:  89 Step:   231 /   793 Train loss: 0.02851987\r\n",
      "Epoch:  89 Step:   232 /   793 Train loss: 0.01926401\r\n",
      "Epoch:  89 Step:   233 /   793 Train loss: 0.02240842\r\n",
      "Epoch:  89 Step:   234 /   793 Train loss: 0.02248283\r\n",
      "Epoch:  89 Step:   235 /   793 Train loss: 0.02573759\r\n",
      "Epoch:  89 Step:   236 /   793 Train loss: 0.03391611\r\n",
      "Epoch:  89 Step:   237 /   793 Train loss: 0.02366957\r\n",
      "Epoch:  89 Step:   238 /   793 Train loss: 0.01784866\r\n",
      "Epoch:  89 Step:   239 /   793 Train loss: 0.01968097\r\n",
      "Epoch:  89 Step:   240 /   793 Train loss: 0.01321917\r\n",
      "Epoch:  89 Step:   241 /   793 Train loss: 0.02797566\r\n",
      "Epoch:  89 Step:   242 /   793 Train loss: 0.02591311\r\n",
      "Epoch:  89 Step:   243 /   793 Train loss: 0.01530423\r\n",
      "Epoch:  89 Step:   244 /   793 Train loss: 0.01502295\r\n",
      "Epoch:  89 Step:   245 /   793 Train loss: 0.02074531\r\n",
      "Epoch:  89 Step:   246 /   793 Train loss: 0.01634032\r\n",
      "Epoch:  89 Step:   247 /   793 Train loss: 0.01529376\r\n",
      "Epoch:  89 Step:   248 /   793 Train loss: 0.03193906\r\n",
      "Epoch:  89 Step:   249 /   793 Train loss: 0.01790107\r\n",
      "Epoch:  89 Step:   250 /   793 Train loss: 0.01952283\r\n",
      "Epoch:  89 Step:   251 /   793 Train loss: 0.02121529\r\n",
      "Epoch:  89 Step:   252 /   793 Train loss: 0.01416029\r\n",
      "Epoch:  89 Step:   253 /   793 Train loss: 0.02167830\r\n",
      "Epoch:  89 Step:   254 /   793 Train loss: 0.02189368\r\n",
      "Epoch:  89 Step:   255 /   793 Train loss: 0.01746077\r\n",
      "Epoch:  89 Step:   256 /   793 Train loss: 0.02080456\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  89 Step:   257 /   793 Train loss: 0.03452132\r\n",
      "Epoch:  89 Step:   258 /   793 Train loss: 0.02712660\r\n",
      "Epoch:  89 Step:   259 /   793 Train loss: 0.02229106\r\n",
      "Epoch:  89 Step:   260 /   793 Train loss: 0.02791197\r\n",
      "Epoch:  89 Step:   261 /   793 Train loss: 0.01724758\r\n",
      "Epoch:  89 Step:   262 /   793 Train loss: 0.01940510\r\n",
      "Epoch:  89 Step:   263 /   793 Train loss: 0.02674299\r\n",
      "Epoch:  89 Step:   264 /   793 Train loss: 0.01738801\r\n",
      "Epoch:  89 Step:   265 /   793 Train loss: 0.04222147\r\n",
      "Epoch:  89 Step:   266 /   793 Train loss: 0.02518891\r\n",
      "Epoch:  89 Step:   267 /   793 Train loss: 0.02056990\r\n",
      "Epoch:  89 Step:   268 /   793 Train loss: 0.01623822\r\n",
      "Epoch:  89 Step:   269 /   793 Train loss: 0.02365365\r\n",
      "Epoch:  89 Step:   270 /   793 Train loss: 0.02261936\r\n",
      "Epoch:  89 Step:   271 /   793 Train loss: 0.02208094\r\n",
      "Epoch:  89 Step:   272 /   793 Train loss: 0.01622810\r\n",
      "Epoch:  89 Step:   273 /   793 Train loss: 0.02210896\r\n",
      "Epoch:  89 Step:   274 /   793 Train loss: 0.02243552\r\n",
      "Epoch:  89 Step:   275 /   793 Train loss: 0.02201931\r\n",
      "Epoch:  89 Step:   276 /   793 Train loss: 0.02597552\r\n",
      "Epoch:  89 Step:   277 /   793 Train loss: 0.01008179\r\n",
      "Epoch:  89 Step:   278 /   793 Train loss: 0.02496019\r\n",
      "Epoch:  89 Step:   279 /   793 Train loss: 0.02129249\r\n",
      "Epoch:  89 Step:   280 /   793 Train loss: 0.01794761\r\n",
      "Epoch:  89 Step:   281 /   793 Train loss: 0.02117382\r\n",
      "Epoch:  89 Step:   282 /   793 Train loss: 0.03473469\r\n",
      "Epoch:  89 Step:   283 /   793 Train loss: 0.02780332\r\n",
      "Epoch:  89 Step:   284 /   793 Train loss: 0.01956154\r\n",
      "Epoch:  89 Step:   285 /   793 Train loss: 0.02664607\r\n",
      "Epoch:  89 Step:   286 /   793 Train loss: 0.03125566\r\n",
      "Epoch:  89 Step:   287 /   793 Train loss: 0.02082094\r\n",
      "Epoch:  89 Step:   288 /   793 Train loss: 0.03143135\r\n",
      "Epoch:  89 Step:   289 /   793 Train loss: 0.02726574\r\n",
      "Epoch:  89 Step:   290 /   793 Train loss: 0.02148856\r\n",
      "Epoch:  89 Step:   291 /   793 Train loss: 0.02599896\r\n",
      "Epoch:  89 Step:   292 /   793 Train loss: 0.01365601\r\n",
      "Epoch:  89 Step:   293 /   793 Train loss: 0.02030510\r\n",
      "Epoch:  89 Step:   294 /   793 Train loss: 0.02438097\r\n",
      "Epoch:  89 Step:   295 /   793 Train loss: 0.01133838\r\n",
      "Epoch:  89 Step:   296 /   793 Train loss: 0.03040347\r\n",
      "Epoch:  89 Step:   297 /   793 Train loss: 0.02848914\r\n",
      "Epoch:  89 Step:   298 /   793 Train loss: 0.02605055\r\n",
      "Epoch:  89 Step:   299 /   793 Train loss: 0.01687350\r\n",
      "Epoch:  89 Step:   300 /   793 Train loss: 0.02005127\r\n",
      "Epoch:  89 Step:   301 /   793 Train loss: 0.02954656\r\n",
      "Epoch:  89 Step:   302 /   793 Train loss: 0.02269688\r\n",
      "Epoch:  89 Step:   303 /   793 Train loss: 0.02953183\r\n",
      "Epoch:  89 Step:   304 /   793 Train loss: 0.03360112\r\n",
      "Epoch:  89 Step:   305 /   793 Train loss: 0.02448127\r\n",
      "Epoch:  89 Step:   306 /   793 Train loss: 0.03035821\r\n",
      "Epoch:  89 Step:   307 /   793 Train loss: 0.01874885\r\n",
      "Epoch:  89 Step:   308 /   793 Train loss: 0.02797575\r\n",
      "Epoch:  89 Step:   309 /   793 Train loss: 0.02393550\r\n",
      "Epoch:  89 Step:   310 /   793 Train loss: 0.02338263\r\n",
      "Epoch:  89 Step:   311 /   793 Train loss: 0.02785673\r\n",
      "Epoch:  89 Step:   312 /   793 Train loss: 0.03024038\r\n",
      "Epoch:  89 Step:   313 /   793 Train loss: 0.03015152\r\n",
      "Epoch:  89 Step:   314 /   793 Train loss: 0.02248134\r\n",
      "Epoch:  89 Step:   315 /   793 Train loss: 0.03143181\r\n",
      "Epoch:  89 Step:   316 /   793 Train loss: 0.02955927\r\n",
      "Epoch:  89 Step:   317 /   793 Train loss: 0.02017590\r\n",
      "Epoch:  89 Step:   318 /   793 Train loss: 0.02305543\r\n",
      "Epoch:  89 Step:   319 /   793 Train loss: 0.01304425\r\n",
      "Epoch:  89 Step:   320 /   793 Train loss: 0.02482972\r\n",
      "Epoch:  89 Step:   321 /   793 Train loss: 0.03608955\r\n",
      "Epoch:  89 Step:   322 /   793 Train loss: 0.02885904\r\n",
      "Epoch:  89 Step:   323 /   793 Train loss: 0.02551884\r\n",
      "Epoch:  89 Step:   324 /   793 Train loss: 0.01960966\r\n",
      "Epoch:  89 Step:   325 /   793 Train loss: 0.02117201\r\n",
      "Epoch:  89 Step:   326 /   793 Train loss: 0.02875055\r\n",
      "Epoch:  89 Step:   327 /   793 Train loss: 0.02695245\r\n",
      "Epoch:  89 Step:   328 /   793 Train loss: 0.03117613\r\n",
      "Epoch:  89 Step:   329 /   793 Train loss: 0.02643770\r\n",
      "Epoch:  89 Step:   330 /   793 Train loss: 0.01514056\r\n",
      "Epoch:  89 Step:   331 /   793 Train loss: 0.03046431\r\n",
      "Epoch:  89 Step:   332 /   793 Train loss: 0.02935727\r\n",
      "Epoch:  89 Step:   333 /   793 Train loss: 0.03541799\r\n",
      "Epoch:  89 Step:   334 /   793 Train loss: 0.02796971\r\n",
      "Epoch:  89 Step:   335 /   793 Train loss: 0.02776885\r\n",
      "Epoch:  89 Step:   336 /   793 Train loss: 0.02838323\r\n",
      "Epoch:  89 Step:   337 /   793 Train loss: 0.02998274\r\n",
      "Epoch:  89 Step:   338 /   793 Train loss: 0.02257474\r\n",
      "Epoch:  89 Step:   339 /   793 Train loss: 0.03022337\r\n",
      "Epoch:  89 Step:   340 /   793 Train loss: 0.01790121\r\n",
      "Epoch:  89 Step:   341 /   793 Train loss: 0.01425507\r\n",
      "Epoch:  89 Step:   342 /   793 Train loss: 0.02500413\r\n",
      "Epoch:  89 Step:   343 /   793 Train loss: 0.02684421\r\n",
      "Epoch:  89 Step:   344 /   793 Train loss: 0.03498139\r\n",
      "Epoch:  89 Step:   345 /   793 Train loss: 0.02259827\r\n",
      "Epoch:  89 Step:   346 /   793 Train loss: 0.02438155\r\n",
      "Epoch:  89 Step:   347 /   793 Train loss: 0.02627749\r\n",
      "Epoch:  89 Step:   348 /   793 Train loss: 0.02763167\r\n",
      "Epoch:  89 Step:   349 /   793 Train loss: 0.01774149\r\n",
      "Epoch:  89 Step:   350 /   793 Train loss: 0.02861486\r\n",
      "Epoch:  89 Step:   351 /   793 Train loss: 0.03196175\r\n",
      "Epoch:  89 Step:   352 /   793 Train loss: 0.02556141\r\n",
      "Epoch:  89 Step:   353 /   793 Train loss: 0.01794554\r\n",
      "Epoch:  89 Step:   354 /   793 Train loss: 0.01658430\r\n",
      "Epoch:  89 Step:   355 /   793 Train loss: 0.02276578\r\n",
      "Epoch:  89 Step:   356 /   793 Train loss: 0.01693499\r\n",
      "Epoch:  89 Step:   357 /   793 Train loss: 0.02124264\r\n",
      "Epoch:  89 Step:   358 /   793 Train loss: 0.03784420\r\n",
      "Epoch:  89 Step:   359 /   793 Train loss: 0.02900468\r\n",
      "Epoch:  89 Step:   360 /   793 Train loss: 0.01884732\r\n",
      "Epoch:  89 Step:   361 /   793 Train loss: 0.03335197\r\n",
      "Epoch:  89 Step:   362 /   793 Train loss: 0.04018755\r\n",
      "Epoch:  89 Step:   363 /   793 Train loss: 0.02234649\r\n",
      "Epoch:  89 Step:   364 /   793 Train loss: 0.01642935\r\n",
      "Epoch:  89 Step:   365 /   793 Train loss: 0.02197605\r\n",
      "Epoch:  89 Step:   366 /   793 Train loss: 0.02611789\r\n",
      "Epoch:  89 Step:   367 /   793 Train loss: 0.01518586\r\n",
      "Epoch:  89 Step:   368 /   793 Train loss: 0.02123800\r\n",
      "Epoch:  89 Step:   369 /   793 Train loss: 0.02159264\r\n",
      "Epoch:  89 Step:   370 /   793 Train loss: 0.02538862\r\n",
      "Epoch:  89 Step:   371 /   793 Train loss: 0.01425897\r\n",
      "Epoch:  89 Step:   372 /   793 Train loss: 0.02925410\r\n",
      "Epoch:  89 Step:   373 /   793 Train loss: 0.01331545\r\n",
      "Epoch:  89 Step:   374 /   793 Train loss: 0.02163542\r\n",
      "Epoch:  89 Step:   375 /   793 Train loss: 0.02533218\r\n",
      "Epoch:  89 Step:   376 /   793 Train loss: 0.02293540\r\n",
      "Epoch:  89 Step:   377 /   793 Train loss: 0.02422990\r\n",
      "Epoch:  89 Step:   378 /   793 Train loss: 0.02514210\r\n",
      "Epoch:  89 Step:   379 /   793 Train loss: 0.01906712\r\n",
      "Epoch:  89 Step:   380 /   793 Train loss: 0.02833439\r\n",
      "Epoch:  89 Step:   381 /   793 Train loss: 0.02517594\r\n",
      "Epoch:  89 Step:   382 /   793 Train loss: 0.02139818\r\n",
      "Epoch:  89 Step:   383 /   793 Train loss: 0.01072759\r\n",
      "Epoch:  89 Step:   384 /   793 Train loss: 0.02103891\r\n",
      "Epoch:  89 Step:   385 /   793 Train loss: 0.04118531\r\n",
      "Epoch:  89 Step:   386 /   793 Train loss: 0.02237818\r\n",
      "Epoch:  89 Step:   387 /   793 Train loss: 0.03293709\r\n",
      "Epoch:  89 Step:   388 /   793 Train loss: 0.02007474\r\n",
      "Epoch:  89 Step:   389 /   793 Train loss: 0.05136179\r\n",
      "Epoch:  89 Step:   390 /   793 Train loss: 0.02338771\r\n",
      "Epoch:  89 Step:   391 /   793 Train loss: 0.02105671\r\n",
      "Epoch:  89 Step:   392 /   793 Train loss: 0.03412224\r\n",
      "Epoch:  89 Step:   393 /   793 Train loss: 0.02060664\r\n",
      "Epoch:  89 Step:   394 /   793 Train loss: 0.02503035\r\n",
      "Epoch:  89 Step:   395 /   793 Train loss: 0.01877297\r\n",
      "Epoch:  89 Step:   396 /   793 Train loss: 0.03999542\r\n",
      "Epoch:  89 Step:   397 /   793 Train loss: 0.02967171\r\n",
      "Epoch:  89 Step:   398 /   793 Train loss: 0.03122697\r\n",
      "Epoch:  89 Step:   399 /   793 Train loss: 0.01519744\r\n",
      "Epoch:  89 Step:   400 /   793 Train loss: 0.02322372\r\n",
      "Epoch:  89 Step:   401 /   793 Train loss: 0.03267766\r\n",
      "Epoch:  89 Step:   402 /   793 Train loss: 0.02780360\r\n",
      "Epoch:  89 Step:   403 /   793 Train loss: 0.01843511\r\n",
      "Epoch:  89 Step:   404 /   793 Train loss: 0.02669754\r\n",
      "Epoch:  89 Step:   405 /   793 Train loss: 0.02963134\r\n",
      "Epoch:  89 Step:   406 /   793 Train loss: 0.02093836\r\n",
      "Epoch:  89 Step:   407 /   793 Train loss: 0.02394549\r\n",
      "Epoch:  89 Step:   408 /   793 Train loss: 0.02655550\r\n",
      "Epoch:  89 Step:   409 /   793 Train loss: 0.01660427\r\n",
      "Epoch:  89 Step:   410 /   793 Train loss: 0.01771799\r\n",
      "Epoch:  89 Step:   411 /   793 Train loss: 0.02282031\r\n",
      "Epoch:  89 Step:   412 /   793 Train loss: 0.02931035\r\n",
      "Epoch:  89 Step:   413 /   793 Train loss: 0.03119391\r\n",
      "Epoch:  89 Step:   414 /   793 Train loss: 0.01592965\r\n",
      "Epoch:  89 Step:   415 /   793 Train loss: 0.01513786\r\n",
      "Epoch:  89 Step:   416 /   793 Train loss: 0.04971266\r\n",
      "Epoch:  89 Step:   417 /   793 Train loss: 0.02549044\r\n",
      "Epoch:  89 Step:   418 /   793 Train loss: 0.03534765\r\n",
      "Epoch:  89 Step:   419 /   793 Train loss: 0.02908123\r\n",
      "Epoch:  89 Step:   420 /   793 Train loss: 0.02774260\r\n",
      "Epoch:  89 Step:   421 /   793 Train loss: 0.02215094\r\n",
      "Epoch:  89 Step:   422 /   793 Train loss: 0.02840343\r\n",
      "Epoch:  89 Step:   423 /   793 Train loss: 0.01814651\r\n",
      "Epoch:  89 Step:   424 /   793 Train loss: 0.02049953\r\n",
      "Epoch:  89 Step:   425 /   793 Train loss: 0.02975875\r\n",
      "Epoch:  89 Step:   426 /   793 Train loss: 0.03799669\r\n",
      "Epoch:  89 Step:   427 /   793 Train loss: 0.01870043\r\n",
      "Epoch:  89 Step:   428 /   793 Train loss: 0.03071294\r\n",
      "Epoch:  89 Step:   429 /   793 Train loss: 0.02019090\r\n",
      "Epoch:  89 Step:   430 /   793 Train loss: 0.02312836\r\n",
      "Epoch:  89 Step:   431 /   793 Train loss: 0.02167913\r\n",
      "Epoch:  89 Step:   432 /   793 Train loss: 0.01807186\r\n",
      "Epoch:  89 Step:   433 /   793 Train loss: 0.04189065\r\n",
      "Epoch:  89 Step:   434 /   793 Train loss: 0.02220586\r\n",
      "Epoch:  89 Step:   435 /   793 Train loss: 0.02608419\r\n",
      "Epoch:  89 Step:   436 /   793 Train loss: 0.01531028\r\n",
      "Epoch:  89 Step:   437 /   793 Train loss: 0.01340609\r\n",
      "Epoch:  89 Step:   438 /   793 Train loss: 0.02527628\r\n",
      "Epoch:  89 Step:   439 /   793 Train loss: 0.02722696\r\n",
      "Epoch:  89 Step:   440 /   793 Train loss: 0.03246268\r\n",
      "Epoch:  89 Step:   441 /   793 Train loss: 0.03290461\r\n",
      "Epoch:  89 Step:   442 /   793 Train loss: 0.01862827\r\n",
      "Epoch:  89 Step:   443 /   793 Train loss: 0.02801503\r\n",
      "Epoch:  89 Step:   444 /   793 Train loss: 0.04309799\r\n",
      "Epoch:  89 Step:   445 /   793 Train loss: 0.00733860\r\n",
      "Epoch:  89 Step:   446 /   793 Train loss: 0.02642974\r\n",
      "Epoch:  89 Step:   447 /   793 Train loss: 0.01765170\r\n",
      "Epoch:  89 Step:   448 /   793 Train loss: 0.03691455\r\n",
      "Epoch:  89 Step:   449 /   793 Train loss: 0.02138545\r\n",
      "Epoch:  89 Step:   450 /   793 Train loss: 0.03634313\r\n",
      "Epoch:  89 Step:   451 /   793 Train loss: 0.02113453\r\n",
      "Epoch:  89 Step:   452 /   793 Train loss: 0.01697671\r\n",
      "Epoch:  89 Step:   453 /   793 Train loss: 0.03108532\r\n",
      "Epoch:  89 Step:   454 /   793 Train loss: 0.01730254\r\n",
      "Epoch:  89 Step:   455 /   793 Train loss: 0.03227262\r\n",
      "Epoch:  89 Step:   456 /   793 Train loss: 0.01096039\r\n",
      "Epoch:  89 Step:   457 /   793 Train loss: 0.01465427\r\n",
      "Epoch:  89 Step:   458 /   793 Train loss: 0.01916626\r\n",
      "Epoch:  89 Step:   459 /   793 Train loss: 0.01798856\r\n",
      "Epoch:  89 Step:   460 /   793 Train loss: 0.01561597\r\n",
      "Epoch:  89 Step:   461 /   793 Train loss: 0.01960320\r\n",
      "Epoch:  89 Step:   462 /   793 Train loss: 0.03196552\r\n",
      "Epoch:  89 Step:   463 /   793 Train loss: 0.04346308\r\n",
      "Epoch:  89 Step:   464 /   793 Train loss: 0.01181588\r\n",
      "Epoch:  89 Step:   465 /   793 Train loss: 0.02255663\r\n",
      "Epoch:  89 Step:   466 /   793 Train loss: 0.02589980\r\n",
      "Epoch:  89 Step:   467 /   793 Train loss: 0.02428409\r\n",
      "Epoch:  89 Step:   468 /   793 Train loss: 0.03316399\r\n",
      "Epoch:  89 Step:   469 /   793 Train loss: 0.01024050\r\n",
      "Epoch:  89 Step:   470 /   793 Train loss: 0.01807702\r\n",
      "Epoch:  89 Step:   471 /   793 Train loss: 0.02838212\r\n",
      "Epoch:  89 Step:   472 /   793 Train loss: 0.02845217\r\n",
      "Epoch:  89 Step:   473 /   793 Train loss: 0.01562558\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  89 Step:   474 /   793 Train loss: 0.02080240\r\n",
      "Epoch:  89 Step:   475 /   793 Train loss: 0.01677011\r\n",
      "Epoch:  89 Step:   476 /   793 Train loss: 0.02573711\r\n",
      "Epoch:  89 Step:   477 /   793 Train loss: 0.01351068\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  89 Step:   478 /   793 Train loss: 0.01653136\r\n",
      "Epoch:  89 Step:   479 /   793 Train loss: 0.02266488\r\n",
      "Epoch:  89 Step:   480 /   793 Train loss: 0.02054809\r\n",
      "Epoch:  89 Step:   481 /   793 Train loss: 0.02296057\r\n",
      "Epoch:  89 Step:   482 /   793 Train loss: 0.02463833\r\n",
      "Epoch:  89 Step:   483 /   793 Train loss: 0.02563709\r\n",
      "Epoch:  89 Step:   484 /   793 Train loss: 0.01741196\r\n",
      "Epoch:  89 Step:   485 /   793 Train loss: 0.02153907\r\n",
      "Epoch:  89 Step:   486 /   793 Train loss: 0.02823153\r\n",
      "Epoch:  89 Step:   487 /   793 Train loss: 0.01551347\r\n",
      "Epoch:  89 Step:   488 /   793 Train loss: 0.02646568\r\n",
      "Epoch:  89 Step:   489 /   793 Train loss: 0.02290187\r\n",
      "Epoch:  89 Step:   490 /   793 Train loss: 0.02242729\r\n",
      "Epoch:  89 Step:   491 /   793 Train loss: 0.01627582\r\n",
      "Epoch:  89 Step:   492 /   793 Train loss: 0.03442220\r\n",
      "Epoch:  89 Step:   493 /   793 Train loss: 0.02565696\r\n",
      "Epoch:  89 Step:   494 /   793 Train loss: 0.01818736\r\n",
      "Epoch:  89 Step:   495 /   793 Train loss: 0.01584026\r\n",
      "Epoch:  89 Step:   496 /   793 Train loss: 0.02127685\r\n",
      "Epoch:  89 Step:   497 /   793 Train loss: 0.02112580\r\n",
      "Epoch:  89 Step:   498 /   793 Train loss: 0.02805269\r\n",
      "Epoch:  89 Step:   499 /   793 Train loss: 0.01687440\r\n",
      "Epoch:  89 Step:   500 /   793 Train loss: 0.03121638\r\n",
      "Epoch:  89 Step:   501 /   793 Train loss: 0.01920635\r\n",
      "Epoch:  89 Step:   502 /   793 Train loss: 0.02164784\r\n",
      "Epoch:  89 Step:   503 /   793 Train loss: 0.02258556\r\n",
      "Epoch:  89 Step:   504 /   793 Train loss: 0.02052812\r\n",
      "Epoch:  89 Step:   505 /   793 Train loss: 0.02288367\r\n",
      "Epoch:  89 Step:   506 /   793 Train loss: 0.02783582\r\n",
      "Epoch:  89 Step:   507 /   793 Train loss: 0.02200239\r\n",
      "Epoch:  89 Step:   508 /   793 Train loss: 0.02330954\r\n",
      "Epoch:  89 Step:   509 /   793 Train loss: 0.01998259\r\n",
      "Epoch:  89 Step:   510 /   793 Train loss: 0.02343581\r\n",
      "Epoch:  89 Step:   511 /   793 Train loss: 0.01685183\r\n",
      "Epoch:  89 Step:   512 /   793 Train loss: 0.01849681\r\n",
      "Epoch:  89 Step:   513 /   793 Train loss: 0.01865463\r\n",
      "Epoch:  89 Step:   514 /   793 Train loss: 0.02096048\r\n",
      "Epoch:  89 Step:   515 /   793 Train loss: 0.03048195\r\n",
      "Epoch:  89 Step:   516 /   793 Train loss: 0.03078618\r\n",
      "Epoch:  89 Step:   517 /   793 Train loss: 0.02968013\r\n",
      "Epoch:  89 Step:   518 /   793 Train loss: 0.02345698\r\n",
      "Epoch:  89 Step:   519 /   793 Train loss: 0.02231318\r\n",
      "Epoch:  89 Step:   520 /   793 Train loss: 0.02920059\r\n",
      "Epoch:  89 Step:   521 /   793 Train loss: 0.02474016\r\n",
      "Epoch:  89 Step:   522 /   793 Train loss: 0.02389157\r\n",
      "Epoch:  89 Step:   523 /   793 Train loss: 0.01512875\r\n",
      "Epoch:  89 Step:   524 /   793 Train loss: 0.01831197\r\n",
      "Epoch:  89 Step:   525 /   793 Train loss: 0.01943964\r\n",
      "Epoch:  89 Step:   526 /   793 Train loss: 0.02063811\r\n",
      "Epoch:  89 Step:   527 /   793 Train loss: 0.03097704\r\n",
      "Epoch:  89 Step:   528 /   793 Train loss: 0.02110116\r\n",
      "Epoch:  89 Step:   529 /   793 Train loss: 0.02936094\r\n",
      "Epoch:  89 Step:   530 /   793 Train loss: 0.02661430\r\n",
      "Epoch:  89 Step:   531 /   793 Train loss: 0.02492961\r\n",
      "Epoch:  89 Step:   532 /   793 Train loss: 0.02242242\r\n",
      "Epoch:  89 Step:   533 /   793 Train loss: 0.02346564\r\n",
      "Epoch:  89 Step:   534 /   793 Train loss: 0.02074822\r\n",
      "Epoch:  89 Step:   535 /   793 Train loss: 0.03105287\r\n",
      "Epoch:  89 Step:   536 /   793 Train loss: 0.01887728\r\n",
      "Epoch:  89 Step:   537 /   793 Train loss: 0.02999358\r\n",
      "Epoch:  89 Step:   538 /   793 Train loss: 0.01991859\r\n",
      "Epoch:  89 Step:   539 /   793 Train loss: 0.01847171\r\n",
      "Epoch:  89 Step:   540 /   793 Train loss: 0.02437827\r\n",
      "Epoch:  89 Step:   541 /   793 Train loss: 0.02190878\r\n",
      "Epoch:  89 Step:   542 /   793 Train loss: 0.01474779\r\n",
      "Epoch:  89 Step:   543 /   793 Train loss: 0.02686490\r\n",
      "Epoch:  89 Step:   544 /   793 Train loss: 0.02047819\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  89 Step:   545 /   793 Train loss: 0.02601043\r\n",
      "Epoch:  89 Step:   546 /   793 Train loss: 0.02189017\r\n",
      "Epoch:  89 Step:   547 /   793 Train loss: 0.02197452\r\n",
      "Epoch:  89 Step:   548 /   793 Train loss: 0.02826503\r\n",
      "Epoch:  89 Step:   549 /   793 Train loss: 0.01842546\r\n",
      "Epoch:  89 Step:   550 /   793 Train loss: 0.02039430\r\n",
      "Epoch:  89 Step:   551 /   793 Train loss: 0.02355727\r\n",
      "Epoch:  89 Step:   552 /   793 Train loss: 0.02218788\r\n",
      "Epoch:  89 Step:   553 /   793 Train loss: 0.03422858\r\n",
      "Epoch:  89 Step:   554 /   793 Train loss: 0.02877252\r\n",
      "Epoch:  89 Step:   555 /   793 Train loss: 0.02180060\r\n",
      "Epoch:  89 Step:   556 /   793 Train loss: 0.02282135\r\n",
      "Epoch:  89 Step:   557 /   793 Train loss: 0.01932168\r\n",
      "Epoch:  89 Step:   558 /   793 Train loss: 0.02665680\r\n",
      "Epoch:  89 Step:   559 /   793 Train loss: 0.02472101\r\n",
      "Epoch:  89 Step:   560 /   793 Train loss: 0.02176952\r\n",
      "Epoch:  89 Step:   561 /   793 Train loss: 0.01960323\r\n",
      "Epoch:  89 Step:   562 /   793 Train loss: 0.02618170\r\n",
      "Epoch:  89 Step:   563 /   793 Train loss: 0.03483004\r\n",
      "Epoch:  89 Step:   564 /   793 Train loss: 0.02889362\r\n",
      "Epoch:  89 Step:   565 /   793 Train loss: 0.02840411\r\n",
      "Epoch:  89 Step:   566 /   793 Train loss: 0.01158902\r\n",
      "Epoch:  89 Step:   567 /   793 Train loss: 0.03274804\r\n",
      "Epoch:  89 Step:   568 /   793 Train loss: 0.02080461\r\n",
      "Epoch:  89 Step:   569 /   793 Train loss: 0.03027404\r\n",
      "Epoch:  89 Step:   570 /   793 Train loss: 0.01443421\r\n",
      "Epoch:  89 Step:   571 /   793 Train loss: 0.02551708\r\n",
      "Epoch:  89 Step:   572 /   793 Train loss: 0.02175200\r\n",
      "Epoch:  89 Step:   573 /   793 Train loss: 0.01650310\r\n",
      "Epoch:  89 Step:   574 /   793 Train loss: 0.01674298\r\n",
      "Epoch:  89 Step:   575 /   793 Train loss: 0.02259789\r\n",
      "Epoch:  89 Step:   576 /   793 Train loss: 0.03066048\r\n",
      "Epoch:  89 Step:   577 /   793 Train loss: 0.02434727\r\n",
      "Epoch:  89 Step:   578 /   793 Train loss: 0.03129949\r\n",
      "Epoch:  89 Step:   579 /   793 Train loss: 0.02057263\r\n",
      "Epoch:  89 Step:   580 /   793 Train loss: 0.02156867\r\n",
      "Epoch:  89 Step:   581 /   793 Train loss: 0.02227484\r\n",
      "Epoch:  89 Step:   582 /   793 Train loss: 0.02699685\r\n",
      "Epoch:  89 Step:   583 /   793 Train loss: 0.02747047\r\n",
      "Epoch:  89 Step:   584 /   793 Train loss: 0.01562813\r\n",
      "Epoch:  89 Step:   585 /   793 Train loss: 0.03156858\r\n",
      "Epoch:  89 Step:   586 /   793 Train loss: 0.03038746\r\n",
      "Epoch:  89 Step:   587 /   793 Train loss: 0.03217810\r\n",
      "Epoch:  89 Step:   588 /   793 Train loss: 0.02755866\r\n",
      "Epoch:  89 Step:   589 /   793 Train loss: 0.02825196\r\n",
      "Epoch:  89 Step:   590 /   793 Train loss: 0.02094511\r\n",
      "Epoch:  89 Step:   591 /   793 Train loss: 0.01752186\r\n",
      "Epoch:  89 Step:   592 /   793 Train loss: 0.03151939\r\n",
      "Epoch:  89 Step:   593 /   793 Train loss: 0.03242784\r\n",
      "Epoch:  89 Step:   594 /   793 Train loss: 0.01834725\r\n",
      "Epoch:  89 Step:   595 /   793 Train loss: 0.03580441\r\n",
      "Epoch:  89 Step:   596 /   793 Train loss: 0.02520794\r\n",
      "Epoch:  89 Step:   597 /   793 Train loss: 0.01981469\r\n",
      "Epoch:  89 Step:   598 /   793 Train loss: 0.02141228\r\n",
      "Epoch:  89 Step:   599 /   793 Train loss: 0.02890132\r\n",
      "Epoch:  89 Step:   600 /   793 Train loss: 0.01959239\r\n",
      "Epoch:  89 Step:   601 /   793 Train loss: 0.01877962\r\n",
      "Epoch:  89 Step:   602 /   793 Train loss: 0.01895016\r\n",
      "Epoch:  89 Step:   603 /   793 Train loss: 0.01879268\r\n",
      "Epoch:  89 Step:   604 /   793 Train loss: 0.02234648\r\n",
      "Epoch:  89 Step:   605 /   793 Train loss: 0.02646993\r\n",
      "Epoch:  89 Step:   606 /   793 Train loss: 0.01735963\r\n",
      "Epoch:  89 Step:   607 /   793 Train loss: 0.03008765\r\n",
      "Epoch:  89 Step:   608 /   793 Train loss: 0.02373056\r\n",
      "Epoch:  89 Step:   609 /   793 Train loss: 0.02855338\r\n",
      "Epoch:  89 Step:   610 /   793 Train loss: 0.02238200\r\n",
      "Epoch:  89 Step:   611 /   793 Train loss: 0.02184759\r\n",
      "Epoch:  89 Step:   612 /   793 Train loss: 0.01690896\r\n",
      "Epoch:  89 Step:   613 /   793 Train loss: 0.01710320\r\n",
      "Epoch:  89 Step:   614 /   793 Train loss: 0.02550123\r\n",
      "Epoch:  89 Step:   615 /   793 Train loss: 0.02161212\r\n",
      "Epoch:  89 Step:   616 /   793 Train loss: 0.02407604\r\n",
      "Epoch:  89 Step:   617 /   793 Train loss: 0.03116601\r\n",
      "Epoch:  89 Step:   618 /   793 Train loss: 0.02637884\r\n",
      "Epoch:  89 Step:   619 /   793 Train loss: 0.02424460\r\n",
      "Epoch:  89 Step:   620 /   793 Train loss: 0.02261604\r\n",
      "Epoch:  89 Step:   621 /   793 Train loss: 0.02196638\r\n",
      "Epoch:  89 Step:   622 /   793 Train loss: 0.02763349\r\n",
      "Epoch:  89 Step:   623 /   793 Train loss: 0.02570392\r\n",
      "Epoch:  89 Step:   624 /   793 Train loss: 0.03269735\r\n",
      "Epoch:  89 Step:   625 /   793 Train loss: 0.02128259\r\n",
      "Epoch:  89 Step:   626 /   793 Train loss: 0.01323347\r\n",
      "Epoch:  89 Step:   627 /   793 Train loss: 0.02553702\r\n",
      "Epoch:  89 Step:   628 /   793 Train loss: 0.02038969\r\n",
      "Epoch:  89 Step:   629 /   793 Train loss: 0.01645007\r\n",
      "Epoch:  89 Step:   630 /   793 Train loss: 0.02022317\r\n",
      "Epoch:  89 Step:   631 /   793 Train loss: 0.04517721\r\n",
      "Epoch:  89 Step:   632 /   793 Train loss: 0.02356235\r\n",
      "Epoch:  89 Step:   633 /   793 Train loss: 0.02594067\r\n",
      "Epoch:  89 Step:   634 /   793 Train loss: 0.01882947\r\n",
      "Epoch:  89 Step:   635 /   793 Train loss: 0.02186739\r\n",
      "Epoch:  89 Step:   636 /   793 Train loss: 0.02248809\r\n",
      "Epoch:  89 Step:   637 /   793 Train loss: 0.02726768\r\n",
      "Epoch:  89 Step:   638 /   793 Train loss: 0.02556829\r\n",
      "Epoch:  89 Step:   639 /   793 Train loss: 0.03293054\r\n",
      "Epoch:  89 Step:   640 /   793 Train loss: 0.02207232\r\n",
      "Epoch:  89 Step:   641 /   793 Train loss: 0.03024884\r\n",
      "Epoch:  89 Step:   642 /   793 Train loss: 0.04124755\r\n",
      "Epoch:  89 Step:   643 /   793 Train loss: 0.01131271\r\n",
      "Epoch:  89 Step:   644 /   793 Train loss: 0.02761097\r\n",
      "Epoch:  89 Step:   645 /   793 Train loss: 0.01434005\r\n",
      "Epoch:  89 Step:   646 /   793 Train loss: 0.03394872\r\n",
      "Epoch:  89 Step:   647 /   793 Train loss: 0.03088282\r\n",
      "Epoch:  89 Step:   648 /   793 Train loss: 0.02689238\r\n",
      "Epoch:  89 Step:   649 /   793 Train loss: 0.03403039\r\n",
      "Epoch:  89 Step:   650 /   793 Train loss: 0.01783716\r\n",
      "Epoch:  89 Step:   651 /   793 Train loss: 0.01462733\r\n",
      "Epoch:  89 Step:   652 /   793 Train loss: 0.03570621\r\n",
      "Epoch:  89 Step:   653 /   793 Train loss: 0.02798083\r\n",
      "Epoch:  89 Step:   654 /   793 Train loss: 0.02484167\r\n",
      "Epoch:  89 Step:   655 /   793 Train loss: 0.02793471\r\n",
      "Epoch:  89 Step:   656 /   793 Train loss: 0.05055016\r\n",
      "Epoch:  89 Step:   657 /   793 Train loss: 0.03353707\r\n",
      "Epoch:  89 Step:   658 /   793 Train loss: 0.03133999\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  89 Step:   659 /   793 Train loss: 0.02591545\r\n",
      "Epoch:  89 Step:   660 /   793 Train loss: 0.03488684\r\n",
      "Epoch:  89 Step:   661 /   793 Train loss: 0.01125610\r\n",
      "Epoch:  89 Step:   662 /   793 Train loss: 0.02276066\r\n",
      "Epoch:  89 Step:   663 /   793 Train loss: 0.01871526\r\n",
      "Epoch:  89 Step:   664 /   793 Train loss: 0.02267972\r\n",
      "Epoch:  89 Step:   665 /   793 Train loss: 0.03444099\r\n",
      "Epoch:  89 Step:   666 /   793 Train loss: 0.01605135\r\n",
      "Epoch:  89 Step:   667 /   793 Train loss: 0.03264677\r\n",
      "Epoch:  89 Step:   668 /   793 Train loss: 0.03183892\r\n",
      "Epoch:  89 Step:   669 /   793 Train loss: 0.03105299\r\n",
      "Epoch:  89 Step:   670 /   793 Train loss: 0.02945680\r\n",
      "Epoch:  89 Step:   671 /   793 Train loss: 0.02182358\r\n",
      "Epoch:  89 Step:   672 /   793 Train loss: 0.02712826\r\n",
      "Epoch:  89 Step:   673 /   793 Train loss: 0.01929686\r\n",
      "Epoch:  89 Step:   674 /   793 Train loss: 0.01715001\r\n",
      "Epoch:  89 Step:   675 /   793 Train loss: 0.01579260\r\n",
      "Epoch:  89 Step:   676 /   793 Train loss: 0.02493399\r\n",
      "Epoch:  89 Step:   677 /   793 Train loss: 0.02438562\r\n",
      "Epoch:  89 Step:   678 /   793 Train loss: 0.02296495\r\n",
      "Epoch:  89 Step:   679 /   793 Train loss: 0.01568793\r\n",
      "Epoch:  89 Step:   680 /   793 Train loss: 0.02089150\r\n",
      "Epoch:  89 Step:   681 /   793 Train loss: 0.01628967\r\n",
      "Epoch:  89 Step:   682 /   793 Train loss: 0.02811078\r\n",
      "Epoch:  89 Step:   683 /   793 Train loss: 0.01788068\r\n",
      "Epoch:  89 Step:   684 /   793 Train loss: 0.02388811\r\n",
      "Epoch:  89 Step:   685 /   793 Train loss: 0.01860832\r\n",
      "Epoch:  89 Step:   686 /   793 Train loss: 0.01639723\r\n",
      "Epoch:  89 Step:   687 /   793 Train loss: 0.04012227\r\n",
      "Epoch:  89 Step:   688 /   793 Train loss: 0.02267100\r\n",
      "Epoch:  89 Step:   689 /   793 Train loss: 0.03276193\r\n",
      "Epoch:  89 Step:   690 /   793 Train loss: 0.03601655\r\n",
      "Epoch:  89 Step:   691 /   793 Train loss: 0.02526797\r\n",
      "Epoch:  89 Step:   692 /   793 Train loss: 0.02256045\r\n",
      "Epoch:  89 Step:   693 /   793 Train loss: 0.03287796\r\n",
      "Epoch:  89 Step:   694 /   793 Train loss: 0.01865635\r\n",
      "Epoch:  89 Step:   695 /   793 Train loss: 0.03002537\r\n",
      "Epoch:  89 Step:   696 /   793 Train loss: 0.02930838\r\n",
      "Epoch:  89 Step:   697 /   793 Train loss: 0.01605604\r\n",
      "Epoch:  89 Step:   698 /   793 Train loss: 0.01442563\r\n",
      "Epoch:  89 Step:   699 /   793 Train loss: 0.03386105\r\n",
      "Epoch:  89 Step:   700 /   793 Train loss: 0.03927382\r\n",
      "Epoch:  89 Step:   701 /   793 Train loss: 0.02000097\r\n",
      "Epoch:  89 Step:   702 /   793 Train loss: 0.02671100\r\n",
      "Epoch:  89 Step:   703 /   793 Train loss: 0.02453945\r\n",
      "Epoch:  89 Step:   704 /   793 Train loss: 0.01683401\r\n",
      "Epoch:  89 Step:   705 /   793 Train loss: 0.02489844\r\n",
      "Epoch:  89 Step:   706 /   793 Train loss: 0.02420699\r\n",
      "Epoch:  89 Step:   707 /   793 Train loss: 0.02258484\r\n",
      "Epoch:  89 Step:   708 /   793 Train loss: 0.02527454\r\n",
      "Epoch:  89 Step:   709 /   793 Train loss: 0.01955032\r\n",
      "Epoch:  89 Step:   710 /   793 Train loss: 0.02164102\r\n",
      "Epoch:  89 Step:   711 /   793 Train loss: 0.03952907\r\n",
      "Epoch:  89 Step:   712 /   793 Train loss: 0.02363342\r\n",
      "Epoch:  89 Step:   713 /   793 Train loss: 0.03136690\r\n",
      "Epoch:  89 Step:   714 /   793 Train loss: 0.03511096\r\n",
      "Epoch:  89 Step:   715 /   793 Train loss: 0.01648107\r\n",
      "Epoch:  89 Step:   716 /   793 Train loss: 0.02424359\r\n",
      "Epoch:  89 Step:   717 /   793 Train loss: 0.03106925\r\n",
      "Epoch:  89 Step:   718 /   793 Train loss: 0.01260829\r\n",
      "Epoch:  89 Step:   719 /   793 Train loss: 0.02767365\r\n",
      "Epoch:  89 Step:   720 /   793 Train loss: 0.01224669\r\n",
      "Epoch:  89 Step:   721 /   793 Train loss: 0.01638328\r\n",
      "Epoch:  89 Step:   722 /   793 Train loss: 0.02635256\r\n",
      "Epoch:  89 Step:   723 /   793 Train loss: 0.01705213\r\n",
      "Epoch:  89 Step:   724 /   793 Train loss: 0.02459498\r\n",
      "Epoch:  89 Step:   725 /   793 Train loss: 0.02955211\r\n",
      "Epoch:  89 Step:   726 /   793 Train loss: 0.02220632\r\n",
      "Epoch:  89 Step:   727 /   793 Train loss: 0.02820877\r\n",
      "Epoch:  89 Step:   728 /   793 Train loss: 0.02324034\r\n",
      "Epoch:  89 Step:   729 /   793 Train loss: 0.01376975\r\n",
      "Epoch:  89 Step:   730 /   793 Train loss: 0.02776203\r\n",
      "Epoch:  89 Step:   731 /   793 Train loss: 0.02180019\r\n",
      "Epoch:  89 Step:   732 /   793 Train loss: 0.03310054\r\n",
      "Epoch:  89 Step:   733 /   793 Train loss: 0.02863138\r\n",
      "Epoch:  89 Step:   734 /   793 Train loss: 0.01060661\r\n",
      "Epoch:  89 Step:   735 /   793 Train loss: 0.01514963\r\n",
      "Epoch:  89 Step:   736 /   793 Train loss: 0.02683193\r\n",
      "Epoch:  89 Step:   737 /   793 Train loss: 0.02391643\r\n",
      "Epoch:  89 Step:   738 /   793 Train loss: 0.03232131\r\n",
      "Epoch:  89 Step:   739 /   793 Train loss: 0.04151639\r\n",
      "Epoch:  89 Step:   740 /   793 Train loss: 0.01748605\r\n",
      "Epoch:  89 Step:   741 /   793 Train loss: 0.02157864\r\n",
      "Epoch:  89 Step:   742 /   793 Train loss: 0.02659905\r\n",
      "Epoch:  89 Step:   743 /   793 Train loss: 0.02008506\r\n",
      "Epoch:  89 Step:   744 /   793 Train loss: 0.02029290\r\n",
      "Epoch:  89 Step:   745 /   793 Train loss: 0.02363449\r\n",
      "Epoch:  89 Step:   746 /   793 Train loss: 0.03520517\r\n",
      "Epoch:  89 Step:   747 /   793 Train loss: 0.02511754\r\n",
      "Epoch:  89 Step:   748 /   793 Train loss: 0.01393082\r\n",
      "Epoch:  89 Step:   749 /   793 Train loss: 0.02125215\r\n",
      "Epoch:  89 Step:   750 /   793 Train loss: 0.03264394\r\n",
      "Epoch:  89 Step:   751 /   793 Train loss: 0.03309041\r\n",
      "Epoch:  89 Step:   752 /   793 Train loss: 0.02828697\r\n",
      "Epoch:  89 Step:   753 /   793 Train loss: 0.03006757\r\n",
      "Epoch:  89 Step:   754 /   793 Train loss: 0.02087004\r\n",
      "Epoch:  89 Step:   755 /   793 Train loss: 0.02045818\r\n",
      "Epoch:  89 Step:   756 /   793 Train loss: 0.02356262\r\n",
      "Epoch:  89 Step:   757 /   793 Train loss: 0.02325952\r\n",
      "Epoch:  89 Step:   758 /   793 Train loss: 0.03436888\r\n",
      "Epoch:  89 Step:   759 /   793 Train loss: 0.01870504\r\n",
      "Epoch:  89 Step:   760 /   793 Train loss: 0.03638498\r\n",
      "Epoch:  89 Step:   761 /   793 Train loss: 0.02642787\r\n",
      "Epoch:  89 Step:   762 /   793 Train loss: 0.02376818\r\n",
      "Epoch:  89 Step:   763 /   793 Train loss: 0.01932191\r\n",
      "Epoch:  89 Step:   764 /   793 Train loss: 0.02146502\r\n",
      "Epoch:  89 Step:   765 /   793 Train loss: 0.00954317\r\n",
      "Epoch:  89 Step:   766 /   793 Train loss: 0.03220465\r\n",
      "Epoch:  89 Step:   767 /   793 Train loss: 0.01824498\r\n",
      "Epoch:  89 Step:   768 /   793 Train loss: 0.03037883\r\n",
      "Epoch:  89 Step:   769 /   793 Train loss: 0.01911952\r\n",
      "Epoch:  89 Step:   770 /   793 Train loss: 0.03722578\r\n",
      "Epoch:  89 Step:   771 /   793 Train loss: 0.02172599\r\n",
      "Epoch:  89 Step:   772 /   793 Train loss: 0.01822236\r\n",
      "Epoch:  89 Step:   773 /   793 Train loss: 0.02228871\r\n",
      "Epoch:  89 Step:   774 /   793 Train loss: 0.03925868\r\n",
      "Epoch:  89 Step:   775 /   793 Train loss: 0.02778607\r\n",
      "Epoch:  89 Step:   776 /   793 Train loss: 0.00686207\r\n",
      "Epoch:  89 Step:   777 /   793 Train loss: 0.02138443\r\n",
      "Epoch:  89 Step:   778 /   793 Train loss: 0.01906509\r\n",
      "Epoch:  89 Step:   779 /   793 Train loss: 0.01896141\r\n",
      "Epoch:  89 Step:   780 /   793 Train loss: 0.02068455\r\n",
      "Epoch:  89 Step:   781 /   793 Train loss: 0.01393335\r\n",
      "Epoch:  89 Step:   782 /   793 Train loss: 0.02763409\r\n",
      "Epoch:  89 Step:   783 /   793 Train loss: 0.03828667\r\n",
      "Epoch:  89 Step:   784 /   793 Train loss: 0.01897570\r\n",
      "Epoch:  89 Step:   785 /   793 Train loss: 0.02172670\r\n",
      "Epoch:  89 Step:   786 /   793 Train loss: 0.01403065\r\n",
      "Epoch:  89 Step:   787 /   793 Train loss: 0.01403953\r\n",
      "Epoch:  89 Step:   788 /   793 Train loss: 0.01533617\r\n",
      "Epoch:  89 Step:   789 /   793 Train loss: 0.02992044\r\n",
      "Epoch:  89 Step:   790 /   793 Train loss: 0.01219012\r\n",
      "Epoch:  89 Step:   791 /   793 Train loss: 0.01449861\r\n",
      "Epoch:  89 Step:   792 /   793 Train loss: 0.01066868\r\n",
      "Epoch:  89 Validation loss: 0.01424696\r\n",
      "Epoch:  90 Step:     0 /   793 Train loss: 0.03216127\r\n",
      "Epoch:  90 Step:     1 /   793 Train loss: 0.00928129\r\n",
      "Epoch:  90 Step:     2 /   793 Train loss: 0.01200088\r\n",
      "Epoch:  90 Step:     3 /   793 Train loss: 0.01607582\r\n",
      "Epoch:  90 Step:     4 /   793 Train loss: 0.01907407\r\n",
      "Epoch:  90 Step:     5 /   793 Train loss: 0.02867504\r\n",
      "Epoch:  90 Step:     6 /   793 Train loss: 0.01857560\r\n",
      "Epoch:  90 Step:     7 /   793 Train loss: 0.02572823\r\n",
      "Epoch:  90 Step:     8 /   793 Train loss: 0.01198342\r\n",
      "Epoch:  90 Step:     9 /   793 Train loss: 0.01762871\r\n",
      "Epoch:  90 Step:    10 /   793 Train loss: 0.01139760\r\n",
      "Epoch:  90 Step:    11 /   793 Train loss: 0.02822286\r\n",
      "Epoch:  90 Step:    12 /   793 Train loss: 0.02491053\r\n",
      "Epoch:  90 Step:    13 /   793 Train loss: 0.01461327\r\n",
      "Epoch:  90 Step:    14 /   793 Train loss: 0.02681740\r\n",
      "Epoch:  90 Step:    15 /   793 Train loss: 0.01301854\r\n",
      "Epoch:  90 Step:    16 /   793 Train loss: 0.03555238\r\n",
      "Epoch:  90 Step:    17 /   793 Train loss: 0.03010300\r\n",
      "Epoch:  90 Step:    18 /   793 Train loss: 0.02718770\r\n",
      "Epoch:  90 Step:    19 /   793 Train loss: 0.01699808\r\n",
      "Epoch:  90 Step:    20 /   793 Train loss: 0.02437558\r\n",
      "Epoch:  90 Step:    21 /   793 Train loss: 0.01707013\r\n",
      "Epoch:  90 Step:    22 /   793 Train loss: 0.02612454\r\n",
      "Epoch:  90 Step:    23 /   793 Train loss: 0.02588709\r\n",
      "Epoch:  90 Step:    24 /   793 Train loss: 0.02675918\r\n",
      "Epoch:  90 Step:    25 /   793 Train loss: 0.01559542\r\n",
      "Epoch:  90 Step:    26 /   793 Train loss: 0.02338656\r\n",
      "Epoch:  90 Step:    27 /   793 Train loss: 0.04002989\r\n",
      "Epoch:  90 Step:    28 /   793 Train loss: 0.03202839\r\n",
      "Epoch:  90 Step:    29 /   793 Train loss: 0.04117929\r\n",
      "Epoch:  90 Step:    30 /   793 Train loss: 0.02659259\r\n",
      "Epoch:  90 Step:    31 /   793 Train loss: 0.01468762\r\n",
      "Epoch:  90 Step:    32 /   793 Train loss: 0.03077587\r\n",
      "Epoch:  90 Step:    33 /   793 Train loss: 0.03854913\r\n",
      "Epoch:  90 Step:    34 /   793 Train loss: 0.01738636\r\n",
      "Epoch:  90 Step:    35 /   793 Train loss: 0.03105625\r\n",
      "Epoch:  90 Step:    36 /   793 Train loss: 0.02887545\r\n",
      "Epoch:  90 Step:    37 /   793 Train loss: 0.02714636\r\n",
      "Epoch:  90 Step:    38 /   793 Train loss: 0.01713751\r\n",
      "Epoch:  90 Step:    39 /   793 Train loss: 0.01876408\r\n",
      "Epoch:  90 Step:    40 /   793 Train loss: 0.02481196\r\n",
      "Epoch:  90 Step:    41 /   793 Train loss: 0.02348316\r\n",
      "Epoch:  90 Step:    42 /   793 Train loss: 0.03768793\r\n",
      "Epoch:  90 Step:    43 /   793 Train loss: 0.02197715\r\n",
      "Epoch:  90 Step:    44 /   793 Train loss: 0.01690650\r\n",
      "Epoch:  90 Step:    45 /   793 Train loss: 0.03177614\r\n",
      "Epoch:  90 Step:    46 /   793 Train loss: 0.02021480\r\n",
      "Epoch:  90 Step:    47 /   793 Train loss: 0.01677762\r\n",
      "Epoch:  90 Step:    48 /   793 Train loss: 0.03275850\r\n",
      "Epoch:  90 Step:    49 /   793 Train loss: 0.01636481\r\n",
      "Epoch:  90 Step:    50 /   793 Train loss: 0.02646600\r\n",
      "Epoch:  90 Step:    51 /   793 Train loss: 0.02547013\r\n",
      "Epoch:  90 Step:    52 /   793 Train loss: 0.01640011\r\n",
      "Epoch:  90 Step:    53 /   793 Train loss: 0.02483352\r\n",
      "Epoch:  90 Step:    54 /   793 Train loss: 0.01629692\r\n",
      "Epoch:  90 Step:    55 /   793 Train loss: 0.02260062\r\n",
      "Epoch:  90 Step:    56 /   793 Train loss: 0.02156147\r\n",
      "Epoch:  90 Step:    57 /   793 Train loss: 0.02275894\r\n",
      "Epoch:  90 Step:    58 /   793 Train loss: 0.02245720\r\n",
      "Epoch:  90 Step:    59 /   793 Train loss: 0.01709873\r\n",
      "Epoch:  90 Step:    60 /   793 Train loss: 0.01360852\r\n",
      "Epoch:  90 Step:    61 /   793 Train loss: 0.01764375\r\n",
      "Epoch:  90 Step:    62 /   793 Train loss: 0.02825167\r\n",
      "Epoch:  90 Step:    63 /   793 Train loss: 0.03071437\r\n",
      "Epoch:  90 Step:    64 /   793 Train loss: 0.02531274\r\n",
      "Epoch:  90 Step:    65 /   793 Train loss: 0.02279211\r\n",
      "Epoch:  90 Step:    66 /   793 Train loss: 0.02250871\r\n",
      "Epoch:  90 Step:    67 /   793 Train loss: 0.01753036\r\n",
      "Epoch:  90 Step:    68 /   793 Train loss: 0.02916545\r\n",
      "Epoch:  90 Step:    69 /   793 Train loss: 0.03023638\r\n",
      "Epoch:  90 Step:    70 /   793 Train loss: 0.02472577\r\n",
      "Epoch:  90 Step:    71 /   793 Train loss: 0.01769116\r\n",
      "Epoch:  90 Step:    72 /   793 Train loss: 0.03680155\r\n",
      "Epoch:  90 Step:    73 /   793 Train loss: 0.01730810\r\n",
      "Epoch:  90 Step:    74 /   793 Train loss: 0.02154849\r\n",
      "Epoch:  90 Step:    75 /   793 Train loss: 0.02950275\r\n",
      "Epoch:  90 Step:    76 /   793 Train loss: 0.03496819\r\n",
      "Epoch:  90 Step:    77 /   793 Train loss: 0.03469657\r\n",
      "Epoch:  90 Step:    78 /   793 Train loss: 0.02601656\r\n",
      "Epoch:  90 Step:    79 /   793 Train loss: 0.03201327\r\n",
      "Epoch:  90 Step:    80 /   793 Train loss: 0.02446696\r\n",
      "Epoch:  90 Step:    81 /   793 Train loss: 0.02573680\r\n",
      "Epoch:  90 Step:    82 /   793 Train loss: 0.01731939\r\n",
      "Epoch:  90 Step:    83 /   793 Train loss: 0.02501722\r\n",
      "Epoch:  90 Step:    84 /   793 Train loss: 0.03295818\r\n",
      "Epoch:  90 Step:    85 /   793 Train loss: 0.02127076\r\n",
      "Epoch:  90 Step:    86 /   793 Train loss: 0.03046498\r\n",
      "Epoch:  90 Step:    87 /   793 Train loss: 0.02429672\r\n",
      "Epoch:  90 Step:    88 /   793 Train loss: 0.02366250\r\n",
      "Epoch:  90 Step:    89 /   793 Train loss: 0.02261442\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  90 Step:    90 /   793 Train loss: 0.02576769\r\n",
      "Epoch:  90 Step:    91 /   793 Train loss: 0.02062413\r\n",
      "Epoch:  90 Step:    92 /   793 Train loss: 0.02210956\r\n",
      "Epoch:  90 Step:    93 /   793 Train loss: 0.01762920\r\n",
      "Epoch:  90 Step:    94 /   793 Train loss: 0.02703469\r\n",
      "Epoch:  90 Step:    95 /   793 Train loss: 0.01891953\r\n",
      "Epoch:  90 Step:    96 /   793 Train loss: 0.01536459\r\n",
      "Epoch:  90 Step:    97 /   793 Train loss: 0.03500005\r\n",
      "Epoch:  90 Step:    98 /   793 Train loss: 0.02560882\r\n",
      "Epoch:  90 Step:    99 /   793 Train loss: 0.02046472\r\n",
      "Epoch:  90 Step:   100 /   793 Train loss: 0.01826174\r\n",
      "Epoch:  90 Step:   101 /   793 Train loss: 0.02102750\r\n",
      "Epoch:  90 Step:   102 /   793 Train loss: 0.03214794\r\n",
      "Epoch:  90 Step:   103 /   793 Train loss: 0.01996565\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  90 Step:   104 /   793 Train loss: 0.01945838\r\n",
      "Epoch:  90 Step:   105 /   793 Train loss: 0.01722540\r\n",
      "Epoch:  90 Step:   106 /   793 Train loss: 0.01901007\r\n",
      "Epoch:  90 Step:   107 /   793 Train loss: 0.01705886\r\n",
      "Epoch:  90 Step:   108 /   793 Train loss: 0.01442340\r\n",
      "Epoch:  90 Step:   109 /   793 Train loss: 0.01901843\r\n",
      "Epoch:  90 Step:   110 /   793 Train loss: 0.02146306\r\n",
      "Epoch:  90 Step:   111 /   793 Train loss: 0.02287596\r\n",
      "Epoch:  90 Step:   112 /   793 Train loss: 0.02132013\r\n",
      "Epoch:  90 Step:   113 /   793 Train loss: 0.02000073\r\n",
      "Epoch:  90 Step:   114 /   793 Train loss: 0.02614678\r\n",
      "Epoch:  90 Step:   115 /   793 Train loss: 0.02845380\r\n",
      "Epoch:  90 Step:   116 /   793 Train loss: 0.02570547\r\n",
      "Epoch:  90 Step:   117 /   793 Train loss: 0.02594026\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  90 Step:   118 /   793 Train loss: 0.01979218\r\n",
      "Epoch:  90 Step:   119 /   793 Train loss: 0.01203954\r\n",
      "Epoch:  90 Step:   120 /   793 Train loss: 0.02261905\r\n",
      "Epoch:  90 Step:   121 /   793 Train loss: 0.03190792\r\n",
      "Epoch:  90 Step:   122 /   793 Train loss: 0.03149331\r\n",
      "Epoch:  90 Step:   123 /   793 Train loss: 0.03097488\r\n",
      "Epoch:  90 Step:   124 /   793 Train loss: 0.01242630\r\n",
      "Epoch:  90 Step:   125 /   793 Train loss: 0.03432508\r\n",
      "Epoch:  90 Step:   126 /   793 Train loss: 0.01896784\r\n",
      "Epoch:  90 Step:   127 /   793 Train loss: 0.03311227\r\n",
      "Epoch:  90 Step:   128 /   793 Train loss: 0.03720123\r\n",
      "Epoch:  90 Step:   129 /   793 Train loss: 0.01964519\r\n",
      "Epoch:  90 Step:   130 /   793 Train loss: 0.02173758\r\n",
      "Epoch:  90 Step:   131 /   793 Train loss: 0.02325144\r\n",
      "Epoch:  90 Step:   132 /   793 Train loss: 0.02475292\r\n",
      "Epoch:  90 Step:   133 /   793 Train loss: 0.02770537\r\n",
      "Epoch:  90 Step:   134 /   793 Train loss: 0.03596902\r\n",
      "Epoch:  90 Step:   135 /   793 Train loss: 0.02882325\r\n",
      "Epoch:  90 Step:   136 /   793 Train loss: 0.02807864\r\n",
      "Epoch:  90 Step:   137 /   793 Train loss: 0.01133299\r\n",
      "Epoch:  90 Step:   138 /   793 Train loss: 0.02799932\r\n",
      "Epoch:  90 Step:   139 /   793 Train loss: 0.01655157\r\n",
      "Epoch:  90 Step:   140 /   793 Train loss: 0.02735090\r\n",
      "Epoch:  90 Step:   141 /   793 Train loss: 0.01893653\r\n",
      "Epoch:  90 Step:   142 /   793 Train loss: 0.01704064\r\n",
      "Epoch:  90 Step:   143 /   793 Train loss: 0.02605894\r\n",
      "Epoch:  90 Step:   144 /   793 Train loss: 0.02814413\r\n",
      "Epoch:  90 Step:   145 /   793 Train loss: 0.01306101\r\n",
      "Epoch:  90 Step:   146 /   793 Train loss: 0.02988325\r\n",
      "Epoch:  90 Step:   147 /   793 Train loss: 0.01275794\r\n",
      "Epoch:  90 Step:   148 /   793 Train loss: 0.02080882\r\n",
      "Epoch:  90 Step:   149 /   793 Train loss: 0.02021714\r\n",
      "Epoch:  90 Step:   150 /   793 Train loss: 0.01986793\r\n",
      "Epoch:  90 Step:   151 /   793 Train loss: 0.01810542\r\n",
      "Epoch:  90 Step:   152 /   793 Train loss: 0.01491345\r\n",
      "Epoch:  90 Step:   153 /   793 Train loss: 0.02146075\r\n",
      "Epoch:  90 Step:   154 /   793 Train loss: 0.01639253\r\n",
      "Epoch:  90 Step:   155 /   793 Train loss: 0.02957855\r\n",
      "Epoch:  90 Step:   156 /   793 Train loss: 0.02254902\r\n",
      "Epoch:  90 Step:   157 /   793 Train loss: 0.02762518\r\n",
      "Epoch:  90 Step:   158 /   793 Train loss: 0.03308117\r\n",
      "Epoch:  90 Step:   159 /   793 Train loss: 0.02428023\r\n",
      "Epoch:  90 Step:   160 /   793 Train loss: 0.02247213\r\n",
      "Epoch:  90 Step:   161 /   793 Train loss: 0.02826365\r\n",
      "Epoch:  90 Step:   162 /   793 Train loss: 0.02908725\r\n",
      "Epoch:  90 Step:   163 /   793 Train loss: 0.01609370\r\n",
      "Epoch:  90 Step:   164 /   793 Train loss: 0.02663539\r\n",
      "Epoch:  90 Step:   165 /   793 Train loss: 0.02036317\r\n",
      "Epoch:  90 Step:   166 /   793 Train loss: 0.01939657\r\n",
      "Epoch:  90 Step:   167 /   793 Train loss: 0.01964150\r\n",
      "Epoch:  90 Step:   168 /   793 Train loss: 0.03276188\r\n",
      "Epoch:  90 Step:   169 /   793 Train loss: 0.02768900\r\n",
      "Epoch:  90 Step:   170 /   793 Train loss: 0.02620252\r\n",
      "Epoch:  90 Step:   171 /   793 Train loss: 0.04520865\r\n",
      "Epoch:  90 Step:   172 /   793 Train loss: 0.03244995\r\n",
      "Epoch:  90 Step:   173 /   793 Train loss: 0.03297450\r\n",
      "Epoch:  90 Step:   174 /   793 Train loss: 0.02433946\r\n",
      "Epoch:  90 Step:   175 /   793 Train loss: 0.02473807\r\n",
      "Epoch:  90 Step:   176 /   793 Train loss: 0.03481353\r\n",
      "Epoch:  90 Step:   177 /   793 Train loss: 0.02731796\r\n",
      "Epoch:  90 Step:   178 /   793 Train loss: 0.01949967\r\n",
      "Epoch:  90 Step:   179 /   793 Train loss: 0.01445958\r\n",
      "Epoch:  90 Step:   180 /   793 Train loss: 0.01847061\r\n",
      "Epoch:  90 Step:   181 /   793 Train loss: 0.01160021\r\n",
      "Epoch:  90 Step:   182 /   793 Train loss: 0.02440990\r\n",
      "Epoch:  90 Step:   183 /   793 Train loss: 0.01275764\r\n",
      "Epoch:  90 Step:   184 /   793 Train loss: 0.01814769\r\n",
      "Epoch:  90 Step:   185 /   793 Train loss: 0.01843056\r\n",
      "Epoch:  90 Step:   186 /   793 Train loss: 0.02470710\r\n",
      "Epoch:  90 Step:   187 /   793 Train loss: 0.03385490\r\n",
      "Epoch:  90 Step:   188 /   793 Train loss: 0.02987911\r\n",
      "Epoch:  90 Step:   189 /   793 Train loss: 0.02967581\r\n",
      "Epoch:  90 Step:   190 /   793 Train loss: 0.03250264\r\n",
      "Epoch:  90 Step:   191 /   793 Train loss: 0.02327417\r\n",
      "Epoch:  90 Step:   192 /   793 Train loss: 0.02235397\r\n",
      "Epoch:  90 Step:   193 /   793 Train loss: 0.01767285\r\n",
      "Epoch:  90 Step:   194 /   793 Train loss: 0.02561051\r\n",
      "Epoch:  90 Step:   195 /   793 Train loss: 0.03232598\r\n",
      "Epoch:  90 Step:   196 /   793 Train loss: 0.02992576\r\n",
      "Epoch:  90 Step:   197 /   793 Train loss: 0.02113071\r\n",
      "Epoch:  90 Step:   198 /   793 Train loss: 0.02488028\r\n",
      "Epoch:  90 Step:   199 /   793 Train loss: 0.02831108\r\n",
      "Epoch:  90 Step:   200 /   793 Train loss: 0.03119794\r\n",
      "Epoch:  90 Step:   201 /   793 Train loss: 0.03224267\r\n",
      "Epoch:  90 Step:   202 /   793 Train loss: 0.02390299\r\n",
      "Epoch:  90 Step:   203 /   793 Train loss: 0.01623290\r\n",
      "Epoch:  90 Step:   204 /   793 Train loss: 0.01852254\r\n",
      "Epoch:  90 Step:   205 /   793 Train loss: 0.03251301\r\n",
      "Epoch:  90 Step:   206 /   793 Train loss: 0.01530400\r\n",
      "Epoch:  90 Step:   207 /   793 Train loss: 0.03427308\r\n",
      "Epoch:  90 Step:   208 /   793 Train loss: 0.03298445\r\n",
      "Epoch:  90 Step:   209 /   793 Train loss: 0.03375664\r\n",
      "Epoch:  90 Step:   210 /   793 Train loss: 0.02298066\r\n",
      "Epoch:  90 Step:   211 /   793 Train loss: 0.02299361\r\n",
      "Epoch:  90 Step:   212 /   793 Train loss: 0.02258353\r\n",
      "Epoch:  90 Step:   213 /   793 Train loss: 0.01973904\r\n",
      "Epoch:  90 Step:   214 /   793 Train loss: 0.03671163\r\n",
      "Epoch:  90 Step:   215 /   793 Train loss: 0.01872848\r\n",
      "Epoch:  90 Step:   216 /   793 Train loss: 0.02576195\r\n",
      "Epoch:  90 Step:   217 /   793 Train loss: 0.02837700\r\n",
      "Epoch:  90 Step:   218 /   793 Train loss: 0.02123601\r\n",
      "Epoch:  90 Step:   219 /   793 Train loss: 0.01835907\r\n",
      "Epoch:  90 Step:   220 /   793 Train loss: 0.02304660\r\n",
      "Epoch:  90 Step:   221 /   793 Train loss: 0.03055568\r\n",
      "Epoch:  90 Step:   222 /   793 Train loss: 0.02266820\r\n",
      "Epoch:  90 Step:   223 /   793 Train loss: 0.01673082\r\n",
      "Epoch:  90 Step:   224 /   793 Train loss: 0.02950792\r\n",
      "Epoch:  90 Step:   225 /   793 Train loss: 0.02960165\r\n",
      "Epoch:  90 Step:   226 /   793 Train loss: 0.02027060\r\n",
      "Epoch:  90 Step:   227 /   793 Train loss: 0.03172878\r\n",
      "Epoch:  90 Step:   228 /   793 Train loss: 0.03213747\r\n",
      "Epoch:  90 Step:   229 /   793 Train loss: 0.01851388\r\n",
      "Epoch:  90 Step:   230 /   793 Train loss: 0.02527147\r\n",
      "Epoch:  90 Step:   231 /   793 Train loss: 0.03989292\r\n",
      "Epoch:  90 Step:   232 /   793 Train loss: 0.02577779\r\n",
      "Epoch:  90 Step:   233 /   793 Train loss: 0.02859195\r\n",
      "Epoch:  90 Step:   234 /   793 Train loss: 0.02400009\r\n",
      "Epoch:  90 Step:   235 /   793 Train loss: 0.02317756\r\n",
      "Epoch:  90 Step:   236 /   793 Train loss: 0.02216441\r\n",
      "Epoch:  90 Step:   237 /   793 Train loss: 0.01678652\r\n",
      "Epoch:  90 Step:   238 /   793 Train loss: 0.01891910\r\n",
      "Epoch:  90 Step:   239 /   793 Train loss: 0.03372318\r\n",
      "Epoch:  90 Step:   240 /   793 Train loss: 0.02798279\r\n",
      "Epoch:  90 Step:   241 /   793 Train loss: 0.03873568\r\n",
      "Epoch:  90 Step:   242 /   793 Train loss: 0.03259473\r\n",
      "Epoch:  90 Step:   243 /   793 Train loss: 0.01615765\r\n",
      "Epoch:  90 Step:   244 /   793 Train loss: 0.01948089\r\n",
      "Epoch:  90 Step:   245 /   793 Train loss: 0.02637142\r\n",
      "Epoch:  90 Step:   246 /   793 Train loss: 0.02121463\r\n",
      "Epoch:  90 Step:   247 /   793 Train loss: 0.01639743\r\n",
      "Epoch:  90 Step:   248 /   793 Train loss: 0.02378314\r\n",
      "Epoch:  90 Step:   249 /   793 Train loss: 0.02936645\r\n",
      "Epoch:  90 Step:   250 /   793 Train loss: 0.01621833\r\n",
      "Epoch:  90 Step:   251 /   793 Train loss: 0.02050024\r\n",
      "Epoch:  90 Step:   252 /   793 Train loss: 0.02947384\r\n",
      "Epoch:  90 Step:   253 /   793 Train loss: 0.02301306\r\n",
      "Epoch:  90 Step:   254 /   793 Train loss: 0.02805416\r\n",
      "Epoch:  90 Step:   255 /   793 Train loss: 0.02058603\r\n",
      "Epoch:  90 Step:   256 /   793 Train loss: 0.02144279\r\n",
      "Epoch:  90 Step:   257 /   793 Train loss: 0.02354654\r\n",
      "Epoch:  90 Step:   258 /   793 Train loss: 0.01169260\r\n",
      "Epoch:  90 Step:   259 /   793 Train loss: 0.01390141\r\n",
      "Epoch:  90 Step:   260 /   793 Train loss: 0.02252392\r\n",
      "Epoch:  90 Step:   261 /   793 Train loss: 0.01610484\r\n",
      "Epoch:  90 Step:   262 /   793 Train loss: 0.02140658\r\n",
      "Epoch:  90 Step:   263 /   793 Train loss: 0.01128448\r\n",
      "Epoch:  90 Step:   264 /   793 Train loss: 0.02710195\r\n",
      "Epoch:  90 Step:   265 /   793 Train loss: 0.02190003\r\n",
      "Epoch:  90 Step:   266 /   793 Train loss: 0.03618351\r\n",
      "Epoch:  90 Step:   267 /   793 Train loss: 0.02113652\r\n",
      "Epoch:  90 Step:   268 /   793 Train loss: 0.02463537\r\n",
      "Epoch:  90 Step:   269 /   793 Train loss: 0.02539793\r\n",
      "Epoch:  90 Step:   270 /   793 Train loss: 0.01394662\r\n",
      "Epoch:  90 Step:   271 /   793 Train loss: 0.02418760\r\n",
      "Epoch:  90 Step:   272 /   793 Train loss: 0.02375587\r\n",
      "Epoch:  90 Step:   273 /   793 Train loss: 0.01810510\r\n",
      "Epoch:  90 Step:   274 /   793 Train loss: 0.02387485\r\n",
      "Epoch:  90 Step:   275 /   793 Train loss: 0.02493139\r\n",
      "Epoch:  90 Step:   276 /   793 Train loss: 0.00782986\r\n",
      "Epoch:  90 Step:   277 /   793 Train loss: 0.01263322\r\n",
      "Epoch:  90 Step:   278 /   793 Train loss: 0.02666255\r\n",
      "Epoch:  90 Step:   279 /   793 Train loss: 0.02285171\r\n",
      "Epoch:  90 Step:   280 /   793 Train loss: 0.02961371\r\n",
      "Epoch:  90 Step:   281 /   793 Train loss: 0.02454291\r\n",
      "Epoch:  90 Step:   282 /   793 Train loss: 0.03639898\r\n",
      "Epoch:  90 Step:   283 /   793 Train loss: 0.02966166\r\n",
      "Epoch:  90 Step:   284 /   793 Train loss: 0.02284433\r\n",
      "Epoch:  90 Step:   285 /   793 Train loss: 0.02122022\r\n",
      "Epoch:  90 Step:   286 /   793 Train loss: 0.02365023\r\n",
      "Epoch:  90 Step:   287 /   793 Train loss: 0.01844307\r\n",
      "Epoch:  90 Step:   288 /   793 Train loss: 0.02464626\r\n",
      "Epoch:  90 Step:   289 /   793 Train loss: 0.01683838\r\n",
      "Epoch:  90 Step:   290 /   793 Train loss: 0.01667885\r\n",
      "Epoch:  90 Step:   291 /   793 Train loss: 0.02318824\r\n",
      "Epoch:  90 Step:   292 /   793 Train loss: 0.02017202\r\n",
      "Epoch:  90 Step:   293 /   793 Train loss: 0.02617827\r\n",
      "Epoch:  90 Step:   294 /   793 Train loss: 0.02525752\r\n",
      "Epoch:  90 Step:   295 /   793 Train loss: 0.02717064\r\n",
      "Epoch:  90 Step:   296 /   793 Train loss: 0.03083863\r\n",
      "Epoch:  90 Step:   297 /   793 Train loss: 0.01989245\r\n",
      "Epoch:  90 Step:   298 /   793 Train loss: 0.02492095\r\n",
      "Epoch:  90 Step:   299 /   793 Train loss: 0.01860145\r\n",
      "Epoch:  90 Step:   300 /   793 Train loss: 0.04422892\r\n",
      "Epoch:  90 Step:   301 /   793 Train loss: 0.02505760\r\n",
      "Epoch:  90 Step:   302 /   793 Train loss: 0.02690063\r\n",
      "Epoch:  90 Step:   303 /   793 Train loss: 0.01036089\r\n",
      "Epoch:  90 Step:   304 /   793 Train loss: 0.03308159\r\n",
      "Epoch:  90 Step:   305 /   793 Train loss: 0.01807641\r\n",
      "Epoch:  90 Step:   306 /   793 Train loss: 0.03370614\r\n",
      "Epoch:  90 Step:   307 /   793 Train loss: 0.02886482\r\n",
      "Epoch:  90 Step:   308 /   793 Train loss: 0.02321674\r\n",
      "Epoch:  90 Step:   309 /   793 Train loss: 0.03217901\r\n",
      "Epoch:  90 Step:   310 /   793 Train loss: 0.01759096\r\n",
      "Epoch:  90 Step:   311 /   793 Train loss: 0.02551603\r\n",
      "Epoch:  90 Step:   312 /   793 Train loss: 0.02730701\r\n",
      "Epoch:  90 Step:   313 /   793 Train loss: 0.03123338\r\n",
      "Epoch:  90 Step:   314 /   793 Train loss: 0.02243114\r\n",
      "Epoch:  90 Step:   315 /   793 Train loss: 0.02077730\r\n",
      "Epoch:  90 Step:   316 /   793 Train loss: 0.01077866\r\n",
      "Epoch:  90 Step:   317 /   793 Train loss: 0.02195575\r\n",
      "Epoch:  90 Step:   318 /   793 Train loss: 0.02543870\r\n",
      "Epoch:  90 Step:   319 /   793 Train loss: 0.01202346\r\n",
      "Epoch:  90 Step:   320 /   793 Train loss: 0.01715858\r\n",
      "Epoch:  90 Step:   321 /   793 Train loss: 0.02544492\r\n",
      "Epoch:  90 Step:   322 /   793 Train loss: 0.01522084\r\n",
      "Epoch:  90 Step:   323 /   793 Train loss: 0.03198875\r\n",
      "Epoch:  90 Step:   324 /   793 Train loss: 0.02632595\r\n",
      "Epoch:  90 Step:   325 /   793 Train loss: 0.02025628\r\n",
      "Epoch:  90 Step:   326 /   793 Train loss: 0.03104159\r\n",
      "Epoch:  90 Step:   327 /   793 Train loss: 0.02760479\r\n",
      "Epoch:  90 Step:   328 /   793 Train loss: 0.02311415\r\n",
      "Epoch:  90 Step:   329 /   793 Train loss: 0.03214289\r\n",
      "Epoch:  90 Step:   330 /   793 Train loss: 0.02681867\r\n",
      "Epoch:  90 Step:   331 /   793 Train loss: 0.01263935\r\n",
      "Epoch:  90 Step:   332 /   793 Train loss: 0.02800467\r\n",
      "Epoch:  90 Step:   333 /   793 Train loss: 0.01578806\r\n",
      "Epoch:  90 Step:   334 /   793 Train loss: 0.03221276\r\n",
      "Epoch:  90 Step:   335 /   793 Train loss: 0.02725914\r\n",
      "Epoch:  90 Step:   336 /   793 Train loss: 0.02235315\r\n",
      "Epoch:  90 Step:   337 /   793 Train loss: 0.02576550\r\n",
      "Epoch:  90 Step:   338 /   793 Train loss: 0.03489365\r\n",
      "Epoch:  90 Step:   339 /   793 Train loss: 0.01908204\r\n",
      "Epoch:  90 Step:   340 /   793 Train loss: 0.02210117\r\n",
      "Epoch:  90 Step:   341 /   793 Train loss: 0.01295726\r\n",
      "Epoch:  90 Step:   342 /   793 Train loss: 0.02976370\r\n",
      "Epoch:  90 Step:   343 /   793 Train loss: 0.03903248\r\n",
      "Epoch:  90 Step:   344 /   793 Train loss: 0.02466562\r\n",
      "Epoch:  90 Step:   345 /   793 Train loss: 0.01927790\r\n",
      "Epoch:  90 Step:   346 /   793 Train loss: 0.02887620\r\n",
      "Epoch:  90 Step:   347 /   793 Train loss: 0.02552704\r\n",
      "Epoch:  90 Step:   348 /   793 Train loss: 0.01519141\r\n",
      "Epoch:  90 Step:   349 /   793 Train loss: 0.01731261\r\n",
      "Epoch:  90 Step:   350 /   793 Train loss: 0.01788536\r\n",
      "Epoch:  90 Step:   351 /   793 Train loss: 0.01656447\r\n",
      "Epoch:  90 Step:   352 /   793 Train loss: 0.02849869\r\n",
      "Epoch:  90 Step:   353 /   793 Train loss: 0.02104543\r\n",
      "Epoch:  90 Step:   354 /   793 Train loss: 0.02922029\r\n",
      "Epoch:  90 Step:   355 /   793 Train loss: 0.02580464\r\n",
      "Epoch:  90 Step:   356 /   793 Train loss: 0.02184624\r\n",
      "Epoch:  90 Step:   357 /   793 Train loss: 0.01267951\r\n",
      "Epoch:  90 Step:   358 /   793 Train loss: 0.01043956\r\n",
      "Epoch:  90 Step:   359 /   793 Train loss: 0.02142126\r\n",
      "Epoch:  90 Step:   360 /   793 Train loss: 0.01753555\r\n",
      "Epoch:  90 Step:   361 /   793 Train loss: 0.04087221\r\n",
      "Epoch:  90 Step:   362 /   793 Train loss: 0.02578852\r\n",
      "Epoch:  90 Step:   363 /   793 Train loss: 0.03373373\r\n",
      "Epoch:  90 Step:   364 /   793 Train loss: 0.03324018\r\n",
      "Epoch:  90 Step:   365 /   793 Train loss: 0.02369401\r\n",
      "Epoch:  90 Step:   366 /   793 Train loss: 0.01546041\r\n",
      "Epoch:  90 Step:   367 /   793 Train loss: 0.02891801\r\n",
      "Epoch:  90 Step:   368 /   793 Train loss: 0.04304384\r\n",
      "Epoch:  90 Step:   369 /   793 Train loss: 0.02083725\r\n",
      "Epoch:  90 Step:   370 /   793 Train loss: 0.02771866\r\n",
      "Epoch:  90 Step:   371 /   793 Train loss: 0.02061974\r\n",
      "Epoch:  90 Step:   372 /   793 Train loss: 0.02501897\r\n",
      "Epoch:  90 Step:   373 /   793 Train loss: 0.01973803\r\n",
      "Epoch:  90 Step:   374 /   793 Train loss: 0.02456567\r\n",
      "Epoch:  90 Step:   375 /   793 Train loss: 0.01910007\r\n",
      "Epoch:  90 Step:   376 /   793 Train loss: 0.02115699\r\n",
      "Epoch:  90 Step:   377 /   793 Train loss: 0.01673453\r\n",
      "Epoch:  90 Step:   378 /   793 Train loss: 0.01829622\r\n",
      "Epoch:  90 Step:   379 /   793 Train loss: 0.01657342\r\n",
      "Epoch:  90 Step:   380 /   793 Train loss: 0.01426460\r\n",
      "Epoch:  90 Step:   381 /   793 Train loss: 0.01297139\r\n",
      "Epoch:  90 Step:   382 /   793 Train loss: 0.02478529\r\n",
      "Epoch:  90 Step:   383 /   793 Train loss: 0.01917839\r\n",
      "Epoch:  90 Step:   384 /   793 Train loss: 0.01576630\r\n",
      "Epoch:  90 Step:   385 /   793 Train loss: 0.02512569\r\n",
      "Epoch:  90 Step:   386 /   793 Train loss: 0.02427657\r\n",
      "Epoch:  90 Step:   387 /   793 Train loss: 0.02812116\r\n",
      "Epoch:  90 Step:   388 /   793 Train loss: 0.03292287\r\n",
      "Epoch:  90 Step:   389 /   793 Train loss: 0.03559721\r\n",
      "Epoch:  90 Step:   390 /   793 Train loss: 0.02583655\r\n",
      "Epoch:  90 Step:   391 /   793 Train loss: 0.02413801\r\n",
      "Epoch:  90 Step:   392 /   793 Train loss: 0.02071257\r\n",
      "Epoch:  90 Step:   393 /   793 Train loss: 0.02785709\r\n",
      "Epoch:  90 Step:   394 /   793 Train loss: 0.03072405\r\n",
      "Epoch:  90 Step:   395 /   793 Train loss: 0.01480913\r\n",
      "Epoch:  90 Step:   396 /   793 Train loss: 0.01927140\r\n",
      "Epoch:  90 Step:   397 /   793 Train loss: 0.02855592\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  90 Step:   398 /   793 Train loss: 0.02610962\r\n",
      "Epoch:  90 Step:   399 /   793 Train loss: 0.02525022\r\n",
      "Epoch:  90 Step:   400 /   793 Train loss: 0.01753261\r\n",
      "Epoch:  90 Step:   401 /   793 Train loss: 0.02755744\r\n",
      "Epoch:  90 Step:   402 /   793 Train loss: 0.02423104\r\n",
      "Epoch:  90 Step:   403 /   793 Train loss: 0.02183451\r\n",
      "Epoch:  90 Step:   404 /   793 Train loss: 0.03842682\r\n",
      "Epoch:  90 Step:   405 /   793 Train loss: 0.02103974\r\n",
      "Epoch:  90 Step:   406 /   793 Train loss: 0.03165215\r\n",
      "Epoch:  90 Step:   407 /   793 Train loss: 0.04025279\r\n",
      "Epoch:  90 Step:   408 /   793 Train loss: 0.02925319\r\n",
      "Epoch:  90 Step:   409 /   793 Train loss: 0.02739298\r\n",
      "Epoch:  90 Step:   410 /   793 Train loss: 0.02785808\r\n",
      "Epoch:  90 Step:   411 /   793 Train loss: 0.02981334\r\n",
      "Epoch:  90 Step:   412 /   793 Train loss: 0.01383198\r\n",
      "Epoch:  90 Step:   413 /   793 Train loss: 0.02456511\r\n",
      "Epoch:  90 Step:   414 /   793 Train loss: 0.02642917\r\n",
      "Epoch:  90 Step:   415 /   793 Train loss: 0.02677168\r\n",
      "Epoch:  90 Step:   416 /   793 Train loss: 0.01825471\r\n",
      "Epoch:  90 Step:   417 /   793 Train loss: 0.02346162\r\n",
      "Epoch:  90 Step:   418 /   793 Train loss: 0.03884036\r\n",
      "Epoch:  90 Step:   419 /   793 Train loss: 0.02235612\r\n",
      "Epoch:  90 Step:   420 /   793 Train loss: 0.01853143\r\n",
      "Epoch:  90 Step:   421 /   793 Train loss: 0.03638618\r\n",
      "Epoch:  90 Step:   422 /   793 Train loss: 0.02714493\r\n",
      "Epoch:  90 Step:   423 /   793 Train loss: 0.01310803\r\n",
      "Epoch:  90 Step:   424 /   793 Train loss: 0.03074904\r\n",
      "Epoch:  90 Step:   425 /   793 Train loss: 0.02707569\r\n",
      "Epoch:  90 Step:   426 /   793 Train loss: 0.02216142\r\n",
      "Epoch:  90 Step:   427 /   793 Train loss: 0.03142129\r\n",
      "Epoch:  90 Step:   428 /   793 Train loss: 0.00773834\r\n",
      "Epoch:  90 Step:   429 /   793 Train loss: 0.02493387\r\n",
      "Epoch:  90 Step:   430 /   793 Train loss: 0.02722703\r\n",
      "Epoch:  90 Step:   431 /   793 Train loss: 0.01433723\r\n",
      "Epoch:  90 Step:   432 /   793 Train loss: 0.02728585\r\n",
      "Epoch:  90 Step:   433 /   793 Train loss: 0.03010251\r\n",
      "Epoch:  90 Step:   434 /   793 Train loss: 0.02498350\r\n",
      "Epoch:  90 Step:   435 /   793 Train loss: 0.02672261\r\n",
      "Epoch:  90 Step:   436 /   793 Train loss: 0.04086784\r\n",
      "Epoch:  90 Step:   437 /   793 Train loss: 0.01959072\r\n",
      "Epoch:  90 Step:   438 /   793 Train loss: 0.02450519\r\n",
      "Epoch:  90 Step:   439 /   793 Train loss: 0.01456702\r\n",
      "Epoch:  90 Step:   440 /   793 Train loss: 0.01840771\r\n",
      "Epoch:  90 Step:   441 /   793 Train loss: 0.01436541\r\n",
      "Epoch:  90 Step:   442 /   793 Train loss: 0.04167952\r\n",
      "Epoch:  90 Step:   443 /   793 Train loss: 0.02342302\r\n",
      "Epoch:  90 Step:   444 /   793 Train loss: 0.02378949\r\n",
      "Epoch:  90 Step:   445 /   793 Train loss: 0.01306920\r\n",
      "Epoch:  90 Step:   446 /   793 Train loss: 0.01429088\r\n",
      "Epoch:  90 Step:   447 /   793 Train loss: 0.02993735\r\n",
      "Epoch:  90 Step:   448 /   793 Train loss: 0.02134128\r\n",
      "Epoch:  90 Step:   449 /   793 Train loss: 0.02179822\r\n",
      "Epoch:  90 Step:   450 /   793 Train loss: 0.02736001\r\n",
      "Epoch:  90 Step:   451 /   793 Train loss: 0.02394405\r\n",
      "Epoch:  90 Step:   452 /   793 Train loss: 0.02558162\r\n",
      "Epoch:  90 Step:   453 /   793 Train loss: 0.03247929\r\n",
      "Epoch:  90 Step:   454 /   793 Train loss: 0.02411241\r\n",
      "Epoch:  90 Step:   455 /   793 Train loss: 0.01278838\r\n",
      "Epoch:  90 Step:   456 /   793 Train loss: 0.03501652\r\n",
      "Epoch:  90 Step:   457 /   793 Train loss: 0.02166406\r\n",
      "Epoch:  90 Step:   458 /   793 Train loss: 0.03113320\r\n",
      "Epoch:  90 Step:   459 /   793 Train loss: 0.01872404\r\n",
      "Epoch:  90 Step:   460 /   793 Train loss: 0.02621014\r\n",
      "Epoch:  90 Step:   461 /   793 Train loss: 0.02950748\r\n",
      "Epoch:  90 Step:   462 /   793 Train loss: 0.01674485\r\n",
      "Epoch:  90 Step:   463 /   793 Train loss: 0.02492760\r\n",
      "Epoch:  90 Step:   464 /   793 Train loss: 0.02819918\r\n",
      "Epoch:  90 Step:   465 /   793 Train loss: 0.02994661\r\n",
      "Epoch:  90 Step:   466 /   793 Train loss: 0.03322619\r\n",
      "Epoch:  90 Step:   467 /   793 Train loss: 0.03223209\r\n",
      "Epoch:  90 Step:   468 /   793 Train loss: 0.03174140\r\n",
      "Epoch:  90 Step:   469 /   793 Train loss: 0.01190751\r\n",
      "Epoch:  90 Step:   470 /   793 Train loss: 0.01670690\r\n",
      "Epoch:  90 Step:   471 /   793 Train loss: 0.01396798\r\n",
      "Epoch:  90 Step:   472 /   793 Train loss: 0.02476206\r\n",
      "Epoch:  90 Step:   473 /   793 Train loss: 0.04015381\r\n",
      "Epoch:  90 Step:   474 /   793 Train loss: 0.01713879\r\n",
      "Epoch:  90 Step:   475 /   793 Train loss: 0.01434124\r\n",
      "Epoch:  90 Step:   476 /   793 Train loss: 0.02584857\r\n",
      "Epoch:  90 Step:   477 /   793 Train loss: 0.01575107\r\n",
      "Epoch:  90 Step:   478 /   793 Train loss: 0.01784958\r\n",
      "Epoch:  90 Step:   479 /   793 Train loss: 0.03329428\r\n",
      "Epoch:  90 Step:   480 /   793 Train loss: 0.03196523\r\n",
      "Epoch:  90 Step:   481 /   793 Train loss: 0.01954908\r\n",
      "Epoch:  90 Step:   482 /   793 Train loss: 0.03451657\r\n",
      "Epoch:  90 Step:   483 /   793 Train loss: 0.01974319\r\n",
      "Epoch:  90 Step:   484 /   793 Train loss: 0.01199652\r\n",
      "Epoch:  90 Step:   485 /   793 Train loss: 0.03461633\r\n",
      "Epoch:  90 Step:   486 /   793 Train loss: 0.01877455\r\n",
      "Epoch:  90 Step:   487 /   793 Train loss: 0.01915576\r\n",
      "Epoch:  90 Step:   488 /   793 Train loss: 0.02400649\r\n",
      "Epoch:  90 Step:   489 /   793 Train loss: 0.02935409\r\n",
      "Epoch:  90 Step:   490 /   793 Train loss: 0.02749216\r\n",
      "Epoch:  90 Step:   491 /   793 Train loss: 0.02481043\r\n",
      "Epoch:  90 Step:   492 /   793 Train loss: 0.03408202\r\n",
      "Epoch:  90 Step:   493 /   793 Train loss: 0.02749178\r\n",
      "Epoch:  90 Step:   494 /   793 Train loss: 0.01003727\r\n",
      "Epoch:  90 Step:   495 /   793 Train loss: 0.01585573\r\n",
      "Epoch:  90 Step:   496 /   793 Train loss: 0.01416109\r\n",
      "Epoch:  90 Step:   497 /   793 Train loss: 0.02752456\r\n",
      "Epoch:  90 Step:   498 /   793 Train loss: 0.02920111\r\n",
      "Epoch:  90 Step:   499 /   793 Train loss: 0.01156351\r\n",
      "Epoch:  90 Step:   500 /   793 Train loss: 0.02721511\r\n",
      "Epoch:  90 Step:   501 /   793 Train loss: 0.02177665\r\n",
      "Epoch:  90 Step:   502 /   793 Train loss: 0.01922366\r\n",
      "Epoch:  90 Step:   503 /   793 Train loss: 0.01675943\r\n",
      "Epoch:  90 Step:   504 /   793 Train loss: 0.02394855\r\n",
      "Epoch:  90 Step:   505 /   793 Train loss: 0.02326536\r\n",
      "Epoch:  90 Step:   506 /   793 Train loss: 0.03540799\r\n",
      "Epoch:  90 Step:   507 /   793 Train loss: 0.02175845\r\n",
      "Epoch:  90 Step:   508 /   793 Train loss: 0.02372410\r\n",
      "Epoch:  90 Step:   509 /   793 Train loss: 0.02428737\r\n",
      "Epoch:  90 Step:   510 /   793 Train loss: 0.03485238\r\n",
      "Epoch:  90 Step:   511 /   793 Train loss: 0.01181426\r\n",
      "Epoch:  90 Step:   512 /   793 Train loss: 0.02076518\r\n",
      "Epoch:  90 Step:   513 /   793 Train loss: 0.03380725\r\n",
      "Epoch:  90 Step:   514 /   793 Train loss: 0.03194574\r\n",
      "Epoch:  90 Step:   515 /   793 Train loss: 0.02321186\r\n",
      "Epoch:  90 Step:   516 /   793 Train loss: 0.03369563\r\n",
      "Epoch:  90 Step:   517 /   793 Train loss: 0.01575485\r\n",
      "Epoch:  90 Step:   518 /   793 Train loss: 0.02336212\r\n",
      "Epoch:  90 Step:   519 /   793 Train loss: 0.01821078\r\n",
      "Epoch:  90 Step:   520 /   793 Train loss: 0.02608319\r\n",
      "Epoch:  90 Step:   521 /   793 Train loss: 0.01817442\r\n",
      "Epoch:  90 Step:   522 /   793 Train loss: 0.01675525\r\n",
      "Epoch:  90 Step:   523 /   793 Train loss: 0.02523423\r\n",
      "Epoch:  90 Step:   524 /   793 Train loss: 0.02304474\r\n",
      "Epoch:  90 Step:   525 /   793 Train loss: 0.01957042\r\n",
      "Epoch:  90 Step:   526 /   793 Train loss: 0.01807713\r\n",
      "Epoch:  90 Step:   527 /   793 Train loss: 0.03020174\r\n",
      "Epoch:  90 Step:   528 /   793 Train loss: 0.03724747\r\n",
      "Epoch:  90 Step:   529 /   793 Train loss: 0.02922835\r\n",
      "Epoch:  90 Step:   530 /   793 Train loss: 0.02001150\r\n",
      "Epoch:  90 Step:   531 /   793 Train loss: 0.03744436\r\n",
      "Epoch:  90 Step:   532 /   793 Train loss: 0.01232868\r\n",
      "Epoch:  90 Step:   533 /   793 Train loss: 0.02127886\r\n",
      "Epoch:  90 Step:   534 /   793 Train loss: 0.01987374\r\n",
      "Epoch:  90 Step:   535 /   793 Train loss: 0.01191936\r\n",
      "Epoch:  90 Step:   536 /   793 Train loss: 0.03945770\r\n",
      "Epoch:  90 Step:   537 /   793 Train loss: 0.02152729\r\n",
      "Epoch:  90 Step:   538 /   793 Train loss: 0.03282844\r\n",
      "Epoch:  90 Step:   539 /   793 Train loss: 0.01742078\r\n",
      "Epoch:  90 Step:   540 /   793 Train loss: 0.02631950\r\n",
      "Epoch:  90 Step:   541 /   793 Train loss: 0.03845258\r\n",
      "Epoch:  90 Step:   542 /   793 Train loss: 0.02618831\r\n",
      "Epoch:  90 Step:   543 /   793 Train loss: 0.03426111\r\n",
      "Epoch:  90 Step:   544 /   793 Train loss: 0.02335067\r\n",
      "Epoch:  90 Step:   545 /   793 Train loss: 0.01983100\r\n",
      "Epoch:  90 Step:   546 /   793 Train loss: 0.01622576\r\n",
      "Epoch:  90 Step:   547 /   793 Train loss: 0.01415249\r\n",
      "Epoch:  90 Step:   548 /   793 Train loss: 0.03570579\r\n",
      "Epoch:  90 Step:   549 /   793 Train loss: 0.03296033\r\n",
      "Epoch:  90 Step:   550 /   793 Train loss: 0.02647174\r\n",
      "Epoch:  90 Step:   551 /   793 Train loss: 0.03231917\r\n",
      "Epoch:  90 Step:   552 /   793 Train loss: 0.02440908\r\n",
      "Epoch:  90 Step:   553 /   793 Train loss: 0.03417696\r\n",
      "Epoch:  90 Step:   554 /   793 Train loss: 0.01272115\r\n",
      "Epoch:  90 Step:   555 /   793 Train loss: 0.01789286\r\n",
      "Epoch:  90 Step:   556 /   793 Train loss: 0.02431880\r\n",
      "Epoch:  90 Step:   557 /   793 Train loss: 0.01888227\r\n",
      "Epoch:  90 Step:   558 /   793 Train loss: 0.02584175\r\n",
      "Epoch:  90 Step:   559 /   793 Train loss: 0.01853229\r\n",
      "Epoch:  90 Step:   560 /   793 Train loss: 0.02620134\r\n",
      "Epoch:  90 Step:   561 /   793 Train loss: 0.03698963\r\n",
      "Epoch:  90 Step:   562 /   793 Train loss: 0.02604561\r\n",
      "Epoch:  90 Step:   563 /   793 Train loss: 0.01954627\r\n",
      "Epoch:  90 Step:   564 /   793 Train loss: 0.01908294\r\n",
      "Epoch:  90 Step:   565 /   793 Train loss: 0.01685764\r\n",
      "Epoch:  90 Step:   566 /   793 Train loss: 0.03039646\r\n",
      "Epoch:  90 Step:   567 /   793 Train loss: 0.02234342\r\n",
      "Epoch:  90 Step:   568 /   793 Train loss: 0.01641843\r\n",
      "Epoch:  90 Step:   569 /   793 Train loss: 0.02931446\r\n",
      "Epoch:  90 Step:   570 /   793 Train loss: 0.02241424\r\n",
      "Epoch:  90 Step:   571 /   793 Train loss: 0.01570565\r\n",
      "Epoch:  90 Step:   572 /   793 Train loss: 0.01535730\r\n",
      "Epoch:  90 Step:   573 /   793 Train loss: 0.02187910\r\n",
      "Epoch:  90 Step:   574 /   793 Train loss: 0.02101811\r\n",
      "Epoch:  90 Step:   575 /   793 Train loss: 0.03645445\r\n",
      "Epoch:  90 Step:   576 /   793 Train loss: 0.02341102\r\n",
      "Epoch:  90 Step:   577 /   793 Train loss: 0.02784397\r\n",
      "Epoch:  90 Step:   578 /   793 Train loss: 0.02927793\r\n",
      "Epoch:  90 Step:   579 /   793 Train loss: 0.01754196\r\n",
      "Epoch:  90 Step:   580 /   793 Train loss: 0.02644460\r\n",
      "Epoch:  90 Step:   581 /   793 Train loss: 0.00878850\r\n",
      "Epoch:  90 Step:   582 /   793 Train loss: 0.01873827\r\n",
      "Epoch:  90 Step:   583 /   793 Train loss: 0.02387199\r\n",
      "Epoch:  90 Step:   584 /   793 Train loss: 0.02552299\r\n",
      "Epoch:  90 Step:   585 /   793 Train loss: 0.01679434\r\n",
      "Epoch:  90 Step:   586 /   793 Train loss: 0.01722783\r\n",
      "Epoch:  90 Step:   587 /   793 Train loss: 0.02131604\r\n",
      "Epoch:  90 Step:   588 /   793 Train loss: 0.02451196\r\n",
      "Epoch:  90 Step:   589 /   793 Train loss: 0.03050911\r\n",
      "Epoch:  90 Step:   590 /   793 Train loss: 0.02772179\r\n",
      "Epoch:  90 Step:   591 /   793 Train loss: 0.02000385\r\n",
      "Epoch:  90 Step:   592 /   793 Train loss: 0.02134644\r\n",
      "Epoch:  90 Step:   593 /   793 Train loss: 0.02657988\r\n",
      "Epoch:  90 Step:   594 /   793 Train loss: 0.02065893\r\n",
      "Epoch:  90 Step:   595 /   793 Train loss: 0.02362132\r\n",
      "Epoch:  90 Step:   596 /   793 Train loss: 0.02695532\r\n",
      "Epoch:  90 Step:   597 /   793 Train loss: 0.01433680\r\n",
      "Epoch:  90 Step:   598 /   793 Train loss: 0.02210432\r\n",
      "Epoch:  90 Step:   599 /   793 Train loss: 0.02464820\r\n",
      "Epoch:  90 Step:   600 /   793 Train loss: 0.03611634\r\n",
      "Epoch:  90 Step:   601 /   793 Train loss: 0.01458658\r\n",
      "Epoch:  90 Step:   602 /   793 Train loss: 0.03098047\r\n",
      "Epoch:  90 Step:   603 /   793 Train loss: 0.02009189\r\n",
      "Epoch:  90 Step:   604 /   793 Train loss: 0.02272334\r\n",
      "Epoch:  90 Step:   605 /   793 Train loss: 0.02381294\r\n",
      "Epoch:  90 Step:   606 /   793 Train loss: 0.01842250\r\n",
      "Epoch:  90 Step:   607 /   793 Train loss: 0.02235560\r\n",
      "Epoch:  90 Step:   608 /   793 Train loss: 0.02844770\r\n",
      "Epoch:  90 Step:   609 /   793 Train loss: 0.02399073\r\n",
      "Epoch:  90 Step:   610 /   793 Train loss: 0.01602399\r\n",
      "Epoch:  90 Step:   611 /   793 Train loss: 0.01790504\r\n",
      "Epoch:  90 Step:   612 /   793 Train loss: 0.01656382\r\n",
      "Epoch:  90 Step:   613 /   793 Train loss: 0.01589764\r\n",
      "Epoch:  90 Step:   614 /   793 Train loss: 0.03227298\r\n",
      "Epoch:  90 Step:   615 /   793 Train loss: 0.02365537\r\n",
      "Epoch:  90 Step:   616 /   793 Train loss: 0.01809784\r\n",
      "Epoch:  90 Step:   617 /   793 Train loss: 0.02057086\r\n",
      "Epoch:  90 Step:   618 /   793 Train loss: 0.03079940\r\n",
      "Epoch:  90 Step:   619 /   793 Train loss: 0.02111837\r\n",
      "Epoch:  90 Step:   620 /   793 Train loss: 0.02856718\r\n",
      "Epoch:  90 Step:   621 /   793 Train loss: 0.03119418\r\n",
      "Epoch:  90 Step:   622 /   793 Train loss: 0.03209885\r\n",
      "Epoch:  90 Step:   623 /   793 Train loss: 0.02035668\r\n",
      "Epoch:  90 Step:   624 /   793 Train loss: 0.02483461\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  90 Step:   625 /   793 Train loss: 0.02042771\r\n",
      "Epoch:  90 Step:   626 /   793 Train loss: 0.03511259\r\n",
      "Epoch:  90 Step:   627 /   793 Train loss: 0.02564054\r\n",
      "Epoch:  90 Step:   628 /   793 Train loss: 0.03302222\r\n",
      "Epoch:  90 Step:   629 /   793 Train loss: 0.03373879\r\n",
      "Epoch:  90 Step:   630 /   793 Train loss: 0.02664718\r\n",
      "Epoch:  90 Step:   631 /   793 Train loss: 0.02340459\r\n",
      "Epoch:  90 Step:   632 /   793 Train loss: 0.02271969\r\n",
      "Epoch:  90 Step:   633 /   793 Train loss: 0.03600104\r\n",
      "Epoch:  90 Step:   634 /   793 Train loss: 0.03077977\r\n",
      "Epoch:  90 Step:   635 /   793 Train loss: 0.01830377\r\n",
      "Epoch:  90 Step:   636 /   793 Train loss: 0.03003420\r\n",
      "Epoch:  90 Step:   637 /   793 Train loss: 0.02123142\r\n",
      "Epoch:  90 Step:   638 /   793 Train loss: 0.03312828\r\n",
      "Epoch:  90 Step:   639 /   793 Train loss: 0.01547180\r\n",
      "Epoch:  90 Step:   640 /   793 Train loss: 0.01532262\r\n",
      "Epoch:  90 Step:   641 /   793 Train loss: 0.02414481\r\n",
      "Epoch:  90 Step:   642 /   793 Train loss: 0.01525807\r\n",
      "Epoch:  90 Step:   643 /   793 Train loss: 0.03047913\r\n",
      "Epoch:  90 Step:   644 /   793 Train loss: 0.01688614\r\n",
      "Epoch:  90 Step:   645 /   793 Train loss: 0.02585635\r\n",
      "Epoch:  90 Step:   646 /   793 Train loss: 0.01142344\r\n",
      "Epoch:  90 Step:   647 /   793 Train loss: 0.03056206\r\n",
      "Epoch:  90 Step:   648 /   793 Train loss: 0.01631250\r\n",
      "Epoch:  90 Step:   649 /   793 Train loss: 0.01702727\r\n",
      "Epoch:  90 Step:   650 /   793 Train loss: 0.02882275\r\n",
      "Epoch:  90 Step:   651 /   793 Train loss: 0.03023940\r\n",
      "Epoch:  90 Step:   652 /   793 Train loss: 0.02713312\r\n",
      "Epoch:  90 Step:   653 /   793 Train loss: 0.02314544\r\n",
      "Epoch:  90 Step:   654 /   793 Train loss: 0.02427647\r\n",
      "Epoch:  90 Step:   655 /   793 Train loss: 0.04038453\r\n",
      "Epoch:  90 Step:   656 /   793 Train loss: 0.01910786\r\n",
      "Epoch:  90 Step:   657 /   793 Train loss: 0.01954353\r\n",
      "Epoch:  90 Step:   658 /   793 Train loss: 0.02531970\r\n",
      "Epoch:  90 Step:   659 /   793 Train loss: 0.01626036\r\n",
      "Epoch:  90 Step:   660 /   793 Train loss: 0.03815940\r\n",
      "Epoch:  90 Step:   661 /   793 Train loss: 0.02913203\r\n",
      "Epoch:  90 Step:   662 /   793 Train loss: 0.03042715\r\n",
      "Epoch:  90 Step:   663 /   793 Train loss: 0.01981143\r\n",
      "Epoch:  90 Step:   664 /   793 Train loss: 0.01282992\r\n",
      "Epoch:  90 Step:   665 /   793 Train loss: 0.01902349\r\n",
      "Epoch:  90 Step:   666 /   793 Train loss: 0.03398030\r\n",
      "Epoch:  90 Step:   667 /   793 Train loss: 0.01202272\r\n",
      "Epoch:  90 Step:   668 /   793 Train loss: 0.01653639\r\n",
      "Epoch:  90 Step:   669 /   793 Train loss: 0.02676864\r\n",
      "Epoch:  90 Step:   670 /   793 Train loss: 0.03055440\r\n",
      "Epoch:  90 Step:   671 /   793 Train loss: 0.01811660\r\n",
      "Epoch:  90 Step:   672 /   793 Train loss: 0.01560715\r\n",
      "Epoch:  90 Step:   673 /   793 Train loss: 0.02840639\r\n",
      "Epoch:  90 Step:   674 /   793 Train loss: 0.02152529\r\n",
      "Epoch:  90 Step:   675 /   793 Train loss: 0.02865290\r\n",
      "Epoch:  90 Step:   676 /   793 Train loss: 0.02857330\r\n",
      "Epoch:  90 Step:   677 /   793 Train loss: 0.01434215\r\n",
      "Epoch:  90 Step:   678 /   793 Train loss: 0.02165385\r\n",
      "Epoch:  90 Step:   679 /   793 Train loss: 0.03223412\r\n",
      "Epoch:  90 Step:   680 /   793 Train loss: 0.01864049\r\n",
      "Epoch:  90 Step:   681 /   793 Train loss: 0.01965671\r\n",
      "Epoch:  90 Step:   682 /   793 Train loss: 0.03729023\r\n",
      "Epoch:  90 Step:   683 /   793 Train loss: 0.01819872\r\n",
      "Epoch:  90 Step:   684 /   793 Train loss: 0.02659666\r\n",
      "Epoch:  90 Step:   685 /   793 Train loss: 0.01833875\r\n",
      "Epoch:  90 Step:   686 /   793 Train loss: 0.02460978\r\n",
      "Epoch:  90 Step:   687 /   793 Train loss: 0.02025610\r\n",
      "Epoch:  90 Step:   688 /   793 Train loss: 0.03442461\r\n",
      "Epoch:  90 Step:   689 /   793 Train loss: 0.03186702\r\n",
      "Epoch:  90 Step:   690 /   793 Train loss: 0.02054152\r\n",
      "Epoch:  90 Step:   691 /   793 Train loss: 0.04291693\r\n",
      "Epoch:  90 Step:   692 /   793 Train loss: 0.02002013\r\n",
      "Epoch:  90 Step:   693 /   793 Train loss: 0.02374649\r\n",
      "Epoch:  90 Step:   694 /   793 Train loss: 0.03108295\r\n",
      "Epoch:  90 Step:   695 /   793 Train loss: 0.01775310\r\n",
      "Epoch:  90 Step:   696 /   793 Train loss: 0.03210524\r\n",
      "Epoch:  90 Step:   697 /   793 Train loss: 0.01865740\r\n",
      "Epoch:  90 Step:   698 /   793 Train loss: 0.01516993\r\n",
      "Epoch:  90 Step:   699 /   793 Train loss: 0.02184665\r\n",
      "Epoch:  90 Step:   700 /   793 Train loss: 0.01822723\r\n",
      "Epoch:  90 Step:   701 /   793 Train loss: 0.01135505\r\n",
      "Epoch:  90 Step:   702 /   793 Train loss: 0.01648749\r\n",
      "Epoch:  90 Step:   703 /   793 Train loss: 0.03478883\r\n",
      "Epoch:  90 Step:   704 /   793 Train loss: 0.02404007\r\n",
      "Epoch:  90 Step:   705 /   793 Train loss: 0.03133067\r\n",
      "Epoch:  90 Step:   706 /   793 Train loss: 0.03561301\r\n",
      "Epoch:  90 Step:   707 /   793 Train loss: 0.01111304\r\n",
      "Epoch:  90 Step:   708 /   793 Train loss: 0.02232243\r\n",
      "Epoch:  90 Step:   709 /   793 Train loss: 0.02129707\r\n",
      "Epoch:  90 Step:   710 /   793 Train loss: 0.02336475\r\n",
      "Epoch:  90 Step:   711 /   793 Train loss: 0.02750746\r\n",
      "Epoch:  90 Step:   712 /   793 Train loss: 0.04370981\r\n",
      "Epoch:  90 Step:   713 /   793 Train loss: 0.01242273\r\n",
      "Epoch:  90 Step:   714 /   793 Train loss: 0.03227499\r\n",
      "Epoch:  90 Step:   715 /   793 Train loss: 0.01516076\r\n",
      "Epoch:  90 Step:   716 /   793 Train loss: 0.02586396\r\n",
      "Epoch:  90 Step:   717 /   793 Train loss: 0.02905201\r\n",
      "Epoch:  90 Step:   718 /   793 Train loss: 0.01753543\r\n",
      "Epoch:  90 Step:   719 /   793 Train loss: 0.03106127\r\n",
      "Epoch:  90 Step:   720 /   793 Train loss: 0.01936814\r\n",
      "Epoch:  90 Step:   721 /   793 Train loss: 0.03444904\r\n",
      "Epoch:  90 Step:   722 /   793 Train loss: 0.02311728\r\n",
      "Epoch:  90 Step:   723 /   793 Train loss: 0.01572741\r\n",
      "Epoch:  90 Step:   724 /   793 Train loss: 0.01946084\r\n",
      "Epoch:  90 Step:   725 /   793 Train loss: 0.01667905\r\n",
      "Epoch:  90 Step:   726 /   793 Train loss: 0.01899883\r\n",
      "Epoch:  90 Step:   727 /   793 Train loss: 0.03622677\r\n",
      "Epoch:  90 Step:   728 /   793 Train loss: 0.02590647\r\n",
      "Epoch:  90 Step:   729 /   793 Train loss: 0.02219430\r\n",
      "Epoch:  90 Step:   730 /   793 Train loss: 0.02759908\r\n",
      "Epoch:  90 Step:   731 /   793 Train loss: 0.03102773\r\n",
      "Epoch:  90 Step:   732 /   793 Train loss: 0.02525790\r\n",
      "Epoch:  90 Step:   733 /   793 Train loss: 0.04514041\r\n",
      "Epoch:  90 Step:   734 /   793 Train loss: 0.02619824\r\n",
      "Epoch:  90 Step:   735 /   793 Train loss: 0.02117448\r\n",
      "Epoch:  90 Step:   736 /   793 Train loss: 0.02488047\r\n",
      "Epoch:  90 Step:   737 /   793 Train loss: 0.02574215\r\n",
      "Epoch:  90 Step:   738 /   793 Train loss: 0.03309372\r\n",
      "Epoch:  90 Step:   739 /   793 Train loss: 0.03426480\r\n",
      "Epoch:  90 Step:   740 /   793 Train loss: 0.02498140\r\n",
      "Epoch:  90 Step:   741 /   793 Train loss: 0.03537329\r\n",
      "Epoch:  90 Step:   742 /   793 Train loss: 0.02309567\r\n",
      "Epoch:  90 Step:   743 /   793 Train loss: 0.02099705\r\n",
      "Epoch:  90 Step:   744 /   793 Train loss: 0.02885067\r\n",
      "Epoch:  90 Step:   745 /   793 Train loss: 0.02288939\r\n",
      "Epoch:  90 Step:   746 /   793 Train loss: 0.01815057\r\n",
      "Epoch:  90 Step:   747 /   793 Train loss: 0.03009872\r\n",
      "Epoch:  90 Step:   748 /   793 Train loss: 0.02752474\r\n",
      "Epoch:  90 Step:   749 /   793 Train loss: 0.03328908\r\n",
      "Epoch:  90 Step:   750 /   793 Train loss: 0.00987418\r\n",
      "Epoch:  90 Step:   751 /   793 Train loss: 0.03104161\r\n",
      "Epoch:  90 Step:   752 /   793 Train loss: 0.03117305\r\n",
      "Epoch:  90 Step:   753 /   793 Train loss: 0.04036434\r\n",
      "Epoch:  90 Step:   754 /   793 Train loss: 0.01695912\r\n",
      "Epoch:  90 Step:   755 /   793 Train loss: 0.02572565\r\n",
      "Epoch:  90 Step:   756 /   793 Train loss: 0.02950539\r\n",
      "Epoch:  90 Step:   757 /   793 Train loss: 0.02561314\r\n",
      "Epoch:  90 Step:   758 /   793 Train loss: 0.02035916\r\n",
      "Epoch:  90 Step:   759 /   793 Train loss: 0.02523826\r\n",
      "Epoch:  90 Step:   760 /   793 Train loss: 0.02611871\r\n",
      "Epoch:  90 Step:   761 /   793 Train loss: 0.01385641\r\n",
      "Epoch:  90 Step:   762 /   793 Train loss: 0.02912300\r\n",
      "Epoch:  90 Step:   763 /   793 Train loss: 0.03537883\r\n",
      "Epoch:  90 Step:   764 /   793 Train loss: 0.02917475\r\n",
      "Epoch:  90 Step:   765 /   793 Train loss: 0.03327452\r\n",
      "Epoch:  90 Step:   766 /   793 Train loss: 0.03072292\r\n",
      "Epoch:  90 Step:   767 /   793 Train loss: 0.02980431\r\n",
      "Epoch:  90 Step:   768 /   793 Train loss: 0.03329898\r\n",
      "Epoch:  90 Step:   769 /   793 Train loss: 0.02733939\r\n",
      "Epoch:  90 Step:   770 /   793 Train loss: 0.03845447\r\n",
      "Epoch:  90 Step:   771 /   793 Train loss: 0.01920998\r\n",
      "Epoch:  90 Step:   772 /   793 Train loss: 0.02797972\r\n",
      "Epoch:  90 Step:   773 /   793 Train loss: 0.02187176\r\n",
      "Epoch:  90 Step:   774 /   793 Train loss: 0.03379251\r\n",
      "Epoch:  90 Step:   775 /   793 Train loss: 0.02549366\r\n",
      "Epoch:  90 Step:   776 /   793 Train loss: 0.02452824\r\n",
      "Epoch:  90 Step:   777 /   793 Train loss: 0.01887359\r\n",
      "Epoch:  90 Step:   778 /   793 Train loss: 0.03078488\r\n",
      "Epoch:  90 Step:   779 /   793 Train loss: 0.01470655\r\n",
      "Epoch:  90 Step:   780 /   793 Train loss: 0.03266431\r\n",
      "Epoch:  90 Step:   781 /   793 Train loss: 0.02457258\r\n",
      "Epoch:  90 Step:   782 /   793 Train loss: 0.01771225\r\n",
      "Epoch:  90 Step:   783 /   793 Train loss: 0.01999034\r\n",
      "Epoch:  90 Step:   784 /   793 Train loss: 0.01901627\r\n",
      "Epoch:  90 Step:   785 /   793 Train loss: 0.01587411\r\n",
      "Epoch:  90 Step:   786 /   793 Train loss: 0.02699958\r\n",
      "Epoch:  90 Step:   787 /   793 Train loss: 0.03287212\r\n",
      "Epoch:  90 Step:   788 /   793 Train loss: 0.00815502\r\n",
      "Epoch:  90 Step:   789 /   793 Train loss: 0.02692277\r\n",
      "Epoch:  90 Step:   790 /   793 Train loss: 0.03158095\r\n",
      "Epoch:  90 Step:   791 /   793 Train loss: 0.02584430\r\n",
      "Epoch:  90 Step:   792 /   793 Train loss: 0.02161947\r\n",
      "Epoch:  91 Step:     0 /   793 Train loss: 0.03015909\r\n",
      "Epoch:  91 Step:     1 /   793 Train loss: 0.01570947\r\n",
      "Epoch:  91 Step:     2 /   793 Train loss: 0.03324264\r\n",
      "Epoch:  91 Step:     3 /   793 Train loss: 0.01541979\r\n",
      "Epoch:  91 Step:     4 /   793 Train loss: 0.03079756\r\n",
      "Epoch:  91 Step:     5 /   793 Train loss: 0.03576677\r\n",
      "Epoch:  91 Step:     6 /   793 Train loss: 0.02774931\r\n",
      "Epoch:  91 Step:     7 /   793 Train loss: 0.02173325\r\n",
      "Epoch:  91 Step:     8 /   793 Train loss: 0.02333273\r\n",
      "Epoch:  91 Step:     9 /   793 Train loss: 0.02407468\r\n",
      "Epoch:  91 Step:    10 /   793 Train loss: 0.03462196\r\n",
      "Epoch:  91 Step:    11 /   793 Train loss: 0.03484203\r\n",
      "Epoch:  91 Step:    12 /   793 Train loss: 0.01893227\r\n",
      "Epoch:  91 Step:    13 /   793 Train loss: 0.02852340\r\n",
      "Epoch:  91 Step:    14 /   793 Train loss: 0.02145700\r\n",
      "Epoch:  91 Step:    15 /   793 Train loss: 0.02410245\r\n",
      "Epoch:  91 Step:    16 /   793 Train loss: 0.02468833\r\n",
      "Epoch:  91 Step:    17 /   793 Train loss: 0.02757527\r\n",
      "Epoch:  91 Step:    18 /   793 Train loss: 0.02330880\r\n",
      "Epoch:  91 Step:    19 /   793 Train loss: 0.02315293\r\n",
      "Epoch:  91 Step:    20 /   793 Train loss: 0.03656787\r\n",
      "Epoch:  91 Step:    21 /   793 Train loss: 0.02391973\r\n",
      "Epoch:  91 Step:    22 /   793 Train loss: 0.02487128\r\n",
      "Epoch:  91 Step:    23 /   793 Train loss: 0.02285345\r\n",
      "Epoch:  91 Step:    24 /   793 Train loss: 0.02981417\r\n",
      "Epoch:  91 Step:    25 /   793 Train loss: 0.03309285\r\n",
      "Epoch:  91 Step:    26 /   793 Train loss: 0.02463698\r\n",
      "Epoch:  91 Step:    27 /   793 Train loss: 0.03272550\r\n",
      "Epoch:  91 Step:    28 /   793 Train loss: 0.02109023\r\n",
      "Epoch:  91 Step:    29 /   793 Train loss: 0.02807412\r\n",
      "Epoch:  91 Step:    30 /   793 Train loss: 0.01342715\r\n",
      "Epoch:  91 Step:    31 /   793 Train loss: 0.01483097\r\n",
      "Epoch:  91 Step:    32 /   793 Train loss: 0.01688113\r\n",
      "Epoch:  91 Step:    33 /   793 Train loss: 0.02940518\r\n",
      "Epoch:  91 Step:    34 /   793 Train loss: 0.02246991\r\n",
      "Epoch:  91 Step:    35 /   793 Train loss: 0.01530608\r\n",
      "Epoch:  91 Step:    36 /   793 Train loss: 0.02420210\r\n",
      "Epoch:  91 Step:    37 /   793 Train loss: 0.02298110\r\n",
      "Epoch:  91 Step:    38 /   793 Train loss: 0.01852775\r\n",
      "Epoch:  91 Step:    39 /   793 Train loss: 0.01984276\r\n",
      "Epoch:  91 Step:    40 /   793 Train loss: 0.02843862\r\n",
      "Epoch:  91 Step:    41 /   793 Train loss: 0.02913979\r\n",
      "Epoch:  91 Step:    42 /   793 Train loss: 0.01846144\r\n",
      "Epoch:  91 Step:    43 /   793 Train loss: 0.03521109\r\n",
      "Epoch:  91 Step:    44 /   793 Train loss: 0.02602898\r\n",
      "Epoch:  91 Step:    45 /   793 Train loss: 0.01892137\r\n",
      "Epoch:  91 Step:    46 /   793 Train loss: 0.01754804\r\n",
      "Epoch:  91 Step:    47 /   793 Train loss: 0.01955143\r\n",
      "Epoch:  91 Step:    48 /   793 Train loss: 0.01947112\r\n",
      "Epoch:  91 Step:    49 /   793 Train loss: 0.01129328\r\n",
      "Epoch:  91 Step:    50 /   793 Train loss: 0.01701572\r\n",
      "Epoch:  91 Step:    51 /   793 Train loss: 0.02123738\r\n",
      "Epoch:  91 Step:    52 /   793 Train loss: 0.01835183\r\n",
      "Epoch:  91 Step:    53 /   793 Train loss: 0.01111851\r\n",
      "Epoch:  91 Step:    54 /   793 Train loss: 0.02560510\r\n",
      "Epoch:  91 Step:    55 /   793 Train loss: 0.01906338\r\n",
      "Epoch:  91 Step:    56 /   793 Train loss: 0.02746499\r\n",
      "Epoch:  91 Step:    57 /   793 Train loss: 0.03160094\r\n",
      "Epoch:  91 Step:    58 /   793 Train loss: 0.03060770\r\n",
      "Epoch:  91 Step:    59 /   793 Train loss: 0.01757361\r\n",
      "Epoch:  91 Step:    60 /   793 Train loss: 0.01085669\r\n",
      "Epoch:  91 Step:    61 /   793 Train loss: 0.02893381\r\n",
      "Epoch:  91 Step:    62 /   793 Train loss: 0.01278119\r\n",
      "Epoch:  91 Step:    63 /   793 Train loss: 0.01620381\r\n",
      "Epoch:  91 Step:    64 /   793 Train loss: 0.03047100\r\n",
      "Epoch:  91 Step:    65 /   793 Train loss: 0.02361779\r\n",
      "Epoch:  91 Step:    66 /   793 Train loss: 0.02595910\r\n",
      "Epoch:  91 Step:    67 /   793 Train loss: 0.02381652\r\n",
      "Epoch:  91 Step:    68 /   793 Train loss: 0.02730099\r\n",
      "Epoch:  91 Step:    69 /   793 Train loss: 0.01782998\r\n",
      "Epoch:  91 Step:    70 /   793 Train loss: 0.02993605\r\n",
      "Epoch:  91 Step:    71 /   793 Train loss: 0.02550063\r\n",
      "Epoch:  91 Step:    72 /   793 Train loss: 0.02517455\r\n",
      "Epoch:  91 Step:    73 /   793 Train loss: 0.02506259\r\n",
      "Epoch:  91 Step:    74 /   793 Train loss: 0.01701725\r\n",
      "Epoch:  91 Step:    75 /   793 Train loss: 0.02698718\r\n",
      "Epoch:  91 Step:    76 /   793 Train loss: 0.01599423\r\n",
      "Epoch:  91 Step:    77 /   793 Train loss: 0.03037237\r\n",
      "Epoch:  91 Step:    78 /   793 Train loss: 0.02918071\r\n",
      "Epoch:  91 Step:    79 /   793 Train loss: 0.01622131\r\n",
      "Epoch:  91 Step:    80 /   793 Train loss: 0.01629259\r\n",
      "Epoch:  91 Step:    81 /   793 Train loss: 0.03370769\r\n",
      "Epoch:  91 Step:    82 /   793 Train loss: 0.01925920\r\n",
      "Epoch:  91 Step:    83 /   793 Train loss: 0.01526455\r\n",
      "Epoch:  91 Step:    84 /   793 Train loss: 0.02293266\r\n",
      "Epoch:  91 Step:    85 /   793 Train loss: 0.03274109\r\n",
      "Epoch:  91 Step:    86 /   793 Train loss: 0.03021501\r\n",
      "Epoch:  91 Step:    87 /   793 Train loss: 0.01754590\r\n",
      "Epoch:  91 Step:    88 /   793 Train loss: 0.01839655\r\n",
      "Epoch:  91 Step:    89 /   793 Train loss: 0.01210532\r\n",
      "Epoch:  91 Step:    90 /   793 Train loss: 0.01944377\r\n",
      "Epoch:  91 Step:    91 /   793 Train loss: 0.02321891\r\n",
      "Epoch:  91 Step:    92 /   793 Train loss: 0.02009676\r\n",
      "Epoch:  91 Step:    93 /   793 Train loss: 0.02041811\r\n",
      "Epoch:  91 Step:    94 /   793 Train loss: 0.02207961\r\n",
      "Epoch:  91 Step:    95 /   793 Train loss: 0.01897493\r\n",
      "Epoch:  91 Step:    96 /   793 Train loss: 0.02484548\r\n",
      "Epoch:  91 Step:    97 /   793 Train loss: 0.01456211\r\n",
      "Epoch:  91 Step:    98 /   793 Train loss: 0.01966780\r\n",
      "Epoch:  91 Step:    99 /   793 Train loss: 0.02956698\r\n",
      "Epoch:  91 Step:   100 /   793 Train loss: 0.01442072\r\n",
      "Epoch:  91 Step:   101 /   793 Train loss: 0.04731480\r\n",
      "Epoch:  91 Step:   102 /   793 Train loss: 0.02716776\r\n",
      "Epoch:  91 Step:   103 /   793 Train loss: 0.05119544\r\n",
      "Epoch:  91 Step:   104 /   793 Train loss: 0.02381392\r\n",
      "Epoch:  91 Step:   105 /   793 Train loss: 0.02766605\r\n",
      "Epoch:  91 Step:   106 /   793 Train loss: 0.04493222\r\n",
      "Epoch:  91 Step:   107 /   793 Train loss: 0.02332486\r\n",
      "Epoch:  91 Step:   108 /   793 Train loss: 0.03230981\r\n",
      "Epoch:  91 Step:   109 /   793 Train loss: 0.01643852\r\n",
      "Epoch:  91 Step:   110 /   793 Train loss: 0.02601832\r\n",
      "Epoch:  91 Step:   111 /   793 Train loss: 0.01843316\r\n",
      "Epoch:  91 Step:   112 /   793 Train loss: 0.03087052\r\n",
      "Epoch:  91 Step:   113 /   793 Train loss: 0.03071253\r\n",
      "Epoch:  91 Step:   114 /   793 Train loss: 0.01079793\r\n",
      "Epoch:  91 Step:   115 /   793 Train loss: 0.02010424\r\n",
      "Epoch:  91 Step:   116 /   793 Train loss: 0.01571932\r\n",
      "Epoch:  91 Step:   117 /   793 Train loss: 0.02081544\r\n",
      "Epoch:  91 Step:   118 /   793 Train loss: 0.01816616\r\n",
      "Epoch:  91 Step:   119 /   793 Train loss: 0.03051079\r\n",
      "Epoch:  91 Step:   120 /   793 Train loss: 0.04450041\r\n",
      "Epoch:  91 Step:   121 /   793 Train loss: 0.02257233\r\n",
      "Epoch:  91 Step:   122 /   793 Train loss: 0.01545758\r\n",
      "Epoch:  91 Step:   123 /   793 Train loss: 0.02332949\r\n",
      "Epoch:  91 Step:   124 /   793 Train loss: 0.03311623\r\n",
      "Epoch:  91 Step:   125 /   793 Train loss: 0.02470940\r\n",
      "Epoch:  91 Step:   126 /   793 Train loss: 0.02254798\r\n",
      "Epoch:  91 Step:   127 /   793 Train loss: 0.04188674\r\n",
      "Epoch:  91 Step:   128 /   793 Train loss: 0.02305467\r\n",
      "Epoch:  91 Step:   129 /   793 Train loss: 0.01775432\r\n",
      "Epoch:  91 Step:   130 /   793 Train loss: 0.01618332\r\n",
      "Epoch:  91 Step:   131 /   793 Train loss: 0.01766099\r\n",
      "Epoch:  91 Step:   132 /   793 Train loss: 0.01726306\r\n",
      "Epoch:  91 Step:   133 /   793 Train loss: 0.02588041\r\n",
      "Epoch:  91 Step:   134 /   793 Train loss: 0.01860927\r\n",
      "Epoch:  91 Step:   135 /   793 Train loss: 0.02351560\r\n",
      "Epoch:  91 Step:   136 /   793 Train loss: 0.02421923\r\n",
      "Epoch:  91 Step:   137 /   793 Train loss: 0.02073357\r\n",
      "Epoch:  91 Step:   138 /   793 Train loss: 0.03020418\r\n",
      "Epoch:  91 Step:   139 /   793 Train loss: 0.01442516\r\n",
      "Epoch:  91 Step:   140 /   793 Train loss: 0.03420445\r\n",
      "Epoch:  91 Step:   141 /   793 Train loss: 0.02457863\r\n",
      "Epoch:  91 Step:   142 /   793 Train loss: 0.02681910\r\n",
      "Epoch:  91 Step:   143 /   793 Train loss: 0.02637196\r\n",
      "Epoch:  91 Step:   144 /   793 Train loss: 0.01907238\r\n",
      "Epoch:  91 Step:   145 /   793 Train loss: 0.02929605\r\n",
      "Epoch:  91 Step:   146 /   793 Train loss: 0.02210140\r\n",
      "Epoch:  91 Step:   147 /   793 Train loss: 0.03405474\r\n",
      "Epoch:  91 Step:   148 /   793 Train loss: 0.03898450\r\n",
      "Epoch:  91 Step:   149 /   793 Train loss: 0.01686533\r\n",
      "Epoch:  91 Step:   150 /   793 Train loss: 0.01949441\r\n",
      "Epoch:  91 Step:   151 /   793 Train loss: 0.01046661\r\n",
      "Epoch:  91 Step:   152 /   793 Train loss: 0.02153802\r\n",
      "Epoch:  91 Step:   153 /   793 Train loss: 0.02312151\r\n",
      "Epoch:  91 Step:   154 /   793 Train loss: 0.03643500\r\n",
      "Epoch:  91 Step:   155 /   793 Train loss: 0.04141813\r\n",
      "Epoch:  91 Step:   156 /   793 Train loss: 0.02895146\r\n",
      "Epoch:  91 Step:   157 /   793 Train loss: 0.01967171\r\n",
      "Epoch:  91 Step:   158 /   793 Train loss: 0.03085182\r\n",
      "Epoch:  91 Step:   159 /   793 Train loss: 0.02794976\r\n",
      "Epoch:  91 Step:   160 /   793 Train loss: 0.04269204\r\n",
      "Epoch:  91 Step:   161 /   793 Train loss: 0.02396307\r\n",
      "Epoch:  91 Step:   162 /   793 Train loss: 0.01472451\r\n",
      "Epoch:  91 Step:   163 /   793 Train loss: 0.03862867\r\n",
      "Epoch:  91 Step:   164 /   793 Train loss: 0.02557325\r\n",
      "Epoch:  91 Step:   165 /   793 Train loss: 0.03162955\r\n",
      "Epoch:  91 Step:   166 /   793 Train loss: 0.02161556\r\n",
      "Epoch:  91 Step:   167 /   793 Train loss: 0.01779044\r\n",
      "Epoch:  91 Step:   168 /   793 Train loss: 0.03512068\r\n",
      "Epoch:  91 Step:   169 /   793 Train loss: 0.02162233\r\n",
      "Epoch:  91 Step:   170 /   793 Train loss: 0.02470105\r\n",
      "Epoch:  91 Step:   171 /   793 Train loss: 0.01666078\r\n",
      "Epoch:  91 Step:   172 /   793 Train loss: 0.01422829\r\n",
      "Epoch:  91 Step:   173 /   793 Train loss: 0.03029208\r\n",
      "Epoch:  91 Step:   174 /   793 Train loss: 0.02996389\r\n",
      "Epoch:  91 Step:   175 /   793 Train loss: 0.02850994\r\n",
      "Epoch:  91 Step:   176 /   793 Train loss: 0.02759921\r\n",
      "Epoch:  91 Step:   177 /   793 Train loss: 0.03713984\r\n",
      "Epoch:  91 Step:   178 /   793 Train loss: 0.02319483\r\n",
      "Epoch:  91 Step:   179 /   793 Train loss: 0.03691373\r\n",
      "Epoch:  91 Step:   180 /   793 Train loss: 0.04002178\r\n",
      "Epoch:  91 Step:   181 /   793 Train loss: 0.02692778\r\n",
      "Epoch:  91 Step:   182 /   793 Train loss: 0.02430291\r\n",
      "Epoch:  91 Step:   183 /   793 Train loss: 0.03597117\r\n",
      "Epoch:  91 Step:   184 /   793 Train loss: 0.02330044\r\n",
      "Epoch:  91 Step:   185 /   793 Train loss: 0.01750995\r\n",
      "Epoch:  91 Step:   186 /   793 Train loss: 0.02774562\r\n",
      "Epoch:  91 Step:   187 /   793 Train loss: 0.02444275\r\n",
      "Epoch:  91 Step:   188 /   793 Train loss: 0.02294127\r\n",
      "Epoch:  91 Step:   189 /   793 Train loss: 0.03098061\r\n",
      "Epoch:  91 Step:   190 /   793 Train loss: 0.01815542\r\n",
      "Epoch:  91 Step:   191 /   793 Train loss: 0.01765286\r\n",
      "Epoch:  91 Step:   192 /   793 Train loss: 0.01780740\r\n",
      "Epoch:  91 Step:   193 /   793 Train loss: 0.02324979\r\n",
      "Epoch:  91 Step:   194 /   793 Train loss: 0.03311500\r\n",
      "Epoch:  91 Step:   195 /   793 Train loss: 0.02491734\r\n",
      "Epoch:  91 Step:   196 /   793 Train loss: 0.01657082\r\n",
      "Epoch:  91 Step:   197 /   793 Train loss: 0.02514157\r\n",
      "Epoch:  91 Step:   198 /   793 Train loss: 0.01931639\r\n",
      "Epoch:  91 Step:   199 /   793 Train loss: 0.02650422\r\n",
      "Epoch:  91 Step:   200 /   793 Train loss: 0.02946702\r\n",
      "Epoch:  91 Step:   201 /   793 Train loss: 0.03015512\r\n",
      "Epoch:  91 Step:   202 /   793 Train loss: 0.02661444\r\n",
      "Epoch:  91 Step:   203 /   793 Train loss: 0.02644601\r\n",
      "Epoch:  91 Step:   204 /   793 Train loss: 0.02766072\r\n",
      "Epoch:  91 Step:   205 /   793 Train loss: 0.02629763\r\n",
      "Epoch:  91 Step:   206 /   793 Train loss: 0.02240529\r\n",
      "Epoch:  91 Step:   207 /   793 Train loss: 0.01748255\r\n",
      "Epoch:  91 Step:   208 /   793 Train loss: 0.02500579\r\n",
      "Epoch:  91 Step:   209 /   793 Train loss: 0.02096037\r\n",
      "Epoch:  91 Step:   210 /   793 Train loss: 0.02205628\r\n",
      "Epoch:  91 Step:   211 /   793 Train loss: 0.02248237\r\n",
      "Epoch:  91 Step:   212 /   793 Train loss: 0.02648149\r\n",
      "Epoch:  91 Step:   213 /   793 Train loss: 0.02795132\r\n",
      "Epoch:  91 Step:   214 /   793 Train loss: 0.01862652\r\n",
      "Epoch:  91 Step:   215 /   793 Train loss: 0.02969144\r\n",
      "Epoch:  91 Step:   216 /   793 Train loss: 0.01895530\r\n",
      "Epoch:  91 Step:   217 /   793 Train loss: 0.01530759\r\n",
      "Epoch:  91 Step:   218 /   793 Train loss: 0.02418187\r\n",
      "Epoch:  91 Step:   219 /   793 Train loss: 0.03052459\r\n",
      "Epoch:  91 Step:   220 /   793 Train loss: 0.02864543\r\n",
      "Epoch:  91 Step:   221 /   793 Train loss: 0.01523739\r\n",
      "Epoch:  91 Step:   222 /   793 Train loss: 0.02932360\r\n",
      "Epoch:  91 Step:   223 /   793 Train loss: 0.02264008\r\n",
      "Epoch:  91 Step:   224 /   793 Train loss: 0.02649770\r\n",
      "Epoch:  91 Step:   225 /   793 Train loss: 0.01821997\r\n",
      "Epoch:  91 Step:   226 /   793 Train loss: 0.02643963\r\n",
      "Epoch:  91 Step:   227 /   793 Train loss: 0.01618207\r\n",
      "Epoch:  91 Step:   228 /   793 Train loss: 0.02899520\r\n",
      "Epoch:  91 Step:   229 /   793 Train loss: 0.02790562\r\n",
      "Epoch:  91 Step:   230 /   793 Train loss: 0.01506823\r\n",
      "Epoch:  91 Step:   231 /   793 Train loss: 0.02837415\r\n",
      "Epoch:  91 Step:   232 /   793 Train loss: 0.02676423\r\n",
      "Epoch:  91 Step:   233 /   793 Train loss: 0.03698424\r\n",
      "Epoch:  91 Step:   234 /   793 Train loss: 0.03438932\r\n",
      "Epoch:  91 Step:   235 /   793 Train loss: 0.03617308\r\n",
      "Epoch:  91 Step:   236 /   793 Train loss: 0.02024851\r\n",
      "Epoch:  91 Step:   237 /   793 Train loss: 0.01703105\r\n",
      "Epoch:  91 Step:   238 /   793 Train loss: 0.03640340\r\n",
      "Epoch:  91 Step:   239 /   793 Train loss: 0.02756574\r\n",
      "Epoch:  91 Step:   240 /   793 Train loss: 0.01803336\r\n",
      "Epoch:  91 Step:   241 /   793 Train loss: 0.03525855\r\n",
      "Epoch:  91 Step:   242 /   793 Train loss: 0.01489827\r\n",
      "Epoch:  91 Step:   243 /   793 Train loss: 0.01349490\r\n",
      "Epoch:  91 Step:   244 /   793 Train loss: 0.02177413\r\n",
      "Epoch:  91 Step:   245 /   793 Train loss: 0.02936535\r\n",
      "Epoch:  91 Step:   246 /   793 Train loss: 0.03561002\r\n",
      "Epoch:  91 Step:   247 /   793 Train loss: 0.02322781\r\n",
      "Epoch:  91 Step:   248 /   793 Train loss: 0.02202486\r\n",
      "Epoch:  91 Step:   249 /   793 Train loss: 0.02205991\r\n",
      "Epoch:  91 Step:   250 /   793 Train loss: 0.02372102\r\n",
      "Epoch:  91 Step:   251 /   793 Train loss: 0.02071873\r\n",
      "Epoch:  91 Step:   252 /   793 Train loss: 0.02743771\r\n",
      "Epoch:  91 Step:   253 /   793 Train loss: 0.01984585\r\n",
      "Epoch:  91 Step:   254 /   793 Train loss: 0.03648707\r\n",
      "Epoch:  91 Step:   255 /   793 Train loss: 0.02335332\r\n",
      "Epoch:  91 Step:   256 /   793 Train loss: 0.01294334\r\n",
      "Epoch:  91 Step:   257 /   793 Train loss: 0.01908594\r\n",
      "Epoch:  91 Step:   258 /   793 Train loss: 0.03026655\r\n",
      "Epoch:  91 Step:   259 /   793 Train loss: 0.02578919\r\n",
      "Epoch:  91 Step:   260 /   793 Train loss: 0.03564692\r\n",
      "Epoch:  91 Step:   261 /   793 Train loss: 0.02300631\r\n",
      "Epoch:  91 Step:   262 /   793 Train loss: 0.01758196\r\n",
      "Epoch:  91 Step:   263 /   793 Train loss: 0.02909787\r\n",
      "Epoch:  91 Step:   264 /   793 Train loss: 0.01931075\r\n",
      "Epoch:  91 Step:   265 /   793 Train loss: 0.02541726\r\n",
      "Epoch:  91 Step:   266 /   793 Train loss: 0.01940651\r\n",
      "Epoch:  91 Step:   267 /   793 Train loss: 0.03904628\r\n",
      "Epoch:  91 Step:   268 /   793 Train loss: 0.02587099\r\n",
      "Epoch:  91 Step:   269 /   793 Train loss: 0.02731791\r\n",
      "Epoch:  91 Step:   270 /   793 Train loss: 0.01830771\r\n",
      "Epoch:  91 Step:   271 /   793 Train loss: 0.03956369\r\n",
      "Epoch:  91 Step:   272 /   793 Train loss: 0.02042774\r\n",
      "Epoch:  91 Step:   273 /   793 Train loss: 0.02218269\r\n",
      "Epoch:  91 Step:   274 /   793 Train loss: 0.04399179\r\n",
      "Epoch:  91 Step:   275 /   793 Train loss: 0.02204316\r\n",
      "Epoch:  91 Step:   276 /   793 Train loss: 0.01946267\r\n",
      "Epoch:  91 Step:   277 /   793 Train loss: 0.01803182\r\n",
      "Epoch:  91 Step:   278 /   793 Train loss: 0.01619732\r\n",
      "Epoch:  91 Step:   279 /   793 Train loss: 0.01886068\r\n",
      "Epoch:  91 Step:   280 /   793 Train loss: 0.01983280\r\n",
      "Epoch:  91 Step:   281 /   793 Train loss: 0.02778308\r\n",
      "Epoch:  91 Step:   282 /   793 Train loss: 0.02215618\r\n",
      "Epoch:  91 Step:   283 /   793 Train loss: 0.01727366\r\n",
      "Epoch:  91 Step:   284 /   793 Train loss: 0.02407458\r\n",
      "Epoch:  91 Step:   285 /   793 Train loss: 0.03357365\r\n",
      "Epoch:  91 Step:   286 /   793 Train loss: 0.01124984\r\n",
      "Epoch:  91 Step:   287 /   793 Train loss: 0.01751007\r\n",
      "Epoch:  91 Step:   288 /   793 Train loss: 0.02412871\r\n",
      "Epoch:  91 Step:   289 /   793 Train loss: 0.01696450\r\n",
      "Epoch:  91 Step:   290 /   793 Train loss: 0.02597561\r\n",
      "Epoch:  91 Step:   291 /   793 Train loss: 0.03046036\r\n",
      "Epoch:  91 Step:   292 /   793 Train loss: 0.01586139\r\n",
      "Epoch:  91 Step:   293 /   793 Train loss: 0.01911422\r\n",
      "Epoch:  91 Step:   294 /   793 Train loss: 0.01841008\r\n",
      "Epoch:  91 Step:   295 /   793 Train loss: 0.02654925\r\n",
      "Epoch:  91 Step:   296 /   793 Train loss: 0.01549402\r\n",
      "Epoch:  91 Step:   297 /   793 Train loss: 0.03418832\r\n",
      "Epoch:  91 Step:   298 /   793 Train loss: 0.02395178\r\n",
      "Epoch:  91 Step:   299 /   793 Train loss: 0.02364234\r\n",
      "Epoch:  91 Step:   300 /   793 Train loss: 0.01579740\r\n",
      "Epoch:  91 Step:   301 /   793 Train loss: 0.01988922\r\n",
      "Epoch:  91 Step:   302 /   793 Train loss: 0.02001882\r\n",
      "Epoch:  91 Step:   303 /   793 Train loss: 0.02774432\r\n",
      "Epoch:  91 Step:   304 /   793 Train loss: 0.01986315\r\n",
      "Epoch:  91 Step:   305 /   793 Train loss: 0.03602577\r\n",
      "Epoch:  91 Step:   306 /   793 Train loss: 0.02417269\r\n",
      "Epoch:  91 Step:   307 /   793 Train loss: 0.02610121\r\n",
      "Epoch:  91 Step:   308 /   793 Train loss: 0.01871232\r\n",
      "Epoch:  91 Step:   309 /   793 Train loss: 0.04081797\r\n",
      "Epoch:  91 Step:   310 /   793 Train loss: 0.02898061\r\n",
      "Epoch:  91 Step:   311 /   793 Train loss: 0.02631959\r\n",
      "Epoch:  91 Step:   312 /   793 Train loss: 0.02351741\r\n",
      "Epoch:  91 Step:   313 /   793 Train loss: 0.02751088\r\n",
      "Epoch:  91 Step:   314 /   793 Train loss: 0.01600400\r\n",
      "Epoch:  91 Step:   315 /   793 Train loss: 0.02216442\r\n",
      "Epoch:  91 Step:   316 /   793 Train loss: 0.01892807\r\n",
      "Epoch:  91 Step:   317 /   793 Train loss: 0.02939964\r\n",
      "Epoch:  91 Step:   318 /   793 Train loss: 0.03029378\r\n",
      "Epoch:  91 Step:   319 /   793 Train loss: 0.03452943\r\n",
      "Epoch:  91 Step:   320 /   793 Train loss: 0.02796324\r\n",
      "Epoch:  91 Step:   321 /   793 Train loss: 0.01935021\r\n",
      "Epoch:  91 Step:   322 /   793 Train loss: 0.01882123\r\n",
      "Epoch:  91 Step:   323 /   793 Train loss: 0.02011304\r\n",
      "Epoch:  91 Step:   324 /   793 Train loss: 0.02600482\r\n",
      "Epoch:  91 Step:   325 /   793 Train loss: 0.01866444\r\n",
      "Epoch:  91 Step:   326 /   793 Train loss: 0.01822597\r\n",
      "Epoch:  91 Step:   327 /   793 Train loss: 0.02347779\r\n",
      "Epoch:  91 Step:   328 /   793 Train loss: 0.01559958\r\n",
      "Epoch:  91 Step:   329 /   793 Train loss: 0.02962211\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  91 Step:   330 /   793 Train loss: 0.02800716\r\n",
      "Epoch:  91 Step:   331 /   793 Train loss: 0.02497756\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  91 Step:   332 /   793 Train loss: 0.02097660\r\n",
      "Epoch:  91 Step:   333 /   793 Train loss: 0.02574883\r\n",
      "Epoch:  91 Step:   334 /   793 Train loss: 0.05201529\r\n",
      "Epoch:  91 Step:   335 /   793 Train loss: 0.02879171\r\n",
      "Epoch:  91 Step:   336 /   793 Train loss: 0.02907935\r\n",
      "Epoch:  91 Step:   337 /   793 Train loss: 0.02504944\r\n",
      "Epoch:  91 Step:   338 /   793 Train loss: 0.02865678\r\n",
      "Epoch:  91 Step:   339 /   793 Train loss: 0.01789937\r\n",
      "Epoch:  91 Step:   340 /   793 Train loss: 0.02589658\r\n",
      "Epoch:  91 Step:   341 /   793 Train loss: 0.02162814\r\n",
      "Epoch:  91 Step:   342 /   793 Train loss: 0.02464732\r\n",
      "Epoch:  91 Step:   343 /   793 Train loss: 0.03123126\r\n",
      "Epoch:  91 Step:   344 /   793 Train loss: 0.01742038\r\n",
      "Epoch:  91 Step:   345 /   793 Train loss: 0.01643745\r\n",
      "Epoch:  91 Step:   346 /   793 Train loss: 0.02559138\r\n",
      "Epoch:  91 Step:   347 /   793 Train loss: 0.03683443\r\n",
      "Epoch:  91 Step:   348 /   793 Train loss: 0.03130589\r\n",
      "Epoch:  91 Step:   349 /   793 Train loss: 0.01929089\r\n",
      "Epoch:  91 Step:   350 /   793 Train loss: 0.02708710\r\n",
      "Epoch:  91 Step:   351 /   793 Train loss: 0.03110220\r\n",
      "Epoch:  91 Step:   352 /   793 Train loss: 0.01500845\r\n",
      "Epoch:  91 Step:   353 /   793 Train loss: 0.01907063\r\n",
      "Epoch:  91 Step:   354 /   793 Train loss: 0.02195833\r\n",
      "Epoch:  91 Step:   355 /   793 Train loss: 0.01532924\r\n",
      "Epoch:  91 Step:   356 /   793 Train loss: 0.03872347\r\n",
      "Epoch:  91 Step:   357 /   793 Train loss: 0.02291532\r\n",
      "Epoch:  91 Step:   358 /   793 Train loss: 0.02672797\r\n",
      "Epoch:  91 Step:   359 /   793 Train loss: 0.01147822\r\n",
      "Epoch:  91 Step:   360 /   793 Train loss: 0.02324140\r\n",
      "Epoch:  91 Step:   361 /   793 Train loss: 0.02574984\r\n",
      "Epoch:  91 Step:   362 /   793 Train loss: 0.02915697\r\n",
      "Epoch:  91 Step:   363 /   793 Train loss: 0.02298753\r\n",
      "Epoch:  91 Step:   364 /   793 Train loss: 0.02718432\r\n",
      "Epoch:  91 Step:   365 /   793 Train loss: 0.01316998\r\n",
      "Epoch:  91 Step:   366 /   793 Train loss: 0.01900877\r\n",
      "Epoch:  91 Step:   367 /   793 Train loss: 0.01877759\r\n",
      "Epoch:  91 Step:   368 /   793 Train loss: 0.03345978\r\n",
      "Epoch:  91 Step:   369 /   793 Train loss: 0.02361804\r\n",
      "Epoch:  91 Step:   370 /   793 Train loss: 0.02487135\r\n",
      "Epoch:  91 Step:   371 /   793 Train loss: 0.02406942\r\n",
      "Epoch:  91 Step:   372 /   793 Train loss: 0.02610324\r\n",
      "Epoch:  91 Step:   373 /   793 Train loss: 0.01461200\r\n",
      "Epoch:  91 Step:   374 /   793 Train loss: 0.02265188\r\n",
      "Epoch:  91 Step:   375 /   793 Train loss: 0.02780550\r\n",
      "Epoch:  91 Step:   376 /   793 Train loss: 0.02498718\r\n",
      "Epoch:  91 Step:   377 /   793 Train loss: 0.02484127\r\n",
      "Epoch:  91 Step:   378 /   793 Train loss: 0.03377491\r\n",
      "Epoch:  91 Step:   379 /   793 Train loss: 0.01749258\r\n",
      "Epoch:  91 Step:   380 /   793 Train loss: 0.02751336\r\n",
      "Epoch:  91 Step:   381 /   793 Train loss: 0.02273173\r\n",
      "Epoch:  91 Step:   382 /   793 Train loss: 0.02389362\r\n",
      "Epoch:  91 Step:   383 /   793 Train loss: 0.01980932\r\n",
      "Epoch:  91 Step:   384 /   793 Train loss: 0.02640453\r\n",
      "Epoch:  91 Step:   385 /   793 Train loss: 0.02385484\r\n",
      "Epoch:  91 Step:   386 /   793 Train loss: 0.03120998\r\n",
      "Epoch:  91 Step:   387 /   793 Train loss: 0.02218131\r\n",
      "Epoch:  91 Step:   388 /   793 Train loss: 0.03681144\r\n",
      "Epoch:  91 Step:   389 /   793 Train loss: 0.01516918\r\n",
      "Epoch:  91 Step:   390 /   793 Train loss: 0.01344037\r\n",
      "Epoch:  91 Step:   391 /   793 Train loss: 0.02652447\r\n",
      "Epoch:  91 Step:   392 /   793 Train loss: 0.02441255\r\n",
      "Epoch:  91 Step:   393 /   793 Train loss: 0.03055649\r\n",
      "Epoch:  91 Step:   394 /   793 Train loss: 0.02650230\r\n",
      "Epoch:  91 Step:   395 /   793 Train loss: 0.02141816\r\n",
      "Epoch:  91 Step:   396 /   793 Train loss: 0.03062786\r\n",
      "Epoch:  91 Step:   397 /   793 Train loss: 0.04769315\r\n",
      "Epoch:  91 Step:   398 /   793 Train loss: 0.02360498\r\n",
      "Epoch:  91 Step:   399 /   793 Train loss: 0.01787430\r\n",
      "Epoch:  91 Step:   400 /   793 Train loss: 0.02004930\r\n",
      "Epoch:  91 Step:   401 /   793 Train loss: 0.03099195\r\n",
      "Epoch:  91 Step:   402 /   793 Train loss: 0.01841808\r\n",
      "Epoch:  91 Step:   403 /   793 Train loss: 0.01877435\r\n",
      "Epoch:  91 Step:   404 /   793 Train loss: 0.03236370\r\n",
      "Epoch:  91 Step:   405 /   793 Train loss: 0.02369810\r\n",
      "Epoch:  91 Step:   406 /   793 Train loss: 0.02133670\r\n",
      "Epoch:  91 Step:   407 /   793 Train loss: 0.02809514\r\n",
      "Epoch:  91 Step:   408 /   793 Train loss: 0.02466790\r\n",
      "Epoch:  91 Step:   409 /   793 Train loss: 0.02108546\r\n",
      "Epoch:  91 Step:   410 /   793 Train loss: 0.03013244\r\n",
      "Epoch:  91 Step:   411 /   793 Train loss: 0.03106793\r\n",
      "Epoch:  91 Step:   412 /   793 Train loss: 0.03005279\r\n",
      "Epoch:  91 Step:   413 /   793 Train loss: 0.02295744\r\n",
      "Epoch:  91 Step:   414 /   793 Train loss: 0.02680115\r\n",
      "Epoch:  91 Step:   415 /   793 Train loss: 0.03329497\r\n",
      "Epoch:  91 Step:   416 /   793 Train loss: 0.02543939\r\n",
      "Epoch:  91 Step:   417 /   793 Train loss: 0.03721418\r\n",
      "Epoch:  91 Step:   418 /   793 Train loss: 0.01944271\r\n",
      "Epoch:  91 Step:   419 /   793 Train loss: 0.01997468\r\n",
      "Epoch:  91 Step:   420 /   793 Train loss: 0.02853664\r\n",
      "Epoch:  91 Step:   421 /   793 Train loss: 0.02289877\r\n",
      "Epoch:  91 Step:   422 /   793 Train loss: 0.02259091\r\n",
      "Epoch:  91 Step:   423 /   793 Train loss: 0.01920562\r\n",
      "Epoch:  91 Step:   424 /   793 Train loss: 0.02191933\r\n",
      "Epoch:  91 Step:   425 /   793 Train loss: 0.02268467\r\n",
      "Epoch:  91 Step:   426 /   793 Train loss: 0.03170781\r\n",
      "Epoch:  91 Step:   427 /   793 Train loss: 0.01704262\r\n",
      "Epoch:  91 Step:   428 /   793 Train loss: 0.03683851\r\n",
      "Epoch:  91 Step:   429 /   793 Train loss: 0.02443975\r\n",
      "Epoch:  91 Step:   430 /   793 Train loss: 0.01918903\r\n",
      "Epoch:  91 Step:   431 /   793 Train loss: 0.03452740\r\n",
      "Epoch:  91 Step:   432 /   793 Train loss: 0.02461700\r\n",
      "Epoch:  91 Step:   433 /   793 Train loss: 0.03700510\r\n",
      "Epoch:  91 Step:   434 /   793 Train loss: 0.02263534\r\n",
      "Epoch:  91 Step:   435 /   793 Train loss: 0.02849472\r\n",
      "Epoch:  91 Step:   436 /   793 Train loss: 0.02262063\r\n",
      "Epoch:  91 Step:   437 /   793 Train loss: 0.02186400\r\n",
      "Epoch:  91 Step:   438 /   793 Train loss: 0.01103784\r\n",
      "Epoch:  91 Step:   439 /   793 Train loss: 0.02431400\r\n",
      "Epoch:  91 Step:   440 /   793 Train loss: 0.02513179\r\n",
      "Epoch:  91 Step:   441 /   793 Train loss: 0.02746898\r\n",
      "Epoch:  91 Step:   442 /   793 Train loss: 0.02242953\r\n",
      "Epoch:  91 Step:   443 /   793 Train loss: 0.02815235\r\n",
      "Epoch:  91 Step:   444 /   793 Train loss: 0.02403251\r\n",
      "Epoch:  91 Step:   445 /   793 Train loss: 0.01914460\r\n",
      "Epoch:  91 Step:   446 /   793 Train loss: 0.02458250\r\n",
      "Epoch:  91 Step:   447 /   793 Train loss: 0.03027279\r\n",
      "Epoch:  91 Step:   448 /   793 Train loss: 0.02055244\r\n",
      "Epoch:  91 Step:   449 /   793 Train loss: 0.02304434\r\n",
      "Epoch:  91 Step:   450 /   793 Train loss: 0.02740907\r\n",
      "Epoch:  91 Step:   451 /   793 Train loss: 0.02748810\r\n",
      "Epoch:  91 Step:   452 /   793 Train loss: 0.02083044\r\n",
      "Epoch:  91 Step:   453 /   793 Train loss: 0.03485857\r\n",
      "Epoch:  91 Step:   454 /   793 Train loss: 0.01402562\r\n",
      "Epoch:  91 Step:   455 /   793 Train loss: 0.01825987\r\n",
      "Epoch:  91 Step:   456 /   793 Train loss: 0.02334468\r\n",
      "Epoch:  91 Step:   457 /   793 Train loss: 0.02569634\r\n",
      "Epoch:  91 Step:   458 /   793 Train loss: 0.03029968\r\n",
      "Epoch:  91 Step:   459 /   793 Train loss: 0.02720818\r\n",
      "Epoch:  91 Step:   460 /   793 Train loss: 0.02512528\r\n",
      "Epoch:  91 Step:   461 /   793 Train loss: 0.02144762\r\n",
      "Epoch:  91 Step:   462 /   793 Train loss: 0.02021230\r\n",
      "Epoch:  91 Step:   463 /   793 Train loss: 0.02216015\r\n",
      "Epoch:  91 Step:   464 /   793 Train loss: 0.02413732\r\n",
      "Epoch:  91 Step:   465 /   793 Train loss: 0.02531912\r\n",
      "Epoch:  91 Step:   466 /   793 Train loss: 0.02404692\r\n",
      "Epoch:  91 Step:   467 /   793 Train loss: 0.02747744\r\n",
      "Epoch:  91 Step:   468 /   793 Train loss: 0.02680199\r\n",
      "Epoch:  91 Step:   469 /   793 Train loss: 0.02567966\r\n",
      "Epoch:  91 Step:   470 /   793 Train loss: 0.03722081\r\n",
      "Epoch:  91 Step:   471 /   793 Train loss: 0.03675169\r\n",
      "Epoch:  91 Step:   472 /   793 Train loss: 0.02514097\r\n",
      "Epoch:  91 Step:   473 /   793 Train loss: 0.02165844\r\n",
      "Epoch:  91 Step:   474 /   793 Train loss: 0.03391971\r\n",
      "Epoch:  91 Step:   475 /   793 Train loss: 0.02129119\r\n",
      "Epoch:  91 Step:   476 /   793 Train loss: 0.03242040\r\n",
      "Epoch:  91 Step:   477 /   793 Train loss: 0.01949356\r\n",
      "Epoch:  91 Step:   478 /   793 Train loss: 0.01392144\r\n",
      "Epoch:  91 Step:   479 /   793 Train loss: 0.02892463\r\n",
      "Epoch:  91 Step:   480 /   793 Train loss: 0.02186564\r\n",
      "Epoch:  91 Step:   481 /   793 Train loss: 0.03056679\r\n",
      "Epoch:  91 Step:   482 /   793 Train loss: 0.02045574\r\n",
      "Epoch:  91 Step:   483 /   793 Train loss: 0.03116188\r\n",
      "Epoch:  91 Step:   484 /   793 Train loss: 0.01453330\r\n",
      "Epoch:  91 Step:   485 /   793 Train loss: 0.02395180\r\n",
      "Epoch:  91 Step:   486 /   793 Train loss: 0.02432860\r\n",
      "Epoch:  91 Step:   487 /   793 Train loss: 0.01855031\r\n",
      "Epoch:  91 Step:   488 /   793 Train loss: 0.01488122\r\n",
      "Epoch:  91 Step:   489 /   793 Train loss: 0.02857276\r\n",
      "Epoch:  91 Step:   490 /   793 Train loss: 0.03414901\r\n",
      "Epoch:  91 Step:   491 /   793 Train loss: 0.03073543\r\n",
      "Epoch:  91 Step:   492 /   793 Train loss: 0.01697008\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  91 Step:   493 /   793 Train loss: 0.02192006\r\n",
      "Epoch:  91 Step:   494 /   793 Train loss: 0.02664551\r\n",
      "Epoch:  91 Step:   495 /   793 Train loss: 0.01612831\r\n",
      "Epoch:  91 Step:   496 /   793 Train loss: 0.02267408\r\n",
      "Epoch:  91 Step:   497 /   793 Train loss: 0.02935285\r\n",
      "Epoch:  91 Step:   498 /   793 Train loss: 0.02398494\r\n",
      "Epoch:  91 Step:   499 /   793 Train loss: 0.03106729\r\n",
      "Epoch:  91 Step:   500 /   793 Train loss: 0.03131188\r\n",
      "Epoch:  91 Step:   501 /   793 Train loss: 0.01436438\r\n",
      "Epoch:  91 Step:   502 /   793 Train loss: 0.03030138\r\n",
      "Epoch:  91 Step:   503 /   793 Train loss: 0.01519926\r\n",
      "Epoch:  91 Step:   504 /   793 Train loss: 0.03882674\r\n",
      "Epoch:  91 Step:   505 /   793 Train loss: 0.01120467\r\n",
      "Epoch:  91 Step:   506 /   793 Train loss: 0.01499821\r\n",
      "Epoch:  91 Step:   507 /   793 Train loss: 0.02414003\r\n",
      "Epoch:  91 Step:   508 /   793 Train loss: 0.02049922\r\n",
      "Epoch:  91 Step:   509 /   793 Train loss: 0.01307292\r\n",
      "Epoch:  91 Step:   510 /   793 Train loss: 0.01697787\r\n",
      "Epoch:  91 Step:   511 /   793 Train loss: 0.03744000\r\n",
      "Epoch:  91 Step:   512 /   793 Train loss: 0.02987247\r\n",
      "Epoch:  91 Step:   513 /   793 Train loss: 0.02924326\r\n",
      "Epoch:  91 Step:   514 /   793 Train loss: 0.01619768\r\n",
      "Epoch:  91 Step:   515 /   793 Train loss: 0.02451103\r\n",
      "Epoch:  91 Step:   516 /   793 Train loss: 0.01679211\r\n",
      "Epoch:  91 Step:   517 /   793 Train loss: 0.03621440\r\n",
      "Epoch:  91 Step:   518 /   793 Train loss: 0.01888091\r\n",
      "Epoch:  91 Step:   519 /   793 Train loss: 0.03154696\r\n",
      "Epoch:  91 Step:   520 /   793 Train loss: 0.03237223\r\n",
      "Epoch:  91 Step:   521 /   793 Train loss: 0.03495726\r\n",
      "Epoch:  91 Step:   522 /   793 Train loss: 0.02094110\r\n",
      "Epoch:  91 Step:   523 /   793 Train loss: 0.03266473\r\n",
      "Epoch:  91 Step:   524 /   793 Train loss: 0.04786612\r\n",
      "Epoch:  91 Step:   525 /   793 Train loss: 0.02711332\r\n",
      "Epoch:  91 Step:   526 /   793 Train loss: 0.02995975\r\n",
      "Epoch:  91 Step:   527 /   793 Train loss: 0.02188067\r\n",
      "Epoch:  91 Step:   528 /   793 Train loss: 0.02290100\r\n",
      "Epoch:  91 Step:   529 /   793 Train loss: 0.02895514\r\n",
      "Epoch:  91 Step:   530 /   793 Train loss: 0.03451461\r\n",
      "Epoch:  91 Step:   531 /   793 Train loss: 0.01873592\r\n",
      "Epoch:  91 Step:   532 /   793 Train loss: 0.01988626\r\n",
      "Epoch:  91 Step:   533 /   793 Train loss: 0.02177194\r\n",
      "Epoch:  91 Step:   534 /   793 Train loss: 0.04076165\r\n",
      "Epoch:  91 Step:   535 /   793 Train loss: 0.02202408\r\n",
      "Epoch:  91 Step:   536 /   793 Train loss: 0.03224988\r\n",
      "Epoch:  91 Step:   537 /   793 Train loss: 0.02970532\r\n",
      "Epoch:  91 Step:   538 /   793 Train loss: 0.01904267\r\n",
      "Epoch:  91 Step:   539 /   793 Train loss: 0.03496896\r\n",
      "Epoch:  91 Step:   540 /   793 Train loss: 0.01589525\r\n",
      "Epoch:  91 Step:   541 /   793 Train loss: 0.01774579\r\n",
      "Epoch:  91 Step:   542 /   793 Train loss: 0.03931564\r\n",
      "Epoch:  91 Step:   543 /   793 Train loss: 0.01761852\r\n",
      "Epoch:  91 Step:   544 /   793 Train loss: 0.02225766\r\n",
      "Epoch:  91 Step:   545 /   793 Train loss: 0.02552547\r\n",
      "Epoch:  91 Step:   546 /   793 Train loss: 0.02943804\r\n",
      "Epoch:  91 Step:   547 /   793 Train loss: 0.02245373\r\n",
      "Epoch:  91 Step:   548 /   793 Train loss: 0.03233613\r\n",
      "Epoch:  91 Step:   549 /   793 Train loss: 0.01856663\r\n",
      "Epoch:  91 Step:   550 /   793 Train loss: 0.02036465\r\n",
      "Epoch:  91 Step:   551 /   793 Train loss: 0.02858606\r\n",
      "Epoch:  91 Step:   552 /   793 Train loss: 0.02234754\r\n",
      "Epoch:  91 Step:   553 /   793 Train loss: 0.02011200\r\n",
      "Epoch:  91 Step:   554 /   793 Train loss: 0.02157699\r\n",
      "Epoch:  91 Step:   555 /   793 Train loss: 0.02588700\r\n",
      "Epoch:  91 Step:   556 /   793 Train loss: 0.02589097\r\n",
      "Epoch:  91 Step:   557 /   793 Train loss: 0.02685651\r\n",
      "Epoch:  91 Step:   558 /   793 Train loss: 0.01525838\r\n",
      "Epoch:  91 Step:   559 /   793 Train loss: 0.03221552\r\n",
      "Epoch:  91 Step:   560 /   793 Train loss: 0.01571061\r\n",
      "Epoch:  91 Step:   561 /   793 Train loss: 0.02406905\r\n",
      "Epoch:  91 Step:   562 /   793 Train loss: 0.02738348\r\n",
      "Epoch:  91 Step:   563 /   793 Train loss: 0.01442672\r\n",
      "Epoch:  91 Step:   564 /   793 Train loss: 0.03230703\r\n",
      "Epoch:  91 Step:   565 /   793 Train loss: 0.01760898\r\n",
      "Epoch:  91 Step:   566 /   793 Train loss: 0.02964964\r\n",
      "Epoch:  91 Step:   567 /   793 Train loss: 0.01094457\r\n",
      "Epoch:  91 Step:   568 /   793 Train loss: 0.02322802\r\n",
      "Epoch:  91 Step:   569 /   793 Train loss: 0.01741341\r\n",
      "Epoch:  91 Step:   570 /   793 Train loss: 0.02107436\r\n",
      "Epoch:  91 Step:   571 /   793 Train loss: 0.01495083\r\n",
      "Epoch:  91 Step:   572 /   793 Train loss: 0.01776308\r\n",
      "Epoch:  91 Step:   573 /   793 Train loss: 0.02346257\r\n",
      "Epoch:  91 Step:   574 /   793 Train loss: 0.02737651\r\n",
      "Epoch:  91 Step:   575 /   793 Train loss: 0.02693412\r\n",
      "Epoch:  91 Step:   576 /   793 Train loss: 0.02069382\r\n",
      "Epoch:  91 Step:   577 /   793 Train loss: 0.02142966\r\n",
      "Epoch:  91 Step:   578 /   793 Train loss: 0.01593609\r\n",
      "Epoch:  91 Step:   579 /   793 Train loss: 0.01980565\r\n",
      "Epoch:  91 Step:   580 /   793 Train loss: 0.02215520\r\n",
      "Epoch:  91 Step:   581 /   793 Train loss: 0.01135800\r\n",
      "Epoch:  91 Step:   582 /   793 Train loss: 0.02372095\r\n",
      "Epoch:  91 Step:   583 /   793 Train loss: 0.01447661\r\n",
      "Epoch:  91 Step:   584 /   793 Train loss: 0.02826631\r\n",
      "Epoch:  91 Step:   585 /   793 Train loss: 0.02120471\r\n",
      "Epoch:  91 Step:   586 /   793 Train loss: 0.01899609\r\n",
      "Epoch:  91 Step:   587 /   793 Train loss: 0.02171974\r\n",
      "Epoch:  91 Step:   588 /   793 Train loss: 0.01923403\r\n",
      "Epoch:  91 Step:   589 /   793 Train loss: 0.01867053\r\n",
      "Epoch:  91 Step:   590 /   793 Train loss: 0.02435682\r\n",
      "Epoch:  91 Step:   591 /   793 Train loss: 0.01982875\r\n",
      "Epoch:  91 Step:   592 /   793 Train loss: 0.03917263\r\n",
      "Epoch:  91 Step:   593 /   793 Train loss: 0.02051299\r\n",
      "Epoch:  91 Step:   594 /   793 Train loss: 0.03301188\r\n",
      "Epoch:  91 Step:   595 /   793 Train loss: 0.02199077\r\n",
      "Epoch:  91 Step:   596 /   793 Train loss: 0.03248959\r\n",
      "Epoch:  91 Step:   597 /   793 Train loss: 0.02578490\r\n",
      "Epoch:  91 Step:   598 /   793 Train loss: 0.03344551\r\n",
      "Epoch:  91 Step:   599 /   793 Train loss: 0.01454950\r\n",
      "Epoch:  91 Step:   600 /   793 Train loss: 0.02070181\r\n",
      "Epoch:  91 Step:   601 /   793 Train loss: 0.01342441\r\n",
      "Epoch:  91 Step:   602 /   793 Train loss: 0.02351345\r\n",
      "Epoch:  91 Step:   603 /   793 Train loss: 0.01693332\r\n",
      "Epoch:  91 Step:   604 /   793 Train loss: 0.02186397\r\n",
      "Epoch:  91 Step:   605 /   793 Train loss: 0.02876174\r\n",
      "Epoch:  91 Step:   606 /   793 Train loss: 0.01892655\r\n",
      "Epoch:  91 Step:   607 /   793 Train loss: 0.03068581\r\n",
      "Epoch:  91 Step:   608 /   793 Train loss: 0.03588456\r\n",
      "Epoch:  91 Step:   609 /   793 Train loss: 0.03233429\r\n",
      "Epoch:  91 Step:   610 /   793 Train loss: 0.03057835\r\n",
      "Epoch:  91 Step:   611 /   793 Train loss: 0.01955560\r\n",
      "Epoch:  91 Step:   612 /   793 Train loss: 0.01836074\r\n",
      "Epoch:  91 Step:   613 /   793 Train loss: 0.01920700\r\n",
      "Epoch:  91 Step:   614 /   793 Train loss: 0.03005048\r\n",
      "Epoch:  91 Step:   615 /   793 Train loss: 0.01102963\r\n",
      "Epoch:  91 Step:   616 /   793 Train loss: 0.02404601\r\n",
      "Epoch:  91 Step:   617 /   793 Train loss: 0.02148938\r\n",
      "Epoch:  91 Step:   618 /   793 Train loss: 0.01487230\r\n",
      "Epoch:  91 Step:   619 /   793 Train loss: 0.01791135\r\n",
      "Epoch:  91 Step:   620 /   793 Train loss: 0.02808657\r\n",
      "Epoch:  91 Step:   621 /   793 Train loss: 0.02845949\r\n",
      "Epoch:  91 Step:   622 /   793 Train loss: 0.02088001\r\n",
      "Epoch:  91 Step:   623 /   793 Train loss: 0.01841443\r\n",
      "Epoch:  91 Step:   624 /   793 Train loss: 0.02000946\r\n",
      "Epoch:  91 Step:   625 /   793 Train loss: 0.01831121\r\n",
      "Epoch:  91 Step:   626 /   793 Train loss: 0.02399819\r\n",
      "Epoch:  91 Step:   627 /   793 Train loss: 0.03462084\r\n",
      "Epoch:  91 Step:   628 /   793 Train loss: 0.03429839\r\n",
      "Epoch:  91 Step:   629 /   793 Train loss: 0.02030618\r\n",
      "Epoch:  91 Step:   630 /   793 Train loss: 0.02288138\r\n",
      "Epoch:  91 Step:   631 /   793 Train loss: 0.02959816\r\n",
      "Epoch:  91 Step:   632 /   793 Train loss: 0.02492664\r\n",
      "Epoch:  91 Step:   633 /   793 Train loss: 0.02487721\r\n",
      "Epoch:  91 Step:   634 /   793 Train loss: 0.02418527\r\n",
      "Epoch:  91 Step:   635 /   793 Train loss: 0.03046039\r\n",
      "Epoch:  91 Step:   636 /   793 Train loss: 0.02351708\r\n",
      "Epoch:  91 Step:   637 /   793 Train loss: 0.02301888\r\n",
      "Epoch:  91 Step:   638 /   793 Train loss: 0.01809735\r\n",
      "Epoch:  91 Step:   639 /   793 Train loss: 0.02562366\r\n",
      "Epoch:  91 Step:   640 /   793 Train loss: 0.02141042\r\n",
      "Epoch:  91 Step:   641 /   793 Train loss: 0.02870548\r\n",
      "Epoch:  91 Step:   642 /   793 Train loss: 0.03354366\r\n",
      "Epoch:  91 Step:   643 /   793 Train loss: 0.01689214\r\n",
      "Epoch:  91 Step:   644 /   793 Train loss: 0.02222185\r\n",
      "Epoch:  91 Step:   645 /   793 Train loss: 0.01555308\r\n",
      "Epoch:  91 Step:   646 /   793 Train loss: 0.02368889\r\n",
      "Epoch:  91 Step:   647 /   793 Train loss: 0.01562802\r\n",
      "Epoch:  91 Step:   648 /   793 Train loss: 0.02270931\r\n",
      "Epoch:  91 Step:   649 /   793 Train loss: 0.01944682\r\n",
      "Epoch:  91 Step:   650 /   793 Train loss: 0.03279843\r\n",
      "Epoch:  91 Step:   651 /   793 Train loss: 0.01255868\r\n",
      "Epoch:  91 Step:   652 /   793 Train loss: 0.03179861\r\n",
      "Epoch:  91 Step:   653 /   793 Train loss: 0.02107900\r\n",
      "Epoch:  91 Step:   654 /   793 Train loss: 0.02033243\r\n",
      "Epoch:  91 Step:   655 /   793 Train loss: 0.02472191\r\n",
      "Epoch:  91 Step:   656 /   793 Train loss: 0.01822992\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  91 Step:   657 /   793 Train loss: 0.01828346\r\n",
      "Epoch:  91 Step:   658 /   793 Train loss: 0.02097924\r\n",
      "Epoch:  91 Step:   659 /   793 Train loss: 0.02447337\r\n",
      "Epoch:  91 Step:   660 /   793 Train loss: 0.02117311\r\n",
      "Epoch:  91 Step:   661 /   793 Train loss: 0.03948870\r\n",
      "Epoch:  91 Step:   662 /   793 Train loss: 0.02607070\r\n",
      "Epoch:  91 Step:   663 /   793 Train loss: 0.02315544\r\n",
      "Epoch:  91 Step:   664 /   793 Train loss: 0.02735621\r\n",
      "Epoch:  91 Step:   665 /   793 Train loss: 0.01958472\r\n",
      "Epoch:  91 Step:   666 /   793 Train loss: 0.02176942\r\n",
      "Epoch:  91 Step:   667 /   793 Train loss: 0.02797428\r\n",
      "Epoch:  91 Step:   668 /   793 Train loss: 0.02108682\r\n",
      "Epoch:  91 Step:   669 /   793 Train loss: 0.03110088\r\n",
      "Epoch:  91 Step:   670 /   793 Train loss: 0.03123709\r\n",
      "Epoch:  91 Step:   671 /   793 Train loss: 0.02445383\r\n",
      "Epoch:  91 Step:   672 /   793 Train loss: 0.02020921\r\n",
      "Epoch:  91 Step:   673 /   793 Train loss: 0.03226139\r\n",
      "Epoch:  91 Step:   674 /   793 Train loss: 0.02622403\r\n",
      "Epoch:  91 Step:   675 /   793 Train loss: 0.01879444\r\n",
      "Epoch:  91 Step:   676 /   793 Train loss: 0.01980611\r\n",
      "Epoch:  91 Step:   677 /   793 Train loss: 0.02161302\r\n",
      "Epoch:  91 Step:   678 /   793 Train loss: 0.01681053\r\n",
      "Epoch:  91 Step:   679 /   793 Train loss: 0.03342672\r\n",
      "Epoch:  91 Step:   680 /   793 Train loss: 0.03122783\r\n",
      "Epoch:  91 Step:   681 /   793 Train loss: 0.02009091\r\n",
      "Epoch:  91 Step:   682 /   793 Train loss: 0.01382854\r\n",
      "Epoch:  91 Step:   683 /   793 Train loss: 0.03820348\r\n",
      "Epoch:  91 Step:   684 /   793 Train loss: 0.02046717\r\n",
      "Epoch:  91 Step:   685 /   793 Train loss: 0.01853052\r\n",
      "Epoch:  91 Step:   686 /   793 Train loss: 0.01466476\r\n",
      "Epoch:  91 Step:   687 /   793 Train loss: 0.03126645\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  91 Step:   688 /   793 Train loss: 0.01688294\r\n",
      "Epoch:  91 Step:   689 /   793 Train loss: 0.02742695\r\n",
      "Epoch:  91 Step:   690 /   793 Train loss: 0.01749892\r\n",
      "Epoch:  91 Step:   691 /   793 Train loss: 0.02674526\r\n",
      "Epoch:  91 Step:   692 /   793 Train loss: 0.02218566\r\n",
      "Epoch:  91 Step:   693 /   793 Train loss: 0.02720947\r\n",
      "Epoch:  91 Step:   694 /   793 Train loss: 0.02592447\r\n",
      "Epoch:  91 Step:   695 /   793 Train loss: 0.03613107\r\n",
      "Epoch:  91 Step:   696 /   793 Train loss: 0.02683513\r\n",
      "Epoch:  91 Step:   697 /   793 Train loss: 0.01867683\r\n",
      "Epoch:  91 Step:   698 /   793 Train loss: 0.01716596\r\n",
      "Epoch:  91 Step:   699 /   793 Train loss: 0.01693429\r\n",
      "Epoch:  91 Step:   700 /   793 Train loss: 0.02106578\r\n",
      "Epoch:  91 Step:   701 /   793 Train loss: 0.02403902\r\n",
      "Epoch:  91 Step:   702 /   793 Train loss: 0.01459250\r\n",
      "Epoch:  91 Step:   703 /   793 Train loss: 0.01773123\r\n",
      "Epoch:  91 Step:   704 /   793 Train loss: 0.03402647\r\n",
      "Epoch:  91 Step:   705 /   793 Train loss: 0.01078308\r\n",
      "Epoch:  91 Step:   706 /   793 Train loss: 0.02286165\r\n",
      "Epoch:  91 Step:   707 /   793 Train loss: 0.02570878\r\n",
      "Epoch:  91 Step:   708 /   793 Train loss: 0.01470260\r\n",
      "Epoch:  91 Step:   709 /   793 Train loss: 0.02579454\r\n",
      "Epoch:  91 Step:   710 /   793 Train loss: 0.02817643\r\n",
      "Epoch:  91 Step:   711 /   793 Train loss: 0.02386003\r\n",
      "Epoch:  91 Step:   712 /   793 Train loss: 0.01236338\r\n",
      "Epoch:  91 Step:   713 /   793 Train loss: 0.01991517\r\n",
      "Epoch:  91 Step:   714 /   793 Train loss: 0.01878045\r\n",
      "Epoch:  91 Step:   715 /   793 Train loss: 0.03430239\r\n",
      "Epoch:  91 Step:   716 /   793 Train loss: 0.02355171\r\n",
      "Epoch:  91 Step:   717 /   793 Train loss: 0.02180017\r\n",
      "Epoch:  91 Step:   718 /   793 Train loss: 0.02166339\r\n",
      "Epoch:  91 Step:   719 /   793 Train loss: 0.02714161\r\n",
      "Epoch:  91 Step:   720 /   793 Train loss: 0.00721970\r\n",
      "Epoch:  91 Step:   721 /   793 Train loss: 0.02042506\r\n",
      "Epoch:  91 Step:   722 /   793 Train loss: 0.02638322\r\n",
      "Epoch:  91 Step:   723 /   793 Train loss: 0.01709623\r\n",
      "Epoch:  91 Step:   724 /   793 Train loss: 0.02309147\r\n",
      "Epoch:  91 Step:   725 /   793 Train loss: 0.01334818\r\n",
      "Epoch:  91 Step:   726 /   793 Train loss: 0.02102109\r\n",
      "Epoch:  91 Step:   727 /   793 Train loss: 0.01711876\r\n",
      "Epoch:  91 Step:   728 /   793 Train loss: 0.02057104\r\n",
      "Epoch:  91 Step:   729 /   793 Train loss: 0.02244838\r\n",
      "Epoch:  91 Step:   730 /   793 Train loss: 0.02542652\r\n",
      "Epoch:  91 Step:   731 /   793 Train loss: 0.02594319\r\n",
      "Epoch:  91 Step:   732 /   793 Train loss: 0.02074116\r\n",
      "Epoch:  91 Step:   733 /   793 Train loss: 0.03041339\r\n",
      "Epoch:  91 Step:   734 /   793 Train loss: 0.01860991\r\n",
      "Epoch:  91 Step:   735 /   793 Train loss: 0.04334750\r\n",
      "Epoch:  91 Step:   736 /   793 Train loss: 0.01930061\r\n",
      "Epoch:  91 Step:   737 /   793 Train loss: 0.02857320\r\n",
      "Epoch:  91 Step:   738 /   793 Train loss: 0.04448714\r\n",
      "Epoch:  91 Step:   739 /   793 Train loss: 0.01958891\r\n",
      "Epoch:  91 Step:   740 /   793 Train loss: 0.02050126\r\n",
      "Epoch:  91 Step:   741 /   793 Train loss: 0.02083899\r\n",
      "Epoch:  91 Step:   742 /   793 Train loss: 0.02004081\r\n",
      "Epoch:  91 Step:   743 /   793 Train loss: 0.01826912\r\n",
      "Epoch:  91 Step:   744 /   793 Train loss: 0.01138304\r\n",
      "Epoch:  91 Step:   745 /   793 Train loss: 0.01746518\r\n",
      "Epoch:  91 Step:   746 /   793 Train loss: 0.03054479\r\n",
      "Epoch:  91 Step:   747 /   793 Train loss: 0.01668492\r\n",
      "Epoch:  91 Step:   748 /   793 Train loss: 0.01458412\r\n",
      "Epoch:  91 Step:   749 /   793 Train loss: 0.01818767\r\n",
      "Epoch:  91 Step:   750 /   793 Train loss: 0.02324129\r\n",
      "Epoch:  91 Step:   751 /   793 Train loss: 0.02167069\r\n",
      "Epoch:  91 Step:   752 /   793 Train loss: 0.02543261\r\n",
      "Epoch:  91 Step:   753 /   793 Train loss: 0.03080204\r\n",
      "Epoch:  91 Step:   754 /   793 Train loss: 0.03440212\r\n",
      "Epoch:  91 Step:   755 /   793 Train loss: 0.01241470\r\n",
      "Epoch:  91 Step:   756 /   793 Train loss: 0.02097323\r\n",
      "Epoch:  91 Step:   757 /   793 Train loss: 0.02468871\r\n",
      "Epoch:  91 Step:   758 /   793 Train loss: 0.01700887\r\n",
      "Epoch:  91 Step:   759 /   793 Train loss: 0.02074069\r\n",
      "Epoch:  91 Step:   760 /   793 Train loss: 0.02855164\r\n",
      "Epoch:  91 Step:   761 /   793 Train loss: 0.01879526\r\n",
      "Epoch:  91 Step:   762 /   793 Train loss: 0.02313327\r\n",
      "Epoch:  91 Step:   763 /   793 Train loss: 0.02802821\r\n",
      "Epoch:  91 Step:   764 /   793 Train loss: 0.00988899\r\n",
      "Epoch:  91 Step:   765 /   793 Train loss: 0.02309196\r\n",
      "Epoch:  91 Step:   766 /   793 Train loss: 0.02265580\r\n",
      "Epoch:  91 Step:   767 /   793 Train loss: 0.01669746\r\n",
      "Epoch:  91 Step:   768 /   793 Train loss: 0.02920329\r\n",
      "Epoch:  91 Step:   769 /   793 Train loss: 0.03561169\r\n",
      "Epoch:  91 Step:   770 /   793 Train loss: 0.02279285\r\n",
      "Epoch:  91 Step:   771 /   793 Train loss: 0.03603639\r\n",
      "Epoch:  91 Step:   772 /   793 Train loss: 0.02193503\r\n",
      "Epoch:  91 Step:   773 /   793 Train loss: 0.01147480\r\n",
      "Epoch:  91 Step:   774 /   793 Train loss: 0.03031525\r\n",
      "Epoch:  91 Step:   775 /   793 Train loss: 0.02210244\r\n",
      "Epoch:  91 Step:   776 /   793 Train loss: 0.01979449\r\n",
      "Epoch:  91 Step:   777 /   793 Train loss: 0.03495041\r\n",
      "Epoch:  91 Step:   778 /   793 Train loss: 0.02292034\r\n",
      "Epoch:  91 Step:   779 /   793 Train loss: 0.02155155\r\n",
      "Epoch:  91 Step:   780 /   793 Train loss: 0.03300883\r\n",
      "Epoch:  91 Step:   781 /   793 Train loss: 0.04188344\r\n",
      "Epoch:  91 Step:   782 /   793 Train loss: 0.02754383\r\n",
      "Epoch:  91 Step:   783 /   793 Train loss: 0.02759507\r\n",
      "Epoch:  91 Step:   784 /   793 Train loss: 0.01407054\r\n",
      "Epoch:  91 Step:   785 /   793 Train loss: 0.01898149\r\n",
      "Epoch:  91 Step:   786 /   793 Train loss: 0.02011209\r\n",
      "Epoch:  91 Step:   787 /   793 Train loss: 0.02549314\r\n",
      "Epoch:  91 Step:   788 /   793 Train loss: 0.02190384\r\n",
      "Epoch:  91 Step:   789 /   793 Train loss: 0.02036827\r\n",
      "Epoch:  91 Step:   790 /   793 Train loss: 0.01891568\r\n",
      "Epoch:  91 Step:   791 /   793 Train loss: 0.02273859\r\n",
      "Epoch:  91 Step:   792 /   793 Train loss: 0.01950299\r\n",
      "Epoch:  91 Validation loss: 0.01419384\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  92 Step:     0 /   793 Train loss: 0.02101529\r\n",
      "Epoch:  92 Step:     1 /   793 Train loss: 0.02298910\r\n",
      "Epoch:  92 Step:     2 /   793 Train loss: 0.01292603\r\n",
      "Epoch:  92 Step:     3 /   793 Train loss: 0.02220532\r\n",
      "Epoch:  92 Step:     4 /   793 Train loss: 0.02607996\r\n",
      "Epoch:  92 Step:     5 /   793 Train loss: 0.02129695\r\n",
      "Epoch:  92 Step:     6 /   793 Train loss: 0.01824746\r\n",
      "Epoch:  92 Step:     7 /   793 Train loss: 0.02584357\r\n",
      "Epoch:  92 Step:     8 /   793 Train loss: 0.02413000\r\n",
      "Epoch:  92 Step:     9 /   793 Train loss: 0.02807377\r\n",
      "Epoch:  92 Step:    10 /   793 Train loss: 0.02465863\r\n",
      "Epoch:  92 Step:    11 /   793 Train loss: 0.01453577\r\n",
      "Epoch:  92 Step:    12 /   793 Train loss: 0.02131861\r\n",
      "Epoch:  92 Step:    13 /   793 Train loss: 0.02963158\r\n",
      "Epoch:  92 Step:    14 /   793 Train loss: 0.02483840\r\n",
      "Epoch:  92 Step:    15 /   793 Train loss: 0.02954626\r\n",
      "Epoch:  92 Step:    16 /   793 Train loss: 0.01998451\r\n",
      "Epoch:  92 Step:    17 /   793 Train loss: 0.03179728\r\n",
      "Epoch:  92 Step:    18 /   793 Train loss: 0.01072929\r\n",
      "Epoch:  92 Step:    19 /   793 Train loss: 0.02299291\r\n",
      "Epoch:  92 Step:    20 /   793 Train loss: 0.02127662\r\n",
      "Epoch:  92 Step:    21 /   793 Train loss: 0.03236792\r\n",
      "Epoch:  92 Step:    22 /   793 Train loss: 0.02434319\r\n",
      "Epoch:  92 Step:    23 /   793 Train loss: 0.01741308\r\n",
      "Epoch:  92 Step:    24 /   793 Train loss: 0.01986253\r\n",
      "Epoch:  92 Step:    25 /   793 Train loss: 0.03111981\r\n",
      "Epoch:  92 Step:    26 /   793 Train loss: 0.01567012\r\n",
      "Epoch:  92 Step:    27 /   793 Train loss: 0.02297106\r\n",
      "Epoch:  92 Step:    28 /   793 Train loss: 0.01739344\r\n",
      "Epoch:  92 Step:    29 /   793 Train loss: 0.02701053\r\n",
      "Epoch:  92 Step:    30 /   793 Train loss: 0.02644102\r\n",
      "Epoch:  92 Step:    31 /   793 Train loss: 0.02339471\r\n",
      "Epoch:  92 Step:    32 /   793 Train loss: 0.02592230\r\n",
      "Epoch:  92 Step:    33 /   793 Train loss: 0.01622332\r\n",
      "Epoch:  92 Step:    34 /   793 Train loss: 0.02054686\r\n",
      "Epoch:  92 Step:    35 /   793 Train loss: 0.01410425\r\n",
      "Epoch:  92 Step:    36 /   793 Train loss: 0.02512061\r\n",
      "Epoch:  92 Step:    37 /   793 Train loss: 0.01126607\r\n",
      "Epoch:  92 Step:    38 /   793 Train loss: 0.01667752\r\n",
      "Epoch:  92 Step:    39 /   793 Train loss: 0.02370090\r\n",
      "Epoch:  92 Step:    40 /   793 Train loss: 0.01793205\r\n",
      "Epoch:  92 Step:    41 /   793 Train loss: 0.02219254\r\n",
      "Epoch:  92 Step:    42 /   793 Train loss: 0.01726266\r\n",
      "Epoch:  92 Step:    43 /   793 Train loss: 0.03494007\r\n",
      "Epoch:  92 Step:    44 /   793 Train loss: 0.02344080\r\n",
      "Epoch:  92 Step:    45 /   793 Train loss: 0.02682594\r\n",
      "Epoch:  92 Step:    46 /   793 Train loss: 0.02010181\r\n",
      "Epoch:  92 Step:    47 /   793 Train loss: 0.02569555\r\n",
      "Epoch:  92 Step:    48 /   793 Train loss: 0.02479842\r\n",
      "Epoch:  92 Step:    49 /   793 Train loss: 0.02481445\r\n",
      "Epoch:  92 Step:    50 /   793 Train loss: 0.01505989\r\n",
      "Epoch:  92 Step:    51 /   793 Train loss: 0.03769780\r\n",
      "Epoch:  92 Step:    52 /   793 Train loss: 0.02943684\r\n",
      "Epoch:  92 Step:    53 /   793 Train loss: 0.02656269\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  92 Step:    54 /   793 Train loss: 0.02648425\r\n",
      "Epoch:  92 Step:    55 /   793 Train loss: 0.01754498\r\n",
      "Epoch:  92 Step:    56 /   793 Train loss: 0.00843292\r\n",
      "Epoch:  92 Step:    57 /   793 Train loss: 0.02427251\r\n",
      "Epoch:  92 Step:    58 /   793 Train loss: 0.02568983\r\n",
      "Epoch:  92 Step:    59 /   793 Train loss: 0.02152227\r\n",
      "Epoch:  92 Step:    60 /   793 Train loss: 0.02181420\r\n",
      "Epoch:  92 Step:    61 /   793 Train loss: 0.02166639\r\n",
      "Epoch:  92 Step:    62 /   793 Train loss: 0.02194780\r\n",
      "Epoch:  92 Step:    63 /   793 Train loss: 0.04157167\r\n",
      "Epoch:  92 Step:    64 /   793 Train loss: 0.01421009\r\n",
      "Epoch:  92 Step:    65 /   793 Train loss: 0.02964791\r\n",
      "Epoch:  92 Step:    66 /   793 Train loss: 0.04278211\r\n",
      "Epoch:  92 Step:    67 /   793 Train loss: 0.02711711\r\n",
      "Epoch:  92 Step:    68 /   793 Train loss: 0.02260227\r\n",
      "Epoch:  92 Step:    69 /   793 Train loss: 0.02204132\r\n",
      "Epoch:  92 Step:    70 /   793 Train loss: 0.04315937\r\n",
      "Epoch:  92 Step:    71 /   793 Train loss: 0.01565601\r\n",
      "Epoch:  92 Step:    72 /   793 Train loss: 0.01486289\r\n",
      "Epoch:  92 Step:    73 /   793 Train loss: 0.01516817\r\n",
      "Epoch:  92 Step:    74 /   793 Train loss: 0.01768928\r\n",
      "Epoch:  92 Step:    75 /   793 Train loss: 0.02933569\r\n",
      "Epoch:  92 Step:    76 /   793 Train loss: 0.02283576\r\n",
      "Epoch:  92 Step:    77 /   793 Train loss: 0.02774127\r\n",
      "Epoch:  92 Step:    78 /   793 Train loss: 0.02998252\r\n",
      "Epoch:  92 Step:    79 /   793 Train loss: 0.02013859\r\n",
      "Epoch:  92 Step:    80 /   793 Train loss: 0.03322217\r\n",
      "Epoch:  92 Step:    81 /   793 Train loss: 0.03390882\r\n",
      "Epoch:  92 Step:    82 /   793 Train loss: 0.03141856\r\n",
      "Epoch:  92 Step:    83 /   793 Train loss: 0.02120587\r\n",
      "Epoch:  92 Step:    84 /   793 Train loss: 0.02032247\r\n",
      "Epoch:  92 Step:    85 /   793 Train loss: 0.02015072\r\n",
      "Epoch:  92 Step:    86 /   793 Train loss: 0.03769219\r\n",
      "Epoch:  92 Step:    87 /   793 Train loss: 0.02171011\r\n",
      "Epoch:  92 Step:    88 /   793 Train loss: 0.01819952\r\n",
      "Epoch:  92 Step:    89 /   793 Train loss: 0.02767953\r\n",
      "Epoch:  92 Step:    90 /   793 Train loss: 0.02222065\r\n",
      "Epoch:  92 Step:    91 /   793 Train loss: 0.01965543\r\n",
      "Epoch:  92 Step:    92 /   793 Train loss: 0.02189702\r\n",
      "Epoch:  92 Step:    93 /   793 Train loss: 0.02976359\r\n",
      "Epoch:  92 Step:    94 /   793 Train loss: 0.02392183\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  92 Step:    95 /   793 Train loss: 0.02562033\r\n",
      "Epoch:  92 Step:    96 /   793 Train loss: 0.03581296\r\n",
      "Epoch:  92 Step:    97 /   793 Train loss: 0.03341518\r\n",
      "Epoch:  92 Step:    98 /   793 Train loss: 0.02618946\r\n",
      "Epoch:  92 Step:    99 /   793 Train loss: 0.02075784\r\n",
      "Epoch:  92 Step:   100 /   793 Train loss: 0.01847756\r\n",
      "Epoch:  92 Step:   101 /   793 Train loss: 0.02226732\r\n",
      "Epoch:  92 Step:   102 /   793 Train loss: 0.02781354\r\n",
      "Epoch:  92 Step:   103 /   793 Train loss: 0.01037330\r\n",
      "Epoch:  92 Step:   104 /   793 Train loss: 0.02495910\r\n",
      "Epoch:  92 Step:   105 /   793 Train loss: 0.03008575\r\n",
      "Epoch:  92 Step:   106 /   793 Train loss: 0.01650800\r\n",
      "Epoch:  92 Step:   107 /   793 Train loss: 0.02325056\r\n",
      "Epoch:  92 Step:   108 /   793 Train loss: 0.02595644\r\n",
      "Epoch:  92 Step:   109 /   793 Train loss: 0.03706373\r\n",
      "Epoch:  92 Step:   110 /   793 Train loss: 0.02689026\r\n",
      "Epoch:  92 Step:   111 /   793 Train loss: 0.01996913\r\n",
      "Epoch:  92 Step:   112 /   793 Train loss: 0.02252994\r\n",
      "Epoch:  92 Step:   113 /   793 Train loss: 0.02136054\r\n",
      "Epoch:  92 Step:   114 /   793 Train loss: 0.01734634\r\n",
      "Epoch:  92 Step:   115 /   793 Train loss: 0.02840638\r\n",
      "Epoch:  92 Step:   116 /   793 Train loss: 0.01667273\r\n",
      "Epoch:  92 Step:   117 /   793 Train loss: 0.02500116\r\n",
      "Epoch:  92 Step:   118 /   793 Train loss: 0.01522287\r\n",
      "Epoch:  92 Step:   119 /   793 Train loss: 0.02734470\r\n",
      "Epoch:  92 Step:   120 /   793 Train loss: 0.02610307\r\n",
      "Epoch:  92 Step:   121 /   793 Train loss: 0.02734707\r\n",
      "Epoch:  92 Step:   122 /   793 Train loss: 0.03244223\r\n",
      "Epoch:  92 Step:   123 /   793 Train loss: 0.02529492\r\n",
      "Epoch:  92 Step:   124 /   793 Train loss: 0.02440287\r\n",
      "Epoch:  92 Step:   125 /   793 Train loss: 0.02073556\r\n",
      "Epoch:  92 Step:   126 /   793 Train loss: 0.03487840\r\n",
      "Epoch:  92 Step:   127 /   793 Train loss: 0.02990731\r\n",
      "Epoch:  92 Step:   128 /   793 Train loss: 0.01951670\r\n",
      "Epoch:  92 Step:   129 /   793 Train loss: 0.01798465\r\n",
      "Epoch:  92 Step:   130 /   793 Train loss: 0.02139704\r\n",
      "Epoch:  92 Step:   131 /   793 Train loss: 0.02718826\r\n",
      "Epoch:  92 Step:   132 /   793 Train loss: 0.02517007\r\n",
      "Epoch:  92 Step:   133 /   793 Train loss: 0.02622180\r\n",
      "Epoch:  92 Step:   134 /   793 Train loss: 0.01750594\r\n",
      "Epoch:  92 Step:   135 /   793 Train loss: 0.03823745\r\n",
      "Epoch:  92 Step:   136 /   793 Train loss: 0.02440485\r\n",
      "Epoch:  92 Step:   137 /   793 Train loss: 0.02034238\r\n",
      "Epoch:  92 Step:   138 /   793 Train loss: 0.01470064\r\n",
      "Epoch:  92 Step:   139 /   793 Train loss: 0.03729130\r\n",
      "Epoch:  92 Step:   140 /   793 Train loss: 0.02916430\r\n",
      "Epoch:  92 Step:   141 /   793 Train loss: 0.02906578\r\n",
      "Epoch:  92 Step:   142 /   793 Train loss: 0.02027268\r\n",
      "Epoch:  92 Step:   143 /   793 Train loss: 0.02802422\r\n",
      "Epoch:  92 Step:   144 /   793 Train loss: 0.02396258\r\n",
      "Epoch:  92 Step:   145 /   793 Train loss: 0.02644546\r\n",
      "Epoch:  92 Step:   146 /   793 Train loss: 0.02106890\r\n",
      "Epoch:  92 Step:   147 /   793 Train loss: 0.02033168\r\n",
      "Epoch:  92 Step:   148 /   793 Train loss: 0.02585234\r\n",
      "Epoch:  92 Step:   149 /   793 Train loss: 0.03538771\r\n",
      "Epoch:  92 Step:   150 /   793 Train loss: 0.02903575\r\n",
      "Epoch:  92 Step:   151 /   793 Train loss: 0.02998142\r\n",
      "Epoch:  92 Step:   152 /   793 Train loss: 0.02469063\r\n",
      "Epoch:  92 Step:   153 /   793 Train loss: 0.02681457\r\n",
      "Epoch:  92 Step:   154 /   793 Train loss: 0.02420924\r\n",
      "Epoch:  92 Step:   155 /   793 Train loss: 0.03074873\r\n",
      "Epoch:  92 Step:   156 /   793 Train loss: 0.02886167\r\n",
      "Epoch:  92 Step:   157 /   793 Train loss: 0.01040441\r\n",
      "Epoch:  92 Step:   158 /   793 Train loss: 0.02958854\r\n",
      "Epoch:  92 Step:   159 /   793 Train loss: 0.02763738\r\n",
      "Epoch:  92 Step:   160 /   793 Train loss: 0.02263715\r\n",
      "Epoch:  92 Step:   161 /   793 Train loss: 0.02411163\r\n",
      "Epoch:  92 Step:   162 /   793 Train loss: 0.02575072\r\n",
      "Epoch:  92 Step:   163 /   793 Train loss: 0.02145222\r\n",
      "Epoch:  92 Step:   164 /   793 Train loss: 0.02332871\r\n",
      "Epoch:  92 Step:   165 /   793 Train loss: 0.01661427\r\n",
      "Epoch:  92 Step:   166 /   793 Train loss: 0.01396277\r\n",
      "Epoch:  92 Step:   167 /   793 Train loss: 0.01882984\r\n",
      "Epoch:  92 Step:   168 /   793 Train loss: 0.03205337\r\n",
      "Epoch:  92 Step:   169 /   793 Train loss: 0.03088078\r\n",
      "Epoch:  92 Step:   170 /   793 Train loss: 0.01907271\r\n",
      "Epoch:  92 Step:   171 /   793 Train loss: 0.02644636\r\n",
      "Epoch:  92 Step:   172 /   793 Train loss: 0.02553464\r\n",
      "Epoch:  92 Step:   173 /   793 Train loss: 0.03338349\r\n",
      "Epoch:  92 Step:   174 /   793 Train loss: 0.02290304\r\n",
      "Epoch:  92 Step:   175 /   793 Train loss: 0.01736804\r\n",
      "Epoch:  92 Step:   176 /   793 Train loss: 0.03237119\r\n",
      "Epoch:  92 Step:   177 /   793 Train loss: 0.03470701\r\n",
      "Epoch:  92 Step:   178 /   793 Train loss: 0.01331672\r\n",
      "Epoch:  92 Step:   179 /   793 Train loss: 0.01994783\r\n",
      "Epoch:  92 Step:   180 /   793 Train loss: 0.03671220\r\n",
      "Epoch:  92 Step:   181 /   793 Train loss: 0.03237730\r\n",
      "Epoch:  92 Step:   182 /   793 Train loss: 0.02183942\r\n",
      "Epoch:  92 Step:   183 /   793 Train loss: 0.01398215\r\n",
      "Epoch:  92 Step:   184 /   793 Train loss: 0.02038278\r\n",
      "Epoch:  92 Step:   185 /   793 Train loss: 0.02312825\r\n",
      "Epoch:  92 Step:   186 /   793 Train loss: 0.02220323\r\n",
      "Epoch:  92 Step:   187 /   793 Train loss: 0.02796480\r\n",
      "Epoch:  92 Step:   188 /   793 Train loss: 0.03146071\r\n",
      "Epoch:  92 Step:   189 /   793 Train loss: 0.01999699\r\n",
      "Epoch:  92 Step:   190 /   793 Train loss: 0.03148115\r\n",
      "Epoch:  92 Step:   191 /   793 Train loss: 0.01536985\r\n",
      "Epoch:  92 Step:   192 /   793 Train loss: 0.01855226\r\n",
      "Epoch:  92 Step:   193 /   793 Train loss: 0.02641110\r\n",
      "Epoch:  92 Step:   194 /   793 Train loss: 0.03911333\r\n",
      "Epoch:  92 Step:   195 /   793 Train loss: 0.01911105\r\n",
      "Epoch:  92 Step:   196 /   793 Train loss: 0.01599341\r\n",
      "Epoch:  92 Step:   197 /   793 Train loss: 0.01456705\r\n",
      "Epoch:  92 Step:   198 /   793 Train loss: 0.03530443\r\n",
      "Epoch:  92 Step:   199 /   793 Train loss: 0.03422235\r\n",
      "Epoch:  92 Step:   200 /   793 Train loss: 0.01757905\r\n",
      "Epoch:  92 Step:   201 /   793 Train loss: 0.01462844\r\n",
      "Epoch:  92 Step:   202 /   793 Train loss: 0.01241853\r\n",
      "Epoch:  92 Step:   203 /   793 Train loss: 0.02521050\r\n",
      "Epoch:  92 Step:   204 /   793 Train loss: 0.01578256\r\n",
      "Epoch:  92 Step:   205 /   793 Train loss: 0.01197293\r\n",
      "Epoch:  92 Step:   206 /   793 Train loss: 0.02419267\r\n",
      "Epoch:  92 Step:   207 /   793 Train loss: 0.02280303\r\n",
      "Epoch:  92 Step:   208 /   793 Train loss: 0.02873317\r\n",
      "Epoch:  92 Step:   209 /   793 Train loss: 0.02760715\r\n",
      "Epoch:  92 Step:   210 /   793 Train loss: 0.03822631\r\n",
      "Epoch:  92 Step:   211 /   793 Train loss: 0.02179119\r\n",
      "Epoch:  92 Step:   212 /   793 Train loss: 0.01496096\r\n",
      "Epoch:  92 Step:   213 /   793 Train loss: 0.02018975\r\n",
      "Epoch:  92 Step:   214 /   793 Train loss: 0.02852031\r\n",
      "Epoch:  92 Step:   215 /   793 Train loss: 0.01217416\r\n",
      "Epoch:  92 Step:   216 /   793 Train loss: 0.01864780\r\n",
      "Epoch:  92 Step:   217 /   793 Train loss: 0.02293420\r\n",
      "Epoch:  92 Step:   218 /   793 Train loss: 0.03499718\r\n",
      "Epoch:  92 Step:   219 /   793 Train loss: 0.02506183\r\n",
      "Epoch:  92 Step:   220 /   793 Train loss: 0.02112523\r\n",
      "Epoch:  92 Step:   221 /   793 Train loss: 0.01885030\r\n",
      "Epoch:  92 Step:   222 /   793 Train loss: 0.02927598\r\n",
      "Epoch:  92 Step:   223 /   793 Train loss: 0.01418490\r\n",
      "Epoch:  92 Step:   224 /   793 Train loss: 0.01486716\r\n",
      "Epoch:  92 Step:   225 /   793 Train loss: 0.02392549\r\n",
      "Epoch:  92 Step:   226 /   793 Train loss: 0.01905995\r\n",
      "Epoch:  92 Step:   227 /   793 Train loss: 0.01554655\r\n",
      "Epoch:  92 Step:   228 /   793 Train loss: 0.02163888\r\n",
      "Epoch:  92 Step:   229 /   793 Train loss: 0.03883860\r\n",
      "Epoch:  92 Step:   230 /   793 Train loss: 0.01943146\r\n",
      "Epoch:  92 Step:   231 /   793 Train loss: 0.02272020\r\n",
      "Epoch:  92 Step:   232 /   793 Train loss: 0.02300233\r\n",
      "Epoch:  92 Step:   233 /   793 Train loss: 0.02529602\r\n",
      "Epoch:  92 Step:   234 /   793 Train loss: 0.02563292\r\n",
      "Epoch:  92 Step:   235 /   793 Train loss: 0.01618097\r\n",
      "Epoch:  92 Step:   236 /   793 Train loss: 0.03278319\r\n",
      "Epoch:  92 Step:   237 /   793 Train loss: 0.02537990\r\n",
      "Epoch:  92 Step:   238 /   793 Train loss: 0.01592607\r\n",
      "Epoch:  92 Step:   239 /   793 Train loss: 0.01627878\r\n",
      "Epoch:  92 Step:   240 /   793 Train loss: 0.02676203\r\n",
      "Epoch:  92 Step:   241 /   793 Train loss: 0.02567530\r\n",
      "Epoch:  92 Step:   242 /   793 Train loss: 0.02200815\r\n",
      "Epoch:  92 Step:   243 /   793 Train loss: 0.03525189\r\n",
      "Epoch:  92 Step:   244 /   793 Train loss: 0.02105231\r\n",
      "Epoch:  92 Step:   245 /   793 Train loss: 0.02747869\r\n",
      "Epoch:  92 Step:   246 /   793 Train loss: 0.01885493\r\n",
      "Epoch:  92 Step:   247 /   793 Train loss: 0.01910362\r\n",
      "Epoch:  92 Step:   248 /   793 Train loss: 0.02472912\r\n",
      "Epoch:  92 Step:   249 /   793 Train loss: 0.02329621\r\n",
      "Epoch:  92 Step:   250 /   793 Train loss: 0.03652040\r\n",
      "Epoch:  92 Step:   251 /   793 Train loss: 0.01418763\r\n",
      "Epoch:  92 Step:   252 /   793 Train loss: 0.01565213\r\n",
      "Epoch:  92 Step:   253 /   793 Train loss: 0.03005729\r\n",
      "Epoch:  92 Step:   254 /   793 Train loss: 0.02120597\r\n",
      "Epoch:  92 Step:   255 /   793 Train loss: 0.01459596\r\n",
      "Epoch:  92 Step:   256 /   793 Train loss: 0.01633279\r\n",
      "Epoch:  92 Step:   257 /   793 Train loss: 0.01688506\r\n",
      "Epoch:  92 Step:   258 /   793 Train loss: 0.03205004\r\n",
      "Epoch:  92 Step:   259 /   793 Train loss: 0.01625039\r\n",
      "Epoch:  92 Step:   260 /   793 Train loss: 0.02471983\r\n",
      "Epoch:  92 Step:   261 /   793 Train loss: 0.01150165\r\n",
      "Epoch:  92 Step:   262 /   793 Train loss: 0.02384290\r\n",
      "Epoch:  92 Step:   263 /   793 Train loss: 0.03206790\r\n",
      "Epoch:  92 Step:   264 /   793 Train loss: 0.02157605\r\n",
      "Epoch:  92 Step:   265 /   793 Train loss: 0.02722679\r\n",
      "Epoch:  92 Step:   266 /   793 Train loss: 0.03348722\r\n",
      "Epoch:  92 Step:   267 /   793 Train loss: 0.02499020\r\n",
      "Epoch:  92 Step:   268 /   793 Train loss: 0.02442230\r\n",
      "Epoch:  92 Step:   269 /   793 Train loss: 0.02038252\r\n",
      "Epoch:  92 Step:   270 /   793 Train loss: 0.02620228\r\n",
      "Epoch:  92 Step:   271 /   793 Train loss: 0.01583239\r\n",
      "Epoch:  92 Step:   272 /   793 Train loss: 0.02440469\r\n",
      "Epoch:  92 Step:   273 /   793 Train loss: 0.02123336\r\n",
      "Epoch:  92 Step:   274 /   793 Train loss: 0.01312225\r\n",
      "Epoch:  92 Step:   275 /   793 Train loss: 0.02462465\r\n",
      "Epoch:  92 Step:   276 /   793 Train loss: 0.02775582\r\n",
      "Epoch:  92 Step:   277 /   793 Train loss: 0.01840467\r\n",
      "Epoch:  92 Step:   278 /   793 Train loss: 0.01705097\r\n",
      "Epoch:  92 Step:   279 /   793 Train loss: 0.02658445\r\n",
      "Epoch:  92 Step:   280 /   793 Train loss: 0.02608830\r\n",
      "Epoch:  92 Step:   281 /   793 Train loss: 0.02696543\r\n",
      "Epoch:  92 Step:   282 /   793 Train loss: 0.01401186\r\n",
      "Epoch:  92 Step:   283 /   793 Train loss: 0.02869160\r\n",
      "Epoch:  92 Step:   284 /   793 Train loss: 0.01761923\r\n",
      "Epoch:  92 Step:   285 /   793 Train loss: 0.01777327\r\n",
      "Epoch:  92 Step:   286 /   793 Train loss: 0.02853228\r\n",
      "Epoch:  92 Step:   287 /   793 Train loss: 0.03595814\r\n",
      "Epoch:  92 Step:   288 /   793 Train loss: 0.02776844\r\n",
      "Epoch:  92 Step:   289 /   793 Train loss: 0.01966986\r\n",
      "Epoch:  92 Step:   290 /   793 Train loss: 0.03466328\r\n",
      "Epoch:  92 Step:   291 /   793 Train loss: 0.02885847\r\n",
      "Epoch:  92 Step:   292 /   793 Train loss: 0.02356993\r\n",
      "Epoch:  92 Step:   293 /   793 Train loss: 0.03065906\r\n",
      "Epoch:  92 Step:   294 /   793 Train loss: 0.02670558\r\n",
      "Epoch:  92 Step:   295 /   793 Train loss: 0.01815725\r\n",
      "Epoch:  92 Step:   296 /   793 Train loss: 0.02147204\r\n",
      "Epoch:  92 Step:   297 /   793 Train loss: 0.01796963\r\n",
      "Epoch:  92 Step:   298 /   793 Train loss: 0.02882344\r\n",
      "Epoch:  92 Step:   299 /   793 Train loss: 0.01800835\r\n",
      "Epoch:  92 Step:   300 /   793 Train loss: 0.03683097\r\n",
      "Epoch:  92 Step:   301 /   793 Train loss: 0.01452431\r\n",
      "Epoch:  92 Step:   302 /   793 Train loss: 0.03527359\r\n",
      "Epoch:  92 Step:   303 /   793 Train loss: 0.01855307\r\n",
      "Epoch:  92 Step:   304 /   793 Train loss: 0.01411315\r\n",
      "Epoch:  92 Step:   305 /   793 Train loss: 0.03605120\r\n",
      "Epoch:  92 Step:   306 /   793 Train loss: 0.03489964\r\n",
      "Epoch:  92 Step:   307 /   793 Train loss: 0.02491694\r\n",
      "Epoch:  92 Step:   308 /   793 Train loss: 0.02191049\r\n",
      "Epoch:  92 Step:   309 /   793 Train loss: 0.02467331\r\n",
      "Epoch:  92 Step:   310 /   793 Train loss: 0.03535316\r\n",
      "Epoch:  92 Step:   311 /   793 Train loss: 0.02967099\r\n",
      "Epoch:  92 Step:   312 /   793 Train loss: 0.03432475\r\n",
      "Epoch:  92 Step:   313 /   793 Train loss: 0.02882080\r\n",
      "Epoch:  92 Step:   314 /   793 Train loss: 0.02228910\r\n",
      "Epoch:  92 Step:   315 /   793 Train loss: 0.01527746\r\n",
      "Epoch:  92 Step:   316 /   793 Train loss: 0.02297179\r\n",
      "Epoch:  92 Step:   317 /   793 Train loss: 0.03036439\r\n",
      "Epoch:  92 Step:   318 /   793 Train loss: 0.02424181\r\n",
      "Epoch:  92 Step:   319 /   793 Train loss: 0.02717727\r\n",
      "Epoch:  92 Step:   320 /   793 Train loss: 0.03112496\r\n",
      "Epoch:  92 Step:   321 /   793 Train loss: 0.01156573\r\n",
      "Epoch:  92 Step:   322 /   793 Train loss: 0.01950345\r\n",
      "Epoch:  92 Step:   323 /   793 Train loss: 0.02917169\r\n",
      "Epoch:  92 Step:   324 /   793 Train loss: 0.03615801\r\n",
      "Epoch:  92 Step:   325 /   793 Train loss: 0.01183659\r\n",
      "Epoch:  92 Step:   326 /   793 Train loss: 0.01412368\r\n",
      "Epoch:  92 Step:   327 /   793 Train loss: 0.01831941\r\n",
      "Epoch:  92 Step:   328 /   793 Train loss: 0.02252021\r\n",
      "Epoch:  92 Step:   329 /   793 Train loss: 0.02395662\r\n",
      "Epoch:  92 Step:   330 /   793 Train loss: 0.03025233\r\n",
      "Epoch:  92 Step:   331 /   793 Train loss: 0.02649014\r\n",
      "Epoch:  92 Step:   332 /   793 Train loss: 0.03885982\r\n",
      "Epoch:  92 Step:   333 /   793 Train loss: 0.03709625\r\n",
      "Epoch:  92 Step:   334 /   793 Train loss: 0.03436832\r\n",
      "Epoch:  92 Step:   335 /   793 Train loss: 0.02738014\r\n",
      "Epoch:  92 Step:   336 /   793 Train loss: 0.02868900\r\n",
      "Epoch:  92 Step:   337 /   793 Train loss: 0.02382022\r\n",
      "Epoch:  92 Step:   338 /   793 Train loss: 0.02758740\r\n",
      "Epoch:  92 Step:   339 /   793 Train loss: 0.02830593\r\n",
      "Epoch:  92 Step:   340 /   793 Train loss: 0.02413212\r\n",
      "Epoch:  92 Step:   341 /   793 Train loss: 0.02019591\r\n",
      "Epoch:  92 Step:   342 /   793 Train loss: 0.02643732\r\n",
      "Epoch:  92 Step:   343 /   793 Train loss: 0.02830157\r\n",
      "Epoch:  92 Step:   344 /   793 Train loss: 0.01792840\r\n",
      "Epoch:  92 Step:   345 /   793 Train loss: 0.02766960\r\n",
      "Epoch:  92 Step:   346 /   793 Train loss: 0.02800848\r\n",
      "Epoch:  92 Step:   347 /   793 Train loss: 0.03160409\r\n",
      "Epoch:  92 Step:   348 /   793 Train loss: 0.01616558\r\n",
      "Epoch:  92 Step:   349 /   793 Train loss: 0.02919866\r\n",
      "Epoch:  92 Step:   350 /   793 Train loss: 0.03295351\r\n",
      "Epoch:  92 Step:   351 /   793 Train loss: 0.03806873\r\n",
      "Epoch:  92 Step:   352 /   793 Train loss: 0.01963706\r\n",
      "Epoch:  92 Step:   353 /   793 Train loss: 0.01798182\r\n",
      "Epoch:  92 Step:   354 /   793 Train loss: 0.03310077\r\n",
      "Epoch:  92 Step:   355 /   793 Train loss: 0.03338391\r\n",
      "Epoch:  92 Step:   356 /   793 Train loss: 0.02469386\r\n",
      "Epoch:  92 Step:   357 /   793 Train loss: 0.02049216\r\n",
      "Epoch:  92 Step:   358 /   793 Train loss: 0.01124587\r\n",
      "Epoch:  92 Step:   359 /   793 Train loss: 0.02268532\r\n",
      "Epoch:  92 Step:   360 /   793 Train loss: 0.02717531\r\n",
      "Epoch:  92 Step:   361 /   793 Train loss: 0.04252874\r\n",
      "Epoch:  92 Step:   362 /   793 Train loss: 0.01297801\r\n",
      "Epoch:  92 Step:   363 /   793 Train loss: 0.01643355\r\n",
      "Epoch:  92 Step:   364 /   793 Train loss: 0.02298693\r\n",
      "Epoch:  92 Step:   365 /   793 Train loss: 0.01858596\r\n",
      "Epoch:  92 Step:   366 /   793 Train loss: 0.03070610\r\n",
      "Epoch:  92 Step:   367 /   793 Train loss: 0.02476777\r\n",
      "Epoch:  92 Step:   368 /   793 Train loss: 0.02537937\r\n",
      "Epoch:  92 Step:   369 /   793 Train loss: 0.02820378\r\n",
      "Epoch:  92 Step:   370 /   793 Train loss: 0.02101925\r\n",
      "Epoch:  92 Step:   371 /   793 Train loss: 0.02656250\r\n",
      "Epoch:  92 Step:   372 /   793 Train loss: 0.04053796\r\n",
      "Epoch:  92 Step:   373 /   793 Train loss: 0.02213310\r\n",
      "Epoch:  92 Step:   374 /   793 Train loss: 0.00875448\r\n",
      "Epoch:  92 Step:   375 /   793 Train loss: 0.02199584\r\n",
      "Epoch:  92 Step:   376 /   793 Train loss: 0.03217161\r\n",
      "Epoch:  92 Step:   377 /   793 Train loss: 0.00796675\r\n",
      "Epoch:  92 Step:   378 /   793 Train loss: 0.01026743\r\n",
      "Epoch:  92 Step:   379 /   793 Train loss: 0.02296978\r\n",
      "Epoch:  92 Step:   380 /   793 Train loss: 0.02583873\r\n",
      "Epoch:  92 Step:   381 /   793 Train loss: 0.01726823\r\n",
      "Epoch:  92 Step:   382 /   793 Train loss: 0.03912669\r\n",
      "Epoch:  92 Step:   383 /   793 Train loss: 0.03092751\r\n",
      "Epoch:  92 Step:   384 /   793 Train loss: 0.02239293\r\n",
      "Epoch:  92 Step:   385 /   793 Train loss: 0.01792212\r\n",
      "Epoch:  92 Step:   386 /   793 Train loss: 0.02450904\r\n",
      "Epoch:  92 Step:   387 /   793 Train loss: 0.02984124\r\n",
      "Epoch:  92 Step:   388 /   793 Train loss: 0.01586792\r\n",
      "Epoch:  92 Step:   389 /   793 Train loss: 0.03206185\r\n",
      "Epoch:  92 Step:   390 /   793 Train loss: 0.01954576\r\n",
      "Epoch:  92 Step:   391 /   793 Train loss: 0.02618127\r\n",
      "Epoch:  92 Step:   392 /   793 Train loss: 0.02801002\r\n",
      "Epoch:  92 Step:   393 /   793 Train loss: 0.03401799\r\n",
      "Epoch:  92 Step:   394 /   793 Train loss: 0.01828575\r\n",
      "Epoch:  92 Step:   395 /   793 Train loss: 0.02027512\r\n",
      "Epoch:  92 Step:   396 /   793 Train loss: 0.02927229\r\n",
      "Epoch:  92 Step:   397 /   793 Train loss: 0.03024147\r\n",
      "Epoch:  92 Step:   398 /   793 Train loss: 0.02551248\r\n",
      "Epoch:  92 Step:   399 /   793 Train loss: 0.02691712\r\n",
      "Epoch:  92 Step:   400 /   793 Train loss: 0.02147250\r\n",
      "Epoch:  92 Step:   401 /   793 Train loss: 0.01694876\r\n",
      "Epoch:  92 Step:   402 /   793 Train loss: 0.03137490\r\n",
      "Epoch:  92 Step:   403 /   793 Train loss: 0.01877417\r\n",
      "Epoch:  92 Step:   404 /   793 Train loss: 0.02979635\r\n",
      "Epoch:  92 Step:   405 /   793 Train loss: 0.03006336\r\n",
      "Epoch:  92 Step:   406 /   793 Train loss: 0.04276152\r\n",
      "Epoch:  92 Step:   407 /   793 Train loss: 0.01861902\r\n",
      "Epoch:  92 Step:   408 /   793 Train loss: 0.03565415\r\n",
      "Epoch:  92 Step:   409 /   793 Train loss: 0.02216440\r\n",
      "Epoch:  92 Step:   410 /   793 Train loss: 0.01751805\r\n",
      "Epoch:  92 Step:   411 /   793 Train loss: 0.02717229\r\n",
      "Epoch:  92 Step:   412 /   793 Train loss: 0.03252073\r\n",
      "Epoch:  92 Step:   413 /   793 Train loss: 0.02578328\r\n",
      "Epoch:  92 Step:   414 /   793 Train loss: 0.01724925\r\n",
      "Epoch:  92 Step:   415 /   793 Train loss: 0.04198826\r\n",
      "Epoch:  92 Step:   416 /   793 Train loss: 0.02609275\r\n",
      "Epoch:  92 Step:   417 /   793 Train loss: 0.01116060\r\n",
      "Epoch:  92 Step:   418 /   793 Train loss: 0.01520268\r\n",
      "Epoch:  92 Step:   419 /   793 Train loss: 0.03304286\r\n",
      "Epoch:  92 Step:   420 /   793 Train loss: 0.02567760\r\n",
      "Epoch:  92 Step:   421 /   793 Train loss: 0.02814970\r\n",
      "Epoch:  92 Step:   422 /   793 Train loss: 0.01500624\r\n",
      "Epoch:  92 Step:   423 /   793 Train loss: 0.02463152\r\n",
      "Epoch:  92 Step:   424 /   793 Train loss: 0.02096399\r\n",
      "Epoch:  92 Step:   425 /   793 Train loss: 0.01959393\r\n",
      "Epoch:  92 Step:   426 /   793 Train loss: 0.02294014\r\n",
      "Epoch:  92 Step:   427 /   793 Train loss: 0.01907047\r\n",
      "Epoch:  92 Step:   428 /   793 Train loss: 0.02536075\r\n",
      "Epoch:  92 Step:   429 /   793 Train loss: 0.02784485\r\n",
      "Epoch:  92 Step:   430 /   793 Train loss: 0.01873426\r\n",
      "Epoch:  92 Step:   431 /   793 Train loss: 0.02760641\r\n",
      "Epoch:  92 Step:   432 /   793 Train loss: 0.02966661\r\n",
      "Epoch:  92 Step:   433 /   793 Train loss: 0.01743351\r\n",
      "Epoch:  92 Step:   434 /   793 Train loss: 0.02671215\r\n",
      "Epoch:  92 Step:   435 /   793 Train loss: 0.03409530\r\n",
      "Epoch:  92 Step:   436 /   793 Train loss: 0.02611444\r\n",
      "Epoch:  92 Step:   437 /   793 Train loss: 0.03169814\r\n",
      "Epoch:  92 Step:   438 /   793 Train loss: 0.02271294\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  92 Step:   439 /   793 Train loss: 0.02768426\r\n",
      "Epoch:  92 Step:   440 /   793 Train loss: 0.01426199\r\n",
      "Epoch:  92 Step:   441 /   793 Train loss: 0.01429644\r\n",
      "Epoch:  92 Step:   442 /   793 Train loss: 0.03127225\r\n",
      "Epoch:  92 Step:   443 /   793 Train loss: 0.01849003\r\n",
      "Epoch:  92 Step:   444 /   793 Train loss: 0.02030873\r\n",
      "Epoch:  92 Step:   445 /   793 Train loss: 0.01304294\r\n",
      "Epoch:  92 Step:   446 /   793 Train loss: 0.04649459\r\n",
      "Epoch:  92 Step:   447 /   793 Train loss: 0.02504196\r\n",
      "Epoch:  92 Step:   448 /   793 Train loss: 0.01847768\r\n",
      "Epoch:  92 Step:   449 /   793 Train loss: 0.02290718\r\n",
      "Epoch:  92 Step:   450 /   793 Train loss: 0.03314392\r\n",
      "Epoch:  92 Step:   451 /   793 Train loss: 0.02451360\r\n",
      "Epoch:  92 Step:   452 /   793 Train loss: 0.00959292\r\n",
      "Epoch:  92 Step:   453 /   793 Train loss: 0.03436596\r\n",
      "Epoch:  92 Step:   454 /   793 Train loss: 0.03180140\r\n",
      "Epoch:  92 Step:   455 /   793 Train loss: 0.02633377\r\n",
      "Epoch:  92 Step:   456 /   793 Train loss: 0.00955275\r\n",
      "Epoch:  92 Step:   457 /   793 Train loss: 0.02380396\r\n",
      "Epoch:  92 Step:   458 /   793 Train loss: 0.02113966\r\n",
      "Epoch:  92 Step:   459 /   793 Train loss: 0.02806914\r\n",
      "Epoch:  92 Step:   460 /   793 Train loss: 0.02899502\r\n",
      "Epoch:  92 Step:   461 /   793 Train loss: 0.03218050\r\n",
      "Epoch:  92 Step:   462 /   793 Train loss: 0.02562398\r\n",
      "Epoch:  92 Step:   463 /   793 Train loss: 0.02519938\r\n",
      "Epoch:  92 Step:   464 /   793 Train loss: 0.02611609\r\n",
      "Epoch:  92 Step:   465 /   793 Train loss: 0.03093082\r\n",
      "Epoch:  92 Step:   466 /   793 Train loss: 0.03391919\r\n",
      "Epoch:  92 Step:   467 /   793 Train loss: 0.02698612\r\n",
      "Epoch:  92 Step:   468 /   793 Train loss: 0.03355748\r\n",
      "Epoch:  92 Step:   469 /   793 Train loss: 0.01549465\r\n",
      "Epoch:  92 Step:   470 /   793 Train loss: 0.02020562\r\n",
      "Epoch:  92 Step:   471 /   793 Train loss: 0.01709047\r\n",
      "Epoch:  92 Step:   472 /   793 Train loss: 0.01549401\r\n",
      "Epoch:  92 Step:   473 /   793 Train loss: 0.03437269\r\n",
      "Epoch:  92 Step:   474 /   793 Train loss: 0.02569951\r\n",
      "Epoch:  92 Step:   475 /   793 Train loss: 0.04099816\r\n",
      "Epoch:  92 Step:   476 /   793 Train loss: 0.01650329\r\n",
      "Epoch:  92 Step:   477 /   793 Train loss: 0.01862673\r\n",
      "Epoch:  92 Step:   478 /   793 Train loss: 0.02955137\r\n",
      "Epoch:  92 Step:   479 /   793 Train loss: 0.01603146\r\n",
      "Epoch:  92 Step:   480 /   793 Train loss: 0.02268251\r\n",
      "Epoch:  92 Step:   481 /   793 Train loss: 0.02081234\r\n",
      "Epoch:  92 Step:   482 /   793 Train loss: 0.02778856\r\n",
      "Epoch:  92 Step:   483 /   793 Train loss: 0.03203493\r\n",
      "Epoch:  92 Step:   484 /   793 Train loss: 0.02744436\r\n",
      "Epoch:  92 Step:   485 /   793 Train loss: 0.02563094\r\n",
      "Epoch:  92 Step:   486 /   793 Train loss: 0.02019306\r\n",
      "Epoch:  92 Step:   487 /   793 Train loss: 0.02441763\r\n",
      "Epoch:  92 Step:   488 /   793 Train loss: 0.01754143\r\n",
      "Epoch:  92 Step:   489 /   793 Train loss: 0.03284729\r\n",
      "Epoch:  92 Step:   490 /   793 Train loss: 0.02229613\r\n",
      "Epoch:  92 Step:   491 /   793 Train loss: 0.01331057\r\n",
      "Epoch:  92 Step:   492 /   793 Train loss: 0.02475723\r\n",
      "Epoch:  92 Step:   493 /   793 Train loss: 0.01956170\r\n",
      "Epoch:  92 Step:   494 /   793 Train loss: 0.02499979\r\n",
      "Epoch:  92 Step:   495 /   793 Train loss: 0.02351918\r\n",
      "Epoch:  92 Step:   496 /   793 Train loss: 0.03099897\r\n",
      "Epoch:  92 Step:   497 /   793 Train loss: 0.02494216\r\n",
      "Epoch:  92 Step:   498 /   793 Train loss: 0.02177630\r\n",
      "Epoch:  92 Step:   499 /   793 Train loss: 0.02689892\r\n",
      "Epoch:  92 Step:   500 /   793 Train loss: 0.02906306\r\n",
      "Epoch:  92 Step:   501 /   793 Train loss: 0.01266412\r\n",
      "Epoch:  92 Step:   502 /   793 Train loss: 0.02682613\r\n",
      "Epoch:  92 Step:   503 /   793 Train loss: 0.02284883\r\n",
      "Epoch:  92 Step:   504 /   793 Train loss: 0.02026420\r\n",
      "Epoch:  92 Step:   505 /   793 Train loss: 0.01151378\r\n",
      "Epoch:  92 Step:   506 /   793 Train loss: 0.01959174\r\n",
      "Epoch:  92 Step:   507 /   793 Train loss: 0.02843639\r\n",
      "Epoch:  92 Step:   508 /   793 Train loss: 0.02158878\r\n",
      "Epoch:  92 Step:   509 /   793 Train loss: 0.02196446\r\n",
      "Epoch:  92 Step:   510 /   793 Train loss: 0.02318981\r\n",
      "Epoch:  92 Step:   511 /   793 Train loss: 0.02398394\r\n",
      "Epoch:  92 Step:   512 /   793 Train loss: 0.01971556\r\n",
      "Epoch:  92 Step:   513 /   793 Train loss: 0.01842843\r\n",
      "Epoch:  92 Step:   514 /   793 Train loss: 0.01548279\r\n",
      "Epoch:  92 Step:   515 /   793 Train loss: 0.01420909\r\n",
      "Epoch:  92 Step:   516 /   793 Train loss: 0.03707449\r\n",
      "Epoch:  92 Step:   517 /   793 Train loss: 0.02703230\r\n",
      "Epoch:  92 Step:   518 /   793 Train loss: 0.03638780\r\n",
      "Epoch:  92 Step:   519 /   793 Train loss: 0.02069873\r\n",
      "Epoch:  92 Step:   520 /   793 Train loss: 0.03568114\r\n",
      "Epoch:  92 Step:   521 /   793 Train loss: 0.02086428\r\n",
      "Epoch:  92 Step:   522 /   793 Train loss: 0.01434050\r\n",
      "Epoch:  92 Step:   523 /   793 Train loss: 0.02169976\r\n",
      "Epoch:  92 Step:   524 /   793 Train loss: 0.02911741\r\n",
      "Epoch:  92 Step:   525 /   793 Train loss: 0.03079226\r\n",
      "Epoch:  92 Step:   526 /   793 Train loss: 0.01703660\r\n",
      "Epoch:  92 Step:   527 /   793 Train loss: 0.01768329\r\n",
      "Epoch:  92 Step:   528 /   793 Train loss: 0.02759653\r\n",
      "Epoch:  92 Step:   529 /   793 Train loss: 0.01151414\r\n",
      "Epoch:  92 Step:   530 /   793 Train loss: 0.02100797\r\n",
      "Epoch:  92 Step:   531 /   793 Train loss: 0.02324875\r\n",
      "Epoch:  92 Step:   532 /   793 Train loss: 0.03017120\r\n",
      "Epoch:  92 Step:   533 /   793 Train loss: 0.03376807\r\n",
      "Epoch:  92 Step:   534 /   793 Train loss: 0.02030078\r\n",
      "Epoch:  92 Step:   535 /   793 Train loss: 0.03242451\r\n",
      "Epoch:  92 Step:   536 /   793 Train loss: 0.02199092\r\n",
      "Epoch:  92 Step:   537 /   793 Train loss: 0.02719988\r\n",
      "Epoch:  92 Step:   538 /   793 Train loss: 0.01948156\r\n",
      "Epoch:  92 Step:   539 /   793 Train loss: 0.02811593\r\n",
      "Epoch:  92 Step:   540 /   793 Train loss: 0.01512270\r\n",
      "Epoch:  92 Step:   541 /   793 Train loss: 0.02193482\r\n",
      "Epoch:  92 Step:   542 /   793 Train loss: 0.03312390\r\n",
      "Epoch:  92 Step:   543 /   793 Train loss: 0.02491113\r\n",
      "Epoch:  92 Step:   544 /   793 Train loss: 0.02494079\r\n",
      "Epoch:  92 Step:   545 /   793 Train loss: 0.01807153\r\n",
      "Epoch:  92 Step:   546 /   793 Train loss: 0.02705623\r\n",
      "Epoch:  92 Step:   547 /   793 Train loss: 0.01885052\r\n",
      "Epoch:  92 Step:   548 /   793 Train loss: 0.02689741\r\n",
      "Epoch:  92 Step:   549 /   793 Train loss: 0.02204514\r\n",
      "Epoch:  92 Step:   550 /   793 Train loss: 0.02539090\r\n",
      "Epoch:  92 Step:   551 /   793 Train loss: 0.02600798\r\n",
      "Epoch:  92 Step:   552 /   793 Train loss: 0.03038857\r\n",
      "Epoch:  92 Step:   553 /   793 Train loss: 0.03282082\r\n",
      "Epoch:  92 Step:   554 /   793 Train loss: 0.02318923\r\n",
      "Epoch:  92 Step:   555 /   793 Train loss: 0.02045284\r\n",
      "Epoch:  92 Step:   556 /   793 Train loss: 0.02047906\r\n",
      "Epoch:  92 Step:   557 /   793 Train loss: 0.01963680\r\n",
      "Epoch:  92 Step:   558 /   793 Train loss: 0.02381157\r\n",
      "Epoch:  92 Step:   559 /   793 Train loss: 0.02275385\r\n",
      "Epoch:  92 Step:   560 /   793 Train loss: 0.02055695\r\n",
      "Epoch:  92 Step:   561 /   793 Train loss: 0.02691158\r\n",
      "Epoch:  92 Step:   562 /   793 Train loss: 0.03370929\r\n",
      "Epoch:  92 Step:   563 /   793 Train loss: 0.02512603\r\n",
      "Epoch:  92 Step:   564 /   793 Train loss: 0.02305162\r\n",
      "Epoch:  92 Step:   565 /   793 Train loss: 0.02179521\r\n",
      "Epoch:  92 Step:   566 /   793 Train loss: 0.03012762\r\n",
      "Epoch:  92 Step:   567 /   793 Train loss: 0.03498409\r\n",
      "Epoch:  92 Step:   568 /   793 Train loss: 0.02499641\r\n",
      "Epoch:  92 Step:   569 /   793 Train loss: 0.01975222\r\n",
      "Epoch:  92 Step:   570 /   793 Train loss: 0.02169666\r\n",
      "Epoch:  92 Step:   571 /   793 Train loss: 0.01468502\r\n",
      "Epoch:  92 Step:   572 /   793 Train loss: 0.02200077\r\n",
      "Epoch:  92 Step:   573 /   793 Train loss: 0.03492954\r\n",
      "Epoch:  92 Step:   574 /   793 Train loss: 0.01783164\r\n",
      "Epoch:  92 Step:   575 /   793 Train loss: 0.01585039\r\n",
      "Epoch:  92 Step:   576 /   793 Train loss: 0.02381028\r\n",
      "Epoch:  92 Step:   577 /   793 Train loss: 0.02828810\r\n",
      "Epoch:  92 Step:   578 /   793 Train loss: 0.01924514\r\n",
      "Epoch:  92 Step:   579 /   793 Train loss: 0.02111894\r\n",
      "Epoch:  92 Step:   580 /   793 Train loss: 0.01644664\r\n",
      "Epoch:  92 Step:   581 /   793 Train loss: 0.02059320\r\n",
      "Epoch:  92 Step:   582 /   793 Train loss: 0.02105589\r\n",
      "Epoch:  92 Step:   583 /   793 Train loss: 0.01969076\r\n",
      "Epoch:  92 Step:   584 /   793 Train loss: 0.01913967\r\n",
      "Epoch:  92 Step:   585 /   793 Train loss: 0.03937950\r\n",
      "Epoch:  92 Step:   586 /   793 Train loss: 0.01574210\r\n",
      "Epoch:  92 Step:   587 /   793 Train loss: 0.01714762\r\n",
      "Epoch:  92 Step:   588 /   793 Train loss: 0.02086754\r\n",
      "Epoch:  92 Step:   589 /   793 Train loss: 0.02241942\r\n",
      "Epoch:  92 Step:   590 /   793 Train loss: 0.02604229\r\n",
      "Epoch:  92 Step:   591 /   793 Train loss: 0.02858382\r\n",
      "Epoch:  92 Step:   592 /   793 Train loss: 0.02284665\r\n",
      "Epoch:  92 Step:   593 /   793 Train loss: 0.04241881\r\n",
      "Epoch:  92 Step:   594 /   793 Train loss: 0.01475888\r\n",
      "Epoch:  92 Step:   595 /   793 Train loss: 0.02176837\r\n",
      "Epoch:  92 Step:   596 /   793 Train loss: 0.02645408\r\n",
      "Epoch:  92 Step:   597 /   793 Train loss: 0.02886596\r\n",
      "Epoch:  92 Step:   598 /   793 Train loss: 0.02514415\r\n",
      "Epoch:  92 Step:   599 /   793 Train loss: 0.02089712\r\n",
      "Epoch:  92 Step:   600 /   793 Train loss: 0.01759877\r\n",
      "Epoch:  92 Step:   601 /   793 Train loss: 0.03283917\r\n",
      "Epoch:  92 Step:   602 /   793 Train loss: 0.02453274\r\n",
      "Epoch:  92 Step:   603 /   793 Train loss: 0.01828613\r\n",
      "Epoch:  92 Step:   604 /   793 Train loss: 0.02490710\r\n",
      "Epoch:  92 Step:   605 /   793 Train loss: 0.03060472\r\n",
      "Epoch:  92 Step:   606 /   793 Train loss: 0.03628072\r\n",
      "Epoch:  92 Step:   607 /   793 Train loss: 0.02255467\r\n",
      "Epoch:  92 Step:   608 /   793 Train loss: 0.04294234\r\n",
      "Epoch:  92 Step:   609 /   793 Train loss: 0.02141186\r\n",
      "Epoch:  92 Step:   610 /   793 Train loss: 0.02649329\r\n",
      "Epoch:  92 Step:   611 /   793 Train loss: 0.03007282\r\n",
      "Epoch:  92 Step:   612 /   793 Train loss: 0.02360286\r\n",
      "Epoch:  92 Step:   613 /   793 Train loss: 0.02680387\r\n",
      "Epoch:  92 Step:   614 /   793 Train loss: 0.01563383\r\n",
      "Epoch:  92 Step:   615 /   793 Train loss: 0.03430451\r\n",
      "Epoch:  92 Step:   616 /   793 Train loss: 0.03521963\r\n",
      "Epoch:  92 Step:   617 /   793 Train loss: 0.02822891\r\n",
      "Epoch:  92 Step:   618 /   793 Train loss: 0.02359834\r\n",
      "Epoch:  92 Step:   619 /   793 Train loss: 0.03709799\r\n",
      "Epoch:  92 Step:   620 /   793 Train loss: 0.03468115\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  92 Step:   621 /   793 Train loss: 0.02820135\r\n",
      "Epoch:  92 Step:   622 /   793 Train loss: 0.01465523\r\n",
      "Epoch:  92 Step:   623 /   793 Train loss: 0.02455838\r\n",
      "Epoch:  92 Step:   624 /   793 Train loss: 0.02072058\r\n",
      "Epoch:  92 Step:   625 /   793 Train loss: 0.02714228\r\n",
      "Epoch:  92 Step:   626 /   793 Train loss: 0.02326878\r\n",
      "Epoch:  92 Step:   627 /   793 Train loss: 0.02215770\r\n",
      "Epoch:  92 Step:   628 /   793 Train loss: 0.01928657\r\n",
      "Epoch:  92 Step:   629 /   793 Train loss: 0.01907303\r\n",
      "Epoch:  92 Step:   630 /   793 Train loss: 0.01738905\r\n",
      "Epoch:  92 Step:   631 /   793 Train loss: 0.00901394\r\n",
      "Epoch:  92 Step:   632 /   793 Train loss: 0.02103132\r\n",
      "Epoch:  92 Step:   633 /   793 Train loss: 0.02260024\r\n",
      "Epoch:  92 Step:   634 /   793 Train loss: 0.03871532\r\n",
      "Epoch:  92 Step:   635 /   793 Train loss: 0.02547970\r\n",
      "Epoch:  92 Step:   636 /   793 Train loss: 0.03287565\r\n",
      "Epoch:  92 Step:   637 /   793 Train loss: 0.01930265\r\n",
      "Epoch:  92 Step:   638 /   793 Train loss: 0.03225501\r\n",
      "Epoch:  92 Step:   639 /   793 Train loss: 0.02393560\r\n",
      "Epoch:  92 Step:   640 /   793 Train loss: 0.02915787\r\n",
      "Epoch:  92 Step:   641 /   793 Train loss: 0.02272157\r\n",
      "Epoch:  92 Step:   642 /   793 Train loss: 0.02578274\r\n",
      "Epoch:  92 Step:   643 /   793 Train loss: 0.01716737\r\n",
      "Epoch:  92 Step:   644 /   793 Train loss: 0.02287046\r\n",
      "Epoch:  92 Step:   645 /   793 Train loss: 0.02956122\r\n",
      "Epoch:  92 Step:   646 /   793 Train loss: 0.01961410\r\n",
      "Epoch:  92 Step:   647 /   793 Train loss: 0.01809741\r\n",
      "Epoch:  92 Step:   648 /   793 Train loss: 0.02364251\r\n",
      "Epoch:  92 Step:   649 /   793 Train loss: 0.01853031\r\n",
      "Epoch:  92 Step:   650 /   793 Train loss: 0.03000698\r\n",
      "Epoch:  92 Step:   651 /   793 Train loss: 0.01498273\r\n",
      "Epoch:  92 Step:   652 /   793 Train loss: 0.02150238\r\n",
      "Epoch:  92 Step:   653 /   793 Train loss: 0.01635969\r\n",
      "Epoch:  92 Step:   654 /   793 Train loss: 0.03656993\r\n",
      "Epoch:  92 Step:   655 /   793 Train loss: 0.01868505\r\n",
      "Epoch:  92 Step:   656 /   793 Train loss: 0.03695809\r\n",
      "Epoch:  92 Step:   657 /   793 Train loss: 0.02268801\r\n",
      "Epoch:  92 Step:   658 /   793 Train loss: 0.02091822\r\n",
      "Epoch:  92 Step:   659 /   793 Train loss: 0.02118623\r\n",
      "Epoch:  92 Step:   660 /   793 Train loss: 0.02346558\r\n",
      "Epoch:  92 Step:   661 /   793 Train loss: 0.02949571\r\n",
      "Epoch:  92 Step:   662 /   793 Train loss: 0.03737356\r\n",
      "Epoch:  92 Step:   663 /   793 Train loss: 0.03267199\r\n",
      "Epoch:  92 Step:   664 /   793 Train loss: 0.02402068\r\n",
      "Epoch:  92 Step:   665 /   793 Train loss: 0.03167276\r\n",
      "Epoch:  92 Step:   666 /   793 Train loss: 0.02220895\r\n",
      "Epoch:  92 Step:   667 /   793 Train loss: 0.02335734\r\n",
      "Epoch:  92 Step:   668 /   793 Train loss: 0.02717955\r\n",
      "Epoch:  92 Step:   669 /   793 Train loss: 0.02057872\r\n",
      "Epoch:  92 Step:   670 /   793 Train loss: 0.01927149\r\n",
      "Epoch:  92 Step:   671 /   793 Train loss: 0.01579926\r\n",
      "Epoch:  92 Step:   672 /   793 Train loss: 0.02016133\r\n",
      "Epoch:  92 Step:   673 /   793 Train loss: 0.02493907\r\n",
      "Epoch:  92 Step:   674 /   793 Train loss: 0.02424817\r\n",
      "Epoch:  92 Step:   675 /   793 Train loss: 0.02385887\r\n",
      "Epoch:  92 Step:   676 /   793 Train loss: 0.02533993\r\n",
      "Epoch:  92 Step:   677 /   793 Train loss: 0.01512834\r\n",
      "Epoch:  92 Step:   678 /   793 Train loss: 0.02044981\r\n",
      "Epoch:  92 Step:   679 /   793 Train loss: 0.01825656\r\n",
      "Epoch:  92 Step:   680 /   793 Train loss: 0.01671583\r\n",
      "Epoch:  92 Step:   681 /   793 Train loss: 0.03224535\r\n",
      "Epoch:  92 Step:   682 /   793 Train loss: 0.01356544\r\n",
      "Epoch:  92 Step:   683 /   793 Train loss: 0.01361029\r\n",
      "Epoch:  92 Step:   684 /   793 Train loss: 0.02589472\r\n",
      "Epoch:  92 Step:   685 /   793 Train loss: 0.02928743\r\n",
      "Epoch:  92 Step:   686 /   793 Train loss: 0.01773877\r\n",
      "Epoch:  92 Step:   687 /   793 Train loss: 0.02970675\r\n",
      "Epoch:  92 Step:   688 /   793 Train loss: 0.02891409\r\n",
      "Epoch:  92 Step:   689 /   793 Train loss: 0.02936598\r\n",
      "Epoch:  92 Step:   690 /   793 Train loss: 0.03869023\r\n",
      "Epoch:  92 Step:   691 /   793 Train loss: 0.02061203\r\n",
      "Epoch:  92 Step:   692 /   793 Train loss: 0.02833472\r\n",
      "Epoch:  92 Step:   693 /   793 Train loss: 0.02392515\r\n",
      "Epoch:  92 Step:   694 /   793 Train loss: 0.03231436\r\n",
      "Epoch:  92 Step:   695 /   793 Train loss: 0.02487849\r\n",
      "Epoch:  92 Step:   696 /   793 Train loss: 0.01443047\r\n",
      "Epoch:  92 Step:   697 /   793 Train loss: 0.02825061\r\n",
      "Epoch:  92 Step:   698 /   793 Train loss: 0.02222228\r\n",
      "Epoch:  92 Step:   699 /   793 Train loss: 0.01296768\r\n",
      "Epoch:  92 Step:   700 /   793 Train loss: 0.02029766\r\n",
      "Epoch:  92 Step:   701 /   793 Train loss: 0.01579848\r\n",
      "Epoch:  92 Step:   702 /   793 Train loss: 0.02767667\r\n",
      "Epoch:  92 Step:   703 /   793 Train loss: 0.02420485\r\n",
      "Epoch:  92 Step:   704 /   793 Train loss: 0.01706367\r\n",
      "Epoch:  92 Step:   705 /   793 Train loss: 0.04061512\r\n",
      "Epoch:  92 Step:   706 /   793 Train loss: 0.01834354\r\n",
      "Epoch:  92 Step:   707 /   793 Train loss: 0.03000330\r\n",
      "Epoch:  92 Step:   708 /   793 Train loss: 0.03362708\r\n",
      "Epoch:  92 Step:   709 /   793 Train loss: 0.03058010\r\n",
      "Epoch:  92 Step:   710 /   793 Train loss: 0.01363540\r\n",
      "Epoch:  92 Step:   711 /   793 Train loss: 0.02232014\r\n",
      "Epoch:  92 Step:   712 /   793 Train loss: 0.02213228\r\n",
      "Epoch:  92 Step:   713 /   793 Train loss: 0.03004411\r\n",
      "Epoch:  92 Step:   714 /   793 Train loss: 0.03098682\r\n",
      "Epoch:  92 Step:   715 /   793 Train loss: 0.01720992\r\n",
      "Epoch:  92 Step:   716 /   793 Train loss: 0.02072429\r\n",
      "Epoch:  92 Step:   717 /   793 Train loss: 0.01790266\r\n",
      "Epoch:  92 Step:   718 /   793 Train loss: 0.01863905\r\n",
      "Epoch:  92 Step:   719 /   793 Train loss: 0.02824113\r\n",
      "Epoch:  92 Step:   720 /   793 Train loss: 0.02712826\r\n",
      "Epoch:  92 Step:   721 /   793 Train loss: 0.03842334\r\n",
      "Epoch:  92 Step:   722 /   793 Train loss: 0.02077779\r\n",
      "Epoch:  92 Step:   723 /   793 Train loss: 0.03419027\r\n",
      "Epoch:  92 Step:   724 /   793 Train loss: 0.01978483\r\n",
      "Epoch:  92 Step:   725 /   793 Train loss: 0.02557380\r\n",
      "Epoch:  92 Step:   726 /   793 Train loss: 0.02433571\r\n",
      "Epoch:  92 Step:   727 /   793 Train loss: 0.01768566\r\n",
      "Epoch:  92 Step:   728 /   793 Train loss: 0.02128391\r\n",
      "Epoch:  92 Step:   729 /   793 Train loss: 0.02183881\r\n",
      "Epoch:  92 Step:   730 /   793 Train loss: 0.02096749\r\n",
      "Epoch:  92 Step:   731 /   793 Train loss: 0.03152960\r\n",
      "Epoch:  92 Step:   732 /   793 Train loss: 0.01989994\r\n",
      "Epoch:  92 Step:   733 /   793 Train loss: 0.02540915\r\n",
      "Epoch:  92 Step:   734 /   793 Train loss: 0.01130698\r\n",
      "Epoch:  92 Step:   735 /   793 Train loss: 0.02316732\r\n",
      "Epoch:  92 Step:   736 /   793 Train loss: 0.02652778\r\n",
      "Epoch:  92 Step:   737 /   793 Train loss: 0.01506779\r\n",
      "Epoch:  92 Step:   738 /   793 Train loss: 0.01699597\r\n",
      "Epoch:  92 Step:   739 /   793 Train loss: 0.02235972\r\n",
      "Epoch:  92 Step:   740 /   793 Train loss: 0.03452975\r\n",
      "Epoch:  92 Step:   741 /   793 Train loss: 0.01364881\r\n",
      "Epoch:  92 Step:   742 /   793 Train loss: 0.03510543\r\n",
      "Epoch:  92 Step:   743 /   793 Train loss: 0.02937312\r\n",
      "Epoch:  92 Step:   744 /   793 Train loss: 0.01471430\r\n",
      "Epoch:  92 Step:   745 /   793 Train loss: 0.03078549\r\n",
      "Epoch:  92 Step:   746 /   793 Train loss: 0.03039762\r\n",
      "Epoch:  92 Step:   747 /   793 Train loss: 0.02783999\r\n",
      "Epoch:  92 Step:   748 /   793 Train loss: 0.03247053\r\n",
      "Epoch:  92 Step:   749 /   793 Train loss: 0.01786984\r\n",
      "Epoch:  92 Step:   750 /   793 Train loss: 0.03464012\r\n",
      "Epoch:  92 Step:   751 /   793 Train loss: 0.01767468\r\n",
      "Epoch:  92 Step:   752 /   793 Train loss: 0.01549420\r\n",
      "Epoch:  92 Step:   753 /   793 Train loss: 0.03620349\r\n",
      "Epoch:  92 Step:   754 /   793 Train loss: 0.02082567\r\n",
      "Epoch:  92 Step:   755 /   793 Train loss: 0.01979369\r\n",
      "Epoch:  92 Step:   756 /   793 Train loss: 0.01612085\r\n",
      "Epoch:  92 Step:   757 /   793 Train loss: 0.01931851\r\n",
      "Epoch:  92 Step:   758 /   793 Train loss: 0.01832430\r\n",
      "Epoch:  92 Step:   759 /   793 Train loss: 0.03111700\r\n",
      "Epoch:  92 Step:   760 /   793 Train loss: 0.02519094\r\n",
      "Epoch:  92 Step:   761 /   793 Train loss: 0.01700424\r\n",
      "Epoch:  92 Step:   762 /   793 Train loss: 0.02161627\r\n",
      "Epoch:  92 Step:   763 /   793 Train loss: 0.01985848\r\n",
      "Epoch:  92 Step:   764 /   793 Train loss: 0.02478237\r\n",
      "Epoch:  92 Step:   765 /   793 Train loss: 0.01401733\r\n",
      "Epoch:  92 Step:   766 /   793 Train loss: 0.02379953\r\n",
      "Epoch:  92 Step:   767 /   793 Train loss: 0.01417845\r\n",
      "Epoch:  92 Step:   768 /   793 Train loss: 0.02578747\r\n",
      "Epoch:  92 Step:   769 /   793 Train loss: 0.02291096\r\n",
      "Epoch:  92 Step:   770 /   793 Train loss: 0.02682021\r\n",
      "Epoch:  92 Step:   771 /   793 Train loss: 0.01259545\r\n",
      "Epoch:  92 Step:   772 /   793 Train loss: 0.02203478\r\n",
      "Epoch:  92 Step:   773 /   793 Train loss: 0.01860042\r\n",
      "Epoch:  92 Step:   774 /   793 Train loss: 0.03062836\r\n",
      "Epoch:  92 Step:   775 /   793 Train loss: 0.03259504\r\n",
      "Epoch:  92 Step:   776 /   793 Train loss: 0.01913050\r\n",
      "Epoch:  92 Step:   777 /   793 Train loss: 0.02557495\r\n",
      "Epoch:  92 Step:   778 /   793 Train loss: 0.02978436\r\n",
      "Epoch:  92 Step:   779 /   793 Train loss: 0.02631035\r\n",
      "Epoch:  92 Step:   780 /   793 Train loss: 0.02110621\r\n",
      "Epoch:  92 Step:   781 /   793 Train loss: 0.02123387\r\n",
      "Epoch:  92 Step:   782 /   793 Train loss: 0.02127301\r\n",
      "Epoch:  92 Step:   783 /   793 Train loss: 0.02904174\r\n",
      "Epoch:  92 Step:   784 /   793 Train loss: 0.02221215\r\n",
      "Epoch:  92 Step:   785 /   793 Train loss: 0.01990984\r\n",
      "Epoch:  92 Step:   786 /   793 Train loss: 0.02211021\r\n",
      "Epoch:  92 Step:   787 /   793 Train loss: 0.02593905\r\n",
      "Epoch:  92 Step:   788 /   793 Train loss: 0.03179910\r\n",
      "Epoch:  92 Step:   789 /   793 Train loss: 0.02215070\r\n",
      "Epoch:  92 Step:   790 /   793 Train loss: 0.02043943\r\n",
      "Epoch:  92 Step:   791 /   793 Train loss: 0.03047823\r\n",
      "Epoch:  92 Step:   792 /   793 Train loss: 0.02976341\r\n",
      "Epoch:  93 Step:     0 /   793 Train loss: 0.01468197\r\n",
      "Epoch:  93 Step:     1 /   793 Train loss: 0.02989185\r\n",
      "Epoch:  93 Step:     2 /   793 Train loss: 0.01788275\r\n",
      "Epoch:  93 Step:     3 /   793 Train loss: 0.02085757\r\n",
      "Epoch:  93 Step:     4 /   793 Train loss: 0.02657841\r\n",
      "Epoch:  93 Step:     5 /   793 Train loss: 0.02586735\r\n",
      "Epoch:  93 Step:     6 /   793 Train loss: 0.01708830\r\n",
      "Epoch:  93 Step:     7 /   793 Train loss: 0.02630512\r\n",
      "Epoch:  93 Step:     8 /   793 Train loss: 0.02809471\r\n",
      "Epoch:  93 Step:     9 /   793 Train loss: 0.02720924\r\n",
      "Epoch:  93 Step:    10 /   793 Train loss: 0.01093696\r\n",
      "Epoch:  93 Step:    11 /   793 Train loss: 0.02540503\r\n",
      "Epoch:  93 Step:    12 /   793 Train loss: 0.03640678\r\n",
      "Epoch:  93 Step:    13 /   793 Train loss: 0.02722469\r\n",
      "Epoch:  93 Step:    14 /   793 Train loss: 0.02905931\r\n",
      "Epoch:  93 Step:    15 /   793 Train loss: 0.01732848\r\n",
      "Epoch:  93 Step:    16 /   793 Train loss: 0.01939375\r\n",
      "Epoch:  93 Step:    17 /   793 Train loss: 0.03086932\r\n",
      "Epoch:  93 Step:    18 /   793 Train loss: 0.02512110\r\n",
      "Epoch:  93 Step:    19 /   793 Train loss: 0.02995335\r\n",
      "Epoch:  93 Step:    20 /   793 Train loss: 0.01700257\r\n",
      "Epoch:  93 Step:    21 /   793 Train loss: 0.02522909\r\n",
      "Epoch:  93 Step:    22 /   793 Train loss: 0.02604463\r\n",
      "Epoch:  93 Step:    23 /   793 Train loss: 0.02431347\r\n",
      "Epoch:  93 Step:    24 /   793 Train loss: 0.02103984\r\n",
      "Epoch:  93 Step:    25 /   793 Train loss: 0.01758950\r\n",
      "Epoch:  93 Step:    26 /   793 Train loss: 0.02807220\r\n",
      "Epoch:  93 Step:    27 /   793 Train loss: 0.01093750\r\n",
      "Epoch:  93 Step:    28 /   793 Train loss: 0.02096592\r\n",
      "Epoch:  93 Step:    29 /   793 Train loss: 0.02839762\r\n",
      "Epoch:  93 Step:    30 /   793 Train loss: 0.02964779\r\n",
      "Epoch:  93 Step:    31 /   793 Train loss: 0.02648342\r\n",
      "Epoch:  93 Step:    32 /   793 Train loss: 0.02194778\r\n",
      "Epoch:  93 Step:    33 /   793 Train loss: 0.02357212\r\n",
      "Epoch:  93 Step:    34 /   793 Train loss: 0.02307830\r\n",
      "Epoch:  93 Step:    35 /   793 Train loss: 0.01680851\r\n",
      "Epoch:  93 Step:    36 /   793 Train loss: 0.01956498\r\n",
      "Epoch:  93 Step:    37 /   793 Train loss: 0.03101542\r\n",
      "Epoch:  93 Step:    38 /   793 Train loss: 0.01861664\r\n",
      "Epoch:  93 Step:    39 /   793 Train loss: 0.03062390\r\n",
      "Epoch:  93 Step:    40 /   793 Train loss: 0.03323926\r\n",
      "Epoch:  93 Step:    41 /   793 Train loss: 0.01911546\r\n",
      "Epoch:  93 Step:    42 /   793 Train loss: 0.02759034\r\n",
      "Epoch:  93 Step:    43 /   793 Train loss: 0.02321874\r\n",
      "Epoch:  93 Step:    44 /   793 Train loss: 0.02238752\r\n",
      "Epoch:  93 Step:    45 /   793 Train loss: 0.02745575\r\n",
      "Epoch:  93 Step:    46 /   793 Train loss: 0.02499192\r\n",
      "Epoch:  93 Step:    47 /   793 Train loss: 0.02108880\r\n",
      "Epoch:  93 Step:    48 /   793 Train loss: 0.02024647\r\n",
      "Epoch:  93 Step:    49 /   793 Train loss: 0.01929079\r\n",
      "Epoch:  93 Step:    50 /   793 Train loss: 0.03122950\r\n",
      "Epoch:  93 Step:    51 /   793 Train loss: 0.01548125\r\n",
      "Epoch:  93 Step:    52 /   793 Train loss: 0.02633749\r\n",
      "Epoch:  93 Step:    53 /   793 Train loss: 0.02846619\r\n",
      "Epoch:  93 Step:    54 /   793 Train loss: 0.01646982\r\n",
      "Epoch:  93 Step:    55 /   793 Train loss: 0.04504976\r\n",
      "Epoch:  93 Step:    56 /   793 Train loss: 0.01997724\r\n",
      "Epoch:  93 Step:    57 /   793 Train loss: 0.01847446\r\n",
      "Epoch:  93 Step:    58 /   793 Train loss: 0.02160884\r\n",
      "Epoch:  93 Step:    59 /   793 Train loss: 0.02447946\r\n",
      "Epoch:  93 Step:    60 /   793 Train loss: 0.03270932\r\n",
      "Epoch:  93 Step:    61 /   793 Train loss: 0.03206453\r\n",
      "Epoch:  93 Step:    62 /   793 Train loss: 0.02893233\r\n",
      "Epoch:  93 Step:    63 /   793 Train loss: 0.02294958\r\n",
      "Epoch:  93 Step:    64 /   793 Train loss: 0.03281756\r\n",
      "Epoch:  93 Step:    65 /   793 Train loss: 0.03092440\r\n",
      "Epoch:  93 Step:    66 /   793 Train loss: 0.02171377\r\n",
      "Epoch:  93 Step:    67 /   793 Train loss: 0.01908103\r\n",
      "Epoch:  93 Step:    68 /   793 Train loss: 0.01653281\r\n",
      "Epoch:  93 Step:    69 /   793 Train loss: 0.02735183\r\n",
      "Epoch:  93 Step:    70 /   793 Train loss: 0.03016507\r\n",
      "Epoch:  93 Step:    71 /   793 Train loss: 0.01946422\r\n",
      "Epoch:  93 Step:    72 /   793 Train loss: 0.01437284\r\n",
      "Epoch:  93 Step:    73 /   793 Train loss: 0.02741455\r\n",
      "Epoch:  93 Step:    74 /   793 Train loss: 0.02681242\r\n",
      "Epoch:  93 Step:    75 /   793 Train loss: 0.01846907\r\n",
      "Epoch:  93 Step:    76 /   793 Train loss: 0.03303155\r\n",
      "Epoch:  93 Step:    77 /   793 Train loss: 0.03710285\r\n",
      "Epoch:  93 Step:    78 /   793 Train loss: 0.01427964\r\n",
      "Epoch:  93 Step:    79 /   793 Train loss: 0.02692981\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  93 Step:    80 /   793 Train loss: 0.02586391\r\n",
      "Epoch:  93 Step:    81 /   793 Train loss: 0.02186431\r\n",
      "Epoch:  93 Step:    82 /   793 Train loss: 0.03094312\r\n",
      "Epoch:  93 Step:    83 /   793 Train loss: 0.02704437\r\n",
      "Epoch:  93 Step:    84 /   793 Train loss: 0.02040920\r\n",
      "Epoch:  93 Step:    85 /   793 Train loss: 0.03822083\r\n",
      "Epoch:  93 Step:    86 /   793 Train loss: 0.01226783\r\n",
      "Epoch:  93 Step:    87 /   793 Train loss: 0.02815019\r\n",
      "Epoch:  93 Step:    88 /   793 Train loss: 0.02467003\r\n",
      "Epoch:  93 Step:    89 /   793 Train loss: 0.03441870\r\n",
      "Epoch:  93 Step:    90 /   793 Train loss: 0.02780347\r\n",
      "Epoch:  93 Step:    91 /   793 Train loss: 0.02011062\r\n",
      "Epoch:  93 Step:    92 /   793 Train loss: 0.02221108\r\n",
      "Epoch:  93 Step:    93 /   793 Train loss: 0.02077738\r\n",
      "Epoch:  93 Step:    94 /   793 Train loss: 0.01089397\r\n",
      "Epoch:  93 Step:    95 /   793 Train loss: 0.01506775\r\n",
      "Epoch:  93 Step:    96 /   793 Train loss: 0.02125199\r\n",
      "Epoch:  93 Step:    97 /   793 Train loss: 0.02820976\r\n",
      "Epoch:  93 Step:    98 /   793 Train loss: 0.00982046\r\n",
      "Epoch:  93 Step:    99 /   793 Train loss: 0.01773865\r\n",
      "Epoch:  93 Step:   100 /   793 Train loss: 0.01825919\r\n",
      "Epoch:  93 Step:   101 /   793 Train loss: 0.01968563\r\n",
      "Epoch:  93 Step:   102 /   793 Train loss: 0.00854665\r\n",
      "Epoch:  93 Step:   103 /   793 Train loss: 0.02358029\r\n",
      "Epoch:  93 Step:   104 /   793 Train loss: 0.01526200\r\n",
      "Epoch:  93 Step:   105 /   793 Train loss: 0.02873458\r\n",
      "Epoch:  93 Step:   106 /   793 Train loss: 0.02070971\r\n",
      "Epoch:  93 Step:   107 /   793 Train loss: 0.02922224\r\n",
      "Epoch:  93 Step:   108 /   793 Train loss: 0.02635640\r\n",
      "Epoch:  93 Step:   109 /   793 Train loss: 0.04270401\r\n",
      "Epoch:  93 Step:   110 /   793 Train loss: 0.02038066\r\n",
      "Epoch:  93 Step:   111 /   793 Train loss: 0.01734183\r\n",
      "Epoch:  93 Step:   112 /   793 Train loss: 0.03210170\r\n",
      "Epoch:  93 Step:   113 /   793 Train loss: 0.03714967\r\n",
      "Epoch:  93 Step:   114 /   793 Train loss: 0.02163441\r\n",
      "Epoch:  93 Step:   115 /   793 Train loss: 0.01757574\r\n",
      "Epoch:  93 Step:   116 /   793 Train loss: 0.01671204\r\n",
      "Epoch:  93 Step:   117 /   793 Train loss: 0.01835812\r\n",
      "Epoch:  93 Step:   118 /   793 Train loss: 0.02510542\r\n",
      "Epoch:  93 Step:   119 /   793 Train loss: 0.02396684\r\n",
      "Epoch:  93 Step:   120 /   793 Train loss: 0.02364803\r\n",
      "Epoch:  93 Step:   121 /   793 Train loss: 0.02651023\r\n",
      "Epoch:  93 Step:   122 /   793 Train loss: 0.01432034\r\n",
      "Epoch:  93 Step:   123 /   793 Train loss: 0.02194258\r\n",
      "Epoch:  93 Step:   124 /   793 Train loss: 0.01661295\r\n",
      "Epoch:  93 Step:   125 /   793 Train loss: 0.01639138\r\n",
      "Epoch:  93 Step:   126 /   793 Train loss: 0.02834988\r\n",
      "Epoch:  93 Step:   127 /   793 Train loss: 0.02616067\r\n",
      "Epoch:  93 Step:   128 /   793 Train loss: 0.02066719\r\n",
      "Epoch:  93 Step:   129 /   793 Train loss: 0.03390994\r\n",
      "Epoch:  93 Step:   130 /   793 Train loss: 0.01579764\r\n",
      "Epoch:  93 Step:   131 /   793 Train loss: 0.01624087\r\n",
      "Epoch:  93 Step:   132 /   793 Train loss: 0.01749047\r\n",
      "Epoch:  93 Step:   133 /   793 Train loss: 0.03162593\r\n",
      "Epoch:  93 Step:   134 /   793 Train loss: 0.02248332\r\n",
      "Epoch:  93 Step:   135 /   793 Train loss: 0.03907973\r\n",
      "Epoch:  93 Step:   136 /   793 Train loss: 0.02940851\r\n",
      "Epoch:  93 Step:   137 /   793 Train loss: 0.01393483\r\n",
      "Epoch:  93 Step:   138 /   793 Train loss: 0.03289580\r\n",
      "Epoch:  93 Step:   139 /   793 Train loss: 0.02706851\r\n",
      "Epoch:  93 Step:   140 /   793 Train loss: 0.02771918\r\n",
      "Epoch:  93 Step:   141 /   793 Train loss: 0.02849451\r\n",
      "Epoch:  93 Step:   142 /   793 Train loss: 0.03125355\r\n",
      "Epoch:  93 Step:   143 /   793 Train loss: 0.02598753\r\n",
      "Epoch:  93 Step:   144 /   793 Train loss: 0.02164032\r\n",
      "Epoch:  93 Step:   145 /   793 Train loss: 0.01851447\r\n",
      "Epoch:  93 Step:   146 /   793 Train loss: 0.02541373\r\n",
      "Epoch:  93 Step:   147 /   793 Train loss: 0.03023303\r\n",
      "Epoch:  93 Step:   148 /   793 Train loss: 0.03422628\r\n",
      "Epoch:  93 Step:   149 /   793 Train loss: 0.02435280\r\n",
      "Epoch:  93 Step:   150 /   793 Train loss: 0.01694038\r\n",
      "Epoch:  93 Step:   151 /   793 Train loss: 0.01403545\r\n",
      "Epoch:  93 Step:   152 /   793 Train loss: 0.02271504\r\n",
      "Epoch:  93 Step:   153 /   793 Train loss: 0.02749597\r\n",
      "Epoch:  93 Step:   154 /   793 Train loss: 0.01973690\r\n",
      "Epoch:  93 Step:   155 /   793 Train loss: 0.02414324\r\n",
      "Epoch:  93 Step:   156 /   793 Train loss: 0.01625844\r\n",
      "Epoch:  93 Step:   157 /   793 Train loss: 0.02398083\r\n",
      "Epoch:  93 Step:   158 /   793 Train loss: 0.02566827\r\n",
      "Epoch:  93 Step:   159 /   793 Train loss: 0.01704819\r\n",
      "Epoch:  93 Step:   160 /   793 Train loss: 0.01982788\r\n",
      "Epoch:  93 Step:   161 /   793 Train loss: 0.01809340\r\n",
      "Epoch:  93 Step:   162 /   793 Train loss: 0.03432611\r\n",
      "Epoch:  93 Step:   163 /   793 Train loss: 0.02682435\r\n",
      "Epoch:  93 Step:   164 /   793 Train loss: 0.03333368\r\n",
      "Epoch:  93 Step:   165 /   793 Train loss: 0.02558292\r\n",
      "Epoch:  93 Step:   166 /   793 Train loss: 0.02058401\r\n",
      "Epoch:  93 Step:   167 /   793 Train loss: 0.03209320\r\n",
      "Epoch:  93 Step:   168 /   793 Train loss: 0.01467616\r\n",
      "Epoch:  93 Step:   169 /   793 Train loss: 0.02817976\r\n",
      "Epoch:  93 Step:   170 /   793 Train loss: 0.01680126\r\n",
      "Epoch:  93 Step:   171 /   793 Train loss: 0.03231613\r\n",
      "Epoch:  93 Step:   172 /   793 Train loss: 0.01743231\r\n",
      "Epoch:  93 Step:   173 /   793 Train loss: 0.03306455\r\n",
      "Epoch:  93 Step:   174 /   793 Train loss: 0.03462509\r\n",
      "Epoch:  93 Step:   175 /   793 Train loss: 0.03084652\r\n",
      "Epoch:  93 Step:   176 /   793 Train loss: 0.01500055\r\n",
      "Epoch:  93 Step:   177 /   793 Train loss: 0.01497108\r\n",
      "Epoch:  93 Step:   178 /   793 Train loss: 0.03073305\r\n",
      "Epoch:  93 Step:   179 /   793 Train loss: 0.01567657\r\n",
      "Epoch:  93 Step:   180 /   793 Train loss: 0.02891643\r\n",
      "Epoch:  93 Step:   181 /   793 Train loss: 0.01612930\r\n",
      "Epoch:  93 Step:   182 /   793 Train loss: 0.02762569\r\n",
      "Epoch:  93 Step:   183 /   793 Train loss: 0.02362251\r\n",
      "Epoch:  93 Step:   184 /   793 Train loss: 0.01635366\r\n",
      "Epoch:  93 Step:   185 /   793 Train loss: 0.02048806\r\n",
      "Epoch:  93 Step:   186 /   793 Train loss: 0.01752769\r\n",
      "Epoch:  93 Step:   187 /   793 Train loss: 0.01750943\r\n",
      "Epoch:  93 Step:   188 /   793 Train loss: 0.02723668\r\n",
      "Epoch:  93 Step:   189 /   793 Train loss: 0.02676838\r\n",
      "Epoch:  93 Step:   190 /   793 Train loss: 0.02817506\r\n",
      "Epoch:  93 Step:   191 /   793 Train loss: 0.03289162\r\n",
      "Epoch:  93 Step:   192 /   793 Train loss: 0.03717357\r\n",
      "Epoch:  93 Step:   193 /   793 Train loss: 0.02032069\r\n",
      "Epoch:  93 Step:   194 /   793 Train loss: 0.02201739\r\n",
      "Epoch:  93 Step:   195 /   793 Train loss: 0.02772710\r\n",
      "Epoch:  93 Step:   196 /   793 Train loss: 0.02055564\r\n",
      "Epoch:  93 Step:   197 /   793 Train loss: 0.01738949\r\n",
      "Epoch:  93 Step:   198 /   793 Train loss: 0.02275450\r\n",
      "Epoch:  93 Step:   199 /   793 Train loss: 0.03029126\r\n",
      "Epoch:  93 Step:   200 /   793 Train loss: 0.01826693\r\n",
      "Epoch:  93 Step:   201 /   793 Train loss: 0.01845805\r\n",
      "Epoch:  93 Step:   202 /   793 Train loss: 0.02578058\r\n",
      "Epoch:  93 Step:   203 /   793 Train loss: 0.02263648\r\n",
      "Epoch:  93 Step:   204 /   793 Train loss: 0.02878930\r\n",
      "Epoch:  93 Step:   205 /   793 Train loss: 0.02705823\r\n",
      "Epoch:  93 Step:   206 /   793 Train loss: 0.01419911\r\n",
      "Epoch:  93 Step:   207 /   793 Train loss: 0.02686122\r\n",
      "Epoch:  93 Step:   208 /   793 Train loss: 0.03405590\r\n",
      "Epoch:  93 Step:   209 /   793 Train loss: 0.01886744\r\n",
      "Epoch:  93 Step:   210 /   793 Train loss: 0.02801635\r\n",
      "Epoch:  93 Step:   211 /   793 Train loss: 0.03003215\r\n",
      "Epoch:  93 Step:   212 /   793 Train loss: 0.02111858\r\n",
      "Epoch:  93 Step:   213 /   793 Train loss: 0.01590436\r\n",
      "Epoch:  93 Step:   214 /   793 Train loss: 0.03312962\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  93 Step:   215 /   793 Train loss: 0.02958740\r\n",
      "Epoch:  93 Step:   216 /   793 Train loss: 0.02409145\r\n",
      "Epoch:  93 Step:   217 /   793 Train loss: 0.01976264\r\n",
      "Epoch:  93 Step:   218 /   793 Train loss: 0.03103130\r\n",
      "Epoch:  93 Step:   219 /   793 Train loss: 0.04064749\r\n",
      "Epoch:  93 Step:   220 /   793 Train loss: 0.02853824\r\n",
      "Epoch:  93 Step:   221 /   793 Train loss: 0.03368702\r\n",
      "Epoch:  93 Step:   222 /   793 Train loss: 0.02449784\r\n",
      "Epoch:  93 Step:   223 /   793 Train loss: 0.02211701\r\n",
      "Epoch:  93 Step:   224 /   793 Train loss: 0.02204305\r\n",
      "Epoch:  93 Step:   225 /   793 Train loss: 0.01431458\r\n",
      "Epoch:  93 Step:   226 /   793 Train loss: 0.02819965\r\n",
      "Epoch:  93 Step:   227 /   793 Train loss: 0.01076490\r\n",
      "Epoch:  93 Step:   228 /   793 Train loss: 0.01890181\r\n",
      "Epoch:  93 Step:   229 /   793 Train loss: 0.02334512\r\n",
      "Epoch:  93 Step:   230 /   793 Train loss: 0.03305430\r\n",
      "Epoch:  93 Step:   231 /   793 Train loss: 0.01343599\r\n",
      "Epoch:  93 Step:   232 /   793 Train loss: 0.03469798\r\n",
      "Epoch:  93 Step:   233 /   793 Train loss: 0.01916178\r\n",
      "Epoch:  93 Step:   234 /   793 Train loss: 0.03124183\r\n",
      "Epoch:  93 Step:   235 /   793 Train loss: 0.02592638\r\n",
      "Epoch:  93 Step:   236 /   793 Train loss: 0.02881291\r\n",
      "Epoch:  93 Step:   237 /   793 Train loss: 0.01955583\r\n",
      "Epoch:  93 Step:   238 /   793 Train loss: 0.01114477\r\n",
      "Epoch:  93 Step:   239 /   793 Train loss: 0.01971969\r\n",
      "Epoch:  93 Step:   240 /   793 Train loss: 0.02737601\r\n",
      "Epoch:  93 Step:   241 /   793 Train loss: 0.02732972\r\n",
      "Epoch:  93 Step:   242 /   793 Train loss: 0.01901479\r\n",
      "Epoch:  93 Step:   243 /   793 Train loss: 0.02239997\r\n",
      "Epoch:  93 Step:   244 /   793 Train loss: 0.02060501\r\n",
      "Epoch:  93 Step:   245 /   793 Train loss: 0.03542969\r\n",
      "Epoch:  93 Step:   246 /   793 Train loss: 0.03143492\r\n",
      "Epoch:  93 Step:   247 /   793 Train loss: 0.02197268\r\n",
      "Epoch:  93 Step:   248 /   793 Train loss: 0.02429666\r\n",
      "Epoch:  93 Step:   249 /   793 Train loss: 0.03477519\r\n",
      "Epoch:  93 Step:   250 /   793 Train loss: 0.02019148\r\n",
      "Epoch:  93 Step:   251 /   793 Train loss: 0.02523988\r\n",
      "Epoch:  93 Step:   252 /   793 Train loss: 0.01646565\r\n",
      "Epoch:  93 Step:   253 /   793 Train loss: 0.02594492\r\n",
      "Epoch:  93 Step:   254 /   793 Train loss: 0.02047526\r\n",
      "Epoch:  93 Step:   255 /   793 Train loss: 0.01822794\r\n",
      "Epoch:  93 Step:   256 /   793 Train loss: 0.02220652\r\n",
      "Epoch:  93 Step:   257 /   793 Train loss: 0.03034127\r\n",
      "Epoch:  93 Step:   258 /   793 Train loss: 0.01243425\r\n",
      "Epoch:  93 Step:   259 /   793 Train loss: 0.03314585\r\n",
      "Epoch:  93 Step:   260 /   793 Train loss: 0.02609000\r\n",
      "Epoch:  93 Step:   261 /   793 Train loss: 0.01548062\r\n",
      "Epoch:  93 Step:   262 /   793 Train loss: 0.01907271\r\n",
      "Epoch:  93 Step:   263 /   793 Train loss: 0.03167093\r\n",
      "Epoch:  93 Step:   264 /   793 Train loss: 0.02583047\r\n",
      "Epoch:  93 Step:   265 /   793 Train loss: 0.02167866\r\n",
      "Epoch:  93 Step:   266 /   793 Train loss: 0.02477800\r\n",
      "Epoch:  93 Step:   267 /   793 Train loss: 0.01762342\r\n",
      "Epoch:  93 Step:   268 /   793 Train loss: 0.01510853\r\n",
      "Epoch:  93 Step:   269 /   793 Train loss: 0.02498500\r\n",
      "Epoch:  93 Step:   270 /   793 Train loss: 0.01793069\r\n",
      "Epoch:  93 Step:   271 /   793 Train loss: 0.03836899\r\n",
      "Epoch:  93 Step:   272 /   793 Train loss: 0.02157127\r\n",
      "Epoch:  93 Step:   273 /   793 Train loss: 0.02940852\r\n",
      "Epoch:  93 Step:   274 /   793 Train loss: 0.01607164\r\n",
      "Epoch:  93 Step:   275 /   793 Train loss: 0.02270341\r\n",
      "Epoch:  93 Step:   276 /   793 Train loss: 0.02188340\r\n",
      "Epoch:  93 Step:   277 /   793 Train loss: 0.04244155\r\n",
      "Epoch:  93 Step:   278 /   793 Train loss: 0.01733783\r\n",
      "Epoch:  93 Step:   279 /   793 Train loss: 0.01709149\r\n",
      "Epoch:  93 Step:   280 /   793 Train loss: 0.02010639\r\n",
      "Epoch:  93 Step:   281 /   793 Train loss: 0.02688311\r\n",
      "Epoch:  93 Step:   282 /   793 Train loss: 0.02250728\r\n",
      "Epoch:  93 Step:   283 /   793 Train loss: 0.02204411\r\n",
      "Epoch:  93 Step:   284 /   793 Train loss: 0.03508005\r\n",
      "Epoch:  93 Step:   285 /   793 Train loss: 0.01492336\r\n",
      "Epoch:  93 Step:   286 /   793 Train loss: 0.01405141\r\n",
      "Epoch:  93 Step:   287 /   793 Train loss: 0.03511245\r\n",
      "Epoch:  93 Step:   288 /   793 Train loss: 0.02482161\r\n",
      "Epoch:  93 Step:   289 /   793 Train loss: 0.02308104\r\n",
      "Epoch:  93 Step:   290 /   793 Train loss: 0.02641322\r\n",
      "Epoch:  93 Step:   291 /   793 Train loss: 0.02385284\r\n",
      "Epoch:  93 Step:   292 /   793 Train loss: 0.01607605\r\n",
      "Epoch:  93 Step:   293 /   793 Train loss: 0.02097622\r\n",
      "Epoch:  93 Step:   294 /   793 Train loss: 0.02895491\r\n",
      "Epoch:  93 Step:   295 /   793 Train loss: 0.02288266\r\n",
      "Epoch:  93 Step:   296 /   793 Train loss: 0.02664206\r\n",
      "Epoch:  93 Step:   297 /   793 Train loss: 0.03992387\r\n",
      "Epoch:  93 Step:   298 /   793 Train loss: 0.02749504\r\n",
      "Epoch:  93 Step:   299 /   793 Train loss: 0.01776746\r\n",
      "Epoch:  93 Step:   300 /   793 Train loss: 0.03554275\r\n",
      "Epoch:  93 Step:   301 /   793 Train loss: 0.02598099\r\n",
      "Epoch:  93 Step:   302 /   793 Train loss: 0.02260263\r\n",
      "Epoch:  93 Step:   303 /   793 Train loss: 0.02553322\r\n",
      "Epoch:  93 Step:   304 /   793 Train loss: 0.01388939\r\n",
      "Epoch:  93 Step:   305 /   793 Train loss: 0.03340326\r\n",
      "Epoch:  93 Step:   306 /   793 Train loss: 0.02244028\r\n",
      "Epoch:  93 Step:   307 /   793 Train loss: 0.01258721\r\n",
      "Epoch:  93 Step:   308 /   793 Train loss: 0.02704479\r\n",
      "Epoch:  93 Step:   309 /   793 Train loss: 0.01738815\r\n",
      "Epoch:  93 Step:   310 /   793 Train loss: 0.02104569\r\n",
      "Epoch:  93 Step:   311 /   793 Train loss: 0.03564875\r\n",
      "Epoch:  93 Step:   312 /   793 Train loss: 0.01461175\r\n",
      "Epoch:  93 Step:   313 /   793 Train loss: 0.02257641\r\n",
      "Epoch:  93 Step:   314 /   793 Train loss: 0.01473586\r\n",
      "Epoch:  93 Step:   315 /   793 Train loss: 0.03173582\r\n",
      "Epoch:  93 Step:   316 /   793 Train loss: 0.00962311\r\n",
      "Epoch:  93 Step:   317 /   793 Train loss: 0.03352623\r\n",
      "Epoch:  93 Step:   318 /   793 Train loss: 0.02073399\r\n",
      "Epoch:  93 Step:   319 /   793 Train loss: 0.03223944\r\n",
      "Epoch:  93 Step:   320 /   793 Train loss: 0.03032806\r\n",
      "Epoch:  93 Step:   321 /   793 Train loss: 0.02358815\r\n",
      "Epoch:  93 Step:   322 /   793 Train loss: 0.02926033\r\n",
      "Epoch:  93 Step:   323 /   793 Train loss: 0.01108809\r\n",
      "Epoch:  93 Step:   324 /   793 Train loss: 0.02380730\r\n",
      "Epoch:  93 Step:   325 /   793 Train loss: 0.02838109\r\n",
      "Epoch:  93 Step:   326 /   793 Train loss: 0.02158622\r\n",
      "Epoch:  93 Step:   327 /   793 Train loss: 0.02089847\r\n",
      "Epoch:  93 Step:   328 /   793 Train loss: 0.02426378\r\n",
      "Epoch:  93 Step:   329 /   793 Train loss: 0.03684284\r\n",
      "Epoch:  93 Step:   330 /   793 Train loss: 0.02446831\r\n",
      "Epoch:  93 Step:   331 /   793 Train loss: 0.01702292\r\n",
      "Epoch:  93 Step:   332 /   793 Train loss: 0.01623057\r\n",
      "Epoch:  93 Step:   333 /   793 Train loss: 0.01638910\r\n",
      "Epoch:  93 Step:   334 /   793 Train loss: 0.01779316\r\n",
      "Epoch:  93 Step:   335 /   793 Train loss: 0.02627013\r\n",
      "Epoch:  93 Step:   336 /   793 Train loss: 0.03774051\r\n",
      "Epoch:  93 Step:   337 /   793 Train loss: 0.02313731\r\n",
      "Epoch:  93 Step:   338 /   793 Train loss: 0.01710997\r\n",
      "Epoch:  93 Step:   339 /   793 Train loss: 0.01673096\r\n",
      "Epoch:  93 Step:   340 /   793 Train loss: 0.02001462\r\n",
      "Epoch:  93 Step:   341 /   793 Train loss: 0.02068375\r\n",
      "Epoch:  93 Step:   342 /   793 Train loss: 0.01754894\r\n",
      "Epoch:  93 Step:   343 /   793 Train loss: 0.02563768\r\n",
      "Epoch:  93 Step:   344 /   793 Train loss: 0.02333339\r\n",
      "Epoch:  93 Step:   345 /   793 Train loss: 0.01363749\r\n",
      "Epoch:  93 Step:   346 /   793 Train loss: 0.01178379\r\n",
      "Epoch:  93 Step:   347 /   793 Train loss: 0.01864871\r\n",
      "Epoch:  93 Step:   348 /   793 Train loss: 0.01717531\r\n",
      "Epoch:  93 Step:   349 /   793 Train loss: 0.03635310\r\n",
      "Epoch:  93 Step:   350 /   793 Train loss: 0.02720552\r\n",
      "Epoch:  93 Step:   351 /   793 Train loss: 0.01660700\r\n",
      "Epoch:  93 Step:   352 /   793 Train loss: 0.01527230\r\n",
      "Epoch:  93 Step:   353 /   793 Train loss: 0.01569756\r\n",
      "Epoch:  93 Step:   354 /   793 Train loss: 0.02466313\r\n",
      "Epoch:  93 Step:   355 /   793 Train loss: 0.02951759\r\n",
      "Epoch:  93 Step:   356 /   793 Train loss: 0.03283459\r\n",
      "Epoch:  93 Step:   357 /   793 Train loss: 0.01592785\r\n",
      "Epoch:  93 Step:   358 /   793 Train loss: 0.03001367\r\n",
      "Epoch:  93 Step:   359 /   793 Train loss: 0.02112743\r\n",
      "Epoch:  93 Step:   360 /   793 Train loss: 0.02512214\r\n",
      "Epoch:  93 Step:   361 /   793 Train loss: 0.02411638\r\n",
      "Epoch:  93 Step:   362 /   793 Train loss: 0.02688498\r\n",
      "Epoch:  93 Step:   363 /   793 Train loss: 0.02504315\r\n",
      "Epoch:  93 Step:   364 /   793 Train loss: 0.02366984\r\n",
      "Epoch:  93 Step:   365 /   793 Train loss: 0.03222647\r\n",
      "Epoch:  93 Step:   366 /   793 Train loss: 0.02479400\r\n",
      "Epoch:  93 Step:   367 /   793 Train loss: 0.02448374\r\n",
      "Epoch:  93 Step:   368 /   793 Train loss: 0.03187111\r\n",
      "Epoch:  93 Step:   369 /   793 Train loss: 0.02767604\r\n",
      "Epoch:  93 Step:   370 /   793 Train loss: 0.01408551\r\n",
      "Epoch:  93 Step:   371 /   793 Train loss: 0.02955525\r\n",
      "Epoch:  93 Step:   372 /   793 Train loss: 0.02037108\r\n",
      "Epoch:  93 Step:   373 /   793 Train loss: 0.02131202\r\n",
      "Epoch:  93 Step:   374 /   793 Train loss: 0.02343127\r\n",
      "Epoch:  93 Step:   375 /   793 Train loss: 0.01639229\r\n",
      "Epoch:  93 Step:   376 /   793 Train loss: 0.01936809\r\n",
      "Epoch:  93 Step:   377 /   793 Train loss: 0.02979156\r\n",
      "Epoch:  93 Step:   378 /   793 Train loss: 0.02071585\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  93 Step:   379 /   793 Train loss: 0.02229765\r\n",
      "Epoch:  93 Step:   380 /   793 Train loss: 0.01792482\r\n",
      "Epoch:  93 Step:   381 /   793 Train loss: 0.00870123\r\n",
      "Epoch:  93 Step:   382 /   793 Train loss: 0.01789728\r\n",
      "Epoch:  93 Step:   383 /   793 Train loss: 0.02534292\r\n",
      "Epoch:  93 Step:   384 /   793 Train loss: 0.02542334\r\n",
      "Epoch:  93 Step:   385 /   793 Train loss: 0.02155009\r\n",
      "Epoch:  93 Step:   386 /   793 Train loss: 0.01554494\r\n",
      "Epoch:  93 Step:   387 /   793 Train loss: 0.03157850\r\n",
      "Epoch:  93 Step:   388 /   793 Train loss: 0.02677177\r\n",
      "Epoch:  93 Step:   389 /   793 Train loss: 0.02191177\r\n",
      "Epoch:  93 Step:   390 /   793 Train loss: 0.02143463\r\n",
      "Epoch:  93 Step:   391 /   793 Train loss: 0.03822903\r\n",
      "Epoch:  93 Step:   392 /   793 Train loss: 0.02545743\r\n",
      "Epoch:  93 Step:   393 /   793 Train loss: 0.01206865\r\n",
      "Epoch:  93 Step:   394 /   793 Train loss: 0.02264003\r\n",
      "Epoch:  93 Step:   395 /   793 Train loss: 0.02812889\r\n",
      "Epoch:  93 Step:   396 /   793 Train loss: 0.01617397\r\n",
      "Epoch:  93 Step:   397 /   793 Train loss: 0.02128200\r\n",
      "Epoch:  93 Step:   398 /   793 Train loss: 0.02200572\r\n",
      "Epoch:  93 Step:   399 /   793 Train loss: 0.02468470\r\n",
      "Epoch:  93 Step:   400 /   793 Train loss: 0.03903263\r\n",
      "Epoch:  93 Step:   401 /   793 Train loss: 0.02465754\r\n",
      "Epoch:  93 Step:   402 /   793 Train loss: 0.02597238\r\n",
      "Epoch:  93 Step:   403 /   793 Train loss: 0.01324170\r\n",
      "Epoch:  93 Step:   404 /   793 Train loss: 0.02445399\r\n",
      "Epoch:  93 Step:   405 /   793 Train loss: 0.01611445\r\n",
      "Epoch:  93 Step:   406 /   793 Train loss: 0.01768875\r\n",
      "Epoch:  93 Step:   407 /   793 Train loss: 0.02978411\r\n",
      "Epoch:  93 Step:   408 /   793 Train loss: 0.02252503\r\n",
      "Epoch:  93 Step:   409 /   793 Train loss: 0.01946273\r\n",
      "Epoch:  93 Step:   410 /   793 Train loss: 0.02129911\r\n",
      "Epoch:  93 Step:   411 /   793 Train loss: 0.03026960\r\n",
      "Epoch:  93 Step:   412 /   793 Train loss: 0.02607220\r\n",
      "Epoch:  93 Step:   413 /   793 Train loss: 0.02528739\r\n",
      "Epoch:  93 Step:   414 /   793 Train loss: 0.01859614\r\n",
      "Epoch:  93 Step:   415 /   793 Train loss: 0.03211086\r\n",
      "Epoch:  93 Step:   416 /   793 Train loss: 0.02017266\r\n",
      "Epoch:  93 Step:   417 /   793 Train loss: 0.02130130\r\n",
      "Epoch:  93 Step:   418 /   793 Train loss: 0.02913112\r\n",
      "Epoch:  93 Step:   419 /   793 Train loss: 0.02602093\r\n",
      "Epoch:  93 Step:   420 /   793 Train loss: 0.01821266\r\n",
      "Epoch:  93 Step:   421 /   793 Train loss: 0.02502266\r\n",
      "Epoch:  93 Step:   422 /   793 Train loss: 0.02109108\r\n",
      "Epoch:  93 Step:   423 /   793 Train loss: 0.02585413\r\n",
      "Epoch:  93 Step:   424 /   793 Train loss: 0.01830002\r\n",
      "Epoch:  93 Step:   425 /   793 Train loss: 0.02321514\r\n",
      "Epoch:  93 Step:   426 /   793 Train loss: 0.02598073\r\n",
      "Epoch:  93 Step:   427 /   793 Train loss: 0.02452974\r\n",
      "Epoch:  93 Step:   428 /   793 Train loss: 0.03507209\r\n",
      "Epoch:  93 Step:   429 /   793 Train loss: 0.03932305\r\n",
      "Epoch:  93 Step:   430 /   793 Train loss: 0.03174663\r\n",
      "Epoch:  93 Step:   431 /   793 Train loss: 0.02537419\r\n",
      "Epoch:  93 Step:   432 /   793 Train loss: 0.01593017\r\n",
      "Epoch:  93 Step:   433 /   793 Train loss: 0.02508054\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  93 Step:   434 /   793 Train loss: 0.01887179\r\n",
      "Epoch:  93 Step:   435 /   793 Train loss: 0.02130767\r\n",
      "Epoch:  93 Step:   436 /   793 Train loss: 0.02837782\r\n",
      "Epoch:  93 Step:   437 /   793 Train loss: 0.03444370\r\n",
      "Epoch:  93 Step:   438 /   793 Train loss: 0.03019772\r\n",
      "Epoch:  93 Step:   439 /   793 Train loss: 0.02239351\r\n",
      "Epoch:  93 Step:   440 /   793 Train loss: 0.02094551\r\n",
      "Epoch:  93 Step:   441 /   793 Train loss: 0.03746802\r\n",
      "Epoch:  93 Step:   442 /   793 Train loss: 0.03400263\r\n",
      "Epoch:  93 Step:   443 /   793 Train loss: 0.01952957\r\n",
      "Epoch:  93 Step:   444 /   793 Train loss: 0.02863076\r\n",
      "Epoch:  93 Step:   445 /   793 Train loss: 0.02120153\r\n",
      "Epoch:  93 Step:   446 /   793 Train loss: 0.03619326\r\n",
      "Epoch:  93 Step:   447 /   793 Train loss: 0.03240459\r\n",
      "Epoch:  93 Step:   448 /   793 Train loss: 0.02462802\r\n",
      "Epoch:  93 Step:   449 /   793 Train loss: 0.02330089\r\n",
      "Epoch:  93 Step:   450 /   793 Train loss: 0.02810919\r\n",
      "Epoch:  93 Step:   451 /   793 Train loss: 0.02368374\r\n",
      "Epoch:  93 Step:   452 /   793 Train loss: 0.02178112\r\n",
      "Epoch:  93 Step:   453 /   793 Train loss: 0.03136921\r\n",
      "Epoch:  93 Step:   454 /   793 Train loss: 0.02741862\r\n",
      "Epoch:  93 Step:   455 /   793 Train loss: 0.03147634\r\n",
      "Epoch:  93 Step:   456 /   793 Train loss: 0.02897680\r\n",
      "Epoch:  93 Step:   457 /   793 Train loss: 0.01783710\r\n",
      "Epoch:  93 Step:   458 /   793 Train loss: 0.02430969\r\n",
      "Epoch:  93 Step:   459 /   793 Train loss: 0.01922974\r\n",
      "Epoch:  93 Step:   460 /   793 Train loss: 0.02461555\r\n",
      "Epoch:  93 Step:   461 /   793 Train loss: 0.01736047\r\n",
      "Epoch:  93 Step:   462 /   793 Train loss: 0.02855683\r\n",
      "Epoch:  93 Step:   463 /   793 Train loss: 0.01963754\r\n",
      "Epoch:  93 Step:   464 /   793 Train loss: 0.02389318\r\n",
      "Epoch:  93 Step:   465 /   793 Train loss: 0.02060739\r\n",
      "Epoch:  93 Step:   466 /   793 Train loss: 0.01931314\r\n",
      "Epoch:  93 Step:   467 /   793 Train loss: 0.03896416\r\n",
      "Epoch:  93 Step:   468 /   793 Train loss: 0.03580274\r\n",
      "Epoch:  93 Step:   469 /   793 Train loss: 0.02581822\r\n",
      "Epoch:  93 Step:   470 /   793 Train loss: 0.01870031\r\n",
      "Epoch:  93 Step:   471 /   793 Train loss: 0.03061635\r\n",
      "Epoch:  93 Step:   472 /   793 Train loss: 0.02656012\r\n",
      "Epoch:  93 Step:   473 /   793 Train loss: 0.02302291\r\n",
      "Epoch:  93 Step:   474 /   793 Train loss: 0.02989476\r\n",
      "Epoch:  93 Step:   475 /   793 Train loss: 0.02500918\r\n",
      "Epoch:  93 Step:   476 /   793 Train loss: 0.01514224\r\n",
      "Epoch:  93 Step:   477 /   793 Train loss: 0.02506714\r\n",
      "Epoch:  93 Step:   478 /   793 Train loss: 0.03563448\r\n",
      "Epoch:  93 Step:   479 /   793 Train loss: 0.02071312\r\n",
      "Epoch:  93 Step:   480 /   793 Train loss: 0.01938494\r\n",
      "Epoch:  93 Step:   481 /   793 Train loss: 0.02447748\r\n",
      "Epoch:  93 Step:   482 /   793 Train loss: 0.02177286\r\n",
      "Epoch:  93 Step:   483 /   793 Train loss: 0.02260794\r\n",
      "Epoch:  93 Step:   484 /   793 Train loss: 0.02460577\r\n",
      "Epoch:  93 Step:   485 /   793 Train loss: 0.01519702\r\n",
      "Epoch:  93 Step:   486 /   793 Train loss: 0.02776031\r\n",
      "Epoch:  93 Step:   487 /   793 Train loss: 0.03658923\r\n",
      "Epoch:  93 Step:   488 /   793 Train loss: 0.01917897\r\n",
      "Epoch:  93 Step:   489 /   793 Train loss: 0.02492869\r\n",
      "Epoch:  93 Step:   490 /   793 Train loss: 0.03383766\r\n",
      "Epoch:  93 Step:   491 /   793 Train loss: 0.02188764\r\n",
      "Epoch:  93 Step:   492 /   793 Train loss: 0.02179199\r\n",
      "Epoch:  93 Step:   493 /   793 Train loss: 0.02835944\r\n",
      "Epoch:  93 Step:   494 /   793 Train loss: 0.01989214\r\n",
      "Epoch:  93 Step:   495 /   793 Train loss: 0.03305154\r\n",
      "Epoch:  93 Step:   496 /   793 Train loss: 0.02629388\r\n",
      "Epoch:  93 Step:   497 /   793 Train loss: 0.02284010\r\n",
      "Epoch:  93 Step:   498 /   793 Train loss: 0.01497988\r\n",
      "Epoch:  93 Step:   499 /   793 Train loss: 0.02142715\r\n",
      "Epoch:  93 Step:   500 /   793 Train loss: 0.02007300\r\n",
      "Epoch:  93 Step:   501 /   793 Train loss: 0.02375577\r\n",
      "Epoch:  93 Step:   502 /   793 Train loss: 0.02940280\r\n",
      "Epoch:  93 Step:   503 /   793 Train loss: 0.02105872\r\n",
      "Epoch:  93 Step:   504 /   793 Train loss: 0.02672420\r\n",
      "Epoch:  93 Step:   505 /   793 Train loss: 0.02567265\r\n",
      "Epoch:  93 Step:   506 /   793 Train loss: 0.03475329\r\n",
      "Epoch:  93 Step:   507 /   793 Train loss: 0.02779859\r\n",
      "Epoch:  93 Step:   508 /   793 Train loss: 0.02385164\r\n",
      "Epoch:  93 Step:   509 /   793 Train loss: 0.02421159\r\n",
      "Epoch:  93 Step:   510 /   793 Train loss: 0.02118876\r\n",
      "Epoch:  93 Step:   511 /   793 Train loss: 0.03167178\r\n",
      "Epoch:  93 Step:   512 /   793 Train loss: 0.02582292\r\n",
      "Epoch:  93 Step:   513 /   793 Train loss: 0.02480632\r\n",
      "Epoch:  93 Step:   514 /   793 Train loss: 0.02179661\r\n",
      "Epoch:  93 Step:   515 /   793 Train loss: 0.02138986\r\n",
      "Epoch:  93 Step:   516 /   793 Train loss: 0.02803063\r\n",
      "Epoch:  93 Step:   517 /   793 Train loss: 0.01247430\r\n",
      "Epoch:  93 Step:   518 /   793 Train loss: 0.02729094\r\n",
      "Epoch:  93 Step:   519 /   793 Train loss: 0.01545188\r\n",
      "Epoch:  93 Step:   520 /   793 Train loss: 0.02530700\r\n",
      "Epoch:  93 Step:   521 /   793 Train loss: 0.03568000\r\n",
      "Epoch:  93 Step:   522 /   793 Train loss: 0.01074219\r\n",
      "Epoch:  93 Step:   523 /   793 Train loss: 0.02644933\r\n",
      "Epoch:  93 Step:   524 /   793 Train loss: 0.01996228\r\n",
      "Epoch:  93 Step:   525 /   793 Train loss: 0.02455019\r\n",
      "Epoch:  93 Step:   526 /   793 Train loss: 0.04691693\r\n",
      "Epoch:  93 Step:   527 /   793 Train loss: 0.03187095\r\n",
      "Epoch:  93 Step:   528 /   793 Train loss: 0.01826605\r\n",
      "Epoch:  93 Step:   529 /   793 Train loss: 0.03373469\r\n",
      "Epoch:  93 Step:   530 /   793 Train loss: 0.02365697\r\n",
      "Epoch:  93 Step:   531 /   793 Train loss: 0.02598028\r\n",
      "Epoch:  93 Step:   532 /   793 Train loss: 0.01916580\r\n",
      "Epoch:  93 Step:   533 /   793 Train loss: 0.03146483\r\n",
      "Epoch:  93 Step:   534 /   793 Train loss: 0.02437744\r\n",
      "Epoch:  93 Step:   535 /   793 Train loss: 0.03320665\r\n",
      "Epoch:  93 Step:   536 /   793 Train loss: 0.02238877\r\n",
      "Epoch:  93 Step:   537 /   793 Train loss: 0.01827596\r\n",
      "Epoch:  93 Step:   538 /   793 Train loss: 0.03106563\r\n",
      "Epoch:  93 Step:   539 /   793 Train loss: 0.01908465\r\n",
      "Epoch:  93 Step:   540 /   793 Train loss: 0.03566791\r\n",
      "Epoch:  93 Step:   541 /   793 Train loss: 0.01817757\r\n",
      "Epoch:  93 Step:   542 /   793 Train loss: 0.02135012\r\n",
      "Epoch:  93 Step:   543 /   793 Train loss: 0.02205358\r\n",
      "Epoch:  93 Step:   544 /   793 Train loss: 0.02005380\r\n",
      "Epoch:  93 Step:   545 /   793 Train loss: 0.02293033\r\n",
      "Epoch:  93 Step:   546 /   793 Train loss: 0.02895617\r\n",
      "Epoch:  93 Step:   547 /   793 Train loss: 0.01955256\r\n",
      "Epoch:  93 Step:   548 /   793 Train loss: 0.02403704\r\n",
      "Epoch:  93 Step:   549 /   793 Train loss: 0.03841901\r\n",
      "Epoch:  93 Step:   550 /   793 Train loss: 0.02969620\r\n",
      "Epoch:  93 Step:   551 /   793 Train loss: 0.02342852\r\n",
      "Epoch:  93 Step:   552 /   793 Train loss: 0.02076614\r\n",
      "Epoch:  93 Step:   553 /   793 Train loss: 0.01882154\r\n",
      "Epoch:  93 Step:   554 /   793 Train loss: 0.03066189\r\n",
      "Epoch:  93 Step:   555 /   793 Train loss: 0.02403903\r\n",
      "Epoch:  93 Step:   556 /   793 Train loss: 0.01608482\r\n",
      "Epoch:  93 Step:   557 /   793 Train loss: 0.01515013\r\n",
      "Epoch:  93 Step:   558 /   793 Train loss: 0.02107378\r\n",
      "Epoch:  93 Step:   559 /   793 Train loss: 0.02518620\r\n",
      "Epoch:  93 Step:   560 /   793 Train loss: 0.02379081\r\n",
      "Epoch:  93 Step:   561 /   793 Train loss: 0.03583686\r\n",
      "Epoch:  93 Step:   562 /   793 Train loss: 0.01820841\r\n",
      "Epoch:  93 Step:   563 /   793 Train loss: 0.03276266\r\n",
      "Epoch:  93 Step:   564 /   793 Train loss: 0.01707444\r\n",
      "Epoch:  93 Step:   565 /   793 Train loss: 0.02481539\r\n",
      "Epoch:  93 Step:   566 /   793 Train loss: 0.03305136\r\n",
      "Epoch:  93 Step:   567 /   793 Train loss: 0.01427941\r\n",
      "Epoch:  93 Step:   568 /   793 Train loss: 0.02006652\r\n",
      "Epoch:  93 Step:   569 /   793 Train loss: 0.02529848\r\n",
      "Epoch:  93 Step:   570 /   793 Train loss: 0.02503521\r\n",
      "Epoch:  93 Step:   571 /   793 Train loss: 0.02983102\r\n",
      "Epoch:  93 Step:   572 /   793 Train loss: 0.02371990\r\n",
      "Epoch:  93 Step:   573 /   793 Train loss: 0.02574694\r\n",
      "Epoch:  93 Step:   574 /   793 Train loss: 0.02253613\r\n",
      "Epoch:  93 Step:   575 /   793 Train loss: 0.02621109\r\n",
      "Epoch:  93 Step:   576 /   793 Train loss: 0.01825043\r\n",
      "Epoch:  93 Step:   577 /   793 Train loss: 0.02460970\r\n",
      "Epoch:  93 Step:   578 /   793 Train loss: 0.02515860\r\n",
      "Epoch:  93 Step:   579 /   793 Train loss: 0.03051212\r\n",
      "Epoch:  93 Step:   580 /   793 Train loss: 0.02446079\r\n",
      "Epoch:  93 Step:   581 /   793 Train loss: 0.02711087\r\n",
      "Epoch:  93 Step:   582 /   793 Train loss: 0.01634450\r\n",
      "Epoch:  93 Step:   583 /   793 Train loss: 0.02892292\r\n",
      "Epoch:  93 Step:   584 /   793 Train loss: 0.02676182\r\n",
      "Epoch:  93 Step:   585 /   793 Train loss: 0.02097254\r\n",
      "Epoch:  93 Step:   586 /   793 Train loss: 0.02830297\r\n",
      "Epoch:  93 Step:   587 /   793 Train loss: 0.02400907\r\n",
      "Epoch:  93 Step:   588 /   793 Train loss: 0.02820851\r\n",
      "Epoch:  93 Step:   589 /   793 Train loss: 0.02123220\r\n",
      "Epoch:  93 Step:   590 /   793 Train loss: 0.02760004\r\n",
      "Epoch:  93 Step:   591 /   793 Train loss: 0.02145849\r\n",
      "Epoch:  93 Step:   592 /   793 Train loss: 0.02250134\r\n",
      "Epoch:  93 Step:   593 /   793 Train loss: 0.01812032\r\n",
      "Epoch:  93 Step:   594 /   793 Train loss: 0.01590029\r\n",
      "Epoch:  93 Step:   595 /   793 Train loss: 0.01741716\r\n",
      "Epoch:  93 Step:   596 /   793 Train loss: 0.02016430\r\n",
      "Epoch:  93 Step:   597 /   793 Train loss: 0.01989031\r\n",
      "Epoch:  93 Step:   598 /   793 Train loss: 0.02666960\r\n",
      "Epoch:  93 Step:   599 /   793 Train loss: 0.02630705\r\n",
      "Epoch:  93 Step:   600 /   793 Train loss: 0.02603078\r\n",
      "Epoch:  93 Step:   601 /   793 Train loss: 0.02314480\r\n",
      "Epoch:  93 Step:   602 /   793 Train loss: 0.03278416\r\n",
      "Epoch:  93 Step:   603 /   793 Train loss: 0.01926735\r\n",
      "Epoch:  93 Step:   604 /   793 Train loss: 0.03040342\r\n",
      "Epoch:  93 Step:   605 /   793 Train loss: 0.02817594\r\n",
      "Epoch:  93 Step:   606 /   793 Train loss: 0.03523620\r\n",
      "Epoch:  93 Step:   607 /   793 Train loss: 0.02153629\r\n",
      "Epoch:  93 Step:   608 /   793 Train loss: 0.01955464\r\n",
      "Epoch:  93 Step:   609 /   793 Train loss: 0.02578821\r\n",
      "Epoch:  93 Step:   610 /   793 Train loss: 0.02712528\r\n",
      "Epoch:  93 Step:   611 /   793 Train loss: 0.01497753\r\n",
      "Epoch:  93 Step:   612 /   793 Train loss: 0.02416480\r\n",
      "Epoch:  93 Step:   613 /   793 Train loss: 0.01783274\r\n",
      "Epoch:  93 Step:   614 /   793 Train loss: 0.02682161\r\n",
      "Epoch:  93 Step:   615 /   793 Train loss: 0.02648615\r\n",
      "Epoch:  93 Step:   616 /   793 Train loss: 0.02459005\r\n",
      "Epoch:  93 Step:   617 /   793 Train loss: 0.02067491\r\n",
      "Epoch:  93 Step:   618 /   793 Train loss: 0.01811331\r\n",
      "Epoch:  93 Step:   619 /   793 Train loss: 0.02162168\r\n",
      "Epoch:  93 Step:   620 /   793 Train loss: 0.02588137\r\n",
      "Epoch:  93 Step:   621 /   793 Train loss: 0.03155248\r\n",
      "Epoch:  93 Step:   622 /   793 Train loss: 0.02494034\r\n",
      "Epoch:  93 Step:   623 /   793 Train loss: 0.02243840\r\n",
      "Epoch:  93 Step:   624 /   793 Train loss: 0.02972313\r\n",
      "Epoch:  93 Step:   625 /   793 Train loss: 0.01644548\r\n",
      "Epoch:  93 Step:   626 /   793 Train loss: 0.02908862\r\n",
      "Epoch:  93 Step:   627 /   793 Train loss: 0.03860870\r\n",
      "Epoch:  93 Step:   628 /   793 Train loss: 0.01820156\r\n",
      "Epoch:  93 Step:   629 /   793 Train loss: 0.02139558\r\n",
      "Epoch:  93 Step:   630 /   793 Train loss: 0.02171507\r\n",
      "Epoch:  93 Step:   631 /   793 Train loss: 0.02394896\r\n",
      "Epoch:  93 Step:   632 /   793 Train loss: 0.01545823\r\n",
      "Epoch:  93 Step:   633 /   793 Train loss: 0.01710101\r\n",
      "Epoch:  93 Step:   634 /   793 Train loss: 0.02687576\r\n",
      "Epoch:  93 Step:   635 /   793 Train loss: 0.02691462\r\n",
      "Epoch:  93 Step:   636 /   793 Train loss: 0.01135035\r\n",
      "Epoch:  93 Step:   637 /   793 Train loss: 0.03394350\r\n",
      "Epoch:  93 Step:   638 /   793 Train loss: 0.02475717\r\n",
      "Epoch:  93 Step:   639 /   793 Train loss: 0.02252457\r\n",
      "Epoch:  93 Step:   640 /   793 Train loss: 0.02879470\r\n",
      "Epoch:  93 Step:   641 /   793 Train loss: 0.02706885\r\n",
      "Epoch:  93 Step:   642 /   793 Train loss: 0.02009802\r\n",
      "Epoch:  93 Step:   643 /   793 Train loss: 0.01774554\r\n",
      "Epoch:  93 Step:   644 /   793 Train loss: 0.02082472\r\n",
      "Epoch:  93 Step:   645 /   793 Train loss: 0.03525263\r\n",
      "Epoch:  93 Step:   646 /   793 Train loss: 0.03574229\r\n",
      "Epoch:  93 Step:   647 /   793 Train loss: 0.03412100\r\n",
      "Epoch:  93 Step:   648 /   793 Train loss: 0.02236588\r\n",
      "Epoch:  93 Step:   649 /   793 Train loss: 0.01483680\r\n",
      "Epoch:  93 Step:   650 /   793 Train loss: 0.02256656\r\n",
      "Epoch:  93 Step:   651 /   793 Train loss: 0.03707083\r\n",
      "Epoch:  93 Step:   652 /   793 Train loss: 0.03143935\r\n",
      "Epoch:  93 Step:   653 /   793 Train loss: 0.03387290\r\n",
      "Epoch:  93 Step:   654 /   793 Train loss: 0.03023592\r\n",
      "Epoch:  93 Step:   655 /   793 Train loss: 0.02556060\r\n",
      "Epoch:  93 Step:   656 /   793 Train loss: 0.02292402\r\n",
      "Epoch:  93 Step:   657 /   793 Train loss: 0.01914647\r\n",
      "Epoch:  93 Step:   658 /   793 Train loss: 0.02510107\r\n",
      "Epoch:  93 Step:   659 /   793 Train loss: 0.03907592\r\n",
      "Epoch:  93 Step:   660 /   793 Train loss: 0.02645748\r\n",
      "Epoch:  93 Step:   661 /   793 Train loss: 0.02118324\r\n",
      "Epoch:  93 Step:   662 /   793 Train loss: 0.02652825\r\n",
      "Epoch:  93 Step:   663 /   793 Train loss: 0.02083835\r\n",
      "Epoch:  93 Step:   664 /   793 Train loss: 0.01827130\r\n",
      "Epoch:  93 Step:   665 /   793 Train loss: 0.02469159\r\n",
      "Epoch:  93 Step:   666 /   793 Train loss: 0.01556225\r\n",
      "Epoch:  93 Step:   667 /   793 Train loss: 0.02844954\r\n",
      "Epoch:  93 Step:   668 /   793 Train loss: 0.02033802\r\n",
      "Epoch:  93 Step:   669 /   793 Train loss: 0.01491160\r\n",
      "Epoch:  93 Step:   670 /   793 Train loss: 0.02625371\r\n",
      "Epoch:  93 Step:   671 /   793 Train loss: 0.03637603\r\n",
      "Epoch:  93 Step:   672 /   793 Train loss: 0.02291561\r\n",
      "Epoch:  93 Step:   673 /   793 Train loss: 0.01947412\r\n",
      "Epoch:  93 Step:   674 /   793 Train loss: 0.02228827\r\n",
      "Epoch:  93 Step:   675 /   793 Train loss: 0.01718818\r\n",
      "Epoch:  93 Step:   676 /   793 Train loss: 0.01555120\r\n",
      "Epoch:  93 Step:   677 /   793 Train loss: 0.02827752\r\n",
      "Epoch:  93 Step:   678 /   793 Train loss: 0.02297598\r\n",
      "Epoch:  93 Step:   679 /   793 Train loss: 0.01678708\r\n",
      "Epoch:  93 Step:   680 /   793 Train loss: 0.02251126\r\n",
      "Epoch:  93 Step:   681 /   793 Train loss: 0.02177204\r\n",
      "Epoch:  93 Step:   682 /   793 Train loss: 0.01636262\r\n",
      "Epoch:  93 Step:   683 /   793 Train loss: 0.02811306\r\n",
      "Epoch:  93 Step:   684 /   793 Train loss: 0.01924799\r\n",
      "Epoch:  93 Step:   685 /   793 Train loss: 0.02388642\r\n",
      "Epoch:  93 Step:   686 /   793 Train loss: 0.03440514\r\n",
      "Epoch:  93 Step:   687 /   793 Train loss: 0.02352693\r\n",
      "Epoch:  93 Step:   688 /   793 Train loss: 0.03767356\r\n",
      "Epoch:  93 Step:   689 /   793 Train loss: 0.02828359\r\n",
      "Epoch:  93 Step:   690 /   793 Train loss: 0.01987902\r\n",
      "Epoch:  93 Step:   691 /   793 Train loss: 0.02220298\r\n",
      "Epoch:  93 Step:   692 /   793 Train loss: 0.02674889\r\n",
      "Epoch:  93 Step:   693 /   793 Train loss: 0.02354441\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  93 Step:   694 /   793 Train loss: 0.02630510\r\n",
      "Epoch:  93 Step:   695 /   793 Train loss: 0.03884719\r\n",
      "Epoch:  93 Step:   696 /   793 Train loss: 0.01743924\r\n",
      "Epoch:  93 Step:   697 /   793 Train loss: 0.01091436\r\n",
      "Epoch:  93 Step:   698 /   793 Train loss: 0.01081870\r\n",
      "Epoch:  93 Step:   699 /   793 Train loss: 0.02619883\r\n",
      "Epoch:  93 Step:   700 /   793 Train loss: 0.03089940\r\n",
      "Epoch:  93 Step:   701 /   793 Train loss: 0.02900901\r\n",
      "Epoch:  93 Step:   702 /   793 Train loss: 0.02507570\r\n",
      "Epoch:  93 Step:   703 /   793 Train loss: 0.03612485\r\n",
      "Epoch:  93 Step:   704 /   793 Train loss: 0.03427465\r\n",
      "Epoch:  93 Step:   705 /   793 Train loss: 0.01894717\r\n",
      "Epoch:  93 Step:   706 /   793 Train loss: 0.01463309\r\n",
      "Epoch:  93 Step:   707 /   793 Train loss: 0.02834888\r\n",
      "Epoch:  93 Step:   708 /   793 Train loss: 0.01979774\r\n",
      "Epoch:  93 Step:   709 /   793 Train loss: 0.02483427\r\n",
      "Epoch:  93 Step:   710 /   793 Train loss: 0.02528469\r\n",
      "Epoch:  93 Step:   711 /   793 Train loss: 0.02445785\r\n",
      "Epoch:  93 Step:   712 /   793 Train loss: 0.01897505\r\n",
      "Epoch:  93 Step:   713 /   793 Train loss: 0.03021657\r\n",
      "Epoch:  93 Step:   714 /   793 Train loss: 0.01658060\r\n",
      "Epoch:  93 Step:   715 /   793 Train loss: 0.02382531\r\n",
      "Epoch:  93 Step:   716 /   793 Train loss: 0.01419285\r\n",
      "Epoch:  93 Step:   717 /   793 Train loss: 0.02158865\r\n",
      "Epoch:  93 Step:   718 /   793 Train loss: 0.01578782\r\n",
      "Epoch:  93 Step:   719 /   793 Train loss: 0.02488662\r\n",
      "Epoch:  93 Step:   720 /   793 Train loss: 0.02543041\r\n",
      "Epoch:  93 Step:   721 /   793 Train loss: 0.02413921\r\n",
      "Epoch:  93 Step:   722 /   793 Train loss: 0.02875074\r\n",
      "Epoch:  93 Step:   723 /   793 Train loss: 0.03337906\r\n",
      "Epoch:  93 Step:   724 /   793 Train loss: 0.01910364\r\n",
      "Epoch:  93 Step:   725 /   793 Train loss: 0.02285448\r\n",
      "Epoch:  93 Step:   726 /   793 Train loss: 0.02450240\r\n",
      "Epoch:  93 Step:   727 /   793 Train loss: 0.02264193\r\n",
      "Epoch:  93 Step:   728 /   793 Train loss: 0.02352163\r\n",
      "Epoch:  93 Step:   729 /   793 Train loss: 0.01811697\r\n",
      "Epoch:  93 Step:   730 /   793 Train loss: 0.01806486\r\n",
      "Epoch:  93 Step:   731 /   793 Train loss: 0.02528032\r\n",
      "Epoch:  93 Step:   732 /   793 Train loss: 0.02394730\r\n",
      "Epoch:  93 Step:   733 /   793 Train loss: 0.01453973\r\n",
      "Epoch:  93 Step:   734 /   793 Train loss: 0.01588468\r\n",
      "Epoch:  93 Step:   735 /   793 Train loss: 0.02697667\r\n",
      "Epoch:  93 Step:   736 /   793 Train loss: 0.03130776\r\n",
      "Epoch:  93 Step:   737 /   793 Train loss: 0.01978862\r\n",
      "Epoch:  93 Step:   738 /   793 Train loss: 0.02568671\r\n",
      "Epoch:  93 Step:   739 /   793 Train loss: 0.01496227\r\n",
      "Epoch:  93 Step:   740 /   793 Train loss: 0.02465190\r\n",
      "Epoch:  93 Step:   741 /   793 Train loss: 0.04135212\r\n",
      "Epoch:  93 Step:   742 /   793 Train loss: 0.01956089\r\n",
      "Epoch:  93 Step:   743 /   793 Train loss: 0.02416287\r\n",
      "Epoch:  93 Step:   744 /   793 Train loss: 0.02278760\r\n",
      "Epoch:  93 Step:   745 /   793 Train loss: 0.02774988\r\n",
      "Epoch:  93 Step:   746 /   793 Train loss: 0.02899013\r\n",
      "Epoch:  93 Step:   747 /   793 Train loss: 0.02440545\r\n",
      "Epoch:  93 Step:   748 /   793 Train loss: 0.02701784\r\n",
      "Epoch:  93 Step:   749 /   793 Train loss: 0.01736556\r\n",
      "Epoch:  93 Step:   750 /   793 Train loss: 0.02025870\r\n",
      "Epoch:  93 Step:   751 /   793 Train loss: 0.01386622\r\n",
      "Epoch:  93 Step:   752 /   793 Train loss: 0.01294808\r\n",
      "Epoch:  93 Step:   753 /   793 Train loss: 0.02571819\r\n",
      "Epoch:  93 Step:   754 /   793 Train loss: 0.01731979\r\n",
      "Epoch:  93 Step:   755 /   793 Train loss: 0.01924105\r\n",
      "Epoch:  93 Step:   756 /   793 Train loss: 0.02251728\r\n",
      "Epoch:  93 Step:   757 /   793 Train loss: 0.02921946\r\n",
      "Epoch:  93 Step:   758 /   793 Train loss: 0.02231186\r\n",
      "Epoch:  93 Step:   759 /   793 Train loss: 0.02310975\r\n",
      "Epoch:  93 Step:   760 /   793 Train loss: 0.03633858\r\n",
      "Epoch:  93 Step:   761 /   793 Train loss: 0.03944841\r\n",
      "Epoch:  93 Step:   762 /   793 Train loss: 0.03287551\r\n",
      "Epoch:  93 Step:   763 /   793 Train loss: 0.02566884\r\n",
      "Epoch:  93 Step:   764 /   793 Train loss: 0.02189690\r\n",
      "Epoch:  93 Step:   765 /   793 Train loss: 0.02119647\r\n",
      "Epoch:  93 Step:   766 /   793 Train loss: 0.01705655\r\n",
      "Epoch:  93 Step:   767 /   793 Train loss: 0.01871841\r\n",
      "Epoch:  93 Step:   768 /   793 Train loss: 0.02024850\r\n",
      "Epoch:  93 Step:   769 /   793 Train loss: 0.03483092\r\n",
      "Epoch:  93 Step:   770 /   793 Train loss: 0.02060964\r\n",
      "Epoch:  93 Step:   771 /   793 Train loss: 0.03682332\r\n",
      "Epoch:  93 Step:   772 /   793 Train loss: 0.04599301\r\n",
      "Epoch:  93 Step:   773 /   793 Train loss: 0.03776180\r\n",
      "Epoch:  93 Step:   774 /   793 Train loss: 0.02426176\r\n",
      "Epoch:  93 Step:   775 /   793 Train loss: 0.02845239\r\n",
      "Epoch:  93 Step:   776 /   793 Train loss: 0.02063818\r\n",
      "Epoch:  93 Step:   777 /   793 Train loss: 0.03333870\r\n",
      "Epoch:  93 Step:   778 /   793 Train loss: 0.02512115\r\n",
      "Epoch:  93 Step:   779 /   793 Train loss: 0.00959413\r\n",
      "Epoch:  93 Step:   780 /   793 Train loss: 0.01865837\r\n",
      "Epoch:  93 Step:   781 /   793 Train loss: 0.00980407\r\n",
      "Epoch:  93 Step:   782 /   793 Train loss: 0.02539745\r\n",
      "Epoch:  93 Step:   783 /   793 Train loss: 0.02380511\r\n",
      "Epoch:  93 Step:   784 /   793 Train loss: 0.02836394\r\n",
      "Epoch:  93 Step:   785 /   793 Train loss: 0.02582256\r\n",
      "Epoch:  93 Step:   786 /   793 Train loss: 0.03495100\r\n",
      "Epoch:  93 Step:   787 /   793 Train loss: 0.01678715\r\n",
      "Epoch:  93 Step:   788 /   793 Train loss: 0.03900325\r\n",
      "Epoch:  93 Step:   789 /   793 Train loss: 0.02310138\r\n",
      "Epoch:  93 Step:   790 /   793 Train loss: 0.02008820\r\n",
      "Epoch:  93 Step:   791 /   793 Train loss: 0.01866523\r\n",
      "Epoch:  93 Step:   792 /   793 Train loss: 0.01990900\r\n",
      "Epoch:  93 Validation loss: 0.01421972\r\n",
      "Epoch:  94 Step:     0 /   793 Train loss: 0.01776368\r\n",
      "Epoch:  94 Step:     1 /   793 Train loss: 0.02188825\r\n",
      "Epoch:  94 Step:     2 /   793 Train loss: 0.02396208\r\n",
      "Epoch:  94 Step:     3 /   793 Train loss: 0.03385596\r\n",
      "Epoch:  94 Step:     4 /   793 Train loss: 0.04560541\r\n",
      "Epoch:  94 Step:     5 /   793 Train loss: 0.02862694\r\n",
      "Epoch:  94 Step:     6 /   793 Train loss: 0.03776171\r\n",
      "Epoch:  94 Step:     7 /   793 Train loss: 0.03105478\r\n",
      "Epoch:  94 Step:     8 /   793 Train loss: 0.01260994\r\n",
      "Epoch:  94 Step:     9 /   793 Train loss: 0.02382660\r\n",
      "Epoch:  94 Step:    10 /   793 Train loss: 0.02699438\r\n",
      "Epoch:  94 Step:    11 /   793 Train loss: 0.03156679\r\n",
      "Epoch:  94 Step:    12 /   793 Train loss: 0.02515659\r\n",
      "Epoch:  94 Step:    13 /   793 Train loss: 0.02395603\r\n",
      "Epoch:  94 Step:    14 /   793 Train loss: 0.02682157\r\n",
      "Epoch:  94 Step:    15 /   793 Train loss: 0.03116431\r\n",
      "Epoch:  94 Step:    16 /   793 Train loss: 0.03127012\r\n",
      "Epoch:  94 Step:    17 /   793 Train loss: 0.02050001\r\n",
      "Epoch:  94 Step:    18 /   793 Train loss: 0.02425139\r\n",
      "Epoch:  94 Step:    19 /   793 Train loss: 0.01352098\r\n",
      "Epoch:  94 Step:    20 /   793 Train loss: 0.02569984\r\n",
      "Epoch:  94 Step:    21 /   793 Train loss: 0.00834526\r\n",
      "Epoch:  94 Step:    22 /   793 Train loss: 0.02150869\r\n",
      "Epoch:  94 Step:    23 /   793 Train loss: 0.02322869\r\n",
      "Epoch:  94 Step:    24 /   793 Train loss: 0.03879998\r\n",
      "Epoch:  94 Step:    25 /   793 Train loss: 0.01089527\r\n",
      "Epoch:  94 Step:    26 /   793 Train loss: 0.02362902\r\n",
      "Epoch:  94 Step:    27 /   793 Train loss: 0.02899794\r\n",
      "Epoch:  94 Step:    28 /   793 Train loss: 0.03731512\r\n",
      "Epoch:  94 Step:    29 /   793 Train loss: 0.02697639\r\n",
      "Epoch:  94 Step:    30 /   793 Train loss: 0.02271966\r\n",
      "Epoch:  94 Step:    31 /   793 Train loss: 0.03765123\r\n",
      "Epoch:  94 Step:    32 /   793 Train loss: 0.02779880\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  94 Step:    33 /   793 Train loss: 0.02658746\r\n",
      "Epoch:  94 Step:    34 /   793 Train loss: 0.03189590\r\n",
      "Epoch:  94 Step:    35 /   793 Train loss: 0.01798077\r\n",
      "Epoch:  94 Step:    36 /   793 Train loss: 0.02837970\r\n",
      "Epoch:  94 Step:    37 /   793 Train loss: 0.02330287\r\n",
      "Epoch:  94 Step:    38 /   793 Train loss: 0.03712280\r\n",
      "Epoch:  94 Step:    39 /   793 Train loss: 0.03303589\r\n",
      "Epoch:  94 Step:    40 /   793 Train loss: 0.01822256\r\n",
      "Epoch:  94 Step:    41 /   793 Train loss: 0.01842194\r\n",
      "Epoch:  94 Step:    42 /   793 Train loss: 0.02690798\r\n",
      "Epoch:  94 Step:    43 /   793 Train loss: 0.02330637\r\n",
      "Epoch:  94 Step:    44 /   793 Train loss: 0.02606560\r\n",
      "Epoch:  94 Step:    45 /   793 Train loss: 0.01966688\r\n",
      "Epoch:  94 Step:    46 /   793 Train loss: 0.03217032\r\n",
      "Epoch:  94 Step:    47 /   793 Train loss: 0.03180066\r\n",
      "Epoch:  94 Step:    48 /   793 Train loss: 0.01641242\r\n",
      "Epoch:  94 Step:    49 /   793 Train loss: 0.02698583\r\n",
      "Epoch:  94 Step:    50 /   793 Train loss: 0.02295142\r\n",
      "Epoch:  94 Step:    51 /   793 Train loss: 0.02392877\r\n",
      "Epoch:  94 Step:    52 /   793 Train loss: 0.02243461\r\n",
      "Epoch:  94 Step:    53 /   793 Train loss: 0.03179841\r\n",
      "Epoch:  94 Step:    54 /   793 Train loss: 0.01977731\r\n",
      "Epoch:  94 Step:    55 /   793 Train loss: 0.01909054\r\n",
      "Epoch:  94 Step:    56 /   793 Train loss: 0.03358007\r\n",
      "Epoch:  94 Step:    57 /   793 Train loss: 0.01773572\r\n",
      "Epoch:  94 Step:    58 /   793 Train loss: 0.03042630\r\n",
      "Epoch:  94 Step:    59 /   793 Train loss: 0.03279654\r\n",
      "Epoch:  94 Step:    60 /   793 Train loss: 0.02453900\r\n",
      "Epoch:  94 Step:    61 /   793 Train loss: 0.01692084\r\n",
      "Epoch:  94 Step:    62 /   793 Train loss: 0.03420530\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  94 Step:    63 /   793 Train loss: 0.02725430\r\n",
      "Epoch:  94 Step:    64 /   793 Train loss: 0.02289319\r\n",
      "Epoch:  94 Step:    65 /   793 Train loss: 0.02780511\r\n",
      "Epoch:  94 Step:    66 /   793 Train loss: 0.02377502\r\n",
      "Epoch:  94 Step:    67 /   793 Train loss: 0.02467796\r\n",
      "Epoch:  94 Step:    68 /   793 Train loss: 0.02443805\r\n",
      "Epoch:  94 Step:    69 /   793 Train loss: 0.01243103\r\n",
      "Epoch:  94 Step:    70 /   793 Train loss: 0.01818958\r\n",
      "Epoch:  94 Step:    71 /   793 Train loss: 0.01994128\r\n",
      "Epoch:  94 Step:    72 /   793 Train loss: 0.03230898\r\n",
      "Epoch:  94 Step:    73 /   793 Train loss: 0.01245416\r\n",
      "Epoch:  94 Step:    74 /   793 Train loss: 0.03058048\r\n",
      "Epoch:  94 Step:    75 /   793 Train loss: 0.02730407\r\n",
      "Epoch:  94 Step:    76 /   793 Train loss: 0.00828346\r\n",
      "Epoch:  94 Step:    77 /   793 Train loss: 0.03391754\r\n",
      "Epoch:  94 Step:    78 /   793 Train loss: 0.01133442\r\n",
      "Epoch:  94 Step:    79 /   793 Train loss: 0.02112376\r\n",
      "Epoch:  94 Step:    80 /   793 Train loss: 0.02112597\r\n",
      "Epoch:  94 Step:    81 /   793 Train loss: 0.02084522\r\n",
      "Epoch:  94 Step:    82 /   793 Train loss: 0.01791760\r\n",
      "Epoch:  94 Step:    83 /   793 Train loss: 0.03083827\r\n",
      "Epoch:  94 Step:    84 /   793 Train loss: 0.02803846\r\n",
      "Epoch:  94 Step:    85 /   793 Train loss: 0.02874177\r\n",
      "Epoch:  94 Step:    86 /   793 Train loss: 0.01191283\r\n",
      "Epoch:  94 Step:    87 /   793 Train loss: 0.02250605\r\n",
      "Epoch:  94 Step:    88 /   793 Train loss: 0.03446324\r\n",
      "Epoch:  94 Step:    89 /   793 Train loss: 0.03068699\r\n",
      "Epoch:  94 Step:    90 /   793 Train loss: 0.01969045\r\n",
      "Epoch:  94 Step:    91 /   793 Train loss: 0.01745034\r\n",
      "Epoch:  94 Step:    92 /   793 Train loss: 0.01696360\r\n",
      "Epoch:  94 Step:    93 /   793 Train loss: 0.04158910\r\n",
      "Epoch:  94 Step:    94 /   793 Train loss: 0.03363618\r\n",
      "Epoch:  94 Step:    95 /   793 Train loss: 0.02607864\r\n",
      "Epoch:  94 Step:    96 /   793 Train loss: 0.01911739\r\n",
      "Epoch:  94 Step:    97 /   793 Train loss: 0.03325436\r\n",
      "Epoch:  94 Step:    98 /   793 Train loss: 0.01298864\r\n",
      "Epoch:  94 Step:    99 /   793 Train loss: 0.02691608\r\n",
      "Epoch:  94 Step:   100 /   793 Train loss: 0.02489270\r\n",
      "Epoch:  94 Step:   101 /   793 Train loss: 0.02559987\r\n",
      "Epoch:  94 Step:   102 /   793 Train loss: 0.03338479\r\n",
      "Epoch:  94 Step:   103 /   793 Train loss: 0.01342415\r\n",
      "Epoch:  94 Step:   104 /   793 Train loss: 0.01931564\r\n",
      "Epoch:  94 Step:   105 /   793 Train loss: 0.02216356\r\n",
      "Epoch:  94 Step:   106 /   793 Train loss: 0.01345866\r\n",
      "Epoch:  94 Step:   107 /   793 Train loss: 0.02699471\r\n",
      "Epoch:  94 Step:   108 /   793 Train loss: 0.02785381\r\n",
      "Epoch:  94 Step:   109 /   793 Train loss: 0.02185033\r\n",
      "Epoch:  94 Step:   110 /   793 Train loss: 0.02435382\r\n",
      "Epoch:  94 Step:   111 /   793 Train loss: 0.02257860\r\n",
      "Epoch:  94 Step:   112 /   793 Train loss: 0.01529724\r\n",
      "Epoch:  94 Step:   113 /   793 Train loss: 0.03113437\r\n",
      "Epoch:  94 Step:   114 /   793 Train loss: 0.01770315\r\n",
      "Epoch:  94 Step:   115 /   793 Train loss: 0.02839049\r\n",
      "Epoch:  94 Step:   116 /   793 Train loss: 0.01531749\r\n",
      "Epoch:  94 Step:   117 /   793 Train loss: 0.02516550\r\n",
      "Epoch:  94 Step:   118 /   793 Train loss: 0.03645004\r\n",
      "Epoch:  94 Step:   119 /   793 Train loss: 0.01633326\r\n",
      "Epoch:  94 Step:   120 /   793 Train loss: 0.01915593\r\n",
      "Epoch:  94 Step:   121 /   793 Train loss: 0.02717747\r\n",
      "Epoch:  94 Step:   122 /   793 Train loss: 0.03044069\r\n",
      "Epoch:  94 Step:   123 /   793 Train loss: 0.03135960\r\n",
      "Epoch:  94 Step:   124 /   793 Train loss: 0.02080690\r\n",
      "Epoch:  94 Step:   125 /   793 Train loss: 0.02705622\r\n",
      "Epoch:  94 Step:   126 /   793 Train loss: 0.02388178\r\n",
      "Epoch:  94 Step:   127 /   793 Train loss: 0.01317029\r\n",
      "Epoch:  94 Step:   128 /   793 Train loss: 0.02387141\r\n",
      "Epoch:  94 Step:   129 /   793 Train loss: 0.01613068\r\n",
      "Epoch:  94 Step:   130 /   793 Train loss: 0.02709796\r\n",
      "Epoch:  94 Step:   131 /   793 Train loss: 0.03904408\r\n",
      "Epoch:  94 Step:   132 /   793 Train loss: 0.02675469\r\n",
      "Epoch:  94 Step:   133 /   793 Train loss: 0.02992740\r\n",
      "Epoch:  94 Step:   134 /   793 Train loss: 0.01543062\r\n",
      "Epoch:  94 Step:   135 /   793 Train loss: 0.02770365\r\n",
      "Epoch:  94 Step:   136 /   793 Train loss: 0.03004135\r\n",
      "Epoch:  94 Step:   137 /   793 Train loss: 0.02227315\r\n",
      "Epoch:  94 Step:   138 /   793 Train loss: 0.02718619\r\n",
      "Epoch:  94 Step:   139 /   793 Train loss: 0.02962541\r\n",
      "Epoch:  94 Step:   140 /   793 Train loss: 0.01113347\r\n",
      "Epoch:  94 Step:   141 /   793 Train loss: 0.02008170\r\n",
      "Epoch:  94 Step:   142 /   793 Train loss: 0.00988997\r\n",
      "Epoch:  94 Step:   143 /   793 Train loss: 0.02860891\r\n",
      "Epoch:  94 Step:   144 /   793 Train loss: 0.02001537\r\n",
      "Epoch:  94 Step:   145 /   793 Train loss: 0.02274963\r\n",
      "Epoch:  94 Step:   146 /   793 Train loss: 0.02370974\r\n",
      "Epoch:  94 Step:   147 /   793 Train loss: 0.02110032\r\n",
      "Epoch:  94 Step:   148 /   793 Train loss: 0.02516435\r\n",
      "Epoch:  94 Step:   149 /   793 Train loss: 0.03861869\r\n",
      "Epoch:  94 Step:   150 /   793 Train loss: 0.01643613\r\n",
      "Epoch:  94 Step:   151 /   793 Train loss: 0.03023504\r\n",
      "Epoch:  94 Step:   152 /   793 Train loss: 0.03283510\r\n",
      "Epoch:  94 Step:   153 /   793 Train loss: 0.03198724\r\n",
      "Epoch:  94 Step:   154 /   793 Train loss: 0.02343060\r\n",
      "Epoch:  94 Step:   155 /   793 Train loss: 0.03611258\r\n",
      "Epoch:  94 Step:   156 /   793 Train loss: 0.02235800\r\n",
      "Epoch:  94 Step:   157 /   793 Train loss: 0.02323325\r\n",
      "Epoch:  94 Step:   158 /   793 Train loss: 0.02059028\r\n",
      "Epoch:  94 Step:   159 /   793 Train loss: 0.01633864\r\n",
      "Epoch:  94 Step:   160 /   793 Train loss: 0.02991223\r\n",
      "Epoch:  94 Step:   161 /   793 Train loss: 0.01988655\r\n",
      "Epoch:  94 Step:   162 /   793 Train loss: 0.01578081\r\n",
      "Epoch:  94 Step:   163 /   793 Train loss: 0.02073229\r\n",
      "Epoch:  94 Step:   164 /   793 Train loss: 0.01794953\r\n",
      "Epoch:  94 Step:   165 /   793 Train loss: 0.03209040\r\n",
      "Epoch:  94 Step:   166 /   793 Train loss: 0.03402291\r\n",
      "Epoch:  94 Step:   167 /   793 Train loss: 0.02706523\r\n",
      "Epoch:  94 Step:   168 /   793 Train loss: 0.01516955\r\n",
      "Epoch:  94 Step:   169 /   793 Train loss: 0.02389874\r\n",
      "Epoch:  94 Step:   170 /   793 Train loss: 0.01132301\r\n",
      "Epoch:  94 Step:   171 /   793 Train loss: 0.02699576\r\n",
      "Epoch:  94 Step:   172 /   793 Train loss: 0.03521162\r\n",
      "Epoch:  94 Step:   173 /   793 Train loss: 0.01866437\r\n",
      "Epoch:  94 Step:   174 /   793 Train loss: 0.03584963\r\n",
      "Epoch:  94 Step:   175 /   793 Train loss: 0.02313176\r\n",
      "Epoch:  94 Step:   176 /   793 Train loss: 0.02760591\r\n",
      "Epoch:  94 Step:   177 /   793 Train loss: 0.02042572\r\n",
      "Epoch:  94 Step:   178 /   793 Train loss: 0.02718511\r\n",
      "Epoch:  94 Step:   179 /   793 Train loss: 0.02106807\r\n",
      "Epoch:  94 Step:   180 /   793 Train loss: 0.02516703\r\n",
      "Epoch:  94 Step:   181 /   793 Train loss: 0.02131255\r\n",
      "Epoch:  94 Step:   182 /   793 Train loss: 0.03175581\r\n",
      "Epoch:  94 Step:   183 /   793 Train loss: 0.01743964\r\n",
      "Epoch:  94 Step:   184 /   793 Train loss: 0.02039023\r\n",
      "Epoch:  94 Step:   185 /   793 Train loss: 0.02178665\r\n",
      "Epoch:  94 Step:   186 /   793 Train loss: 0.01859709\r\n",
      "Epoch:  94 Step:   187 /   793 Train loss: 0.03927093\r\n",
      "Epoch:  94 Step:   188 /   793 Train loss: 0.02612852\r\n",
      "Epoch:  94 Step:   189 /   793 Train loss: 0.01592442\r\n",
      "Epoch:  94 Step:   190 /   793 Train loss: 0.02474429\r\n",
      "Epoch:  94 Step:   191 /   793 Train loss: 0.02599860\r\n",
      "Epoch:  94 Step:   192 /   793 Train loss: 0.05244979\r\n",
      "Epoch:  94 Step:   193 /   793 Train loss: 0.02942953\r\n",
      "Epoch:  94 Step:   194 /   793 Train loss: 0.03036288\r\n",
      "Epoch:  94 Step:   195 /   793 Train loss: 0.01881131\r\n",
      "Epoch:  94 Step:   196 /   793 Train loss: 0.03259842\r\n",
      "Epoch:  94 Step:   197 /   793 Train loss: 0.01669650\r\n",
      "Epoch:  94 Step:   198 /   793 Train loss: 0.01788125\r\n",
      "Epoch:  94 Step:   199 /   793 Train loss: 0.02796607\r\n",
      "Epoch:  94 Step:   200 /   793 Train loss: 0.02637379\r\n",
      "Epoch:  94 Step:   201 /   793 Train loss: 0.01677228\r\n",
      "Epoch:  94 Step:   202 /   793 Train loss: 0.01217108\r\n",
      "Epoch:  94 Step:   203 /   793 Train loss: 0.02936304\r\n",
      "Epoch:  94 Step:   204 /   793 Train loss: 0.01343013\r\n",
      "Epoch:  94 Step:   205 /   793 Train loss: 0.01501758\r\n",
      "Epoch:  94 Step:   206 /   793 Train loss: 0.02073354\r\n",
      "Epoch:  94 Step:   207 /   793 Train loss: 0.02324872\r\n",
      "Epoch:  94 Step:   208 /   793 Train loss: 0.02206800\r\n",
      "Epoch:  94 Step:   209 /   793 Train loss: 0.02064383\r\n",
      "Epoch:  94 Step:   210 /   793 Train loss: 0.03340803\r\n",
      "Epoch:  94 Step:   211 /   793 Train loss: 0.02160215\r\n",
      "Epoch:  94 Step:   212 /   793 Train loss: 0.02342258\r\n",
      "Epoch:  94 Step:   213 /   793 Train loss: 0.01146269\r\n",
      "Epoch:  94 Step:   214 /   793 Train loss: 0.02002133\r\n",
      "Epoch:  94 Step:   215 /   793 Train loss: 0.02179787\r\n",
      "Epoch:  94 Step:   216 /   793 Train loss: 0.02385198\r\n",
      "Epoch:  94 Step:   217 /   793 Train loss: 0.04129278\r\n",
      "Epoch:  94 Step:   218 /   793 Train loss: 0.02633718\r\n",
      "Epoch:  94 Step:   219 /   793 Train loss: 0.02853288\r\n",
      "Epoch:  94 Step:   220 /   793 Train loss: 0.03317450\r\n",
      "Epoch:  94 Step:   221 /   793 Train loss: 0.03456829\r\n",
      "Epoch:  94 Step:   222 /   793 Train loss: 0.02280216\r\n",
      "Epoch:  94 Step:   223 /   793 Train loss: 0.02231283\r\n",
      "Epoch:  94 Step:   224 /   793 Train loss: 0.02928910\r\n",
      "Epoch:  94 Step:   225 /   793 Train loss: 0.01303689\r\n",
      "Epoch:  94 Step:   226 /   793 Train loss: 0.01732717\r\n",
      "Epoch:  94 Step:   227 /   793 Train loss: 0.02323425\r\n",
      "Epoch:  94 Step:   228 /   793 Train loss: 0.02781841\r\n",
      "Epoch:  94 Step:   229 /   793 Train loss: 0.02933245\r\n",
      "Epoch:  94 Step:   230 /   793 Train loss: 0.02109330\r\n",
      "Epoch:  94 Step:   231 /   793 Train loss: 0.02467678\r\n",
      "Epoch:  94 Step:   232 /   793 Train loss: 0.01220148\r\n",
      "Epoch:  94 Step:   233 /   793 Train loss: 0.02070879\r\n",
      "Epoch:  94 Step:   234 /   793 Train loss: 0.02228661\r\n",
      "Epoch:  94 Step:   235 /   793 Train loss: 0.02383037\r\n",
      "Epoch:  94 Step:   236 /   793 Train loss: 0.02844309\r\n",
      "Epoch:  94 Step:   237 /   793 Train loss: 0.01474934\r\n",
      "Epoch:  94 Step:   238 /   793 Train loss: 0.01784133\r\n",
      "Epoch:  94 Step:   239 /   793 Train loss: 0.02705256\r\n",
      "Epoch:  94 Step:   240 /   793 Train loss: 0.03027766\r\n",
      "Epoch:  94 Step:   241 /   793 Train loss: 0.03008870\r\n",
      "Epoch:  94 Step:   242 /   793 Train loss: 0.02335177\r\n",
      "Epoch:  94 Step:   243 /   793 Train loss: 0.02105743\r\n",
      "Epoch:  94 Step:   244 /   793 Train loss: 0.02462090\r\n",
      "Epoch:  94 Step:   245 /   793 Train loss: 0.01751283\r\n",
      "Epoch:  94 Step:   246 /   793 Train loss: 0.02981193\r\n",
      "Epoch:  94 Step:   247 /   793 Train loss: 0.02540093\r\n",
      "Epoch:  94 Step:   248 /   793 Train loss: 0.02334113\r\n",
      "Epoch:  94 Step:   249 /   793 Train loss: 0.02166652\r\n",
      "Epoch:  94 Step:   250 /   793 Train loss: 0.02240703\r\n",
      "Epoch:  94 Step:   251 /   793 Train loss: 0.02201123\r\n",
      "Epoch:  94 Step:   252 /   793 Train loss: 0.03270139\r\n",
      "Epoch:  94 Step:   253 /   793 Train loss: 0.02161471\r\n",
      "Epoch:  94 Step:   254 /   793 Train loss: 0.03452628\r\n",
      "Epoch:  94 Step:   255 /   793 Train loss: 0.01953972\r\n",
      "Epoch:  94 Step:   256 /   793 Train loss: 0.01557821\r\n",
      "Epoch:  94 Step:   257 /   793 Train loss: 0.03100854\r\n",
      "Epoch:  94 Step:   258 /   793 Train loss: 0.01692348\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  94 Step:   259 /   793 Train loss: 0.03274697\r\n",
      "Epoch:  94 Step:   260 /   793 Train loss: 0.02392212\r\n",
      "Epoch:  94 Step:   261 /   793 Train loss: 0.02033140\r\n",
      "Epoch:  94 Step:   262 /   793 Train loss: 0.02952608\r\n",
      "Epoch:  94 Step:   263 /   793 Train loss: 0.03087019\r\n",
      "Epoch:  94 Step:   264 /   793 Train loss: 0.01703016\r\n",
      "Epoch:  94 Step:   265 /   793 Train loss: 0.01577590\r\n",
      "Epoch:  94 Step:   266 /   793 Train loss: 0.03006567\r\n",
      "Epoch:  94 Step:   267 /   793 Train loss: 0.01895147\r\n",
      "Epoch:  94 Step:   268 /   793 Train loss: 0.02635165\r\n",
      "Epoch:  94 Step:   269 /   793 Train loss: 0.02606481\r\n",
      "Epoch:  94 Step:   270 /   793 Train loss: 0.02131249\r\n",
      "Epoch:  94 Step:   271 /   793 Train loss: 0.04004348\r\n",
      "Epoch:  94 Step:   272 /   793 Train loss: 0.02060822\r\n",
      "Epoch:  94 Step:   273 /   793 Train loss: 0.02044446\r\n",
      "Epoch:  94 Step:   274 /   793 Train loss: 0.04238302\r\n",
      "Epoch:  94 Step:   275 /   793 Train loss: 0.00836788\r\n",
      "Epoch:  94 Step:   276 /   793 Train loss: 0.02224251\r\n",
      "Epoch:  94 Step:   277 /   793 Train loss: 0.03748129\r\n",
      "Epoch:  94 Step:   278 /   793 Train loss: 0.04515951\r\n",
      "Epoch:  94 Step:   279 /   793 Train loss: 0.03079211\r\n",
      "Epoch:  94 Step:   280 /   793 Train loss: 0.03848390\r\n",
      "Epoch:  94 Step:   281 /   793 Train loss: 0.03095593\r\n",
      "Epoch:  94 Step:   282 /   793 Train loss: 0.02805991\r\n",
      "Epoch:  94 Step:   283 /   793 Train loss: 0.03248579\r\n",
      "Epoch:  94 Step:   284 /   793 Train loss: 0.02097124\r\n",
      "Epoch:  94 Step:   285 /   793 Train loss: 0.02999207\r\n",
      "Epoch:  94 Step:   286 /   793 Train loss: 0.01964267\r\n",
      "Epoch:  94 Step:   287 /   793 Train loss: 0.01812047\r\n",
      "Epoch:  94 Step:   288 /   793 Train loss: 0.02303795\r\n",
      "Epoch:  94 Step:   289 /   793 Train loss: 0.01864203\r\n",
      "Epoch:  94 Step:   290 /   793 Train loss: 0.02548595\r\n",
      "Epoch:  94 Step:   291 /   793 Train loss: 0.02553950\r\n",
      "Epoch:  94 Step:   292 /   793 Train loss: 0.02301574\r\n",
      "Epoch:  94 Step:   293 /   793 Train loss: 0.02430010\r\n",
      "Epoch:  94 Step:   294 /   793 Train loss: 0.02708440\r\n",
      "Epoch:  94 Step:   295 /   793 Train loss: 0.02438199\r\n",
      "Epoch:  94 Step:   296 /   793 Train loss: 0.01697877\r\n",
      "Epoch:  94 Step:   297 /   793 Train loss: 0.02831683\r\n",
      "Epoch:  94 Step:   298 /   793 Train loss: 0.02073392\r\n",
      "Epoch:  94 Step:   299 /   793 Train loss: 0.02178940\r\n",
      "Epoch:  94 Step:   300 /   793 Train loss: 0.03102358\r\n",
      "Epoch:  94 Step:   301 /   793 Train loss: 0.02081221\r\n",
      "Epoch:  94 Step:   302 /   793 Train loss: 0.02374346\r\n",
      "Epoch:  94 Step:   303 /   793 Train loss: 0.01254017\r\n",
      "Epoch:  94 Step:   304 /   793 Train loss: 0.03375195\r\n",
      "Epoch:  94 Step:   305 /   793 Train loss: 0.02363444\r\n",
      "Epoch:  94 Step:   306 /   793 Train loss: 0.02686668\r\n",
      "Epoch:  94 Step:   307 /   793 Train loss: 0.01426256\r\n",
      "Epoch:  94 Step:   308 /   793 Train loss: 0.03034555\r\n",
      "Epoch:  94 Step:   309 /   793 Train loss: 0.01673829\r\n",
      "Epoch:  94 Step:   310 /   793 Train loss: 0.01997088\r\n",
      "Epoch:  94 Step:   311 /   793 Train loss: 0.01862946\r\n",
      "Epoch:  94 Step:   312 /   793 Train loss: 0.02437996\r\n",
      "Epoch:  94 Step:   313 /   793 Train loss: 0.02940746\r\n",
      "Epoch:  94 Step:   314 /   793 Train loss: 0.02414876\r\n",
      "Epoch:  94 Step:   315 /   793 Train loss: 0.03745791\r\n",
      "Epoch:  94 Step:   316 /   793 Train loss: 0.02904630\r\n",
      "Epoch:  94 Step:   317 /   793 Train loss: 0.02683236\r\n",
      "Epoch:  94 Step:   318 /   793 Train loss: 0.02929763\r\n",
      "Epoch:  94 Step:   319 /   793 Train loss: 0.01617867\r\n",
      "Epoch:  94 Step:   320 /   793 Train loss: 0.01851946\r\n",
      "Epoch:  94 Step:   321 /   793 Train loss: 0.03837429\r\n",
      "Epoch:  94 Step:   322 /   793 Train loss: 0.02411688\r\n",
      "Epoch:  94 Step:   323 /   793 Train loss: 0.03633873\r\n",
      "Epoch:  94 Step:   324 /   793 Train loss: 0.01874868\r\n",
      "Epoch:  94 Step:   325 /   793 Train loss: 0.02201150\r\n",
      "Epoch:  94 Step:   326 /   793 Train loss: 0.02092666\r\n",
      "Epoch:  94 Step:   327 /   793 Train loss: 0.02057096\r\n",
      "Epoch:  94 Step:   328 /   793 Train loss: 0.02711847\r\n",
      "Epoch:  94 Step:   329 /   793 Train loss: 0.02026532\r\n",
      "Epoch:  94 Step:   330 /   793 Train loss: 0.03569002\r\n",
      "Epoch:  94 Step:   331 /   793 Train loss: 0.01422380\r\n",
      "Epoch:  94 Step:   332 /   793 Train loss: 0.01231587\r\n",
      "Epoch:  94 Step:   333 /   793 Train loss: 0.02100475\r\n",
      "Epoch:  94 Step:   334 /   793 Train loss: 0.02277129\r\n",
      "Epoch:  94 Step:   335 /   793 Train loss: 0.02630729\r\n",
      "Epoch:  94 Step:   336 /   793 Train loss: 0.03121043\r\n",
      "Epoch:  94 Step:   337 /   793 Train loss: 0.02315906\r\n",
      "Epoch:  94 Step:   338 /   793 Train loss: 0.02260231\r\n",
      "Epoch:  94 Step:   339 /   793 Train loss: 0.03090013\r\n",
      "Epoch:  94 Step:   340 /   793 Train loss: 0.02050467\r\n",
      "Epoch:  94 Step:   341 /   793 Train loss: 0.02153006\r\n",
      "Epoch:  94 Step:   342 /   793 Train loss: 0.02292453\r\n",
      "Epoch:  94 Step:   343 /   793 Train loss: 0.03503563\r\n",
      "Epoch:  94 Step:   344 /   793 Train loss: 0.01804744\r\n",
      "Epoch:  94 Step:   345 /   793 Train loss: 0.01681196\r\n",
      "Epoch:  94 Step:   346 /   793 Train loss: 0.02394833\r\n",
      "Epoch:  94 Step:   347 /   793 Train loss: 0.05084178\r\n",
      "Epoch:  94 Step:   348 /   793 Train loss: 0.02500783\r\n",
      "Epoch:  94 Step:   349 /   793 Train loss: 0.01925314\r\n",
      "Epoch:  94 Step:   350 /   793 Train loss: 0.01800882\r\n",
      "Epoch:  94 Step:   351 /   793 Train loss: 0.03096025\r\n",
      "Epoch:  94 Step:   352 /   793 Train loss: 0.02300902\r\n",
      "Epoch:  94 Step:   353 /   793 Train loss: 0.01567731\r\n",
      "Epoch:  94 Step:   354 /   793 Train loss: 0.03584810\r\n",
      "Epoch:  94 Step:   355 /   793 Train loss: 0.02907912\r\n",
      "Epoch:  94 Step:   356 /   793 Train loss: 0.02173924\r\n",
      "Epoch:  94 Step:   357 /   793 Train loss: 0.01797472\r\n",
      "Epoch:  94 Step:   358 /   793 Train loss: 0.01977860\r\n",
      "Epoch:  94 Step:   359 /   793 Train loss: 0.02182478\r\n",
      "Epoch:  94 Step:   360 /   793 Train loss: 0.02105597\r\n",
      "Epoch:  94 Step:   361 /   793 Train loss: 0.02793097\r\n",
      "Epoch:  94 Step:   362 /   793 Train loss: 0.02651029\r\n",
      "Epoch:  94 Step:   363 /   793 Train loss: 0.02697897\r\n",
      "Epoch:  94 Step:   364 /   793 Train loss: 0.03391384\r\n",
      "Epoch:  94 Step:   365 /   793 Train loss: 0.02245928\r\n",
      "Epoch:  94 Step:   366 /   793 Train loss: 0.02044508\r\n",
      "Epoch:  94 Step:   367 /   793 Train loss: 0.02712594\r\n",
      "Epoch:  94 Step:   368 /   793 Train loss: 0.01928853\r\n",
      "Epoch:  94 Step:   369 /   793 Train loss: 0.01821556\r\n",
      "Epoch:  94 Step:   370 /   793 Train loss: 0.02368947\r\n",
      "Epoch:  94 Step:   371 /   793 Train loss: 0.02578837\r\n",
      "Epoch:  94 Step:   372 /   793 Train loss: 0.01012418\r\n",
      "Epoch:  94 Step:   373 /   793 Train loss: 0.01116511\r\n",
      "Epoch:  94 Step:   374 /   793 Train loss: 0.02471912\r\n",
      "Epoch:  94 Step:   375 /   793 Train loss: 0.03299082\r\n",
      "Epoch:  94 Step:   376 /   793 Train loss: 0.03515639\r\n",
      "Epoch:  94 Step:   377 /   793 Train loss: 0.03986998\r\n",
      "Epoch:  94 Step:   378 /   793 Train loss: 0.02554505\r\n",
      "Epoch:  94 Step:   379 /   793 Train loss: 0.02934409\r\n",
      "Epoch:  94 Step:   380 /   793 Train loss: 0.03024905\r\n",
      "Epoch:  94 Step:   381 /   793 Train loss: 0.01740452\r\n",
      "Epoch:  94 Step:   382 /   793 Train loss: 0.02979572\r\n",
      "Epoch:  94 Step:   383 /   793 Train loss: 0.00840167\r\n",
      "Epoch:  94 Step:   384 /   793 Train loss: 0.01746874\r\n",
      "Epoch:  94 Step:   385 /   793 Train loss: 0.02069996\r\n",
      "Epoch:  94 Step:   386 /   793 Train loss: 0.02667035\r\n",
      "Epoch:  94 Step:   387 /   793 Train loss: 0.03982581\r\n",
      "Epoch:  94 Step:   388 /   793 Train loss: 0.01949236\r\n",
      "Epoch:  94 Step:   389 /   793 Train loss: 0.03195664\r\n",
      "Epoch:  94 Step:   390 /   793 Train loss: 0.01728351\r\n",
      "Epoch:  94 Step:   391 /   793 Train loss: 0.01714780\r\n",
      "Epoch:  94 Step:   392 /   793 Train loss: 0.02787104\r\n",
      "Epoch:  94 Step:   393 /   793 Train loss: 0.03167864\r\n",
      "Epoch:  94 Step:   394 /   793 Train loss: 0.01639125\r\n",
      "Epoch:  94 Step:   395 /   793 Train loss: 0.02430853\r\n",
      "Epoch:  94 Step:   396 /   793 Train loss: 0.01553143\r\n",
      "Epoch:  94 Step:   397 /   793 Train loss: 0.02857994\r\n",
      "Epoch:  94 Step:   398 /   793 Train loss: 0.01921543\r\n",
      "Epoch:  94 Step:   399 /   793 Train loss: 0.04157703\r\n",
      "Epoch:  94 Step:   400 /   793 Train loss: 0.01452145\r\n",
      "Epoch:  94 Step:   401 /   793 Train loss: 0.02643530\r\n",
      "Epoch:  94 Step:   402 /   793 Train loss: 0.01468563\r\n",
      "Epoch:  94 Step:   403 /   793 Train loss: 0.03390032\r\n",
      "Epoch:  94 Step:   404 /   793 Train loss: 0.01709101\r\n",
      "Epoch:  94 Step:   405 /   793 Train loss: 0.01844894\r\n",
      "Epoch:  94 Step:   406 /   793 Train loss: 0.02712501\r\n",
      "Epoch:  94 Step:   407 /   793 Train loss: 0.00900733\r\n",
      "Epoch:  94 Step:   408 /   793 Train loss: 0.01760755\r\n",
      "Epoch:  94 Step:   409 /   793 Train loss: 0.02640078\r\n",
      "Epoch:  94 Step:   410 /   793 Train loss: 0.01569342\r\n",
      "Epoch:  94 Step:   411 /   793 Train loss: 0.02083787\r\n",
      "Epoch:  94 Step:   412 /   793 Train loss: 0.01480503\r\n",
      "Epoch:  94 Step:   413 /   793 Train loss: 0.02364922\r\n",
      "Epoch:  94 Step:   414 /   793 Train loss: 0.01731162\r\n",
      "Epoch:  94 Step:   415 /   793 Train loss: 0.04049586\r\n",
      "Epoch:  94 Step:   416 /   793 Train loss: 0.02805192\r\n",
      "Epoch:  94 Step:   417 /   793 Train loss: 0.02948376\r\n",
      "Epoch:  94 Step:   418 /   793 Train loss: 0.02125098\r\n",
      "Epoch:  94 Step:   419 /   793 Train loss: 0.02660660\r\n",
      "Epoch:  94 Step:   420 /   793 Train loss: 0.01793387\r\n",
      "Epoch:  94 Step:   421 /   793 Train loss: 0.01839798\r\n",
      "Epoch:  94 Step:   422 /   793 Train loss: 0.03291626\r\n",
      "Epoch:  94 Step:   423 /   793 Train loss: 0.03371574\r\n",
      "Epoch:  94 Step:   424 /   793 Train loss: 0.02042417\r\n",
      "Epoch:  94 Step:   425 /   793 Train loss: 0.03410409\r\n",
      "Epoch:  94 Step:   426 /   793 Train loss: 0.03239808\r\n",
      "Epoch:  94 Step:   427 /   793 Train loss: 0.02478893\r\n",
      "Epoch:  94 Step:   428 /   793 Train loss: 0.03181452\r\n",
      "Epoch:  94 Step:   429 /   793 Train loss: 0.02396506\r\n",
      "Epoch:  94 Step:   430 /   793 Train loss: 0.02970955\r\n",
      "Epoch:  94 Step:   431 /   793 Train loss: 0.01995785\r\n",
      "Epoch:  94 Step:   432 /   793 Train loss: 0.01365026\r\n",
      "Epoch:  94 Step:   433 /   793 Train loss: 0.02567073\r\n",
      "Epoch:  94 Step:   434 /   793 Train loss: 0.02372165\r\n",
      "Epoch:  94 Step:   435 /   793 Train loss: 0.02260090\r\n",
      "Epoch:  94 Step:   436 /   793 Train loss: 0.02776615\r\n",
      "Epoch:  94 Step:   437 /   793 Train loss: 0.02586416\r\n",
      "Epoch:  94 Step:   438 /   793 Train loss: 0.02830547\r\n",
      "Epoch:  94 Step:   439 /   793 Train loss: 0.02448253\r\n",
      "Epoch:  94 Step:   440 /   793 Train loss: 0.02372115\r\n",
      "Epoch:  94 Step:   441 /   793 Train loss: 0.02279924\r\n",
      "Epoch:  94 Step:   442 /   793 Train loss: 0.01328738\r\n",
      "Epoch:  94 Step:   443 /   793 Train loss: 0.02096884\r\n",
      "Epoch:  94 Step:   444 /   793 Train loss: 0.01469041\r\n",
      "Epoch:  94 Step:   445 /   793 Train loss: 0.01978601\r\n",
      "Epoch:  94 Step:   446 /   793 Train loss: 0.01714651\r\n",
      "Epoch:  94 Step:   447 /   793 Train loss: 0.02581270\r\n",
      "Epoch:  94 Step:   448 /   793 Train loss: 0.02684485\r\n",
      "Epoch:  94 Step:   449 /   793 Train loss: 0.02050353\r\n",
      "Epoch:  94 Step:   450 /   793 Train loss: 0.01971964\r\n",
      "Epoch:  94 Step:   451 /   793 Train loss: 0.01860202\r\n",
      "Epoch:  94 Step:   452 /   793 Train loss: 0.01963761\r\n",
      "Epoch:  94 Step:   453 /   793 Train loss: 0.01534837\r\n",
      "Epoch:  94 Step:   454 /   793 Train loss: 0.02281788\r\n",
      "Epoch:  94 Step:   455 /   793 Train loss: 0.03140681\r\n",
      "Epoch:  94 Step:   456 /   793 Train loss: 0.01837663\r\n",
      "Epoch:  94 Step:   457 /   793 Train loss: 0.02093545\r\n",
      "Epoch:  94 Step:   458 /   793 Train loss: 0.02069513\r\n",
      "Epoch:  94 Step:   459 /   793 Train loss: 0.03649545\r\n",
      "Epoch:  94 Step:   460 /   793 Train loss: 0.03368165\r\n",
      "Epoch:  94 Step:   461 /   793 Train loss: 0.02339718\r\n",
      "Epoch:  94 Step:   462 /   793 Train loss: 0.03302360\r\n",
      "Epoch:  94 Step:   463 /   793 Train loss: 0.02856719\r\n",
      "Epoch:  94 Step:   464 /   793 Train loss: 0.01874375\r\n",
      "Epoch:  94 Step:   465 /   793 Train loss: 0.02739425\r\n",
      "Epoch:  94 Step:   466 /   793 Train loss: 0.01262252\r\n",
      "Epoch:  94 Step:   467 /   793 Train loss: 0.01886048\r\n",
      "Epoch:  94 Step:   468 /   793 Train loss: 0.02908174\r\n",
      "Epoch:  94 Step:   469 /   793 Train loss: 0.02569313\r\n",
      "Epoch:  94 Step:   470 /   793 Train loss: 0.02564877\r\n",
      "Epoch:  94 Step:   471 /   793 Train loss: 0.02216412\r\n",
      "Epoch:  94 Step:   472 /   793 Train loss: 0.01499491\r\n",
      "Epoch:  94 Step:   473 /   793 Train loss: 0.02225451\r\n",
      "Epoch:  94 Step:   474 /   793 Train loss: 0.01693642\r\n",
      "Epoch:  94 Step:   475 /   793 Train loss: 0.03111136\r\n",
      "Epoch:  94 Step:   476 /   793 Train loss: 0.02404118\r\n",
      "Epoch:  94 Step:   477 /   793 Train loss: 0.02395293\r\n",
      "Epoch:  94 Step:   478 /   793 Train loss: 0.02546448\r\n",
      "Epoch:  94 Step:   479 /   793 Train loss: 0.02564564\r\n",
      "Epoch:  94 Step:   480 /   793 Train loss: 0.03147104\r\n",
      "Epoch:  94 Step:   481 /   793 Train loss: 0.02237244\r\n",
      "Epoch:  94 Step:   482 /   793 Train loss: 0.01655916\r\n",
      "Epoch:  94 Step:   483 /   793 Train loss: 0.01550498\r\n",
      "Epoch:  94 Step:   484 /   793 Train loss: 0.01107418\r\n",
      "Epoch:  94 Step:   485 /   793 Train loss: 0.02770738\r\n",
      "Epoch:  94 Step:   486 /   793 Train loss: 0.02322552\r\n",
      "Epoch:  94 Step:   487 /   793 Train loss: 0.02658698\r\n",
      "Epoch:  94 Step:   488 /   793 Train loss: 0.02741791\r\n",
      "Epoch:  94 Step:   489 /   793 Train loss: 0.03528511\r\n",
      "Epoch:  94 Step:   490 /   793 Train loss: 0.02040428\r\n",
      "Epoch:  94 Step:   491 /   793 Train loss: 0.01676219\r\n",
      "Epoch:  94 Step:   492 /   793 Train loss: 0.02799509\r\n",
      "Epoch:  94 Step:   493 /   793 Train loss: 0.01287274\r\n",
      "Epoch:  94 Step:   494 /   793 Train loss: 0.01599621\r\n",
      "Epoch:  94 Step:   495 /   793 Train loss: 0.03118469\r\n",
      "Epoch:  94 Step:   496 /   793 Train loss: 0.03046427\r\n",
      "Epoch:  94 Step:   497 /   793 Train loss: 0.03178337\r\n",
      "Epoch:  94 Step:   498 /   793 Train loss: 0.03301184\r\n",
      "Epoch:  94 Step:   499 /   793 Train loss: 0.02484844\r\n",
      "Epoch:  94 Step:   500 /   793 Train loss: 0.02403693\r\n",
      "Epoch:  94 Step:   501 /   793 Train loss: 0.01646181\r\n",
      "Epoch:  94 Step:   502 /   793 Train loss: 0.02685992\r\n",
      "Epoch:  94 Step:   503 /   793 Train loss: 0.02071735\r\n",
      "Epoch:  94 Step:   504 /   793 Train loss: 0.01383480\r\n",
      "Epoch:  94 Step:   505 /   793 Train loss: 0.02071548\r\n",
      "Epoch:  94 Step:   506 /   793 Train loss: 0.02611747\r\n",
      "Epoch:  94 Step:   507 /   793 Train loss: 0.02942447\r\n",
      "Epoch:  94 Step:   508 /   793 Train loss: 0.01905402\r\n",
      "Epoch:  94 Step:   509 /   793 Train loss: 0.02114718\r\n",
      "Epoch:  94 Step:   510 /   793 Train loss: 0.02587142\r\n",
      "Epoch:  94 Step:   511 /   793 Train loss: 0.01760390\r\n",
      "Epoch:  94 Step:   512 /   793 Train loss: 0.02596402\r\n",
      "Epoch:  94 Step:   513 /   793 Train loss: 0.02725276\r\n",
      "Epoch:  94 Step:   514 /   793 Train loss: 0.02666074\r\n",
      "Epoch:  94 Step:   515 /   793 Train loss: 0.01457793\r\n",
      "Epoch:  94 Step:   516 /   793 Train loss: 0.02114104\r\n",
      "Epoch:  94 Step:   517 /   793 Train loss: 0.01943932\r\n",
      "Epoch:  94 Step:   518 /   793 Train loss: 0.02536898\r\n",
      "Epoch:  94 Step:   519 /   793 Train loss: 0.02310558\r\n",
      "Epoch:  94 Step:   520 /   793 Train loss: 0.02045193\r\n",
      "Epoch:  94 Step:   521 /   793 Train loss: 0.01086813\r\n",
      "Epoch:  94 Step:   522 /   793 Train loss: 0.02470692\r\n",
      "Epoch:  94 Step:   523 /   793 Train loss: 0.01814939\r\n",
      "Epoch:  94 Step:   524 /   793 Train loss: 0.02587247\r\n",
      "Epoch:  94 Step:   525 /   793 Train loss: 0.02291621\r\n",
      "Epoch:  94 Step:   526 /   793 Train loss: 0.02483424\r\n",
      "Epoch:  94 Step:   527 /   793 Train loss: 0.02012898\r\n",
      "Epoch:  94 Step:   528 /   793 Train loss: 0.02500596\r\n",
      "Epoch:  94 Step:   529 /   793 Train loss: 0.01362412\r\n",
      "Epoch:  94 Step:   530 /   793 Train loss: 0.03417145\r\n",
      "Epoch:  94 Step:   531 /   793 Train loss: 0.01318320\r\n",
      "Epoch:  94 Step:   532 /   793 Train loss: 0.02591069\r\n",
      "Epoch:  94 Step:   533 /   793 Train loss: 0.01754196\r\n",
      "Epoch:  94 Step:   534 /   793 Train loss: 0.02894590\r\n",
      "Epoch:  94 Step:   535 /   793 Train loss: 0.01702575\r\n",
      "Epoch:  94 Step:   536 /   793 Train loss: 0.02886749\r\n",
      "Epoch:  94 Step:   537 /   793 Train loss: 0.03080344\r\n",
      "Epoch:  94 Step:   538 /   793 Train loss: 0.03589105\r\n",
      "Epoch:  94 Step:   539 /   793 Train loss: 0.01585153\r\n",
      "Epoch:  94 Step:   540 /   793 Train loss: 0.04846238\r\n",
      "Epoch:  94 Step:   541 /   793 Train loss: 0.02838920\r\n",
      "Epoch:  94 Step:   542 /   793 Train loss: 0.02439811\r\n",
      "Epoch:  94 Step:   543 /   793 Train loss: 0.02877512\r\n",
      "Epoch:  94 Step:   544 /   793 Train loss: 0.02990472\r\n",
      "Epoch:  94 Step:   545 /   793 Train loss: 0.03942214\r\n",
      "Epoch:  94 Step:   546 /   793 Train loss: 0.00904476\r\n",
      "Epoch:  94 Step:   547 /   793 Train loss: 0.03574630\r\n",
      "Epoch:  94 Step:   548 /   793 Train loss: 0.01782940\r\n",
      "Epoch:  94 Step:   549 /   793 Train loss: 0.01783837\r\n",
      "Epoch:  94 Step:   550 /   793 Train loss: 0.01943070\r\n",
      "Epoch:  94 Step:   551 /   793 Train loss: 0.03082162\r\n",
      "Epoch:  94 Step:   552 /   793 Train loss: 0.01940403\r\n",
      "Epoch:  94 Step:   553 /   793 Train loss: 0.02825566\r\n",
      "Epoch:  94 Step:   554 /   793 Train loss: 0.02378607\r\n",
      "Epoch:  94 Step:   555 /   793 Train loss: 0.02370947\r\n",
      "Epoch:  94 Step:   556 /   793 Train loss: 0.02160495\r\n",
      "Epoch:  94 Step:   557 /   793 Train loss: 0.03154770\r\n",
      "Epoch:  94 Step:   558 /   793 Train loss: 0.02515143\r\n",
      "Epoch:  94 Step:   559 /   793 Train loss: 0.03768756\r\n",
      "Epoch:  94 Step:   560 /   793 Train loss: 0.03775439\r\n",
      "Epoch:  94 Step:   561 /   793 Train loss: 0.02018951\r\n",
      "Epoch:  94 Step:   562 /   793 Train loss: 0.01552353\r\n",
      "Epoch:  94 Step:   563 /   793 Train loss: 0.02399698\r\n",
      "Epoch:  94 Step:   564 /   793 Train loss: 0.03363432\r\n",
      "Epoch:  94 Step:   565 /   793 Train loss: 0.01727405\r\n",
      "Epoch:  94 Step:   566 /   793 Train loss: 0.02994028\r\n",
      "Epoch:  94 Step:   567 /   793 Train loss: 0.01095484\r\n",
      "Epoch:  94 Step:   568 /   793 Train loss: 0.01883204\r\n",
      "Epoch:  94 Step:   569 /   793 Train loss: 0.02503373\r\n",
      "Epoch:  94 Step:   570 /   793 Train loss: 0.01998452\r\n",
      "Epoch:  94 Step:   571 /   793 Train loss: 0.01897611\r\n",
      "Epoch:  94 Step:   572 /   793 Train loss: 0.02080890\r\n",
      "Epoch:  94 Step:   573 /   793 Train loss: 0.01936806\r\n",
      "Epoch:  94 Step:   574 /   793 Train loss: 0.02440053\r\n",
      "Epoch:  94 Step:   575 /   793 Train loss: 0.02810637\r\n",
      "Epoch:  94 Step:   576 /   793 Train loss: 0.02012321\r\n",
      "Epoch:  94 Step:   577 /   793 Train loss: 0.03091021\r\n",
      "Epoch:  94 Step:   578 /   793 Train loss: 0.02094528\r\n",
      "Epoch:  94 Step:   579 /   793 Train loss: 0.03133756\r\n",
      "Epoch:  94 Step:   580 /   793 Train loss: 0.01815669\r\n",
      "Epoch:  94 Step:   581 /   793 Train loss: 0.02346281\r\n",
      "Epoch:  94 Step:   582 /   793 Train loss: 0.02616297\r\n",
      "Epoch:  94 Step:   583 /   793 Train loss: 0.02071557\r\n",
      "Epoch:  94 Step:   584 /   793 Train loss: 0.02112238\r\n",
      "Epoch:  94 Step:   585 /   793 Train loss: 0.02520663\r\n",
      "Epoch:  94 Step:   586 /   793 Train loss: 0.02452517\r\n",
      "Epoch:  94 Step:   587 /   793 Train loss: 0.01932818\r\n",
      "Epoch:  94 Step:   588 /   793 Train loss: 0.01464541\r\n",
      "Epoch:  94 Step:   589 /   793 Train loss: 0.03110115\r\n",
      "Epoch:  94 Step:   590 /   793 Train loss: 0.01854772\r\n",
      "Epoch:  94 Step:   591 /   793 Train loss: 0.03573556\r\n",
      "Epoch:  94 Step:   592 /   793 Train loss: 0.01230315\r\n",
      "Epoch:  94 Step:   593 /   793 Train loss: 0.02284652\r\n",
      "Epoch:  94 Step:   594 /   793 Train loss: 0.03004951\r\n",
      "Epoch:  94 Step:   595 /   793 Train loss: 0.03716958\r\n",
      "Epoch:  94 Step:   596 /   793 Train loss: 0.03152759\r\n",
      "Epoch:  94 Step:   597 /   793 Train loss: 0.02687770\r\n",
      "Epoch:  94 Step:   598 /   793 Train loss: 0.03247098\r\n",
      "Epoch:  94 Step:   599 /   793 Train loss: 0.02178432\r\n",
      "Epoch:  94 Step:   600 /   793 Train loss: 0.02074981\r\n",
      "Epoch:  94 Step:   601 /   793 Train loss: 0.02049111\r\n",
      "Epoch:  94 Step:   602 /   793 Train loss: 0.01441947\r\n",
      "Epoch:  94 Step:   603 /   793 Train loss: 0.03249800\r\n",
      "Epoch:  94 Step:   604 /   793 Train loss: 0.01787848\r\n",
      "Epoch:  94 Step:   605 /   793 Train loss: 0.01863415\r\n",
      "Epoch:  94 Step:   606 /   793 Train loss: 0.02558086\r\n",
      "Epoch:  94 Step:   607 /   793 Train loss: 0.01524793\r\n",
      "Epoch:  94 Step:   608 /   793 Train loss: 0.02336928\r\n",
      "Epoch:  94 Step:   609 /   793 Train loss: 0.02478760\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  94 Step:   610 /   793 Train loss: 0.01980928\r\n",
      "Epoch:  94 Step:   611 /   793 Train loss: 0.03142126\r\n",
      "Epoch:  94 Step:   612 /   793 Train loss: 0.03507571\r\n",
      "Epoch:  94 Step:   613 /   793 Train loss: 0.02216564\r\n",
      "Epoch:  94 Step:   614 /   793 Train loss: 0.03770822\r\n",
      "Epoch:  94 Step:   615 /   793 Train loss: 0.02739185\r\n",
      "Epoch:  94 Step:   616 /   793 Train loss: 0.01148694\r\n",
      "Epoch:  94 Step:   617 /   793 Train loss: 0.03055378\r\n",
      "Epoch:  94 Step:   618 /   793 Train loss: 0.01863086\r\n",
      "Epoch:  94 Step:   619 /   793 Train loss: 0.03532493\r\n",
      "Epoch:  94 Step:   620 /   793 Train loss: 0.03086665\r\n",
      "Epoch:  94 Step:   621 /   793 Train loss: 0.03938491\r\n",
      "Epoch:  94 Step:   622 /   793 Train loss: 0.03349684\r\n",
      "Epoch:  94 Step:   623 /   793 Train loss: 0.02910300\r\n",
      "Epoch:  94 Step:   624 /   793 Train loss: 0.03025226\r\n",
      "Epoch:  94 Step:   625 /   793 Train loss: 0.01986010\r\n",
      "Epoch:  94 Step:   626 /   793 Train loss: 0.02727264\r\n",
      "Epoch:  94 Step:   627 /   793 Train loss: 0.03595847\r\n",
      "Epoch:  94 Step:   628 /   793 Train loss: 0.00842195\r\n",
      "Epoch:  94 Step:   629 /   793 Train loss: 0.02237875\r\n",
      "Epoch:  94 Step:   630 /   793 Train loss: 0.03421023\r\n",
      "Epoch:  94 Step:   631 /   793 Train loss: 0.03014219\r\n",
      "Epoch:  94 Step:   632 /   793 Train loss: 0.04376885\r\n",
      "Epoch:  94 Step:   633 /   793 Train loss: 0.02086875\r\n",
      "Epoch:  94 Step:   634 /   793 Train loss: 0.03404452\r\n",
      "Epoch:  94 Step:   635 /   793 Train loss: 0.02662916\r\n",
      "Epoch:  94 Step:   636 /   793 Train loss: 0.01951179\r\n",
      "Epoch:  94 Step:   637 /   793 Train loss: 0.03233785\r\n",
      "Epoch:  94 Step:   638 /   793 Train loss: 0.03213791\r\n",
      "Epoch:  94 Step:   639 /   793 Train loss: 0.02623517\r\n",
      "Epoch:  94 Step:   640 /   793 Train loss: 0.02236040\r\n",
      "Epoch:  94 Step:   641 /   793 Train loss: 0.02312409\r\n",
      "Epoch:  94 Step:   642 /   793 Train loss: 0.01551394\r\n",
      "Epoch:  94 Step:   643 /   793 Train loss: 0.03097704\r\n",
      "Epoch:  94 Step:   644 /   793 Train loss: 0.01616350\r\n",
      "Epoch:  94 Step:   645 /   793 Train loss: 0.01915894\r\n",
      "Epoch:  94 Step:   646 /   793 Train loss: 0.02816122\r\n",
      "Epoch:  94 Step:   647 /   793 Train loss: 0.01990103\r\n",
      "Epoch:  94 Step:   648 /   793 Train loss: 0.01615021\r\n",
      "Epoch:  94 Step:   649 /   793 Train loss: 0.01460622\r\n",
      "Epoch:  94 Step:   650 /   793 Train loss: 0.01149042\r\n",
      "Epoch:  94 Step:   651 /   793 Train loss: 0.02650766\r\n",
      "Epoch:  94 Step:   652 /   793 Train loss: 0.02691294\r\n",
      "Epoch:  94 Step:   653 /   793 Train loss: 0.03340456\r\n",
      "Epoch:  94 Step:   654 /   793 Train loss: 0.02514821\r\n",
      "Epoch:  94 Step:   655 /   793 Train loss: 0.04188328\r\n",
      "Epoch:  94 Step:   656 /   793 Train loss: 0.02431313\r\n",
      "Epoch:  94 Step:   657 /   793 Train loss: 0.02093963\r\n",
      "Epoch:  94 Step:   658 /   793 Train loss: 0.00839866\r\n",
      "Epoch:  94 Step:   659 /   793 Train loss: 0.01989232\r\n",
      "Epoch:  94 Step:   660 /   793 Train loss: 0.03172117\r\n",
      "Epoch:  94 Step:   661 /   793 Train loss: 0.03124136\r\n",
      "Epoch:  94 Step:   662 /   793 Train loss: 0.02427581\r\n",
      "Epoch:  94 Step:   663 /   793 Train loss: 0.02152457\r\n",
      "Epoch:  94 Step:   664 /   793 Train loss: 0.01825010\r\n",
      "Epoch:  94 Step:   665 /   793 Train loss: 0.03599155\r\n",
      "Epoch:  94 Step:   666 /   793 Train loss: 0.02699597\r\n",
      "Epoch:  94 Step:   667 /   793 Train loss: 0.02268242\r\n",
      "Epoch:  94 Step:   668 /   793 Train loss: 0.01523175\r\n",
      "Epoch:  94 Step:   669 /   793 Train loss: 0.03237158\r\n",
      "Epoch:  94 Step:   670 /   793 Train loss: 0.01006739\r\n",
      "Epoch:  94 Step:   671 /   793 Train loss: 0.02001479\r\n",
      "Epoch:  94 Step:   672 /   793 Train loss: 0.01524054\r\n",
      "Epoch:  94 Step:   673 /   793 Train loss: 0.01742122\r\n",
      "Epoch:  94 Step:   674 /   793 Train loss: 0.01626272\r\n",
      "Epoch:  94 Step:   675 /   793 Train loss: 0.01996974\r\n",
      "Epoch:  94 Step:   676 /   793 Train loss: 0.02964711\r\n",
      "Epoch:  94 Step:   677 /   793 Train loss: 0.02273909\r\n",
      "Epoch:  94 Step:   678 /   793 Train loss: 0.01707657\r\n",
      "Epoch:  94 Step:   679 /   793 Train loss: 0.01669874\r\n",
      "Epoch:  94 Step:   680 /   793 Train loss: 0.01095429\r\n",
      "Epoch:  94 Step:   681 /   793 Train loss: 0.02704039\r\n",
      "Epoch:  94 Step:   682 /   793 Train loss: 0.02445948\r\n",
      "Epoch:  94 Step:   683 /   793 Train loss: 0.02668941\r\n",
      "Epoch:  94 Step:   684 /   793 Train loss: 0.01790563\r\n",
      "Epoch:  94 Step:   685 /   793 Train loss: 0.01475806\r\n",
      "Epoch:  94 Step:   686 /   793 Train loss: 0.02563016\r\n",
      "Epoch:  94 Step:   687 /   793 Train loss: 0.01936326\r\n",
      "Epoch:  94 Step:   688 /   793 Train loss: 0.02653168\r\n",
      "Epoch:  94 Step:   689 /   793 Train loss: 0.01539813\r\n",
      "Epoch:  94 Step:   690 /   793 Train loss: 0.01273300\r\n",
      "Epoch:  94 Step:   691 /   793 Train loss: 0.01988534\r\n",
      "Epoch:  94 Step:   692 /   793 Train loss: 0.01574958\r\n",
      "Epoch:  94 Step:   693 /   793 Train loss: 0.02830240\r\n",
      "Epoch:  94 Step:   694 /   793 Train loss: 0.02095090\r\n",
      "Epoch:  94 Step:   695 /   793 Train loss: 0.01536809\r\n",
      "Epoch:  94 Step:   696 /   793 Train loss: 0.01287453\r\n",
      "Epoch:  94 Step:   697 /   793 Train loss: 0.01967755\r\n",
      "Epoch:  94 Step:   698 /   793 Train loss: 0.02554217\r\n",
      "Epoch:  94 Step:   699 /   793 Train loss: 0.02712809\r\n",
      "Epoch:  94 Step:   700 /   793 Train loss: 0.03101443\r\n",
      "Epoch:  94 Step:   701 /   793 Train loss: 0.02225133\r\n",
      "Epoch:  94 Step:   702 /   793 Train loss: 0.02372648\r\n",
      "Epoch:  94 Step:   703 /   793 Train loss: 0.03489787\r\n",
      "Epoch:  94 Step:   704 /   793 Train loss: 0.02731237\r\n",
      "Epoch:  94 Step:   705 /   793 Train loss: 0.02990062\r\n",
      "Epoch:  94 Step:   706 /   793 Train loss: 0.02510271\r\n",
      "Epoch:  94 Step:   707 /   793 Train loss: 0.02158665\r\n",
      "Epoch:  94 Step:   708 /   793 Train loss: 0.03638560\r\n",
      "Epoch:  94 Step:   709 /   793 Train loss: 0.02302322\r\n",
      "Epoch:  94 Step:   710 /   793 Train loss: 0.01633778\r\n",
      "Epoch:  94 Step:   711 /   793 Train loss: 0.02445989\r\n",
      "Epoch:  94 Step:   712 /   793 Train loss: 0.01688061\r\n",
      "Epoch:  94 Step:   713 /   793 Train loss: 0.03049789\r\n",
      "Epoch:  94 Step:   714 /   793 Train loss: 0.01718693\r\n",
      "Epoch:  94 Step:   715 /   793 Train loss: 0.02214788\r\n",
      "Epoch:  94 Step:   716 /   793 Train loss: 0.03509865\r\n",
      "Epoch:  94 Step:   717 /   793 Train loss: 0.02163208\r\n",
      "Epoch:  94 Step:   718 /   793 Train loss: 0.02279207\r\n",
      "Epoch:  94 Step:   719 /   793 Train loss: 0.02058725\r\n",
      "Epoch:  94 Step:   720 /   793 Train loss: 0.02462575\r\n",
      "Epoch:  94 Step:   721 /   793 Train loss: 0.03573858\r\n",
      "Epoch:  94 Step:   722 /   793 Train loss: 0.02205112\r\n",
      "Epoch:  94 Step:   723 /   793 Train loss: 0.01209902\r\n",
      "Epoch:  94 Step:   724 /   793 Train loss: 0.03247114\r\n",
      "Epoch:  94 Step:   725 /   793 Train loss: 0.02607834\r\n",
      "Epoch:  94 Step:   726 /   793 Train loss: 0.02621451\r\n",
      "Epoch:  94 Step:   727 /   793 Train loss: 0.02214721\r\n",
      "Epoch:  94 Step:   728 /   793 Train loss: 0.02314691\r\n",
      "Epoch:  94 Step:   729 /   793 Train loss: 0.01541507\r\n",
      "Epoch:  94 Step:   730 /   793 Train loss: 0.02407795\r\n",
      "Epoch:  94 Step:   731 /   793 Train loss: 0.02807485\r\n",
      "Epoch:  94 Step:   732 /   793 Train loss: 0.02573934\r\n",
      "Epoch:  94 Step:   733 /   793 Train loss: 0.02726384\r\n",
      "Epoch:  94 Step:   734 /   793 Train loss: 0.03588771\r\n",
      "Epoch:  94 Step:   735 /   793 Train loss: 0.01849709\r\n",
      "Epoch:  94 Step:   736 /   793 Train loss: 0.01871161\r\n",
      "Epoch:  94 Step:   737 /   793 Train loss: 0.03335606\r\n",
      "Epoch:  94 Step:   738 /   793 Train loss: 0.02882030\r\n",
      "Epoch:  94 Step:   739 /   793 Train loss: 0.01070216\r\n",
      "Epoch:  94 Step:   740 /   793 Train loss: 0.03697083\r\n",
      "Epoch:  94 Step:   741 /   793 Train loss: 0.01817863\r\n",
      "Epoch:  94 Step:   742 /   793 Train loss: 0.04307956\r\n",
      "Epoch:  94 Step:   743 /   793 Train loss: 0.01223998\r\n",
      "Epoch:  94 Step:   744 /   793 Train loss: 0.02087866\r\n",
      "Epoch:  94 Step:   745 /   793 Train loss: 0.01933013\r\n",
      "Epoch:  94 Step:   746 /   793 Train loss: 0.03945185\r\n",
      "Epoch:  94 Step:   747 /   793 Train loss: 0.02708415\r\n",
      "Epoch:  94 Step:   748 /   793 Train loss: 0.01532791\r\n",
      "Epoch:  94 Step:   749 /   793 Train loss: 0.02411478\r\n",
      "Epoch:  94 Step:   750 /   793 Train loss: 0.02294340\r\n",
      "Epoch:  94 Step:   751 /   793 Train loss: 0.01362829\r\n",
      "Epoch:  94 Step:   752 /   793 Train loss: 0.02467216\r\n",
      "Epoch:  94 Step:   753 /   793 Train loss: 0.01760725\r\n",
      "Epoch:  94 Step:   754 /   793 Train loss: 0.03311400\r\n",
      "Epoch:  94 Step:   755 /   793 Train loss: 0.02551351\r\n",
      "Epoch:  94 Step:   756 /   793 Train loss: 0.02562871\r\n",
      "Epoch:  94 Step:   757 /   793 Train loss: 0.02015887\r\n",
      "Epoch:  94 Step:   758 /   793 Train loss: 0.02794149\r\n",
      "Epoch:  94 Step:   759 /   793 Train loss: 0.02125399\r\n",
      "Epoch:  94 Step:   760 /   793 Train loss: 0.02385021\r\n",
      "Epoch:  94 Step:   761 /   793 Train loss: 0.02941681\r\n",
      "Epoch:  94 Step:   762 /   793 Train loss: 0.01708631\r\n",
      "Epoch:  94 Step:   763 /   793 Train loss: 0.03401374\r\n",
      "Epoch:  94 Step:   764 /   793 Train loss: 0.01863739\r\n",
      "Epoch:  94 Step:   765 /   793 Train loss: 0.02258013\r\n",
      "Epoch:  94 Step:   766 /   793 Train loss: 0.02362706\r\n",
      "Epoch:  94 Step:   767 /   793 Train loss: 0.02630505\r\n",
      "Epoch:  94 Step:   768 /   793 Train loss: 0.02295002\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  94 Step:   769 /   793 Train loss: 0.02371296\r\n",
      "Epoch:  94 Step:   770 /   793 Train loss: 0.02405647\r\n",
      "Epoch:  94 Step:   771 /   793 Train loss: 0.02319761\r\n",
      "Epoch:  94 Step:   772 /   793 Train loss: 0.02384443\r\n",
      "Epoch:  94 Step:   773 /   793 Train loss: 0.02096977\r\n",
      "Epoch:  94 Step:   774 /   793 Train loss: 0.01379591\r\n",
      "Epoch:  94 Step:   775 /   793 Train loss: 0.02194811\r\n",
      "Epoch:  94 Step:   776 /   793 Train loss: 0.02328180\r\n",
      "Epoch:  94 Step:   777 /   793 Train loss: 0.02816469\r\n",
      "Epoch:  94 Step:   778 /   793 Train loss: 0.02593235\r\n",
      "Epoch:  94 Step:   779 /   793 Train loss: 0.02160171\r\n",
      "Epoch:  94 Step:   780 /   793 Train loss: 0.02757566\r\n",
      "Epoch:  94 Step:   781 /   793 Train loss: 0.01749956\r\n",
      "Epoch:  94 Step:   782 /   793 Train loss: 0.02306280\r\n",
      "Epoch:  94 Step:   783 /   793 Train loss: 0.02515380\r\n",
      "Epoch:  94 Step:   784 /   793 Train loss: 0.02175922\r\n",
      "Epoch:  94 Step:   785 /   793 Train loss: 0.03513762\r\n",
      "Epoch:  94 Step:   786 /   793 Train loss: 0.02992633\r\n",
      "Epoch:  94 Step:   787 /   793 Train loss: 0.02877417\r\n",
      "Epoch:  94 Step:   788 /   793 Train loss: 0.03457109\r\n",
      "Epoch:  94 Step:   789 /   793 Train loss: 0.02650099\r\n",
      "Epoch:  94 Step:   790 /   793 Train loss: 0.01417833\r\n",
      "Epoch:  94 Step:   791 /   793 Train loss: 0.02075797\r\n",
      "Epoch:  94 Step:   792 /   793 Train loss: 0.02528828\r\n",
      "Epoch:  95 Step:     0 /   793 Train loss: 0.02907996\r\n",
      "Epoch:  95 Step:     1 /   793 Train loss: 0.01469738\r\n",
      "Epoch:  95 Step:     2 /   793 Train loss: 0.02351929\r\n",
      "Epoch:  95 Step:     3 /   793 Train loss: 0.03095148\r\n",
      "Epoch:  95 Step:     4 /   793 Train loss: 0.01440858\r\n",
      "Epoch:  95 Step:     5 /   793 Train loss: 0.03191781\r\n",
      "Epoch:  95 Step:     6 /   793 Train loss: 0.03700707\r\n",
      "Epoch:  95 Step:     7 /   793 Train loss: 0.02750103\r\n",
      "Epoch:  95 Step:     8 /   793 Train loss: 0.01645029\r\n",
      "Epoch:  95 Step:     9 /   793 Train loss: 0.01853875\r\n",
      "Epoch:  95 Step:    10 /   793 Train loss: 0.01731341\r\n",
      "Epoch:  95 Step:    11 /   793 Train loss: 0.02509292\r\n",
      "Epoch:  95 Step:    12 /   793 Train loss: 0.01759025\r\n",
      "Epoch:  95 Step:    13 /   793 Train loss: 0.03778914\r\n",
      "Epoch:  95 Step:    14 /   793 Train loss: 0.04377113\r\n",
      "Epoch:  95 Step:    15 /   793 Train loss: 0.02536063\r\n",
      "Epoch:  95 Step:    16 /   793 Train loss: 0.04061862\r\n",
      "Epoch:  95 Step:    17 /   793 Train loss: 0.01719129\r\n",
      "Epoch:  95 Step:    18 /   793 Train loss: 0.02298092\r\n",
      "Epoch:  95 Step:    19 /   793 Train loss: 0.02270532\r\n",
      "Epoch:  95 Step:    20 /   793 Train loss: 0.02492439\r\n",
      "Epoch:  95 Step:    21 /   793 Train loss: 0.03144000\r\n",
      "Epoch:  95 Step:    22 /   793 Train loss: 0.01758068\r\n",
      "Epoch:  95 Step:    23 /   793 Train loss: 0.02700080\r\n",
      "Epoch:  95 Step:    24 /   793 Train loss: 0.03173461\r\n",
      "Epoch:  95 Step:    25 /   793 Train loss: 0.02396334\r\n",
      "Epoch:  95 Step:    26 /   793 Train loss: 0.02052375\r\n",
      "Epoch:  95 Step:    27 /   793 Train loss: 0.02964949\r\n",
      "Epoch:  95 Step:    28 /   793 Train loss: 0.02832408\r\n",
      "Epoch:  95 Step:    29 /   793 Train loss: 0.02061825\r\n",
      "Epoch:  95 Step:    30 /   793 Train loss: 0.02820170\r\n",
      "Epoch:  95 Step:    31 /   793 Train loss: 0.02470187\r\n",
      "Epoch:  95 Step:    32 /   793 Train loss: 0.03118515\r\n",
      "Epoch:  95 Step:    33 /   793 Train loss: 0.02515519\r\n",
      "Epoch:  95 Step:    34 /   793 Train loss: 0.01498768\r\n",
      "Epoch:  95 Step:    35 /   793 Train loss: 0.03222782\r\n",
      "Epoch:  95 Step:    36 /   793 Train loss: 0.02814749\r\n",
      "Epoch:  95 Step:    37 /   793 Train loss: 0.03506690\r\n",
      "Epoch:  95 Step:    38 /   793 Train loss: 0.02107460\r\n",
      "Epoch:  95 Step:    39 /   793 Train loss: 0.01817900\r\n",
      "Epoch:  95 Step:    40 /   793 Train loss: 0.03248556\r\n",
      "Epoch:  95 Step:    41 /   793 Train loss: 0.02747818\r\n",
      "Epoch:  95 Step:    42 /   793 Train loss: 0.02562222\r\n",
      "Epoch:  95 Step:    43 /   793 Train loss: 0.02611389\r\n",
      "Epoch:  95 Step:    44 /   793 Train loss: 0.02431879\r\n",
      "Epoch:  95 Step:    45 /   793 Train loss: 0.02341599\r\n",
      "Epoch:  95 Step:    46 /   793 Train loss: 0.02511704\r\n",
      "Epoch:  95 Step:    47 /   793 Train loss: 0.01927732\r\n",
      "Epoch:  95 Step:    48 /   793 Train loss: 0.03233902\r\n",
      "Epoch:  95 Step:    49 /   793 Train loss: 0.03315846\r\n",
      "Epoch:  95 Step:    50 /   793 Train loss: 0.02929074\r\n",
      "Epoch:  95 Step:    51 /   793 Train loss: 0.01546369\r\n",
      "Epoch:  95 Step:    52 /   793 Train loss: 0.02225702\r\n",
      "Epoch:  95 Step:    53 /   793 Train loss: 0.02082441\r\n",
      "Epoch:  95 Step:    54 /   793 Train loss: 0.01905782\r\n",
      "Epoch:  95 Step:    55 /   793 Train loss: 0.02886781\r\n",
      "Epoch:  95 Step:    56 /   793 Train loss: 0.02873401\r\n",
      "Epoch:  95 Step:    57 /   793 Train loss: 0.02763614\r\n",
      "Epoch:  95 Step:    58 /   793 Train loss: 0.02092115\r\n",
      "Epoch:  95 Step:    59 /   793 Train loss: 0.03120945\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  95 Step:    60 /   793 Train loss: 0.02838801\r\n",
      "Epoch:  95 Step:    61 /   793 Train loss: 0.02315230\r\n",
      "Epoch:  95 Step:    62 /   793 Train loss: 0.01276109\r\n",
      "Epoch:  95 Step:    63 /   793 Train loss: 0.03498768\r\n",
      "Epoch:  95 Step:    64 /   793 Train loss: 0.02787970\r\n",
      "Epoch:  95 Step:    65 /   793 Train loss: 0.01466048\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  95 Step:    66 /   793 Train loss: 0.02662922\r\n",
      "Epoch:  95 Step:    67 /   793 Train loss: 0.02542207\r\n",
      "Epoch:  95 Step:    68 /   793 Train loss: 0.02318614\r\n",
      "Epoch:  95 Step:    69 /   793 Train loss: 0.01700262\r\n",
      "Epoch:  95 Step:    70 /   793 Train loss: 0.03861088\r\n",
      "Epoch:  95 Step:    71 /   793 Train loss: 0.01677686\r\n",
      "Epoch:  95 Step:    72 /   793 Train loss: 0.02758381\r\n",
      "Epoch:  95 Step:    73 /   793 Train loss: 0.02254005\r\n",
      "Epoch:  95 Step:    74 /   793 Train loss: 0.03223945\r\n",
      "Epoch:  95 Step:    75 /   793 Train loss: 0.03262960\r\n",
      "Epoch:  95 Step:    76 /   793 Train loss: 0.01891414\r\n",
      "Epoch:  95 Step:    77 /   793 Train loss: 0.03516572\r\n",
      "Epoch:  95 Step:    78 /   793 Train loss: 0.03666890\r\n",
      "Epoch:  95 Step:    79 /   793 Train loss: 0.02667709\r\n",
      "Epoch:  95 Step:    80 /   793 Train loss: 0.03409508\r\n",
      "Epoch:  95 Step:    81 /   793 Train loss: 0.01333120\r\n",
      "Epoch:  95 Step:    82 /   793 Train loss: 0.02489368\r\n",
      "Epoch:  95 Step:    83 /   793 Train loss: 0.02433132\r\n",
      "Epoch:  95 Step:    84 /   793 Train loss: 0.02783978\r\n",
      "Epoch:  95 Step:    85 /   793 Train loss: 0.02435579\r\n",
      "Epoch:  95 Step:    86 /   793 Train loss: 0.02954534\r\n",
      "Epoch:  95 Step:    87 /   793 Train loss: 0.02377669\r\n",
      "Epoch:  95 Step:    88 /   793 Train loss: 0.02897085\r\n",
      "Epoch:  95 Step:    89 /   793 Train loss: 0.02079006\r\n",
      "Epoch:  95 Step:    90 /   793 Train loss: 0.00981635\r\n",
      "Epoch:  95 Step:    91 /   793 Train loss: 0.02306577\r\n",
      "Epoch:  95 Step:    92 /   793 Train loss: 0.03466204\r\n",
      "Epoch:  95 Step:    93 /   793 Train loss: 0.02730659\r\n",
      "Epoch:  95 Step:    94 /   793 Train loss: 0.02592950\r\n",
      "Epoch:  95 Step:    95 /   793 Train loss: 0.02382063\r\n",
      "Epoch:  95 Step:    96 /   793 Train loss: 0.03453365\r\n",
      "Epoch:  95 Step:    97 /   793 Train loss: 0.03228609\r\n",
      "Epoch:  95 Step:    98 /   793 Train loss: 0.02347805\r\n",
      "Epoch:  95 Step:    99 /   793 Train loss: 0.01750288\r\n",
      "Epoch:  95 Step:   100 /   793 Train loss: 0.01943874\r\n",
      "Epoch:  95 Step:   101 /   793 Train loss: 0.00906217\r\n",
      "Epoch:  95 Step:   102 /   793 Train loss: 0.02015349\r\n",
      "Epoch:  95 Step:   103 /   793 Train loss: 0.02502422\r\n",
      "Epoch:  95 Step:   104 /   793 Train loss: 0.02781548\r\n",
      "Epoch:  95 Step:   105 /   793 Train loss: 0.02487154\r\n",
      "Epoch:  95 Step:   106 /   793 Train loss: 0.01786984\r\n",
      "Epoch:  95 Step:   107 /   793 Train loss: 0.02803851\r\n",
      "Epoch:  95 Step:   108 /   793 Train loss: 0.03168965\r\n",
      "Epoch:  95 Step:   109 /   793 Train loss: 0.01605168\r\n",
      "Epoch:  95 Step:   110 /   793 Train loss: 0.01543074\r\n",
      "Epoch:  95 Step:   111 /   793 Train loss: 0.03554107\r\n",
      "Epoch:  95 Step:   112 /   793 Train loss: 0.03516542\r\n",
      "Epoch:  95 Step:   113 /   793 Train loss: 0.02335319\r\n",
      "Epoch:  95 Step:   114 /   793 Train loss: 0.02723285\r\n",
      "Epoch:  95 Step:   115 /   793 Train loss: 0.02948564\r\n",
      "Epoch:  95 Step:   116 /   793 Train loss: 0.01719520\r\n",
      "Epoch:  95 Step:   117 /   793 Train loss: 0.02861499\r\n",
      "Epoch:  95 Step:   118 /   793 Train loss: 0.04424218\r\n",
      "Epoch:  95 Step:   119 /   793 Train loss: 0.02220665\r\n",
      "Epoch:  95 Step:   120 /   793 Train loss: 0.02085606\r\n",
      "Epoch:  95 Step:   121 /   793 Train loss: 0.03299101\r\n",
      "Epoch:  95 Step:   122 /   793 Train loss: 0.03089670\r\n",
      "Epoch:  95 Step:   123 /   793 Train loss: 0.02156783\r\n",
      "Epoch:  95 Step:   124 /   793 Train loss: 0.02069422\r\n",
      "Epoch:  95 Step:   125 /   793 Train loss: 0.01977828\r\n",
      "Epoch:  95 Step:   126 /   793 Train loss: 0.02259165\r\n",
      "Epoch:  95 Step:   127 /   793 Train loss: 0.03377367\r\n",
      "Epoch:  95 Step:   128 /   793 Train loss: 0.03078350\r\n",
      "Epoch:  95 Step:   129 /   793 Train loss: 0.01854746\r\n",
      "Epoch:  95 Step:   130 /   793 Train loss: 0.02354632\r\n",
      "Epoch:  95 Step:   131 /   793 Train loss: 0.04065451\r\n",
      "Epoch:  95 Step:   132 /   793 Train loss: 0.02591099\r\n",
      "Epoch:  95 Step:   133 /   793 Train loss: 0.01945415\r\n",
      "Epoch:  95 Step:   134 /   793 Train loss: 0.02455783\r\n",
      "Epoch:  95 Step:   135 /   793 Train loss: 0.02220351\r\n",
      "Epoch:  95 Step:   136 /   793 Train loss: 0.01354690\r\n",
      "Epoch:  95 Step:   137 /   793 Train loss: 0.01819202\r\n",
      "Epoch:  95 Step:   138 /   793 Train loss: 0.03845898\r\n",
      "Epoch:  95 Step:   139 /   793 Train loss: 0.02431552\r\n",
      "Epoch:  95 Step:   140 /   793 Train loss: 0.01648612\r\n",
      "Epoch:  95 Step:   141 /   793 Train loss: 0.01602077\r\n",
      "Epoch:  95 Step:   142 /   793 Train loss: 0.01924642\r\n",
      "Epoch:  95 Step:   143 /   793 Train loss: 0.01584031\r\n",
      "Epoch:  95 Step:   144 /   793 Train loss: 0.03284439\r\n",
      "Epoch:  95 Step:   145 /   793 Train loss: 0.02789531\r\n",
      "Epoch:  95 Step:   146 /   793 Train loss: 0.02073529\r\n",
      "Epoch:  95 Step:   147 /   793 Train loss: 0.02067715\r\n",
      "Epoch:  95 Step:   148 /   793 Train loss: 0.05520516\r\n",
      "Epoch:  95 Step:   149 /   793 Train loss: 0.02868202\r\n",
      "Epoch:  95 Step:   150 /   793 Train loss: 0.03625999\r\n",
      "Epoch:  95 Step:   151 /   793 Train loss: 0.05467935\r\n",
      "Epoch:  95 Step:   152 /   793 Train loss: 0.02296809\r\n",
      "Epoch:  95 Step:   153 /   793 Train loss: 0.02315997\r\n",
      "Epoch:  95 Step:   154 /   793 Train loss: 0.01793557\r\n",
      "Epoch:  95 Step:   155 /   793 Train loss: 0.01449147\r\n",
      "Epoch:  95 Step:   156 /   793 Train loss: 0.02123369\r\n",
      "Epoch:  95 Step:   157 /   793 Train loss: 0.03946747\r\n",
      "Epoch:  95 Step:   158 /   793 Train loss: 0.01766974\r\n",
      "Epoch:  95 Step:   159 /   793 Train loss: 0.02351451\r\n",
      "Epoch:  95 Step:   160 /   793 Train loss: 0.01590456\r\n",
      "Epoch:  95 Step:   161 /   793 Train loss: 0.01605632\r\n",
      "Epoch:  95 Step:   162 /   793 Train loss: 0.01800312\r\n",
      "Epoch:  95 Step:   163 /   793 Train loss: 0.02256120\r\n",
      "Epoch:  95 Step:   164 /   793 Train loss: 0.01848860\r\n",
      "Epoch:  95 Step:   165 /   793 Train loss: 0.01515313\r\n",
      "Epoch:  95 Step:   166 /   793 Train loss: 0.01354621\r\n",
      "Epoch:  95 Step:   167 /   793 Train loss: 0.01345008\r\n",
      "Epoch:  95 Step:   168 /   793 Train loss: 0.02881883\r\n",
      "Epoch:  95 Step:   169 /   793 Train loss: 0.01242942\r\n",
      "Epoch:  95 Step:   170 /   793 Train loss: 0.02890717\r\n",
      "Epoch:  95 Step:   171 /   793 Train loss: 0.02018052\r\n",
      "Epoch:  95 Step:   172 /   793 Train loss: 0.01948130\r\n",
      "Epoch:  95 Step:   173 /   793 Train loss: 0.03720091\r\n",
      "Epoch:  95 Step:   174 /   793 Train loss: 0.02646173\r\n",
      "Epoch:  95 Step:   175 /   793 Train loss: 0.02156255\r\n",
      "Epoch:  95 Step:   176 /   793 Train loss: 0.02442232\r\n",
      "Epoch:  95 Step:   177 /   793 Train loss: 0.02163122\r\n",
      "Epoch:  95 Step:   178 /   793 Train loss: 0.01401813\r\n",
      "Epoch:  95 Step:   179 /   793 Train loss: 0.03747504\r\n",
      "Epoch:  95 Step:   180 /   793 Train loss: 0.02913997\r\n",
      "Epoch:  95 Step:   181 /   793 Train loss: 0.02836962\r\n",
      "Epoch:  95 Step:   182 /   793 Train loss: 0.03103992\r\n",
      "Epoch:  95 Step:   183 /   793 Train loss: 0.02239658\r\n",
      "Epoch:  95 Step:   184 /   793 Train loss: 0.02576965\r\n",
      "Epoch:  95 Step:   185 /   793 Train loss: 0.01522955\r\n",
      "Epoch:  95 Step:   186 /   793 Train loss: 0.01709477\r\n",
      "Epoch:  95 Step:   187 /   793 Train loss: 0.02325431\r\n",
      "Epoch:  95 Step:   188 /   793 Train loss: 0.02268616\r\n",
      "Epoch:  95 Step:   189 /   793 Train loss: 0.02036222\r\n",
      "Epoch:  95 Step:   190 /   793 Train loss: 0.02695599\r\n",
      "Epoch:  95 Step:   191 /   793 Train loss: 0.01906495\r\n",
      "Epoch:  95 Step:   192 /   793 Train loss: 0.03310451\r\n",
      "Epoch:  95 Step:   193 /   793 Train loss: 0.01523236\r\n",
      "Epoch:  95 Step:   194 /   793 Train loss: 0.02557209\r\n",
      "Epoch:  95 Step:   195 /   793 Train loss: 0.01270744\r\n",
      "Epoch:  95 Step:   196 /   793 Train loss: 0.01514102\r\n",
      "Epoch:  95 Step:   197 /   793 Train loss: 0.02418370\r\n",
      "Epoch:  95 Step:   198 /   793 Train loss: 0.01855655\r\n",
      "Epoch:  95 Step:   199 /   793 Train loss: 0.02221221\r\n",
      "Epoch:  95 Step:   200 /   793 Train loss: 0.01657711\r\n",
      "Epoch:  95 Step:   201 /   793 Train loss: 0.02582596\r\n",
      "Epoch:  95 Step:   202 /   793 Train loss: 0.01550622\r\n",
      "Epoch:  95 Step:   203 /   793 Train loss: 0.02246858\r\n",
      "Epoch:  95 Step:   204 /   793 Train loss: 0.02406754\r\n",
      "Epoch:  95 Step:   205 /   793 Train loss: 0.01854839\r\n",
      "Epoch:  95 Step:   206 /   793 Train loss: 0.02477555\r\n",
      "Epoch:  95 Step:   207 /   793 Train loss: 0.02310262\r\n",
      "Epoch:  95 Step:   208 /   793 Train loss: 0.02085944\r\n",
      "Epoch:  95 Step:   209 /   793 Train loss: 0.02452005\r\n",
      "Epoch:  95 Step:   210 /   793 Train loss: 0.03503500\r\n",
      "Epoch:  95 Step:   211 /   793 Train loss: 0.03372464\r\n",
      "Epoch:  95 Step:   212 /   793 Train loss: 0.02267421\r\n",
      "Epoch:  95 Step:   213 /   793 Train loss: 0.02541813\r\n",
      "Epoch:  95 Step:   214 /   793 Train loss: 0.01573518\r\n",
      "Epoch:  95 Step:   215 /   793 Train loss: 0.02770568\r\n",
      "Epoch:  95 Step:   216 /   793 Train loss: 0.02019601\r\n",
      "Epoch:  95 Step:   217 /   793 Train loss: 0.01650920\r\n",
      "Epoch:  95 Step:   218 /   793 Train loss: 0.02912964\r\n",
      "Epoch:  95 Step:   219 /   793 Train loss: 0.02082203\r\n",
      "Epoch:  95 Step:   220 /   793 Train loss: 0.02493076\r\n",
      "Epoch:  95 Step:   221 /   793 Train loss: 0.02536269\r\n",
      "Epoch:  95 Step:   222 /   793 Train loss: 0.02960961\r\n",
      "Epoch:  95 Step:   223 /   793 Train loss: 0.01428125\r\n",
      "Epoch:  95 Step:   224 /   793 Train loss: 0.03895748\r\n",
      "Epoch:  95 Step:   225 /   793 Train loss: 0.04235486\r\n",
      "Epoch:  95 Step:   226 /   793 Train loss: 0.02080873\r\n",
      "Epoch:  95 Step:   227 /   793 Train loss: 0.02822784\r\n",
      "Epoch:  95 Step:   228 /   793 Train loss: 0.01464587\r\n",
      "Epoch:  95 Step:   229 /   793 Train loss: 0.01456500\r\n",
      "Epoch:  95 Step:   230 /   793 Train loss: 0.03220403\r\n",
      "Epoch:  95 Step:   231 /   793 Train loss: 0.02295320\r\n",
      "Epoch:  95 Step:   232 /   793 Train loss: 0.02653144\r\n",
      "Epoch:  95 Step:   233 /   793 Train loss: 0.02837320\r\n",
      "Epoch:  95 Step:   234 /   793 Train loss: 0.02507287\r\n",
      "Epoch:  95 Step:   235 /   793 Train loss: 0.01592822\r\n",
      "Epoch:  95 Step:   236 /   793 Train loss: 0.02731068\r\n",
      "Epoch:  95 Step:   237 /   793 Train loss: 0.01670038\r\n",
      "Epoch:  95 Step:   238 /   793 Train loss: 0.02108863\r\n",
      "Epoch:  95 Step:   239 /   793 Train loss: 0.02247160\r\n",
      "Epoch:  95 Step:   240 /   793 Train loss: 0.02516398\r\n",
      "Epoch:  95 Step:   241 /   793 Train loss: 0.04428449\r\n",
      "Epoch:  95 Step:   242 /   793 Train loss: 0.02218188\r\n",
      "Epoch:  95 Step:   243 /   793 Train loss: 0.03475145\r\n",
      "Epoch:  95 Step:   244 /   793 Train loss: 0.00862106\r\n",
      "Epoch:  95 Step:   245 /   793 Train loss: 0.01786100\r\n",
      "Epoch:  95 Step:   246 /   793 Train loss: 0.02110858\r\n",
      "Epoch:  95 Step:   247 /   793 Train loss: 0.02666115\r\n",
      "Epoch:  95 Step:   248 /   793 Train loss: 0.02141566\r\n",
      "Epoch:  95 Step:   249 /   793 Train loss: 0.02129658\r\n",
      "Epoch:  95 Step:   250 /   793 Train loss: 0.01598759\r\n",
      "Epoch:  95 Step:   251 /   793 Train loss: 0.01879491\r\n",
      "Epoch:  95 Step:   252 /   793 Train loss: 0.03641667\r\n",
      "Epoch:  95 Step:   253 /   793 Train loss: 0.02625370\r\n",
      "Epoch:  95 Step:   254 /   793 Train loss: 0.02654918\r\n",
      "Epoch:  95 Step:   255 /   793 Train loss: 0.02410536\r\n",
      "Epoch:  95 Step:   256 /   793 Train loss: 0.03052604\r\n",
      "Epoch:  95 Step:   257 /   793 Train loss: 0.01664507\r\n",
      "Epoch:  95 Step:   258 /   793 Train loss: 0.01652548\r\n",
      "Epoch:  95 Step:   259 /   793 Train loss: 0.03791980\r\n",
      "Epoch:  95 Step:   260 /   793 Train loss: 0.01691088\r\n",
      "Epoch:  95 Step:   261 /   793 Train loss: 0.03134517\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  95 Step:   262 /   793 Train loss: 0.02554184\r\n",
      "Epoch:  95 Step:   263 /   793 Train loss: 0.02692198\r\n",
      "Epoch:  95 Step:   264 /   793 Train loss: 0.02757384\r\n",
      "Epoch:  95 Step:   265 /   793 Train loss: 0.02648155\r\n",
      "Epoch:  95 Step:   266 /   793 Train loss: 0.03096857\r\n",
      "Epoch:  95 Step:   267 /   793 Train loss: 0.03279235\r\n",
      "Epoch:  95 Step:   268 /   793 Train loss: 0.01386691\r\n",
      "Epoch:  95 Step:   269 /   793 Train loss: 0.03333289\r\n",
      "Epoch:  95 Step:   270 /   793 Train loss: 0.02038340\r\n",
      "Epoch:  95 Step:   271 /   793 Train loss: 0.01371500\r\n",
      "Epoch:  95 Step:   272 /   793 Train loss: 0.03412056\r\n",
      "Epoch:  95 Step:   273 /   793 Train loss: 0.02398783\r\n",
      "Epoch:  95 Step:   274 /   793 Train loss: 0.01646101\r\n",
      "Epoch:  95 Step:   275 /   793 Train loss: 0.01988689\r\n",
      "Epoch:  95 Step:   276 /   793 Train loss: 0.03230970\r\n",
      "Epoch:  95 Step:   277 /   793 Train loss: 0.02537063\r\n",
      "Epoch:  95 Step:   278 /   793 Train loss: 0.01844289\r\n",
      "Epoch:  95 Step:   279 /   793 Train loss: 0.02617061\r\n",
      "Epoch:  95 Step:   280 /   793 Train loss: 0.02632040\r\n",
      "Epoch:  95 Step:   281 /   793 Train loss: 0.02938984\r\n",
      "Epoch:  95 Step:   282 /   793 Train loss: 0.03287481\r\n",
      "Epoch:  95 Step:   283 /   793 Train loss: 0.02482846\r\n",
      "Epoch:  95 Step:   284 /   793 Train loss: 0.02491529\r\n",
      "Epoch:  95 Step:   285 /   793 Train loss: 0.02425695\r\n",
      "Epoch:  95 Step:   286 /   793 Train loss: 0.03376064\r\n",
      "Epoch:  95 Step:   287 /   793 Train loss: 0.02610682\r\n",
      "Epoch:  95 Step:   288 /   793 Train loss: 0.02861031\r\n",
      "Epoch:  95 Step:   289 /   793 Train loss: 0.02035893\r\n",
      "Epoch:  95 Step:   290 /   793 Train loss: 0.02074043\r\n",
      "Epoch:  95 Step:   291 /   793 Train loss: 0.02071879\r\n",
      "Epoch:  95 Step:   292 /   793 Train loss: 0.03199491\r\n",
      "Epoch:  95 Step:   293 /   793 Train loss: 0.01799668\r\n",
      "Epoch:  95 Step:   294 /   793 Train loss: 0.01486142\r\n",
      "Epoch:  95 Step:   295 /   793 Train loss: 0.03235122\r\n",
      "Epoch:  95 Step:   296 /   793 Train loss: 0.02567105\r\n",
      "Epoch:  95 Step:   297 /   793 Train loss: 0.03546957\r\n",
      "Epoch:  95 Step:   298 /   793 Train loss: 0.04144069\r\n",
      "Epoch:  95 Step:   299 /   793 Train loss: 0.02939096\r\n",
      "Epoch:  95 Step:   300 /   793 Train loss: 0.01760262\r\n",
      "Epoch:  95 Step:   301 /   793 Train loss: 0.02818096\r\n",
      "Epoch:  95 Step:   302 /   793 Train loss: 0.02633181\r\n",
      "Epoch:  95 Step:   303 /   793 Train loss: 0.01328309\r\n",
      "Epoch:  95 Step:   304 /   793 Train loss: 0.02017346\r\n",
      "Epoch:  95 Step:   305 /   793 Train loss: 0.01573376\r\n",
      "Epoch:  95 Step:   306 /   793 Train loss: 0.02764054\r\n",
      "Epoch:  95 Step:   307 /   793 Train loss: 0.02071517\r\n",
      "Epoch:  95 Step:   308 /   793 Train loss: 0.01504289\r\n",
      "Epoch:  95 Step:   309 /   793 Train loss: 0.01719792\r\n",
      "Epoch:  95 Step:   310 /   793 Train loss: 0.02213790\r\n",
      "Epoch:  95 Step:   311 /   793 Train loss: 0.01604296\r\n",
      "Epoch:  95 Step:   312 /   793 Train loss: 0.03014131\r\n",
      "Epoch:  95 Step:   313 /   793 Train loss: 0.02405901\r\n",
      "Epoch:  95 Step:   314 /   793 Train loss: 0.02095068\r\n",
      "Epoch:  95 Step:   315 /   793 Train loss: 0.01960883\r\n",
      "Epoch:  95 Step:   316 /   793 Train loss: 0.02794018\r\n",
      "Epoch:  95 Step:   317 /   793 Train loss: 0.02582400\r\n",
      "Epoch:  95 Step:   318 /   793 Train loss: 0.01464105\r\n",
      "Epoch:  95 Step:   319 /   793 Train loss: 0.01763324\r\n",
      "Epoch:  95 Step:   320 /   793 Train loss: 0.02338193\r\n",
      "Epoch:  95 Step:   321 /   793 Train loss: 0.02124507\r\n",
      "Epoch:  95 Step:   322 /   793 Train loss: 0.02440737\r\n",
      "Epoch:  95 Step:   323 /   793 Train loss: 0.02535630\r\n",
      "Epoch:  95 Step:   324 /   793 Train loss: 0.01990227\r\n",
      "Epoch:  95 Step:   325 /   793 Train loss: 0.03443161\r\n",
      "Epoch:  95 Step:   326 /   793 Train loss: 0.01533136\r\n",
      "Epoch:  95 Step:   327 /   793 Train loss: 0.01849552\r\n",
      "Epoch:  95 Step:   328 /   793 Train loss: 0.02541320\r\n",
      "Epoch:  95 Step:   329 /   793 Train loss: 0.03615364\r\n",
      "Epoch:  95 Step:   330 /   793 Train loss: 0.03159299\r\n",
      "Epoch:  95 Step:   331 /   793 Train loss: 0.02254320\r\n",
      "Epoch:  95 Step:   332 /   793 Train loss: 0.01808266\r\n",
      "Epoch:  95 Step:   333 /   793 Train loss: 0.02661157\r\n",
      "Epoch:  95 Step:   334 /   793 Train loss: 0.01393629\r\n",
      "Epoch:  95 Step:   335 /   793 Train loss: 0.03517034\r\n",
      "Epoch:  95 Step:   336 /   793 Train loss: 0.01732666\r\n",
      "Epoch:  95 Step:   337 /   793 Train loss: 0.02390461\r\n",
      "Epoch:  95 Step:   338 /   793 Train loss: 0.03065359\r\n",
      "Epoch:  95 Step:   339 /   793 Train loss: 0.01508341\r\n",
      "Epoch:  95 Step:   340 /   793 Train loss: 0.01369294\r\n",
      "Epoch:  95 Step:   341 /   793 Train loss: 0.02858684\r\n",
      "Epoch:  95 Step:   342 /   793 Train loss: 0.02807050\r\n",
      "Epoch:  95 Step:   343 /   793 Train loss: 0.01787628\r\n",
      "Epoch:  95 Step:   344 /   793 Train loss: 0.02029996\r\n",
      "Epoch:  95 Step:   345 /   793 Train loss: 0.03204799\r\n",
      "Epoch:  95 Step:   346 /   793 Train loss: 0.02771212\r\n",
      "Epoch:  95 Step:   347 /   793 Train loss: 0.01942885\r\n",
      "Epoch:  95 Step:   348 /   793 Train loss: 0.01862621\r\n",
      "Epoch:  95 Step:   349 /   793 Train loss: 0.02229497\r\n",
      "Epoch:  95 Step:   350 /   793 Train loss: 0.02626110\r\n",
      "Epoch:  95 Step:   351 /   793 Train loss: 0.02618466\r\n",
      "Epoch:  95 Step:   352 /   793 Train loss: 0.02624467\r\n",
      "Epoch:  95 Step:   353 /   793 Train loss: 0.01695500\r\n",
      "Epoch:  95 Step:   354 /   793 Train loss: 0.01567371\r\n",
      "Epoch:  95 Step:   355 /   793 Train loss: 0.01288166\r\n",
      "Epoch:  95 Step:   356 /   793 Train loss: 0.02011883\r\n",
      "Epoch:  95 Step:   357 /   793 Train loss: 0.03404431\r\n",
      "Epoch:  95 Step:   358 /   793 Train loss: 0.03297547\r\n",
      "Epoch:  95 Step:   359 /   793 Train loss: 0.04138308\r\n",
      "Epoch:  95 Step:   360 /   793 Train loss: 0.02610616\r\n",
      "Epoch:  95 Step:   361 /   793 Train loss: 0.01598958\r\n",
      "Epoch:  95 Step:   362 /   793 Train loss: 0.01584678\r\n",
      "Epoch:  95 Step:   363 /   793 Train loss: 0.01640134\r\n",
      "Epoch:  95 Step:   364 /   793 Train loss: 0.02969706\r\n",
      "Epoch:  95 Step:   365 /   793 Train loss: 0.01873967\r\n",
      "Epoch:  95 Step:   366 /   793 Train loss: 0.03658401\r\n",
      "Epoch:  95 Step:   367 /   793 Train loss: 0.02383917\r\n",
      "Epoch:  95 Step:   368 /   793 Train loss: 0.02284549\r\n",
      "Epoch:  95 Step:   369 /   793 Train loss: 0.02787759\r\n",
      "Epoch:  95 Step:   370 /   793 Train loss: 0.02355501\r\n",
      "Epoch:  95 Step:   371 /   793 Train loss: 0.01277178\r\n",
      "Epoch:  95 Step:   372 /   793 Train loss: 0.02511173\r\n",
      "Epoch:  95 Step:   373 /   793 Train loss: 0.01705882\r\n",
      "Epoch:  95 Step:   374 /   793 Train loss: 0.01524129\r\n",
      "Epoch:  95 Step:   375 /   793 Train loss: 0.02346073\r\n",
      "Epoch:  95 Step:   376 /   793 Train loss: 0.01804130\r\n",
      "Epoch:  95 Step:   377 /   793 Train loss: 0.02566212\r\n",
      "Epoch:  95 Step:   378 /   793 Train loss: 0.03490520\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  95 Step:   379 /   793 Train loss: 0.01244579\r\n",
      "Epoch:  95 Step:   380 /   793 Train loss: 0.02828250\r\n",
      "Epoch:  95 Step:   381 /   793 Train loss: 0.01956065\r\n",
      "Epoch:  95 Step:   382 /   793 Train loss: 0.02446381\r\n",
      "Epoch:  95 Step:   383 /   793 Train loss: 0.02130613\r\n",
      "Epoch:  95 Step:   384 /   793 Train loss: 0.02202886\r\n",
      "Epoch:  95 Step:   385 /   793 Train loss: 0.01824379\r\n",
      "Epoch:  95 Step:   386 /   793 Train loss: 0.02272751\r\n",
      "Epoch:  95 Step:   387 /   793 Train loss: 0.01788912\r\n",
      "Epoch:  95 Step:   388 /   793 Train loss: 0.02785147\r\n",
      "Epoch:  95 Step:   389 /   793 Train loss: 0.01572864\r\n",
      "Epoch:  95 Step:   390 /   793 Train loss: 0.03105544\r\n",
      "Epoch:  95 Step:   391 /   793 Train loss: 0.03791894\r\n",
      "Epoch:  95 Step:   392 /   793 Train loss: 0.02882435\r\n",
      "Epoch:  95 Step:   393 /   793 Train loss: 0.01691492\r\n",
      "Epoch:  95 Step:   394 /   793 Train loss: 0.01612647\r\n",
      "Epoch:  95 Step:   395 /   793 Train loss: 0.01962923\r\n",
      "Epoch:  95 Step:   396 /   793 Train loss: 0.02829396\r\n",
      "Epoch:  95 Step:   397 /   793 Train loss: 0.01557025\r\n",
      "Epoch:  95 Step:   398 /   793 Train loss: 0.02701293\r\n",
      "Epoch:  95 Step:   399 /   793 Train loss: 0.02680942\r\n",
      "Epoch:  95 Step:   400 /   793 Train loss: 0.03360705\r\n",
      "Epoch:  95 Step:   401 /   793 Train loss: 0.02087687\r\n",
      "Epoch:  95 Step:   402 /   793 Train loss: 0.02390227\r\n",
      "Epoch:  95 Step:   403 /   793 Train loss: 0.02083957\r\n",
      "Epoch:  95 Step:   404 /   793 Train loss: 0.02907471\r\n",
      "Epoch:  95 Step:   405 /   793 Train loss: 0.03172753\r\n",
      "Epoch:  95 Step:   406 /   793 Train loss: 0.02489697\r\n",
      "Epoch:  95 Step:   407 /   793 Train loss: 0.02008650\r\n",
      "Epoch:  95 Step:   408 /   793 Train loss: 0.02471167\r\n",
      "Epoch:  95 Step:   409 /   793 Train loss: 0.03548375\r\n",
      "Epoch:  95 Step:   410 /   793 Train loss: 0.02326459\r\n",
      "Epoch:  95 Step:   411 /   793 Train loss: 0.02395291\r\n",
      "Epoch:  95 Step:   412 /   793 Train loss: 0.01605242\r\n",
      "Epoch:  95 Step:   413 /   793 Train loss: 0.02337182\r\n",
      "Epoch:  95 Step:   414 /   793 Train loss: 0.02062136\r\n",
      "Epoch:  95 Step:   415 /   793 Train loss: 0.01783878\r\n",
      "Epoch:  95 Step:   416 /   793 Train loss: 0.02232841\r\n",
      "Epoch:  95 Step:   417 /   793 Train loss: 0.01962914\r\n",
      "Epoch:  95 Step:   418 /   793 Train loss: 0.02776928\r\n",
      "Epoch:  95 Step:   419 /   793 Train loss: 0.02842272\r\n",
      "Epoch:  95 Step:   420 /   793 Train loss: 0.02004741\r\n",
      "Epoch:  95 Step:   421 /   793 Train loss: 0.02505141\r\n",
      "Epoch:  95 Step:   422 /   793 Train loss: 0.01345091\r\n",
      "Epoch:  95 Step:   423 /   793 Train loss: 0.03401253\r\n",
      "Epoch:  95 Step:   424 /   793 Train loss: 0.02480262\r\n",
      "Epoch:  95 Step:   425 /   793 Train loss: 0.01727028\r\n",
      "Epoch:  95 Step:   426 /   793 Train loss: 0.01821043\r\n",
      "Epoch:  95 Step:   427 /   793 Train loss: 0.03657188\r\n",
      "Epoch:  95 Step:   428 /   793 Train loss: 0.02341755\r\n",
      "Epoch:  95 Step:   429 /   793 Train loss: 0.01769477\r\n",
      "Epoch:  95 Step:   430 /   793 Train loss: 0.03210033\r\n",
      "Epoch:  95 Step:   431 /   793 Train loss: 0.02173525\r\n",
      "Epoch:  95 Step:   432 /   793 Train loss: 0.02326487\r\n",
      "Epoch:  95 Step:   433 /   793 Train loss: 0.02048223\r\n",
      "Epoch:  95 Step:   434 /   793 Train loss: 0.02198843\r\n",
      "Epoch:  95 Step:   435 /   793 Train loss: 0.03150729\r\n",
      "Epoch:  95 Step:   436 /   793 Train loss: 0.02457107\r\n",
      "Epoch:  95 Step:   437 /   793 Train loss: 0.02528513\r\n",
      "Epoch:  95 Step:   438 /   793 Train loss: 0.02671092\r\n",
      "Epoch:  95 Step:   439 /   793 Train loss: 0.02705495\r\n",
      "Epoch:  95 Step:   440 /   793 Train loss: 0.02714710\r\n",
      "Epoch:  95 Step:   441 /   793 Train loss: 0.02874080\r\n",
      "Epoch:  95 Step:   442 /   793 Train loss: 0.03936709\r\n",
      "Epoch:  95 Step:   443 /   793 Train loss: 0.02512559\r\n",
      "Epoch:  95 Step:   444 /   793 Train loss: 0.01805205\r\n",
      "Epoch:  95 Step:   445 /   793 Train loss: 0.02856338\r\n",
      "Epoch:  95 Step:   446 /   793 Train loss: 0.02151260\r\n",
      "Epoch:  95 Step:   447 /   793 Train loss: 0.02418378\r\n",
      "Epoch:  95 Step:   448 /   793 Train loss: 0.01631600\r\n",
      "Epoch:  95 Step:   449 /   793 Train loss: 0.02412655\r\n",
      "Epoch:  95 Step:   450 /   793 Train loss: 0.01946408\r\n",
      "Epoch:  95 Step:   451 /   793 Train loss: 0.02277716\r\n",
      "Epoch:  95 Step:   452 /   793 Train loss: 0.02231561\r\n",
      "Epoch:  95 Step:   453 /   793 Train loss: 0.02373249\r\n",
      "Epoch:  95 Step:   454 /   793 Train loss: 0.02637719\r\n",
      "Epoch:  95 Step:   455 /   793 Train loss: 0.01838257\r\n",
      "Epoch:  95 Step:   456 /   793 Train loss: 0.03682090\r\n",
      "Epoch:  95 Step:   457 /   793 Train loss: 0.02136358\r\n",
      "Epoch:  95 Step:   458 /   793 Train loss: 0.01940656\r\n",
      "Epoch:  95 Step:   459 /   793 Train loss: 0.02027283\r\n",
      "Epoch:  95 Step:   460 /   793 Train loss: 0.02438748\r\n",
      "Epoch:  95 Step:   461 /   793 Train loss: 0.03173411\r\n",
      "Epoch:  95 Step:   462 /   793 Train loss: 0.02408820\r\n",
      "Epoch:  95 Step:   463 /   793 Train loss: 0.03205846\r\n",
      "Epoch:  95 Step:   464 /   793 Train loss: 0.02516589\r\n",
      "Epoch:  95 Step:   465 /   793 Train loss: 0.02558225\r\n",
      "Epoch:  95 Step:   466 /   793 Train loss: 0.02762341\r\n",
      "Epoch:  95 Step:   467 /   793 Train loss: 0.01550232\r\n",
      "Epoch:  95 Step:   468 /   793 Train loss: 0.03082639\r\n",
      "Epoch:  95 Step:   469 /   793 Train loss: 0.02640685\r\n",
      "Epoch:  95 Step:   470 /   793 Train loss: 0.02936050\r\n",
      "Epoch:  95 Step:   471 /   793 Train loss: 0.01355524\r\n",
      "Epoch:  95 Step:   472 /   793 Train loss: 0.02864573\r\n",
      "Epoch:  95 Step:   473 /   793 Train loss: 0.02296901\r\n",
      "Epoch:  95 Step:   474 /   793 Train loss: 0.02197691\r\n",
      "Epoch:  95 Step:   475 /   793 Train loss: 0.01477577\r\n",
      "Epoch:  95 Step:   476 /   793 Train loss: 0.02495769\r\n",
      "Epoch:  95 Step:   477 /   793 Train loss: 0.02838789\r\n",
      "Epoch:  95 Step:   478 /   793 Train loss: 0.02279845\r\n",
      "Epoch:  95 Step:   479 /   793 Train loss: 0.01732087\r\n",
      "Epoch:  95 Step:   480 /   793 Train loss: 0.01683915\r\n",
      "Epoch:  95 Step:   481 /   793 Train loss: 0.02209687\r\n",
      "Epoch:  95 Step:   482 /   793 Train loss: 0.01695647\r\n",
      "Epoch:  95 Step:   483 /   793 Train loss: 0.02556244\r\n",
      "Epoch:  95 Step:   484 /   793 Train loss: 0.02332697\r\n",
      "Epoch:  95 Step:   485 /   793 Train loss: 0.02109978\r\n",
      "Epoch:  95 Step:   486 /   793 Train loss: 0.02760994\r\n",
      "Epoch:  95 Step:   487 /   793 Train loss: 0.01982937\r\n",
      "Epoch:  95 Step:   488 /   793 Train loss: 0.02354454\r\n",
      "Epoch:  95 Step:   489 /   793 Train loss: 0.03098105\r\n",
      "Epoch:  95 Step:   490 /   793 Train loss: 0.03140381\r\n",
      "Epoch:  95 Step:   491 /   793 Train loss: 0.03300089\r\n",
      "Epoch:  95 Step:   492 /   793 Train loss: 0.02568445\r\n",
      "Epoch:  95 Step:   493 /   793 Train loss: 0.02402514\r\n",
      "Epoch:  95 Step:   494 /   793 Train loss: 0.02093828\r\n",
      "Epoch:  95 Step:   495 /   793 Train loss: 0.02150286\r\n",
      "Epoch:  95 Step:   496 /   793 Train loss: 0.02861461\r\n",
      "Epoch:  95 Step:   497 /   793 Train loss: 0.01596681\r\n",
      "Epoch:  95 Step:   498 /   793 Train loss: 0.02345007\r\n",
      "Epoch:  95 Step:   499 /   793 Train loss: 0.02457829\r\n",
      "Epoch:  95 Step:   500 /   793 Train loss: 0.02550394\r\n",
      "Epoch:  95 Step:   501 /   793 Train loss: 0.01517010\r\n",
      "Epoch:  95 Step:   502 /   793 Train loss: 0.05020251\r\n",
      "Epoch:  95 Step:   503 /   793 Train loss: 0.02626953\r\n",
      "Epoch:  95 Step:   504 /   793 Train loss: 0.03919291\r\n",
      "Epoch:  95 Step:   505 /   793 Train loss: 0.02326794\r\n",
      "Epoch:  95 Step:   506 /   793 Train loss: 0.02103587\r\n",
      "Epoch:  95 Step:   507 /   793 Train loss: 0.02326359\r\n",
      "Epoch:  95 Step:   508 /   793 Train loss: 0.03064084\r\n",
      "Epoch:  95 Step:   509 /   793 Train loss: 0.02438992\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  95 Step:   510 /   793 Train loss: 0.01250742\r\n",
      "Epoch:  95 Step:   511 /   793 Train loss: 0.02373130\r\n",
      "Epoch:  95 Step:   512 /   793 Train loss: 0.02711372\r\n",
      "Epoch:  95 Step:   513 /   793 Train loss: 0.01451920\r\n",
      "Epoch:  95 Step:   514 /   793 Train loss: 0.03042755\r\n",
      "Epoch:  95 Step:   515 /   793 Train loss: 0.03730328\r\n",
      "Epoch:  95 Step:   516 /   793 Train loss: 0.02366526\r\n",
      "Epoch:  95 Step:   517 /   793 Train loss: 0.03277805\r\n",
      "Epoch:  95 Step:   518 /   793 Train loss: 0.03821374\r\n",
      "Epoch:  95 Step:   519 /   793 Train loss: 0.02159129\r\n",
      "Epoch:  95 Step:   520 /   793 Train loss: 0.01673408\r\n",
      "Epoch:  95 Step:   521 /   793 Train loss: 0.02456124\r\n",
      "Epoch:  95 Step:   522 /   793 Train loss: 0.02328604\r\n",
      "Epoch:  95 Step:   523 /   793 Train loss: 0.01411231\r\n",
      "Epoch:  95 Step:   524 /   793 Train loss: 0.02063812\r\n",
      "Epoch:  95 Step:   525 /   793 Train loss: 0.01880150\r\n",
      "Epoch:  95 Step:   526 /   793 Train loss: 0.01948925\r\n",
      "Epoch:  95 Step:   527 /   793 Train loss: 0.02130785\r\n",
      "Epoch:  95 Step:   528 /   793 Train loss: 0.03187791\r\n",
      "Epoch:  95 Step:   529 /   793 Train loss: 0.04076145\r\n",
      "Epoch:  95 Step:   530 /   793 Train loss: 0.01816204\r\n",
      "Epoch:  95 Step:   531 /   793 Train loss: 0.03062718\r\n",
      "Epoch:  95 Step:   532 /   793 Train loss: 0.02895800\r\n",
      "Epoch:  95 Step:   533 /   793 Train loss: 0.03011505\r\n",
      "Epoch:  95 Step:   534 /   793 Train loss: 0.02417034\r\n",
      "Epoch:  95 Step:   535 /   793 Train loss: 0.02176375\r\n",
      "Epoch:  95 Step:   536 /   793 Train loss: 0.02308851\r\n",
      "Epoch:  95 Step:   537 /   793 Train loss: 0.02366347\r\n",
      "Epoch:  95 Step:   538 /   793 Train loss: 0.01656409\r\n",
      "Epoch:  95 Step:   539 /   793 Train loss: 0.01634848\r\n",
      "Epoch:  95 Step:   540 /   793 Train loss: 0.03038592\r\n",
      "Epoch:  95 Step:   541 /   793 Train loss: 0.01915439\r\n",
      "Epoch:  95 Step:   542 /   793 Train loss: 0.02507627\r\n",
      "Epoch:  95 Step:   543 /   793 Train loss: 0.01333423\r\n",
      "Epoch:  95 Step:   544 /   793 Train loss: 0.02183528\r\n",
      "Epoch:  95 Step:   545 /   793 Train loss: 0.02183262\r\n",
      "Epoch:  95 Step:   546 /   793 Train loss: 0.02440062\r\n",
      "Epoch:  95 Step:   547 /   793 Train loss: 0.02844113\r\n",
      "Epoch:  95 Step:   548 /   793 Train loss: 0.02156484\r\n",
      "Epoch:  95 Step:   549 /   793 Train loss: 0.03117161\r\n",
      "Epoch:  95 Step:   550 /   793 Train loss: 0.03520451\r\n",
      "Epoch:  95 Step:   551 /   793 Train loss: 0.02644406\r\n",
      "Epoch:  95 Step:   552 /   793 Train loss: 0.02104164\r\n",
      "Epoch:  95 Step:   553 /   793 Train loss: 0.01756969\r\n",
      "Epoch:  95 Step:   554 /   793 Train loss: 0.01937009\r\n",
      "Epoch:  95 Step:   555 /   793 Train loss: 0.01856220\r\n",
      "Epoch:  95 Step:   556 /   793 Train loss: 0.01966571\r\n",
      "Epoch:  95 Step:   557 /   793 Train loss: 0.01983182\r\n",
      "Epoch:  95 Step:   558 /   793 Train loss: 0.01474954\r\n",
      "Epoch:  95 Step:   559 /   793 Train loss: 0.02561210\r\n",
      "Epoch:  95 Step:   560 /   793 Train loss: 0.01612620\r\n",
      "Epoch:  95 Step:   561 /   793 Train loss: 0.01580120\r\n",
      "Epoch:  95 Step:   562 /   793 Train loss: 0.02726754\r\n",
      "Epoch:  95 Step:   563 /   793 Train loss: 0.03295502\r\n",
      "Epoch:  95 Step:   564 /   793 Train loss: 0.02452442\r\n",
      "Epoch:  95 Step:   565 /   793 Train loss: 0.02175919\r\n",
      "Epoch:  95 Step:   566 /   793 Train loss: 0.02051182\r\n",
      "Epoch:  95 Step:   567 /   793 Train loss: 0.02946050\r\n",
      "Epoch:  95 Step:   568 /   793 Train loss: 0.02635367\r\n",
      "Epoch:  95 Step:   569 /   793 Train loss: 0.01509708\r\n",
      "Epoch:  95 Step:   570 /   793 Train loss: 0.01285277\r\n",
      "Epoch:  95 Step:   571 /   793 Train loss: 0.02269017\r\n",
      "Epoch:  95 Step:   572 /   793 Train loss: 0.02637956\r\n",
      "Epoch:  95 Step:   573 /   793 Train loss: 0.01683940\r\n",
      "Epoch:  95 Step:   574 /   793 Train loss: 0.02572649\r\n",
      "Epoch:  95 Step:   575 /   793 Train loss: 0.02424015\r\n",
      "Epoch:  95 Step:   576 /   793 Train loss: 0.03172656\r\n",
      "Epoch:  95 Step:   577 /   793 Train loss: 0.03036221\r\n",
      "Epoch:  95 Step:   578 /   793 Train loss: 0.01634645\r\n",
      "Epoch:  95 Step:   579 /   793 Train loss: 0.02044764\r\n",
      "Epoch:  95 Step:   580 /   793 Train loss: 0.03130938\r\n",
      "Epoch:  95 Step:   581 /   793 Train loss: 0.02910285\r\n",
      "Epoch:  95 Step:   582 /   793 Train loss: 0.02066515\r\n",
      "Epoch:  95 Step:   583 /   793 Train loss: 0.01472722\r\n",
      "Epoch:  95 Step:   584 /   793 Train loss: 0.02603867\r\n",
      "Epoch:  95 Step:   585 /   793 Train loss: 0.02980587\r\n",
      "Epoch:  95 Step:   586 /   793 Train loss: 0.03463462\r\n",
      "Epoch:  95 Step:   587 /   793 Train loss: 0.01820520\r\n",
      "Epoch:  95 Step:   588 /   793 Train loss: 0.02201455\r\n",
      "Epoch:  95 Step:   589 /   793 Train loss: 0.04271036\r\n",
      "Epoch:  95 Step:   590 /   793 Train loss: 0.01168325\r\n",
      "Epoch:  95 Step:   591 /   793 Train loss: 0.02879177\r\n",
      "Epoch:  95 Step:   592 /   793 Train loss: 0.01537148\r\n",
      "Epoch:  95 Step:   593 /   793 Train loss: 0.01732846\r\n",
      "Epoch:  95 Step:   594 /   793 Train loss: 0.02107765\r\n",
      "Epoch:  95 Step:   595 /   793 Train loss: 0.02458931\r\n",
      "Epoch:  95 Step:   596 /   793 Train loss: 0.01577658\r\n",
      "Epoch:  95 Step:   597 /   793 Train loss: 0.01982679\r\n",
      "Epoch:  95 Step:   598 /   793 Train loss: 0.02103613\r\n",
      "Epoch:  95 Step:   599 /   793 Train loss: 0.03349824\r\n",
      "Epoch:  95 Step:   600 /   793 Train loss: 0.02385228\r\n",
      "Epoch:  95 Step:   601 /   793 Train loss: 0.02816152\r\n",
      "Epoch:  95 Step:   602 /   793 Train loss: 0.01752306\r\n",
      "Epoch:  95 Step:   603 /   793 Train loss: 0.01890619\r\n",
      "Epoch:  95 Step:   604 /   793 Train loss: 0.01809035\r\n",
      "Epoch:  95 Step:   605 /   793 Train loss: 0.02229177\r\n",
      "Epoch:  95 Step:   606 /   793 Train loss: 0.02714688\r\n",
      "Epoch:  95 Step:   607 /   793 Train loss: 0.02515758\r\n",
      "Epoch:  95 Step:   608 /   793 Train loss: 0.01885013\r\n",
      "Epoch:  95 Step:   609 /   793 Train loss: 0.03433419\r\n",
      "Epoch:  95 Step:   610 /   793 Train loss: 0.02012076\r\n",
      "Epoch:  95 Step:   611 /   793 Train loss: 0.02002159\r\n",
      "Epoch:  95 Step:   612 /   793 Train loss: 0.01901766\r\n",
      "Epoch:  95 Step:   613 /   793 Train loss: 0.02950227\r\n",
      "Epoch:  95 Step:   614 /   793 Train loss: 0.02750319\r\n",
      "Epoch:  95 Step:   615 /   793 Train loss: 0.02080878\r\n",
      "Epoch:  95 Step:   616 /   793 Train loss: 0.02968926\r\n",
      "Epoch:  95 Step:   617 /   793 Train loss: 0.02085054\r\n",
      "Epoch:  95 Step:   618 /   793 Train loss: 0.02814074\r\n",
      "Epoch:  95 Step:   619 /   793 Train loss: 0.02893579\r\n",
      "Epoch:  95 Step:   620 /   793 Train loss: 0.02999215\r\n",
      "Epoch:  95 Step:   621 /   793 Train loss: 0.01949247\r\n",
      "Epoch:  95 Step:   622 /   793 Train loss: 0.03066010\r\n",
      "Epoch:  95 Step:   623 /   793 Train loss: 0.03409299\r\n",
      "Epoch:  95 Step:   624 /   793 Train loss: 0.01527738\r\n",
      "Epoch:  95 Step:   625 /   793 Train loss: 0.01832611\r\n",
      "Epoch:  95 Step:   626 /   793 Train loss: 0.03130224\r\n",
      "Epoch:  95 Step:   627 /   793 Train loss: 0.02582211\r\n",
      "Epoch:  95 Step:   628 /   793 Train loss: 0.03122588\r\n",
      "Epoch:  95 Step:   629 /   793 Train loss: 0.01528488\r\n",
      "Epoch:  95 Step:   630 /   793 Train loss: 0.02909908\r\n",
      "Epoch:  95 Step:   631 /   793 Train loss: 0.01989553\r\n",
      "Epoch:  95 Step:   632 /   793 Train loss: 0.02220796\r\n",
      "Epoch:  95 Step:   633 /   793 Train loss: 0.02730684\r\n",
      "Epoch:  95 Step:   634 /   793 Train loss: 0.02585864\r\n",
      "Epoch:  95 Step:   635 /   793 Train loss: 0.02212638\r\n",
      "Epoch:  95 Step:   636 /   793 Train loss: 0.02367304\r\n",
      "Epoch:  95 Step:   637 /   793 Train loss: 0.02397751\r\n",
      "Epoch:  95 Step:   638 /   793 Train loss: 0.02461136\r\n",
      "Epoch:  95 Step:   639 /   793 Train loss: 0.02161622\r\n",
      "Epoch:  95 Step:   640 /   793 Train loss: 0.02834902\r\n",
      "Epoch:  95 Step:   641 /   793 Train loss: 0.01968224\r\n",
      "Epoch:  95 Step:   642 /   793 Train loss: 0.02807808\r\n",
      "Epoch:  95 Step:   643 /   793 Train loss: 0.03614191\r\n",
      "Epoch:  95 Step:   644 /   793 Train loss: 0.02395245\r\n",
      "Epoch:  95 Step:   645 /   793 Train loss: 0.01725148\r\n",
      "Epoch:  95 Step:   646 /   793 Train loss: 0.02892699\r\n",
      "Epoch:  95 Step:   647 /   793 Train loss: 0.03533673\r\n",
      "Epoch:  95 Step:   648 /   793 Train loss: 0.01393873\r\n",
      "Epoch:  95 Step:   649 /   793 Train loss: 0.02183798\r\n",
      "Epoch:  95 Step:   650 /   793 Train loss: 0.02873569\r\n",
      "Epoch:  95 Step:   651 /   793 Train loss: 0.01937325\r\n",
      "Epoch:  95 Step:   652 /   793 Train loss: 0.03500982\r\n",
      "Epoch:  95 Step:   653 /   793 Train loss: 0.02865904\r\n",
      "Epoch:  95 Step:   654 /   793 Train loss: 0.02989364\r\n",
      "Epoch:  95 Step:   655 /   793 Train loss: 0.03115283\r\n",
      "Epoch:  95 Step:   656 /   793 Train loss: 0.01886388\r\n",
      "Epoch:  95 Step:   657 /   793 Train loss: 0.01906088\r\n",
      "Epoch:  95 Step:   658 /   793 Train loss: 0.02152594\r\n",
      "Epoch:  95 Step:   659 /   793 Train loss: 0.04377540\r\n",
      "Epoch:  95 Step:   660 /   793 Train loss: 0.02168709\r\n",
      "Epoch:  95 Step:   661 /   793 Train loss: 0.02909299\r\n",
      "Epoch:  95 Step:   662 /   793 Train loss: 0.03158218\r\n",
      "Epoch:  95 Step:   663 /   793 Train loss: 0.02971856\r\n",
      "Epoch:  95 Step:   664 /   793 Train loss: 0.02767970\r\n",
      "Epoch:  95 Step:   665 /   793 Train loss: 0.02562856\r\n",
      "Epoch:  95 Step:   666 /   793 Train loss: 0.02651580\r\n",
      "Epoch:  95 Step:   667 /   793 Train loss: 0.02061887\r\n",
      "Epoch:  95 Step:   668 /   793 Train loss: 0.03005284\r\n",
      "Epoch:  95 Step:   669 /   793 Train loss: 0.03147892\r\n",
      "Epoch:  95 Step:   670 /   793 Train loss: 0.02796444\r\n",
      "Epoch:  95 Step:   671 /   793 Train loss: 0.03207965\r\n",
      "Epoch:  95 Step:   672 /   793 Train loss: 0.03652101\r\n",
      "Epoch:  95 Step:   673 /   793 Train loss: 0.02497048\r\n",
      "Epoch:  95 Step:   674 /   793 Train loss: 0.01100654\r\n",
      "Epoch:  95 Step:   675 /   793 Train loss: 0.01433749\r\n",
      "Epoch:  95 Step:   676 /   793 Train loss: 0.01716616\r\n",
      "Epoch:  95 Step:   677 /   793 Train loss: 0.02669360\r\n",
      "Epoch:  95 Step:   678 /   793 Train loss: 0.03431984\r\n",
      "Epoch:  95 Step:   679 /   793 Train loss: 0.01711069\r\n",
      "Epoch:  95 Step:   680 /   793 Train loss: 0.04281400\r\n",
      "Epoch:  95 Step:   681 /   793 Train loss: 0.01555366\r\n",
      "Epoch:  95 Step:   682 /   793 Train loss: 0.02590191\r\n",
      "Epoch:  95 Step:   683 /   793 Train loss: 0.01398947\r\n",
      "Epoch:  95 Step:   684 /   793 Train loss: 0.01372378\r\n",
      "Epoch:  95 Step:   685 /   793 Train loss: 0.02575861\r\n",
      "Epoch:  95 Step:   686 /   793 Train loss: 0.02656192\r\n",
      "Epoch:  95 Step:   687 /   793 Train loss: 0.01376413\r\n",
      "Epoch:  95 Step:   688 /   793 Train loss: 0.02580719\r\n",
      "Epoch:  95 Step:   689 /   793 Train loss: 0.03527595\r\n",
      "Epoch:  95 Step:   690 /   793 Train loss: 0.01980639\r\n",
      "Epoch:  95 Step:   691 /   793 Train loss: 0.03150257\r\n",
      "Epoch:  95 Step:   692 /   793 Train loss: 0.02197037\r\n",
      "Epoch:  95 Step:   693 /   793 Train loss: 0.01536471\r\n",
      "Epoch:  95 Step:   694 /   793 Train loss: 0.02260711\r\n",
      "Epoch:  95 Step:   695 /   793 Train loss: 0.02685555\r\n",
      "Epoch:  95 Step:   696 /   793 Train loss: 0.01808867\r\n",
      "Epoch:  95 Step:   697 /   793 Train loss: 0.02041547\r\n",
      "Epoch:  95 Step:   698 /   793 Train loss: 0.02524698\r\n",
      "Epoch:  95 Step:   699 /   793 Train loss: 0.02801286\r\n",
      "Epoch:  95 Step:   700 /   793 Train loss: 0.01412507\r\n",
      "Epoch:  95 Step:   701 /   793 Train loss: 0.01938646\r\n",
      "Epoch:  95 Step:   702 /   793 Train loss: 0.02987690\r\n",
      "Epoch:  95 Step:   703 /   793 Train loss: 0.02209038\r\n",
      "Epoch:  95 Step:   704 /   793 Train loss: 0.02578888\r\n",
      "Epoch:  95 Step:   705 /   793 Train loss: 0.02576082\r\n",
      "Epoch:  95 Step:   706 /   793 Train loss: 0.02813752\r\n",
      "Epoch:  95 Step:   707 /   793 Train loss: 0.01403575\r\n",
      "Epoch:  95 Step:   708 /   793 Train loss: 0.03228567\r\n",
      "Epoch:  95 Step:   709 /   793 Train loss: 0.02104679\r\n",
      "Epoch:  95 Step:   710 /   793 Train loss: 0.02365191\r\n",
      "Epoch:  95 Step:   711 /   793 Train loss: 0.03173234\r\n",
      "Epoch:  95 Step:   712 /   793 Train loss: 0.02840321\r\n",
      "Epoch:  95 Step:   713 /   793 Train loss: 0.02148221\r\n",
      "Epoch:  95 Step:   714 /   793 Train loss: 0.02072415\r\n",
      "Epoch:  95 Step:   715 /   793 Train loss: 0.02666270\r\n",
      "Epoch:  95 Step:   716 /   793 Train loss: 0.01760226\r\n",
      "Epoch:  95 Step:   717 /   793 Train loss: 0.01150782\r\n",
      "Epoch:  95 Step:   718 /   793 Train loss: 0.02442898\r\n",
      "Epoch:  95 Step:   719 /   793 Train loss: 0.02122275\r\n",
      "Epoch:  95 Step:   720 /   793 Train loss: 0.01993801\r\n",
      "Epoch:  95 Step:   721 /   793 Train loss: 0.02827954\r\n",
      "Epoch:  95 Step:   722 /   793 Train loss: 0.02641502\r\n",
      "Epoch:  95 Step:   723 /   793 Train loss: 0.02830539\r\n",
      "Epoch:  95 Step:   724 /   793 Train loss: 0.02368189\r\n",
      "Epoch:  95 Step:   725 /   793 Train loss: 0.02331364\r\n",
      "Epoch:  95 Step:   726 /   793 Train loss: 0.02985453\r\n",
      "Epoch:  95 Step:   727 /   793 Train loss: 0.01882699\r\n",
      "Epoch:  95 Step:   728 /   793 Train loss: 0.02294175\r\n",
      "Epoch:  95 Step:   729 /   793 Train loss: 0.01310409\r\n",
      "Epoch:  95 Step:   730 /   793 Train loss: 0.02335282\r\n",
      "Epoch:  95 Step:   731 /   793 Train loss: 0.03278966\r\n",
      "Epoch:  95 Step:   732 /   793 Train loss: 0.02796469\r\n",
      "Epoch:  95 Step:   733 /   793 Train loss: 0.01846423\r\n",
      "Epoch:  95 Step:   734 /   793 Train loss: 0.01950527\r\n",
      "Epoch:  95 Step:   735 /   793 Train loss: 0.02225689\r\n",
      "Epoch:  95 Step:   736 /   793 Train loss: 0.01564356\r\n",
      "Epoch:  95 Step:   737 /   793 Train loss: 0.02107506\r\n",
      "Epoch:  95 Step:   738 /   793 Train loss: 0.01347911\r\n",
      "Epoch:  95 Step:   739 /   793 Train loss: 0.02052023\r\n",
      "Epoch:  95 Step:   740 /   793 Train loss: 0.02637619\r\n",
      "Epoch:  95 Step:   741 /   793 Train loss: 0.03124753\r\n",
      "Epoch:  95 Step:   742 /   793 Train loss: 0.01547802\r\n",
      "Epoch:  95 Step:   743 /   793 Train loss: 0.02598998\r\n",
      "Epoch:  95 Step:   744 /   793 Train loss: 0.01582434\r\n",
      "Epoch:  95 Step:   745 /   793 Train loss: 0.02393337\r\n",
      "Epoch:  95 Step:   746 /   793 Train loss: 0.02160357\r\n",
      "Epoch:  95 Step:   747 /   793 Train loss: 0.01400114\r\n",
      "Epoch:  95 Step:   748 /   793 Train loss: 0.02543591\r\n",
      "Epoch:  95 Step:   749 /   793 Train loss: 0.03524551\r\n",
      "Epoch:  95 Step:   750 /   793 Train loss: 0.01931266\r\n",
      "Epoch:  95 Step:   751 /   793 Train loss: 0.04272557\r\n",
      "Epoch:  95 Step:   752 /   793 Train loss: 0.03340938\r\n",
      "Epoch:  95 Step:   753 /   793 Train loss: 0.03258261\r\n",
      "Epoch:  95 Step:   754 /   793 Train loss: 0.02389613\r\n",
      "Epoch:  95 Step:   755 /   793 Train loss: 0.01861266\r\n",
      "Epoch:  95 Step:   756 /   793 Train loss: 0.02652919\r\n",
      "Epoch:  95 Step:   757 /   793 Train loss: 0.01657020\r\n",
      "Epoch:  95 Step:   758 /   793 Train loss: 0.02375207\r\n",
      "Epoch:  95 Step:   759 /   793 Train loss: 0.02659299\r\n",
      "Epoch:  95 Step:   760 /   793 Train loss: 0.01696726\r\n",
      "Epoch:  95 Step:   761 /   793 Train loss: 0.03893486\r\n",
      "Epoch:  95 Step:   762 /   793 Train loss: 0.02269864\r\n",
      "Epoch:  95 Step:   763 /   793 Train loss: 0.01566402\r\n",
      "Epoch:  95 Step:   764 /   793 Train loss: 0.01476141\r\n",
      "Epoch:  95 Step:   765 /   793 Train loss: 0.02820976\r\n",
      "Epoch:  95 Step:   766 /   793 Train loss: 0.01608577\r\n",
      "Epoch:  95 Step:   767 /   793 Train loss: 0.02331820\r\n",
      "Epoch:  95 Step:   768 /   793 Train loss: 0.01326963\r\n",
      "Epoch:  95 Step:   769 /   793 Train loss: 0.04010374\r\n",
      "Epoch:  95 Step:   770 /   793 Train loss: 0.02262027\r\n",
      "Epoch:  95 Step:   771 /   793 Train loss: 0.03180699\r\n",
      "Epoch:  95 Step:   772 /   793 Train loss: 0.01649499\r\n",
      "Epoch:  95 Step:   773 /   793 Train loss: 0.02090991\r\n",
      "Epoch:  95 Step:   774 /   793 Train loss: 0.03337491\r\n",
      "Epoch:  95 Step:   775 /   793 Train loss: 0.02834398\r\n",
      "Epoch:  95 Step:   776 /   793 Train loss: 0.01884968\r\n",
      "Epoch:  95 Step:   777 /   793 Train loss: 0.01243992\r\n",
      "Epoch:  95 Step:   778 /   793 Train loss: 0.02629944\r\n",
      "Epoch:  95 Step:   779 /   793 Train loss: 0.02832855\r\n",
      "Epoch:  95 Step:   780 /   793 Train loss: 0.01813917\r\n",
      "Epoch:  95 Step:   781 /   793 Train loss: 0.01202240\r\n",
      "Epoch:  95 Step:   782 /   793 Train loss: 0.01909831\r\n",
      "Epoch:  95 Step:   783 /   793 Train loss: 0.01952409\r\n",
      "Epoch:  95 Step:   784 /   793 Train loss: 0.01961743\r\n",
      "Epoch:  95 Step:   785 /   793 Train loss: 0.01440469\r\n",
      "Epoch:  95 Step:   786 /   793 Train loss: 0.04384989\r\n",
      "Epoch:  95 Step:   787 /   793 Train loss: 0.01793335\r\n",
      "Epoch:  95 Step:   788 /   793 Train loss: 0.02232017\r\n",
      "Epoch:  95 Step:   789 /   793 Train loss: 0.02121361\r\n",
      "Epoch:  95 Step:   790 /   793 Train loss: 0.02655610\r\n",
      "Epoch:  95 Step:   791 /   793 Train loss: 0.01904754\r\n",
      "Epoch:  95 Step:   792 /   793 Train loss: 0.00896559\r\n",
      "Epoch:  95 Validation loss: 0.01426984\r\n",
      "Epoch:  96 Step:     0 /   793 Train loss: 0.03435732\r\n",
      "Epoch:  96 Step:     1 /   793 Train loss: 0.01749601\r\n",
      "Epoch:  96 Step:     2 /   793 Train loss: 0.02056563\r\n",
      "Epoch:  96 Step:     3 /   793 Train loss: 0.02727314\r\n",
      "Epoch:  96 Step:     4 /   793 Train loss: 0.02642984\r\n",
      "Epoch:  96 Step:     5 /   793 Train loss: 0.02274190\r\n",
      "Epoch:  96 Step:     6 /   793 Train loss: 0.02153534\r\n",
      "Epoch:  96 Step:     7 /   793 Train loss: 0.03576849\r\n",
      "Epoch:  96 Step:     8 /   793 Train loss: 0.03476152\r\n",
      "Epoch:  96 Step:     9 /   793 Train loss: 0.03136569\r\n",
      "Epoch:  96 Step:    10 /   793 Train loss: 0.01552166\r\n",
      "Epoch:  96 Step:    11 /   793 Train loss: 0.00758989\r\n",
      "Epoch:  96 Step:    12 /   793 Train loss: 0.02642198\r\n",
      "Epoch:  96 Step:    13 /   793 Train loss: 0.02132506\r\n",
      "Epoch:  96 Step:    14 /   793 Train loss: 0.02521771\r\n",
      "Epoch:  96 Step:    15 /   793 Train loss: 0.03136234\r\n",
      "Epoch:  96 Step:    16 /   793 Train loss: 0.01389171\r\n",
      "Epoch:  96 Step:    17 /   793 Train loss: 0.01745762\r\n",
      "Epoch:  96 Step:    18 /   793 Train loss: 0.00842464\r\n",
      "Epoch:  96 Step:    19 /   793 Train loss: 0.02313524\r\n",
      "Epoch:  96 Step:    20 /   793 Train loss: 0.03255037\r\n",
      "Epoch:  96 Step:    21 /   793 Train loss: 0.02015512\r\n",
      "Epoch:  96 Step:    22 /   793 Train loss: 0.02932527\r\n",
      "Epoch:  96 Step:    23 /   793 Train loss: 0.02050741\r\n",
      "Epoch:  96 Step:    24 /   793 Train loss: 0.02657066\r\n",
      "Epoch:  96 Step:    25 /   793 Train loss: 0.02526246\r\n",
      "Epoch:  96 Step:    26 /   793 Train loss: 0.01799440\r\n",
      "Epoch:  96 Step:    27 /   793 Train loss: 0.02775187\r\n",
      "Epoch:  96 Step:    28 /   793 Train loss: 0.02263023\r\n",
      "Epoch:  96 Step:    29 /   793 Train loss: 0.02571275\r\n",
      "Epoch:  96 Step:    30 /   793 Train loss: 0.03136871\r\n",
      "Epoch:  96 Step:    31 /   793 Train loss: 0.01694135\r\n",
      "Epoch:  96 Step:    32 /   793 Train loss: 0.02275326\r\n",
      "Epoch:  96 Step:    33 /   793 Train loss: 0.02031672\r\n",
      "Epoch:  96 Step:    34 /   793 Train loss: 0.02313600\r\n",
      "Epoch:  96 Step:    35 /   793 Train loss: 0.02796676\r\n",
      "Epoch:  96 Step:    36 /   793 Train loss: 0.03769755\r\n",
      "Epoch:  96 Step:    37 /   793 Train loss: 0.03512020\r\n",
      "Epoch:  96 Step:    38 /   793 Train loss: 0.02130044\r\n",
      "Epoch:  96 Step:    39 /   793 Train loss: 0.03520202\r\n",
      "Epoch:  96 Step:    40 /   793 Train loss: 0.02279814\r\n",
      "Epoch:  96 Step:    41 /   793 Train loss: 0.01921071\r\n",
      "Epoch:  96 Step:    42 /   793 Train loss: 0.01766792\r\n",
      "Epoch:  96 Step:    43 /   793 Train loss: 0.02133798\r\n",
      "Epoch:  96 Step:    44 /   793 Train loss: 0.02502914\r\n",
      "Epoch:  96 Step:    45 /   793 Train loss: 0.03716912\r\n",
      "Epoch:  96 Step:    46 /   793 Train loss: 0.02763807\r\n",
      "Epoch:  96 Step:    47 /   793 Train loss: 0.01615958\r\n",
      "Epoch:  96 Step:    48 /   793 Train loss: 0.01707746\r\n",
      "Epoch:  96 Step:    49 /   793 Train loss: 0.02116697\r\n",
      "Epoch:  96 Step:    50 /   793 Train loss: 0.02500316\r\n",
      "Epoch:  96 Step:    51 /   793 Train loss: 0.03014258\r\n",
      "Epoch:  96 Step:    52 /   793 Train loss: 0.04455804\r\n",
      "Epoch:  96 Step:    53 /   793 Train loss: 0.03733894\r\n",
      "Epoch:  96 Step:    54 /   793 Train loss: 0.02124482\r\n",
      "Epoch:  96 Step:    55 /   793 Train loss: 0.02445499\r\n",
      "Epoch:  96 Step:    56 /   793 Train loss: 0.02113550\r\n",
      "Epoch:  96 Step:    57 /   793 Train loss: 0.02600946\r\n",
      "Epoch:  96 Step:    58 /   793 Train loss: 0.02545564\r\n",
      "Epoch:  96 Step:    59 /   793 Train loss: 0.01428942\r\n",
      "Epoch:  96 Step:    60 /   793 Train loss: 0.02188161\r\n",
      "Epoch:  96 Step:    61 /   793 Train loss: 0.01963856\r\n",
      "Epoch:  96 Step:    62 /   793 Train loss: 0.02937063\r\n",
      "Epoch:  96 Step:    63 /   793 Train loss: 0.02614407\r\n",
      "Epoch:  96 Step:    64 /   793 Train loss: 0.01539996\r\n",
      "Epoch:  96 Step:    65 /   793 Train loss: 0.02183289\r\n",
      "Epoch:  96 Step:    66 /   793 Train loss: 0.02264634\r\n",
      "Epoch:  96 Step:    67 /   793 Train loss: 0.01633363\r\n",
      "Epoch:  96 Step:    68 /   793 Train loss: 0.02130298\r\n",
      "Epoch:  96 Step:    69 /   793 Train loss: 0.01908396\r\n",
      "Epoch:  96 Step:    70 /   793 Train loss: 0.03037789\r\n",
      "Epoch:  96 Step:    71 /   793 Train loss: 0.02172167\r\n",
      "Epoch:  96 Step:    72 /   793 Train loss: 0.01056275\r\n",
      "Epoch:  96 Step:    73 /   793 Train loss: 0.01736150\r\n",
      "Epoch:  96 Step:    74 /   793 Train loss: 0.03740184\r\n",
      "Epoch:  96 Step:    75 /   793 Train loss: 0.02703285\r\n",
      "Epoch:  96 Step:    76 /   793 Train loss: 0.03295441\r\n",
      "Epoch:  96 Step:    77 /   793 Train loss: 0.02806611\r\n",
      "Epoch:  96 Step:    78 /   793 Train loss: 0.02348411\r\n",
      "Epoch:  96 Step:    79 /   793 Train loss: 0.01666055\r\n",
      "Epoch:  96 Step:    80 /   793 Train loss: 0.02542432\r\n",
      "Epoch:  96 Step:    81 /   793 Train loss: 0.01799172\r\n",
      "Epoch:  96 Step:    82 /   793 Train loss: 0.02451336\r\n",
      "Epoch:  96 Step:    83 /   793 Train loss: 0.01815786\r\n",
      "Epoch:  96 Step:    84 /   793 Train loss: 0.03563397\r\n",
      "Epoch:  96 Step:    85 /   793 Train loss: 0.01743922\r\n",
      "Epoch:  96 Step:    86 /   793 Train loss: 0.01783195\r\n",
      "Epoch:  96 Step:    87 /   793 Train loss: 0.02341520\r\n",
      "Epoch:  96 Step:    88 /   793 Train loss: 0.02131690\r\n",
      "Epoch:  96 Step:    89 /   793 Train loss: 0.01543786\r\n",
      "Epoch:  96 Step:    90 /   793 Train loss: 0.03530375\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  96 Step:    91 /   793 Train loss: 0.02991699\r\n",
      "Epoch:  96 Step:    92 /   793 Train loss: 0.03018685\r\n",
      "Epoch:  96 Step:    93 /   793 Train loss: 0.02231082\r\n",
      "Epoch:  96 Step:    94 /   793 Train loss: 0.01315617\r\n",
      "Epoch:  96 Step:    95 /   793 Train loss: 0.02616699\r\n",
      "Epoch:  96 Step:    96 /   793 Train loss: 0.01748513\r\n",
      "Epoch:  96 Step:    97 /   793 Train loss: 0.02323220\r\n",
      "Epoch:  96 Step:    98 /   793 Train loss: 0.01506202\r\n",
      "Epoch:  96 Step:    99 /   793 Train loss: 0.03490867\r\n",
      "Epoch:  96 Step:   100 /   793 Train loss: 0.03496785\r\n",
      "Epoch:  96 Step:   101 /   793 Train loss: 0.01538151\r\n",
      "Epoch:  96 Step:   102 /   793 Train loss: 0.04021578\r\n",
      "Epoch:  96 Step:   103 /   793 Train loss: 0.03031338\r\n",
      "Epoch:  96 Step:   104 /   793 Train loss: 0.02260882\r\n",
      "Epoch:  96 Step:   105 /   793 Train loss: 0.04132777\r\n",
      "Epoch:  96 Step:   106 /   793 Train loss: 0.02726342\r\n",
      "Epoch:  96 Step:   107 /   793 Train loss: 0.02401504\r\n",
      "Epoch:  96 Step:   108 /   793 Train loss: 0.02956507\r\n",
      "Epoch:  96 Step:   109 /   793 Train loss: 0.03992300\r\n",
      "Epoch:  96 Step:   110 /   793 Train loss: 0.01609508\r\n",
      "Epoch:  96 Step:   111 /   793 Train loss: 0.02815303\r\n",
      "Epoch:  96 Step:   112 /   793 Train loss: 0.01911864\r\n",
      "Epoch:  96 Step:   113 /   793 Train loss: 0.02082877\r\n",
      "Epoch:  96 Step:   114 /   793 Train loss: 0.02700906\r\n",
      "Epoch:  96 Step:   115 /   793 Train loss: 0.02686911\r\n",
      "Epoch:  96 Step:   116 /   793 Train loss: 0.01575742\r\n",
      "Epoch:  96 Step:   117 /   793 Train loss: 0.01521795\r\n",
      "Epoch:  96 Step:   118 /   793 Train loss: 0.02917709\r\n",
      "Epoch:  96 Step:   119 /   793 Train loss: 0.02245186\r\n",
      "Epoch:  96 Step:   120 /   793 Train loss: 0.01950029\r\n",
      "Epoch:  96 Step:   121 /   793 Train loss: 0.03351987\r\n",
      "Epoch:  96 Step:   122 /   793 Train loss: 0.02401360\r\n",
      "Epoch:  96 Step:   123 /   793 Train loss: 0.02996834\r\n",
      "Epoch:  96 Step:   124 /   793 Train loss: 0.01733114\r\n",
      "Epoch:  96 Step:   125 /   793 Train loss: 0.02055299\r\n",
      "Epoch:  96 Step:   126 /   793 Train loss: 0.02448852\r\n",
      "Epoch:  96 Step:   127 /   793 Train loss: 0.01482272\r\n",
      "Epoch:  96 Step:   128 /   793 Train loss: 0.03178687\r\n",
      "Epoch:  96 Step:   129 /   793 Train loss: 0.02151752\r\n",
      "Epoch:  96 Step:   130 /   793 Train loss: 0.02880793\r\n",
      "Epoch:  96 Step:   131 /   793 Train loss: 0.02452705\r\n",
      "Epoch:  96 Step:   132 /   793 Train loss: 0.01936301\r\n",
      "Epoch:  96 Step:   133 /   793 Train loss: 0.02241752\r\n",
      "Epoch:  96 Step:   134 /   793 Train loss: 0.02106754\r\n",
      "Epoch:  96 Step:   135 /   793 Train loss: 0.01211119\r\n",
      "Epoch:  96 Step:   136 /   793 Train loss: 0.02521514\r\n",
      "Epoch:  96 Step:   137 /   793 Train loss: 0.02094009\r\n",
      "Epoch:  96 Step:   138 /   793 Train loss: 0.03046221\r\n",
      "Epoch:  96 Step:   139 /   793 Train loss: 0.03509742\r\n",
      "Epoch:  96 Step:   140 /   793 Train loss: 0.02196174\r\n",
      "Epoch:  96 Step:   141 /   793 Train loss: 0.01817382\r\n",
      "Epoch:  96 Step:   142 /   793 Train loss: 0.02739064\r\n",
      "Epoch:  96 Step:   143 /   793 Train loss: 0.02344285\r\n",
      "Epoch:  96 Step:   144 /   793 Train loss: 0.03603825\r\n",
      "Epoch:  96 Step:   145 /   793 Train loss: 0.01780495\r\n",
      "Epoch:  96 Step:   146 /   793 Train loss: 0.02403797\r\n",
      "Epoch:  96 Step:   147 /   793 Train loss: 0.03295424\r\n",
      "Epoch:  96 Step:   148 /   793 Train loss: 0.03416613\r\n",
      "Epoch:  96 Step:   149 /   793 Train loss: 0.03513199\r\n",
      "Epoch:  96 Step:   150 /   793 Train loss: 0.02715014\r\n",
      "Epoch:  96 Step:   151 /   793 Train loss: 0.01051491\r\n",
      "Epoch:  96 Step:   152 /   793 Train loss: 0.02362347\r\n",
      "Epoch:  96 Step:   153 /   793 Train loss: 0.01957206\r\n",
      "Epoch:  96 Step:   154 /   793 Train loss: 0.01932992\r\n",
      "Epoch:  96 Step:   155 /   793 Train loss: 0.02137051\r\n",
      "Epoch:  96 Step:   156 /   793 Train loss: 0.02265717\r\n",
      "Epoch:  96 Step:   157 /   793 Train loss: 0.01283595\r\n",
      "Epoch:  96 Step:   158 /   793 Train loss: 0.01572685\r\n",
      "Epoch:  96 Step:   159 /   793 Train loss: 0.01688368\r\n",
      "Epoch:  96 Step:   160 /   793 Train loss: 0.02168168\r\n",
      "Epoch:  96 Step:   161 /   793 Train loss: 0.03484363\r\n",
      "Epoch:  96 Step:   162 /   793 Train loss: 0.02040523\r\n",
      "Epoch:  96 Step:   163 /   793 Train loss: 0.01478856\r\n",
      "Epoch:  96 Step:   164 /   793 Train loss: 0.02365199\r\n",
      "Epoch:  96 Step:   165 /   793 Train loss: 0.03385894\r\n",
      "Epoch:  96 Step:   166 /   793 Train loss: 0.03913493\r\n",
      "Epoch:  96 Step:   167 /   793 Train loss: 0.02549787\r\n",
      "Epoch:  96 Step:   168 /   793 Train loss: 0.01430938\r\n",
      "Epoch:  96 Step:   169 /   793 Train loss: 0.02429833\r\n",
      "Epoch:  96 Step:   170 /   793 Train loss: 0.01876886\r\n",
      "Epoch:  96 Step:   171 /   793 Train loss: 0.01831583\r\n",
      "Epoch:  96 Step:   172 /   793 Train loss: 0.02179243\r\n",
      "Epoch:  96 Step:   173 /   793 Train loss: 0.02483946\r\n",
      "Epoch:  96 Step:   174 /   793 Train loss: 0.02132311\r\n",
      "Epoch:  96 Step:   175 /   793 Train loss: 0.02716394\r\n",
      "Epoch:  96 Step:   176 /   793 Train loss: 0.02742776\r\n",
      "Epoch:  96 Step:   177 /   793 Train loss: 0.02221546\r\n",
      "Epoch:  96 Step:   178 /   793 Train loss: 0.01584640\r\n",
      "Epoch:  96 Step:   179 /   793 Train loss: 0.01582931\r\n",
      "Epoch:  96 Step:   180 /   793 Train loss: 0.02345351\r\n",
      "Epoch:  96 Step:   181 /   793 Train loss: 0.01524719\r\n",
      "Epoch:  96 Step:   182 /   793 Train loss: 0.02271252\r\n",
      "Epoch:  96 Step:   183 /   793 Train loss: 0.02661785\r\n",
      "Epoch:  96 Step:   184 /   793 Train loss: 0.01945543\r\n",
      "Epoch:  96 Step:   185 /   793 Train loss: 0.02444379\r\n",
      "Epoch:  96 Step:   186 /   793 Train loss: 0.02085070\r\n",
      "Epoch:  96 Step:   187 /   793 Train loss: 0.02052416\r\n",
      "Epoch:  96 Step:   188 /   793 Train loss: 0.04259308\r\n",
      "Epoch:  96 Step:   189 /   793 Train loss: 0.01683842\r\n",
      "Epoch:  96 Step:   190 /   793 Train loss: 0.02851382\r\n",
      "Epoch:  96 Step:   191 /   793 Train loss: 0.02256555\r\n",
      "Epoch:  96 Step:   192 /   793 Train loss: 0.01894654\r\n",
      "Epoch:  96 Step:   193 /   793 Train loss: 0.02995759\r\n",
      "Epoch:  96 Step:   194 /   793 Train loss: 0.02377609\r\n",
      "Epoch:  96 Step:   195 /   793 Train loss: 0.04628470\r\n",
      "Epoch:  96 Step:   196 /   793 Train loss: 0.03234341\r\n",
      "Epoch:  96 Step:   197 /   793 Train loss: 0.02743285\r\n",
      "Epoch:  96 Step:   198 /   793 Train loss: 0.02124050\r\n",
      "Epoch:  96 Step:   199 /   793 Train loss: 0.02337448\r\n",
      "Epoch:  96 Step:   200 /   793 Train loss: 0.01194051\r\n",
      "Epoch:  96 Step:   201 /   793 Train loss: 0.02105056\r\n",
      "Epoch:  96 Step:   202 /   793 Train loss: 0.02784603\r\n",
      "Epoch:  96 Step:   203 /   793 Train loss: 0.01241467\r\n",
      "Epoch:  96 Step:   204 /   793 Train loss: 0.02236184\r\n",
      "Epoch:  96 Step:   205 /   793 Train loss: 0.03087476\r\n",
      "Epoch:  96 Step:   206 /   793 Train loss: 0.01895593\r\n",
      "Epoch:  96 Step:   207 /   793 Train loss: 0.02378417\r\n",
      "Epoch:  96 Step:   208 /   793 Train loss: 0.01700669\r\n",
      "Epoch:  96 Step:   209 /   793 Train loss: 0.02069082\r\n",
      "Epoch:  96 Step:   210 /   793 Train loss: 0.02151169\r\n",
      "Epoch:  96 Step:   211 /   793 Train loss: 0.04564933\r\n",
      "Epoch:  96 Step:   212 /   793 Train loss: 0.03192464\r\n",
      "Epoch:  96 Step:   213 /   793 Train loss: 0.03557223\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  96 Step:   214 /   793 Train loss: 0.02537617\r\n",
      "Epoch:  96 Step:   215 /   793 Train loss: 0.02995048\r\n",
      "Epoch:  96 Step:   216 /   793 Train loss: 0.03836747\r\n",
      "Epoch:  96 Step:   217 /   793 Train loss: 0.03224017\r\n",
      "Epoch:  96 Step:   218 /   793 Train loss: 0.02248095\r\n",
      "Epoch:  96 Step:   219 /   793 Train loss: 0.02821125\r\n",
      "Epoch:  96 Step:   220 /   793 Train loss: 0.01207444\r\n",
      "Epoch:  96 Step:   221 /   793 Train loss: 0.02068100\r\n",
      "Epoch:  96 Step:   222 /   793 Train loss: 0.02991782\r\n",
      "Epoch:  96 Step:   223 /   793 Train loss: 0.02065197\r\n",
      "Epoch:  96 Step:   224 /   793 Train loss: 0.01575923\r\n",
      "Epoch:  96 Step:   225 /   793 Train loss: 0.02607710\r\n",
      "Epoch:  96 Step:   226 /   793 Train loss: 0.03364393\r\n",
      "Epoch:  96 Step:   227 /   793 Train loss: 0.03056594\r\n",
      "Epoch:  96 Step:   228 /   793 Train loss: 0.02167910\r\n",
      "Epoch:  96 Step:   229 /   793 Train loss: 0.02241856\r\n",
      "Epoch:  96 Step:   230 /   793 Train loss: 0.02282962\r\n",
      "Epoch:  96 Step:   231 /   793 Train loss: 0.01883841\r\n",
      "Epoch:  96 Step:   232 /   793 Train loss: 0.02753643\r\n",
      "Epoch:  96 Step:   233 /   793 Train loss: 0.02179102\r\n",
      "Epoch:  96 Step:   234 /   793 Train loss: 0.01381987\r\n",
      "Epoch:  96 Step:   235 /   793 Train loss: 0.02304818\r\n",
      "Epoch:  96 Step:   236 /   793 Train loss: 0.01763571\r\n",
      "Epoch:  96 Step:   237 /   793 Train loss: 0.01723987\r\n",
      "Epoch:  96 Step:   238 /   793 Train loss: 0.02458927\r\n",
      "Epoch:  96 Step:   239 /   793 Train loss: 0.01763133\r\n",
      "Epoch:  96 Step:   240 /   793 Train loss: 0.02872954\r\n",
      "Epoch:  96 Step:   241 /   793 Train loss: 0.01642935\r\n",
      "Epoch:  96 Step:   242 /   793 Train loss: 0.01440019\r\n",
      "Epoch:  96 Step:   243 /   793 Train loss: 0.01922268\r\n",
      "Epoch:  96 Step:   244 /   793 Train loss: 0.01457904\r\n",
      "Epoch:  96 Step:   245 /   793 Train loss: 0.02257177\r\n",
      "Epoch:  96 Step:   246 /   793 Train loss: 0.03252704\r\n",
      "Epoch:  96 Step:   247 /   793 Train loss: 0.01526453\r\n",
      "Epoch:  96 Step:   248 /   793 Train loss: 0.01909845\r\n",
      "Epoch:  96 Step:   249 /   793 Train loss: 0.02239848\r\n",
      "Epoch:  96 Step:   250 /   793 Train loss: 0.02622019\r\n",
      "Epoch:  96 Step:   251 /   793 Train loss: 0.02009080\r\n",
      "Epoch:  96 Step:   252 /   793 Train loss: 0.02002387\r\n",
      "Epoch:  96 Step:   253 /   793 Train loss: 0.02213782\r\n",
      "Epoch:  96 Step:   254 /   793 Train loss: 0.01834527\r\n",
      "Epoch:  96 Step:   255 /   793 Train loss: 0.03084975\r\n",
      "Epoch:  96 Step:   256 /   793 Train loss: 0.03289478\r\n",
      "Epoch:  96 Step:   257 /   793 Train loss: 0.01946233\r\n",
      "Epoch:  96 Step:   258 /   793 Train loss: 0.01999851\r\n",
      "Epoch:  96 Step:   259 /   793 Train loss: 0.01365144\r\n",
      "Epoch:  96 Step:   260 /   793 Train loss: 0.01532220\r\n",
      "Epoch:  96 Step:   261 /   793 Train loss: 0.02235823\r\n",
      "Epoch:  96 Step:   262 /   793 Train loss: 0.02556292\r\n",
      "Epoch:  96 Step:   263 /   793 Train loss: 0.04469003\r\n",
      "Epoch:  96 Step:   264 /   793 Train loss: 0.02718022\r\n",
      "Epoch:  96 Step:   265 /   793 Train loss: 0.01997881\r\n",
      "Epoch:  96 Step:   266 /   793 Train loss: 0.03168441\r\n",
      "Epoch:  96 Step:   267 /   793 Train loss: 0.01391986\r\n",
      "Epoch:  96 Step:   268 /   793 Train loss: 0.02357915\r\n",
      "Epoch:  96 Step:   269 /   793 Train loss: 0.03673875\r\n",
      "Epoch:  96 Step:   270 /   793 Train loss: 0.02031201\r\n",
      "Epoch:  96 Step:   271 /   793 Train loss: 0.01700443\r\n",
      "Epoch:  96 Step:   272 /   793 Train loss: 0.02492080\r\n",
      "Epoch:  96 Step:   273 /   793 Train loss: 0.01868729\r\n",
      "Epoch:  96 Step:   274 /   793 Train loss: 0.03024575\r\n",
      "Epoch:  96 Step:   275 /   793 Train loss: 0.03081241\r\n",
      "Epoch:  96 Step:   276 /   793 Train loss: 0.01618985\r\n",
      "Epoch:  96 Step:   277 /   793 Train loss: 0.01584035\r\n",
      "Epoch:  96 Step:   278 /   793 Train loss: 0.03009073\r\n",
      "Epoch:  96 Step:   279 /   793 Train loss: 0.01531538\r\n",
      "Epoch:  96 Step:   280 /   793 Train loss: 0.03168991\r\n",
      "Epoch:  96 Step:   281 /   793 Train loss: 0.01420417\r\n",
      "Epoch:  96 Step:   282 /   793 Train loss: 0.02743665\r\n",
      "Epoch:  96 Step:   283 /   793 Train loss: 0.02122423\r\n",
      "Epoch:  96 Step:   284 /   793 Train loss: 0.02669619\r\n",
      "Epoch:  96 Step:   285 /   793 Train loss: 0.03284906\r\n",
      "Epoch:  96 Step:   286 /   793 Train loss: 0.03310722\r\n",
      "Epoch:  96 Step:   287 /   793 Train loss: 0.01353543\r\n",
      "Epoch:  96 Step:   288 /   793 Train loss: 0.02698106\r\n",
      "Epoch:  96 Step:   289 /   793 Train loss: 0.02119688\r\n",
      "Epoch:  96 Step:   290 /   793 Train loss: 0.01266191\r\n",
      "Epoch:  96 Step:   291 /   793 Train loss: 0.02255099\r\n",
      "Epoch:  96 Step:   292 /   793 Train loss: 0.01912813\r\n",
      "Epoch:  96 Step:   293 /   793 Train loss: 0.01791061\r\n",
      "Epoch:  96 Step:   294 /   793 Train loss: 0.03648731\r\n",
      "Epoch:  96 Step:   295 /   793 Train loss: 0.02056798\r\n",
      "Epoch:  96 Step:   296 /   793 Train loss: 0.02133860\r\n",
      "Epoch:  96 Step:   297 /   793 Train loss: 0.02795664\r\n",
      "Epoch:  96 Step:   298 /   793 Train loss: 0.03478279\r\n",
      "Epoch:  96 Step:   299 /   793 Train loss: 0.02074623\r\n",
      "Epoch:  96 Step:   300 /   793 Train loss: 0.02701785\r\n",
      "Epoch:  96 Step:   301 /   793 Train loss: 0.03302068\r\n",
      "Epoch:  96 Step:   302 /   793 Train loss: 0.02533725\r\n",
      "Epoch:  96 Step:   303 /   793 Train loss: 0.01397244\r\n",
      "Epoch:  96 Step:   304 /   793 Train loss: 0.02190673\r\n",
      "Epoch:  96 Step:   305 /   793 Train loss: 0.02275786\r\n",
      "Epoch:  96 Step:   306 /   793 Train loss: 0.01812242\r\n",
      "Epoch:  96 Step:   307 /   793 Train loss: 0.02437286\r\n",
      "Epoch:  96 Step:   308 /   793 Train loss: 0.02269643\r\n",
      "Epoch:  96 Step:   309 /   793 Train loss: 0.01733035\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  96 Step:   310 /   793 Train loss: 0.01791689\r\n",
      "Epoch:  96 Step:   311 /   793 Train loss: 0.02485792\r\n",
      "Epoch:  96 Step:   312 /   793 Train loss: 0.02334966\r\n",
      "Epoch:  96 Step:   313 /   793 Train loss: 0.02823816\r\n",
      "Epoch:  96 Step:   314 /   793 Train loss: 0.01890139\r\n",
      "Epoch:  96 Step:   315 /   793 Train loss: 0.01976991\r\n",
      "Epoch:  96 Step:   316 /   793 Train loss: 0.01864941\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  96 Step:   317 /   793 Train loss: 0.03354344\r\n",
      "Epoch:  96 Step:   318 /   793 Train loss: 0.01644507\r\n",
      "Epoch:  96 Step:   319 /   793 Train loss: 0.01418719\r\n",
      "Epoch:  96 Step:   320 /   793 Train loss: 0.02271293\r\n",
      "Epoch:  96 Step:   321 /   793 Train loss: 0.02796723\r\n",
      "Epoch:  96 Step:   322 /   793 Train loss: 0.02157486\r\n",
      "Epoch:  96 Step:   323 /   793 Train loss: 0.01775160\r\n",
      "Epoch:  96 Step:   324 /   793 Train loss: 0.02734820\r\n",
      "Epoch:  96 Step:   325 /   793 Train loss: 0.03308599\r\n",
      "Epoch:  96 Step:   326 /   793 Train loss: 0.01833534\r\n",
      "Epoch:  96 Step:   327 /   793 Train loss: 0.02684085\r\n",
      "Epoch:  96 Step:   328 /   793 Train loss: 0.02100663\r\n",
      "Epoch:  96 Step:   329 /   793 Train loss: 0.02809716\r\n",
      "Epoch:  96 Step:   330 /   793 Train loss: 0.01804301\r\n",
      "Epoch:  96 Step:   331 /   793 Train loss: 0.01832623\r\n",
      "Epoch:  96 Step:   332 /   793 Train loss: 0.03353278\r\n",
      "Epoch:  96 Step:   333 /   793 Train loss: 0.02789506\r\n",
      "Epoch:  96 Step:   334 /   793 Train loss: 0.02579409\r\n",
      "Epoch:  96 Step:   335 /   793 Train loss: 0.01814290\r\n",
      "Epoch:  96 Step:   336 /   793 Train loss: 0.02135385\r\n",
      "Epoch:  96 Step:   337 /   793 Train loss: 0.02282893\r\n",
      "Epoch:  96 Step:   338 /   793 Train loss: 0.03676219\r\n",
      "Epoch:  96 Step:   339 /   793 Train loss: 0.01495629\r\n",
      "Epoch:  96 Step:   340 /   793 Train loss: 0.02996108\r\n",
      "Epoch:  96 Step:   341 /   793 Train loss: 0.02401908\r\n",
      "Epoch:  96 Step:   342 /   793 Train loss: 0.01963959\r\n",
      "Epoch:  96 Step:   343 /   793 Train loss: 0.01855316\r\n",
      "Epoch:  96 Step:   344 /   793 Train loss: 0.01462008\r\n",
      "Epoch:  96 Step:   345 /   793 Train loss: 0.02349062\r\n",
      "Epoch:  96 Step:   346 /   793 Train loss: 0.02093574\r\n",
      "Epoch:  96 Step:   347 /   793 Train loss: 0.01743335\r\n",
      "Epoch:  96 Step:   348 /   793 Train loss: 0.02224433\r\n",
      "Epoch:  96 Step:   349 /   793 Train loss: 0.03363845\r\n",
      "Epoch:  96 Step:   350 /   793 Train loss: 0.01268202\r\n",
      "Epoch:  96 Step:   351 /   793 Train loss: 0.03233878\r\n",
      "Epoch:  96 Step:   352 /   793 Train loss: 0.02179152\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  96 Step:   353 /   793 Train loss: 0.01087948\r\n",
      "Epoch:  96 Step:   354 /   793 Train loss: 0.03223749\r\n",
      "Epoch:  96 Step:   355 /   793 Train loss: 0.02153615\r\n",
      "Epoch:  96 Step:   356 /   793 Train loss: 0.01826839\r\n",
      "Epoch:  96 Step:   357 /   793 Train loss: 0.01812469\r\n",
      "Epoch:  96 Step:   358 /   793 Train loss: 0.02100314\r\n",
      "Epoch:  96 Step:   359 /   793 Train loss: 0.01788491\r\n",
      "Epoch:  96 Step:   360 /   793 Train loss: 0.02583508\r\n",
      "Epoch:  96 Step:   361 /   793 Train loss: 0.03111348\r\n",
      "Epoch:  96 Step:   362 /   793 Train loss: 0.03945519\r\n",
      "Epoch:  96 Step:   363 /   793 Train loss: 0.02522457\r\n",
      "Epoch:  96 Step:   364 /   793 Train loss: 0.02587512\r\n",
      "Epoch:  96 Step:   365 /   793 Train loss: 0.02990556\r\n",
      "Epoch:  96 Step:   366 /   793 Train loss: 0.03595642\r\n",
      "Epoch:  96 Step:   367 /   793 Train loss: 0.02036647\r\n",
      "Epoch:  96 Step:   368 /   793 Train loss: 0.01891080\r\n",
      "Epoch:  96 Step:   369 /   793 Train loss: 0.03081730\r\n",
      "Epoch:  96 Step:   370 /   793 Train loss: 0.01625162\r\n",
      "Epoch:  96 Step:   371 /   793 Train loss: 0.02252733\r\n",
      "Epoch:  96 Step:   372 /   793 Train loss: 0.03184497\r\n",
      "Epoch:  96 Step:   373 /   793 Train loss: 0.02674287\r\n",
      "Epoch:  96 Step:   374 /   793 Train loss: 0.02951108\r\n",
      "Epoch:  96 Step:   375 /   793 Train loss: 0.04256552\r\n",
      "Epoch:  96 Step:   376 /   793 Train loss: 0.01745888\r\n",
      "Epoch:  96 Step:   377 /   793 Train loss: 0.01892928\r\n",
      "Epoch:  96 Step:   378 /   793 Train loss: 0.03610393\r\n",
      "Epoch:  96 Step:   379 /   793 Train loss: 0.02669827\r\n",
      "Epoch:  96 Step:   380 /   793 Train loss: 0.02178590\r\n",
      "Epoch:  96 Step:   381 /   793 Train loss: 0.02438413\r\n",
      "Epoch:  96 Step:   382 /   793 Train loss: 0.01826146\r\n",
      "Epoch:  96 Step:   383 /   793 Train loss: 0.01906952\r\n",
      "Epoch:  96 Step:   384 /   793 Train loss: 0.01881796\r\n",
      "Epoch:  96 Step:   385 /   793 Train loss: 0.02523044\r\n",
      "Epoch:  96 Step:   386 /   793 Train loss: 0.02588215\r\n",
      "Epoch:  96 Step:   387 /   793 Train loss: 0.03302041\r\n",
      "Epoch:  96 Step:   388 /   793 Train loss: 0.02606412\r\n",
      "Epoch:  96 Step:   389 /   793 Train loss: 0.02071832\r\n",
      "Epoch:  96 Step:   390 /   793 Train loss: 0.01669917\r\n",
      "Epoch:  96 Step:   391 /   793 Train loss: 0.03130455\r\n",
      "Epoch:  96 Step:   392 /   793 Train loss: 0.02640000\r\n",
      "Epoch:  96 Step:   393 /   793 Train loss: 0.02898562\r\n",
      "Epoch:  96 Step:   394 /   793 Train loss: 0.01887236\r\n",
      "Epoch:  96 Step:   395 /   793 Train loss: 0.01858333\r\n",
      "Epoch:  96 Step:   396 /   793 Train loss: 0.02431110\r\n",
      "Epoch:  96 Step:   397 /   793 Train loss: 0.04500839\r\n",
      "Epoch:  96 Step:   398 /   793 Train loss: 0.01885524\r\n",
      "Epoch:  96 Step:   399 /   793 Train loss: 0.03459340\r\n",
      "Epoch:  96 Step:   400 /   793 Train loss: 0.03020805\r\n",
      "Epoch:  96 Step:   401 /   793 Train loss: 0.03169046\r\n",
      "Epoch:  96 Step:   402 /   793 Train loss: 0.02880582\r\n",
      "Epoch:  96 Step:   403 /   793 Train loss: 0.03072764\r\n",
      "Epoch:  96 Step:   404 /   793 Train loss: 0.02337075\r\n",
      "Epoch:  96 Step:   405 /   793 Train loss: 0.02653313\r\n",
      "Epoch:  96 Step:   406 /   793 Train loss: 0.02727776\r\n",
      "Epoch:  96 Step:   407 /   793 Train loss: 0.02163672\r\n",
      "Epoch:  96 Step:   408 /   793 Train loss: 0.03293803\r\n",
      "Epoch:  96 Step:   409 /   793 Train loss: 0.02965748\r\n",
      "Epoch:  96 Step:   410 /   793 Train loss: 0.02419727\r\n",
      "Epoch:  96 Step:   411 /   793 Train loss: 0.02652617\r\n",
      "Epoch:  96 Step:   412 /   793 Train loss: 0.01937778\r\n",
      "Epoch:  96 Step:   413 /   793 Train loss: 0.01899511\r\n",
      "Epoch:  96 Step:   414 /   793 Train loss: 0.03354748\r\n",
      "Epoch:  96 Step:   415 /   793 Train loss: 0.03104870\r\n",
      "Epoch:  96 Step:   416 /   793 Train loss: 0.00999695\r\n",
      "Epoch:  96 Step:   417 /   793 Train loss: 0.01563202\r\n",
      "Epoch:  96 Step:   418 /   793 Train loss: 0.01801150\r\n",
      "Epoch:  96 Step:   419 /   793 Train loss: 0.02298524\r\n",
      "Epoch:  96 Step:   420 /   793 Train loss: 0.02404122\r\n",
      "Epoch:  96 Step:   421 /   793 Train loss: 0.03650719\r\n",
      "Epoch:  96 Step:   422 /   793 Train loss: 0.04224617\r\n",
      "Epoch:  96 Step:   423 /   793 Train loss: 0.02642530\r\n",
      "Epoch:  96 Step:   424 /   793 Train loss: 0.03423036\r\n",
      "Epoch:  96 Step:   425 /   793 Train loss: 0.01715534\r\n",
      "Epoch:  96 Step:   426 /   793 Train loss: 0.02971980\r\n",
      "Epoch:  96 Step:   427 /   793 Train loss: 0.02316628\r\n",
      "Epoch:  96 Step:   428 /   793 Train loss: 0.02060766\r\n",
      "Epoch:  96 Step:   429 /   793 Train loss: 0.01654201\r\n",
      "Epoch:  96 Step:   430 /   793 Train loss: 0.02300179\r\n",
      "Epoch:  96 Step:   431 /   793 Train loss: 0.01517794\r\n",
      "Epoch:  96 Step:   432 /   793 Train loss: 0.03824808\r\n",
      "Epoch:  96 Step:   433 /   793 Train loss: 0.02164131\r\n",
      "Epoch:  96 Step:   434 /   793 Train loss: 0.01622737\r\n",
      "Epoch:  96 Step:   435 /   793 Train loss: 0.01508828\r\n",
      "Epoch:  96 Step:   436 /   793 Train loss: 0.02400546\r\n",
      "Epoch:  96 Step:   437 /   793 Train loss: 0.03058823\r\n",
      "Epoch:  96 Step:   438 /   793 Train loss: 0.00619191\r\n",
      "Epoch:  96 Step:   439 /   793 Train loss: 0.02293956\r\n",
      "Epoch:  96 Step:   440 /   793 Train loss: 0.02321232\r\n",
      "Epoch:  96 Step:   441 /   793 Train loss: 0.02727442\r\n",
      "Epoch:  96 Step:   442 /   793 Train loss: 0.02243744\r\n",
      "Epoch:  96 Step:   443 /   793 Train loss: 0.02609914\r\n",
      "Epoch:  96 Step:   444 /   793 Train loss: 0.01804605\r\n",
      "Epoch:  96 Step:   445 /   793 Train loss: 0.01015471\r\n",
      "Epoch:  96 Step:   446 /   793 Train loss: 0.03113009\r\n",
      "Epoch:  96 Step:   447 /   793 Train loss: 0.02109121\r\n",
      "Epoch:  96 Step:   448 /   793 Train loss: 0.02949906\r\n",
      "Epoch:  96 Step:   449 /   793 Train loss: 0.03164469\r\n",
      "Epoch:  96 Step:   450 /   793 Train loss: 0.02338147\r\n",
      "Epoch:  96 Step:   451 /   793 Train loss: 0.02850874\r\n",
      "Epoch:  96 Step:   452 /   793 Train loss: 0.01595679\r\n",
      "Epoch:  96 Step:   453 /   793 Train loss: 0.02673731\r\n",
      "Epoch:  96 Step:   454 /   793 Train loss: 0.01844212\r\n",
      "Epoch:  96 Step:   455 /   793 Train loss: 0.01873440\r\n",
      "Epoch:  96 Step:   456 /   793 Train loss: 0.01833013\r\n",
      "Epoch:  96 Step:   457 /   793 Train loss: 0.02065597\r\n",
      "Epoch:  96 Step:   458 /   793 Train loss: 0.02856637\r\n",
      "Epoch:  96 Step:   459 /   793 Train loss: 0.02018180\r\n",
      "Epoch:  96 Step:   460 /   793 Train loss: 0.02491043\r\n",
      "Epoch:  96 Step:   461 /   793 Train loss: 0.01781124\r\n",
      "Epoch:  96 Step:   462 /   793 Train loss: 0.02956538\r\n",
      "Epoch:  96 Step:   463 /   793 Train loss: 0.01880679\r\n",
      "Epoch:  96 Step:   464 /   793 Train loss: 0.02186864\r\n",
      "Epoch:  96 Step:   465 /   793 Train loss: 0.01818482\r\n",
      "Epoch:  96 Step:   466 /   793 Train loss: 0.02948127\r\n",
      "Epoch:  96 Step:   467 /   793 Train loss: 0.02793819\r\n",
      "Epoch:  96 Step:   468 /   793 Train loss: 0.01821778\r\n",
      "Epoch:  96 Step:   469 /   793 Train loss: 0.02261548\r\n",
      "Epoch:  96 Step:   470 /   793 Train loss: 0.01250215\r\n",
      "Epoch:  96 Step:   471 /   793 Train loss: 0.02542529\r\n",
      "Epoch:  96 Step:   472 /   793 Train loss: 0.03835728\r\n",
      "Epoch:  96 Step:   473 /   793 Train loss: 0.01965723\r\n",
      "Epoch:  96 Step:   474 /   793 Train loss: 0.02384531\r\n",
      "Epoch:  96 Step:   475 /   793 Train loss: 0.01887094\r\n",
      "Epoch:  96 Step:   476 /   793 Train loss: 0.03215774\r\n",
      "Epoch:  96 Step:   477 /   793 Train loss: 0.02936403\r\n",
      "Epoch:  96 Step:   478 /   793 Train loss: 0.02213775\r\n",
      "Epoch:  96 Step:   479 /   793 Train loss: 0.02181707\r\n",
      "Epoch:  96 Step:   480 /   793 Train loss: 0.02386515\r\n",
      "Epoch:  96 Step:   481 /   793 Train loss: 0.03628457\r\n",
      "Epoch:  96 Step:   482 /   793 Train loss: 0.03180344\r\n",
      "Epoch:  96 Step:   483 /   793 Train loss: 0.01226534\r\n",
      "Epoch:  96 Step:   484 /   793 Train loss: 0.01668197\r\n",
      "Epoch:  96 Step:   485 /   793 Train loss: 0.02635337\r\n",
      "Epoch:  96 Step:   486 /   793 Train loss: 0.01490588\r\n",
      "Epoch:  96 Step:   487 /   793 Train loss: 0.02421215\r\n",
      "Epoch:  96 Step:   488 /   793 Train loss: 0.03216422\r\n",
      "Epoch:  96 Step:   489 /   793 Train loss: 0.02396014\r\n",
      "Epoch:  96 Step:   490 /   793 Train loss: 0.03130617\r\n",
      "Epoch:  96 Step:   491 /   793 Train loss: 0.02569287\r\n",
      "Epoch:  96 Step:   492 /   793 Train loss: 0.03842255\r\n",
      "Epoch:  96 Step:   493 /   793 Train loss: 0.03020161\r\n",
      "Epoch:  96 Step:   494 /   793 Train loss: 0.01773167\r\n",
      "Epoch:  96 Step:   495 /   793 Train loss: 0.01112081\r\n",
      "Epoch:  96 Step:   496 /   793 Train loss: 0.02509842\r\n",
      "Epoch:  96 Step:   497 /   793 Train loss: 0.02674066\r\n",
      "Epoch:  96 Step:   498 /   793 Train loss: 0.03953993\r\n",
      "Epoch:  96 Step:   499 /   793 Train loss: 0.03010349\r\n",
      "Epoch:  96 Step:   500 /   793 Train loss: 0.01976490\r\n",
      "Epoch:  96 Step:   501 /   793 Train loss: 0.02218351\r\n",
      "Epoch:  96 Step:   502 /   793 Train loss: 0.02144404\r\n",
      "Epoch:  96 Step:   503 /   793 Train loss: 0.04200283\r\n",
      "Epoch:  96 Step:   504 /   793 Train loss: 0.03596655\r\n",
      "Epoch:  96 Step:   505 /   793 Train loss: 0.02336104\r\n",
      "Epoch:  96 Step:   506 /   793 Train loss: 0.01871028\r\n",
      "Epoch:  96 Step:   507 /   793 Train loss: 0.02320306\r\n",
      "Epoch:  96 Step:   508 /   793 Train loss: 0.01174410\r\n",
      "Epoch:  96 Step:   509 /   793 Train loss: 0.02121036\r\n",
      "Epoch:  96 Step:   510 /   793 Train loss: 0.02309977\r\n",
      "Epoch:  96 Step:   511 /   793 Train loss: 0.02013316\r\n",
      "Epoch:  96 Step:   512 /   793 Train loss: 0.01871817\r\n",
      "Epoch:  96 Step:   513 /   793 Train loss: 0.02986609\r\n",
      "Epoch:  96 Step:   514 /   793 Train loss: 0.01263682\r\n",
      "Epoch:  96 Step:   515 /   793 Train loss: 0.02935216\r\n",
      "Epoch:  96 Step:   516 /   793 Train loss: 0.02441752\r\n",
      "Epoch:  96 Step:   517 /   793 Train loss: 0.03317526\r\n",
      "Epoch:  96 Step:   518 /   793 Train loss: 0.03389394\r\n",
      "Epoch:  96 Step:   519 /   793 Train loss: 0.03349941\r\n",
      "Epoch:  96 Step:   520 /   793 Train loss: 0.02547868\r\n",
      "Epoch:  96 Step:   521 /   793 Train loss: 0.02197726\r\n",
      "Epoch:  96 Step:   522 /   793 Train loss: 0.01874246\r\n",
      "Epoch:  96 Step:   523 /   793 Train loss: 0.01980629\r\n",
      "Epoch:  96 Step:   524 /   793 Train loss: 0.02938321\r\n",
      "Epoch:  96 Step:   525 /   793 Train loss: 0.02020265\r\n",
      "Epoch:  96 Step:   526 /   793 Train loss: 0.02658288\r\n",
      "Epoch:  96 Step:   527 /   793 Train loss: 0.02851818\r\n",
      "Epoch:  96 Step:   528 /   793 Train loss: 0.02097842\r\n",
      "Epoch:  96 Step:   529 /   793 Train loss: 0.02770286\r\n",
      "Epoch:  96 Step:   530 /   793 Train loss: 0.03102206\r\n",
      "Epoch:  96 Step:   531 /   793 Train loss: 0.03009179\r\n",
      "Epoch:  96 Step:   532 /   793 Train loss: 0.04935249\r\n",
      "Epoch:  96 Step:   533 /   793 Train loss: 0.03848378\r\n",
      "Epoch:  96 Step:   534 /   793 Train loss: 0.03030035\r\n",
      "Epoch:  96 Step:   535 /   793 Train loss: 0.02719707\r\n",
      "Epoch:  96 Step:   536 /   793 Train loss: 0.02741976\r\n",
      "Epoch:  96 Step:   537 /   793 Train loss: 0.02191374\r\n",
      "Epoch:  96 Step:   538 /   793 Train loss: 0.01633937\r\n",
      "Epoch:  96 Step:   539 /   793 Train loss: 0.01888181\r\n",
      "Epoch:  96 Step:   540 /   793 Train loss: 0.02744960\r\n",
      "Epoch:  96 Step:   541 /   793 Train loss: 0.03036578\r\n",
      "Epoch:  96 Step:   542 /   793 Train loss: 0.02420279\r\n",
      "Epoch:  96 Step:   543 /   793 Train loss: 0.02434938\r\n",
      "Epoch:  96 Step:   544 /   793 Train loss: 0.02559439\r\n",
      "Epoch:  96 Step:   545 /   793 Train loss: 0.03420944\r\n",
      "Epoch:  96 Step:   546 /   793 Train loss: 0.03923286\r\n",
      "Epoch:  96 Step:   547 /   793 Train loss: 0.03401921\r\n",
      "Epoch:  96 Step:   548 /   793 Train loss: 0.01765175\r\n",
      "Epoch:  96 Step:   549 /   793 Train loss: 0.01223279\r\n",
      "Epoch:  96 Step:   550 /   793 Train loss: 0.03343938\r\n",
      "Epoch:  96 Step:   551 /   793 Train loss: 0.02139856\r\n",
      "Epoch:  96 Step:   552 /   793 Train loss: 0.02061440\r\n",
      "Epoch:  96 Step:   553 /   793 Train loss: 0.01972928\r\n",
      "Epoch:  96 Step:   554 /   793 Train loss: 0.02503764\r\n",
      "Epoch:  96 Step:   555 /   793 Train loss: 0.02558399\r\n",
      "Epoch:  96 Step:   556 /   793 Train loss: 0.03171529\r\n",
      "Epoch:  96 Step:   557 /   793 Train loss: 0.04019345\r\n",
      "Epoch:  96 Step:   558 /   793 Train loss: 0.01841295\r\n",
      "Epoch:  96 Step:   559 /   793 Train loss: 0.02533465\r\n",
      "Epoch:  96 Step:   560 /   793 Train loss: 0.02320467\r\n",
      "Epoch:  96 Step:   561 /   793 Train loss: 0.02007535\r\n",
      "Epoch:  96 Step:   562 /   793 Train loss: 0.02224808\r\n",
      "Epoch:  96 Step:   563 /   793 Train loss: 0.02110696\r\n",
      "Epoch:  96 Step:   564 /   793 Train loss: 0.01550941\r\n",
      "Epoch:  96 Step:   565 /   793 Train loss: 0.02728246\r\n",
      "Epoch:  96 Step:   566 /   793 Train loss: 0.02393453\r\n",
      "Epoch:  96 Step:   567 /   793 Train loss: 0.01980147\r\n",
      "Epoch:  96 Step:   568 /   793 Train loss: 0.01665178\r\n",
      "Epoch:  96 Step:   569 /   793 Train loss: 0.01195856\r\n",
      "Epoch:  96 Step:   570 /   793 Train loss: 0.01611479\r\n",
      "Epoch:  96 Step:   571 /   793 Train loss: 0.02205790\r\n",
      "Epoch:  96 Step:   572 /   793 Train loss: 0.01977978\r\n",
      "Epoch:  96 Step:   573 /   793 Train loss: 0.02301004\r\n",
      "Epoch:  96 Step:   574 /   793 Train loss: 0.02746395\r\n",
      "Epoch:  96 Step:   575 /   793 Train loss: 0.01954593\r\n",
      "Epoch:  96 Step:   576 /   793 Train loss: 0.01811318\r\n",
      "Epoch:  96 Step:   577 /   793 Train loss: 0.02697273\r\n",
      "Epoch:  96 Step:   578 /   793 Train loss: 0.02194754\r\n",
      "Epoch:  96 Step:   579 /   793 Train loss: 0.02499529\r\n",
      "Epoch:  96 Step:   580 /   793 Train loss: 0.03298919\r\n",
      "Epoch:  96 Step:   581 /   793 Train loss: 0.02106635\r\n",
      "Epoch:  96 Step:   582 /   793 Train loss: 0.02180175\r\n",
      "Epoch:  96 Step:   583 /   793 Train loss: 0.03178136\r\n",
      "Epoch:  96 Step:   584 /   793 Train loss: 0.01657598\r\n",
      "Epoch:  96 Step:   585 /   793 Train loss: 0.02242326\r\n",
      "Epoch:  96 Step:   586 /   793 Train loss: 0.01593674\r\n",
      "Epoch:  96 Step:   587 /   793 Train loss: 0.01887602\r\n",
      "Epoch:  96 Step:   588 /   793 Train loss: 0.02343908\r\n",
      "Epoch:  96 Step:   589 /   793 Train loss: 0.01808406\r\n",
      "Epoch:  96 Step:   590 /   793 Train loss: 0.02144844\r\n",
      "Epoch:  96 Step:   591 /   793 Train loss: 0.02893893\r\n",
      "Epoch:  96 Step:   592 /   793 Train loss: 0.02679812\r\n",
      "Epoch:  96 Step:   593 /   793 Train loss: 0.02501815\r\n",
      "Epoch:  96 Step:   594 /   793 Train loss: 0.02879071\r\n",
      "Epoch:  96 Step:   595 /   793 Train loss: 0.02518626\r\n",
      "Epoch:  96 Step:   596 /   793 Train loss: 0.02918574\r\n",
      "Epoch:  96 Step:   597 /   793 Train loss: 0.02360224\r\n",
      "Epoch:  96 Step:   598 /   793 Train loss: 0.01754719\r\n",
      "Epoch:  96 Step:   599 /   793 Train loss: 0.03316916\r\n",
      "Epoch:  96 Step:   600 /   793 Train loss: 0.01638428\r\n",
      "Epoch:  96 Step:   601 /   793 Train loss: 0.02488856\r\n",
      "Epoch:  96 Step:   602 /   793 Train loss: 0.02407475\r\n",
      "Epoch:  96 Step:   603 /   793 Train loss: 0.03805279\r\n",
      "Epoch:  96 Step:   604 /   793 Train loss: 0.02107166\r\n",
      "Epoch:  96 Step:   605 /   793 Train loss: 0.02129868\r\n",
      "Epoch:  96 Step:   606 /   793 Train loss: 0.02610329\r\n",
      "Epoch:  96 Step:   607 /   793 Train loss: 0.02660278\r\n",
      "Epoch:  96 Step:   608 /   793 Train loss: 0.03238021\r\n",
      "Epoch:  96 Step:   609 /   793 Train loss: 0.02621347\r\n",
      "Epoch:  96 Step:   610 /   793 Train loss: 0.02774533\r\n",
      "Epoch:  96 Step:   611 /   793 Train loss: 0.01896567\r\n",
      "Epoch:  96 Step:   612 /   793 Train loss: 0.02248676\r\n",
      "Epoch:  96 Step:   613 /   793 Train loss: 0.02771732\r\n",
      "Epoch:  96 Step:   614 /   793 Train loss: 0.02360898\r\n",
      "Epoch:  96 Step:   615 /   793 Train loss: 0.02445516\r\n",
      "Epoch:  96 Step:   616 /   793 Train loss: 0.02812482\r\n",
      "Epoch:  96 Step:   617 /   793 Train loss: 0.03026042\r\n",
      "Epoch:  96 Step:   618 /   793 Train loss: 0.03703709\r\n",
      "Epoch:  96 Step:   619 /   793 Train loss: 0.01663482\r\n",
      "Epoch:  96 Step:   620 /   793 Train loss: 0.02235330\r\n",
      "Epoch:  96 Step:   621 /   793 Train loss: 0.03616117\r\n",
      "Epoch:  96 Step:   622 /   793 Train loss: 0.01656247\r\n",
      "Epoch:  96 Step:   623 /   793 Train loss: 0.02448997\r\n",
      "Epoch:  96 Step:   624 /   793 Train loss: 0.02622046\r\n",
      "Epoch:  96 Step:   625 /   793 Train loss: 0.02426434\r\n",
      "Epoch:  96 Step:   626 /   793 Train loss: 0.01816084\r\n",
      "Epoch:  96 Step:   627 /   793 Train loss: 0.01883833\r\n",
      "Epoch:  96 Step:   628 /   793 Train loss: 0.02646347\r\n",
      "Epoch:  96 Step:   629 /   793 Train loss: 0.02875217\r\n",
      "Epoch:  96 Step:   630 /   793 Train loss: 0.02985757\r\n",
      "Epoch:  96 Step:   631 /   793 Train loss: 0.03065418\r\n",
      "Epoch:  96 Step:   632 /   793 Train loss: 0.01643015\r\n",
      "Epoch:  96 Step:   633 /   793 Train loss: 0.02098067\r\n",
      "Epoch:  96 Step:   634 /   793 Train loss: 0.01815832\r\n",
      "Epoch:  96 Step:   635 /   793 Train loss: 0.01836312\r\n",
      "Epoch:  96 Step:   636 /   793 Train loss: 0.02514419\r\n",
      "Epoch:  96 Step:   637 /   793 Train loss: 0.03022742\r\n",
      "Epoch:  96 Step:   638 /   793 Train loss: 0.02121545\r\n",
      "Epoch:  96 Step:   639 /   793 Train loss: 0.02224965\r\n",
      "Epoch:  96 Step:   640 /   793 Train loss: 0.02106929\r\n",
      "Epoch:  96 Step:   641 /   793 Train loss: 0.04017024\r\n",
      "Epoch:  96 Step:   642 /   793 Train loss: 0.02669135\r\n",
      "Epoch:  96 Step:   643 /   793 Train loss: 0.02800711\r\n",
      "Epoch:  96 Step:   644 /   793 Train loss: 0.00923603\r\n",
      "Epoch:  96 Step:   645 /   793 Train loss: 0.02462290\r\n",
      "Epoch:  96 Step:   646 /   793 Train loss: 0.02689703\r\n",
      "Epoch:  96 Step:   647 /   793 Train loss: 0.01923893\r\n",
      "Epoch:  96 Step:   648 /   793 Train loss: 0.02095246\r\n",
      "Epoch:  96 Step:   649 /   793 Train loss: 0.02718416\r\n",
      "Epoch:  96 Step:   650 /   793 Train loss: 0.01806055\r\n",
      "Epoch:  96 Step:   651 /   793 Train loss: 0.03545167\r\n",
      "Epoch:  96 Step:   652 /   793 Train loss: 0.01982043\r\n",
      "Epoch:  96 Step:   653 /   793 Train loss: 0.01983213\r\n",
      "Epoch:  96 Step:   654 /   793 Train loss: 0.03658217\r\n",
      "Epoch:  96 Step:   655 /   793 Train loss: 0.01690701\r\n",
      "Epoch:  96 Step:   656 /   793 Train loss: 0.03884378\r\n",
      "Epoch:  96 Step:   657 /   793 Train loss: 0.03373551\r\n",
      "Epoch:  96 Step:   658 /   793 Train loss: 0.02101877\r\n",
      "Epoch:  96 Step:   659 /   793 Train loss: 0.01011799\r\n",
      "Epoch:  96 Step:   660 /   793 Train loss: 0.03272040\r\n",
      "Epoch:  96 Step:   661 /   793 Train loss: 0.02184612\r\n",
      "Epoch:  96 Step:   662 /   793 Train loss: 0.02961053\r\n",
      "Epoch:  96 Step:   663 /   793 Train loss: 0.03268452\r\n",
      "Epoch:  96 Step:   664 /   793 Train loss: 0.02714783\r\n",
      "Epoch:  96 Step:   665 /   793 Train loss: 0.01569645\r\n",
      "Epoch:  96 Step:   666 /   793 Train loss: 0.02243424\r\n",
      "Epoch:  96 Step:   667 /   793 Train loss: 0.02875520\r\n",
      "Epoch:  96 Step:   668 /   793 Train loss: 0.02636173\r\n",
      "Epoch:  96 Step:   669 /   793 Train loss: 0.02074039\r\n",
      "Epoch:  96 Step:   670 /   793 Train loss: 0.01457586\r\n",
      "Epoch:  96 Step:   671 /   793 Train loss: 0.02682213\r\n",
      "Epoch:  96 Step:   672 /   793 Train loss: 0.03101281\r\n",
      "Epoch:  96 Step:   673 /   793 Train loss: 0.02831931\r\n",
      "Epoch:  96 Step:   674 /   793 Train loss: 0.02955511\r\n",
      "Epoch:  96 Step:   675 /   793 Train loss: 0.02034218\r\n",
      "Epoch:  96 Step:   676 /   793 Train loss: 0.02499053\r\n",
      "Epoch:  96 Step:   677 /   793 Train loss: 0.02734982\r\n",
      "Epoch:  96 Step:   678 /   793 Train loss: 0.02763962\r\n",
      "Epoch:  96 Step:   679 /   793 Train loss: 0.02816578\r\n",
      "Epoch:  96 Step:   680 /   793 Train loss: 0.01646355\r\n",
      "Epoch:  96 Step:   681 /   793 Train loss: 0.01509088\r\n",
      "Epoch:  96 Step:   682 /   793 Train loss: 0.02789180\r\n",
      "Epoch:  96 Step:   683 /   793 Train loss: 0.02308992\r\n",
      "Epoch:  96 Step:   684 /   793 Train loss: 0.02219249\r\n",
      "Epoch:  96 Step:   685 /   793 Train loss: 0.03633519\r\n",
      "Epoch:  96 Step:   686 /   793 Train loss: 0.02443839\r\n",
      "Epoch:  96 Step:   687 /   793 Train loss: 0.02979887\r\n",
      "Epoch:  96 Step:   688 /   793 Train loss: 0.03393477\r\n",
      "Epoch:  96 Step:   689 /   793 Train loss: 0.02424642\r\n",
      "Epoch:  96 Step:   690 /   793 Train loss: 0.03311716\r\n",
      "Epoch:  96 Step:   691 /   793 Train loss: 0.02650958\r\n",
      "Epoch:  96 Step:   692 /   793 Train loss: 0.02400190\r\n",
      "Epoch:  96 Step:   693 /   793 Train loss: 0.01951398\r\n",
      "Epoch:  96 Step:   694 /   793 Train loss: 0.01894087\r\n",
      "Epoch:  96 Step:   695 /   793 Train loss: 0.02613593\r\n",
      "Epoch:  96 Step:   696 /   793 Train loss: 0.02055886\r\n",
      "Epoch:  96 Step:   697 /   793 Train loss: 0.02499174\r\n",
      "Epoch:  96 Step:   698 /   793 Train loss: 0.01892125\r\n",
      "Epoch:  96 Step:   699 /   793 Train loss: 0.01637106\r\n",
      "Epoch:  96 Step:   700 /   793 Train loss: 0.02060538\r\n",
      "Epoch:  96 Step:   701 /   793 Train loss: 0.01679797\r\n",
      "Epoch:  96 Step:   702 /   793 Train loss: 0.01707479\r\n",
      "Epoch:  96 Step:   703 /   793 Train loss: 0.03268188\r\n",
      "Epoch:  96 Step:   704 /   793 Train loss: 0.04015740\r\n",
      "Epoch:  96 Step:   705 /   793 Train loss: 0.02336811\r\n",
      "Epoch:  96 Step:   706 /   793 Train loss: 0.03097912\r\n",
      "Epoch:  96 Step:   707 /   793 Train loss: 0.02316054\r\n",
      "Epoch:  96 Step:   708 /   793 Train loss: 0.02578104\r\n",
      "Epoch:  96 Step:   709 /   793 Train loss: 0.02652198\r\n",
      "Epoch:  96 Step:   710 /   793 Train loss: 0.03205749\r\n",
      "Epoch:  96 Step:   711 /   793 Train loss: 0.02107699\r\n",
      "Epoch:  96 Step:   712 /   793 Train loss: 0.02198136\r\n",
      "Epoch:  96 Step:   713 /   793 Train loss: 0.01659061\r\n",
      "Epoch:  96 Step:   714 /   793 Train loss: 0.02544064\r\n",
      "Epoch:  96 Step:   715 /   793 Train loss: 0.01762049\r\n",
      "Epoch:  96 Step:   716 /   793 Train loss: 0.03624434\r\n",
      "Epoch:  96 Step:   717 /   793 Train loss: 0.02403584\r\n",
      "Epoch:  96 Step:   718 /   793 Train loss: 0.01969740\r\n",
      "Epoch:  96 Step:   719 /   793 Train loss: 0.02215547\r\n",
      "Epoch:  96 Step:   720 /   793 Train loss: 0.02440659\r\n",
      "Epoch:  96 Step:   721 /   793 Train loss: 0.01320040\r\n",
      "Epoch:  96 Step:   722 /   793 Train loss: 0.01881508\r\n",
      "Epoch:  96 Step:   723 /   793 Train loss: 0.03169912\r\n",
      "Epoch:  96 Step:   724 /   793 Train loss: 0.01514420\r\n",
      "Epoch:  96 Step:   725 /   793 Train loss: 0.02493181\r\n",
      "Epoch:  96 Step:   726 /   793 Train loss: 0.03344476\r\n",
      "Epoch:  96 Step:   727 /   793 Train loss: 0.01807158\r\n",
      "Epoch:  96 Step:   728 /   793 Train loss: 0.01516773\r\n",
      "Epoch:  96 Step:   729 /   793 Train loss: 0.02231590\r\n",
      "Epoch:  96 Step:   730 /   793 Train loss: 0.02679008\r\n",
      "Epoch:  96 Step:   731 /   793 Train loss: 0.01868872\r\n",
      "Epoch:  96 Step:   732 /   793 Train loss: 0.02267660\r\n",
      "Epoch:  96 Step:   733 /   793 Train loss: 0.02548461\r\n",
      "Epoch:  96 Step:   734 /   793 Train loss: 0.01700521\r\n",
      "Epoch:  96 Step:   735 /   793 Train loss: 0.01566223\r\n",
      "Epoch:  96 Step:   736 /   793 Train loss: 0.02148161\r\n",
      "Epoch:  96 Step:   737 /   793 Train loss: 0.03068566\r\n",
      "Epoch:  96 Step:   738 /   793 Train loss: 0.02747238\r\n",
      "Epoch:  96 Step:   739 /   793 Train loss: 0.01393632\r\n",
      "Epoch:  96 Step:   740 /   793 Train loss: 0.03345137\r\n",
      "Epoch:  96 Step:   741 /   793 Train loss: 0.02248911\r\n",
      "Epoch:  96 Step:   742 /   793 Train loss: 0.02369988\r\n",
      "Epoch:  96 Step:   743 /   793 Train loss: 0.02218541\r\n",
      "Epoch:  96 Step:   744 /   793 Train loss: 0.02416903\r\n",
      "Epoch:  96 Step:   745 /   793 Train loss: 0.01953567\r\n",
      "Epoch:  96 Step:   746 /   793 Train loss: 0.02253846\r\n",
      "Epoch:  96 Step:   747 /   793 Train loss: 0.01788702\r\n",
      "Epoch:  96 Step:   748 /   793 Train loss: 0.02482484\r\n",
      "Epoch:  96 Step:   749 /   793 Train loss: 0.03738071\r\n",
      "Epoch:  96 Step:   750 /   793 Train loss: 0.01873522\r\n",
      "Epoch:  96 Step:   751 /   793 Train loss: 0.01822705\r\n",
      "Epoch:  96 Step:   752 /   793 Train loss: 0.01969649\r\n",
      "Epoch:  96 Step:   753 /   793 Train loss: 0.02421527\r\n",
      "Epoch:  96 Step:   754 /   793 Train loss: 0.03074896\r\n",
      "Epoch:  96 Step:   755 /   793 Train loss: 0.01526644\r\n",
      "Epoch:  96 Step:   756 /   793 Train loss: 0.01581044\r\n",
      "Epoch:  96 Step:   757 /   793 Train loss: 0.02765407\r\n",
      "Epoch:  96 Step:   758 /   793 Train loss: 0.01916042\r\n",
      "Epoch:  96 Step:   759 /   793 Train loss: 0.02650212\r\n",
      "Epoch:  96 Step:   760 /   793 Train loss: 0.02476900\r\n",
      "Epoch:  96 Step:   761 /   793 Train loss: 0.02968735\r\n",
      "Epoch:  96 Step:   762 /   793 Train loss: 0.01355876\r\n",
      "Epoch:  96 Step:   763 /   793 Train loss: 0.02500119\r\n",
      "Epoch:  96 Step:   764 /   793 Train loss: 0.02155134\r\n",
      "Epoch:  96 Step:   765 /   793 Train loss: 0.02210957\r\n",
      "Epoch:  96 Step:   766 /   793 Train loss: 0.02213925\r\n",
      "Epoch:  96 Step:   767 /   793 Train loss: 0.02663219\r\n",
      "Epoch:  96 Step:   768 /   793 Train loss: 0.01833955\r\n",
      "Epoch:  96 Step:   769 /   793 Train loss: 0.03600349\r\n",
      "Epoch:  96 Step:   770 /   793 Train loss: 0.02206386\r\n",
      "Epoch:  96 Step:   771 /   793 Train loss: 0.02216753\r\n",
      "Epoch:  96 Step:   772 /   793 Train loss: 0.02417191\r\n",
      "Epoch:  96 Step:   773 /   793 Train loss: 0.01153000\r\n",
      "Epoch:  96 Step:   774 /   793 Train loss: 0.02417683\r\n",
      "Epoch:  96 Step:   775 /   793 Train loss: 0.01620017\r\n",
      "Epoch:  96 Step:   776 /   793 Train loss: 0.02149429\r\n",
      "Epoch:  96 Step:   777 /   793 Train loss: 0.03093499\r\n",
      "Epoch:  96 Step:   778 /   793 Train loss: 0.02675741\r\n",
      "Epoch:  96 Step:   779 /   793 Train loss: 0.01382977\r\n",
      "Epoch:  96 Step:   780 /   793 Train loss: 0.02246357\r\n",
      "Epoch:  96 Step:   781 /   793 Train loss: 0.02272398\r\n",
      "Epoch:  96 Step:   782 /   793 Train loss: 0.03090639\r\n",
      "Epoch:  96 Step:   783 /   793 Train loss: 0.02825107\r\n",
      "Epoch:  96 Step:   784 /   793 Train loss: 0.03187254\r\n",
      "Epoch:  96 Step:   785 /   793 Train loss: 0.02977795\r\n",
      "Epoch:  96 Step:   786 /   793 Train loss: 0.01910674\r\n",
      "Epoch:  96 Step:   787 /   793 Train loss: 0.02424925\r\n",
      "Epoch:  96 Step:   788 /   793 Train loss: 0.01973466\r\n",
      "Epoch:  96 Step:   789 /   793 Train loss: 0.02356837\r\n",
      "Epoch:  96 Step:   790 /   793 Train loss: 0.01596841\r\n",
      "Epoch:  96 Step:   791 /   793 Train loss: 0.01667465\r\n",
      "Epoch:  96 Step:   792 /   793 Train loss: 0.01676720\r\n",
      "Epoch:  97 Step:     0 /   793 Train loss: 0.02150712\r\n",
      "Epoch:  97 Step:     1 /   793 Train loss: 0.01390282\r\n",
      "Epoch:  97 Step:     2 /   793 Train loss: 0.03627665\r\n",
      "Epoch:  97 Step:     3 /   793 Train loss: 0.01000100\r\n",
      "Epoch:  97 Step:     4 /   793 Train loss: 0.02299181\r\n",
      "Epoch:  97 Step:     5 /   793 Train loss: 0.03456306\r\n",
      "Epoch:  97 Step:     6 /   793 Train loss: 0.01593695\r\n",
      "Epoch:  97 Step:     7 /   793 Train loss: 0.01634542\r\n",
      "Epoch:  97 Step:     8 /   793 Train loss: 0.02773361\r\n",
      "Epoch:  97 Step:     9 /   793 Train loss: 0.03057880\r\n",
      "Epoch:  97 Step:    10 /   793 Train loss: 0.03022711\r\n",
      "Epoch:  97 Step:    11 /   793 Train loss: 0.01710528\r\n",
      "Epoch:  97 Step:    12 /   793 Train loss: 0.02848742\r\n",
      "Epoch:  97 Step:    13 /   793 Train loss: 0.01457145\r\n",
      "Epoch:  97 Step:    14 /   793 Train loss: 0.02196469\r\n",
      "Epoch:  97 Step:    15 /   793 Train loss: 0.01845037\r\n",
      "Epoch:  97 Step:    16 /   793 Train loss: 0.02733658\r\n",
      "Epoch:  97 Step:    17 /   793 Train loss: 0.01750538\r\n",
      "Epoch:  97 Step:    18 /   793 Train loss: 0.02535108\r\n",
      "Epoch:  97 Step:    19 /   793 Train loss: 0.02204866\r\n",
      "Epoch:  97 Step:    20 /   793 Train loss: 0.01419032\r\n",
      "Epoch:  97 Step:    21 /   793 Train loss: 0.02554394\r\n",
      "Epoch:  97 Step:    22 /   793 Train loss: 0.01950606\r\n",
      "Epoch:  97 Step:    23 /   793 Train loss: 0.02802143\r\n",
      "Epoch:  97 Step:    24 /   793 Train loss: 0.04186819\r\n",
      "Epoch:  97 Step:    25 /   793 Train loss: 0.02345544\r\n",
      "Epoch:  97 Step:    26 /   793 Train loss: 0.02151316\r\n",
      "Epoch:  97 Step:    27 /   793 Train loss: 0.01776809\r\n",
      "Epoch:  97 Step:    28 /   793 Train loss: 0.01629047\r\n",
      "Epoch:  97 Step:    29 /   793 Train loss: 0.02219279\r\n",
      "Epoch:  97 Step:    30 /   793 Train loss: 0.02215579\r\n",
      "Epoch:  97 Step:    31 /   793 Train loss: 0.02798768\r\n",
      "Epoch:  97 Step:    32 /   793 Train loss: 0.02805051\r\n",
      "Epoch:  97 Step:    33 /   793 Train loss: 0.02443604\r\n",
      "Epoch:  97 Step:    34 /   793 Train loss: 0.02081792\r\n",
      "Epoch:  97 Step:    35 /   793 Train loss: 0.03253464\r\n",
      "Epoch:  97 Step:    36 /   793 Train loss: 0.02386153\r\n",
      "Epoch:  97 Step:    37 /   793 Train loss: 0.02325822\r\n",
      "Epoch:  97 Step:    38 /   793 Train loss: 0.01127490\r\n",
      "Epoch:  97 Step:    39 /   793 Train loss: 0.03564587\r\n",
      "Epoch:  97 Step:    40 /   793 Train loss: 0.03621567\r\n",
      "Epoch:  97 Step:    41 /   793 Train loss: 0.01592264\r\n",
      "Epoch:  97 Step:    42 /   793 Train loss: 0.03013282\r\n",
      "Epoch:  97 Step:    43 /   793 Train loss: 0.02692639\r\n",
      "Epoch:  97 Step:    44 /   793 Train loss: 0.02658037\r\n",
      "Epoch:  97 Step:    45 /   793 Train loss: 0.01711291\r\n",
      "Epoch:  97 Step:    46 /   793 Train loss: 0.02920951\r\n",
      "Epoch:  97 Step:    47 /   793 Train loss: 0.03019827\r\n",
      "Epoch:  97 Step:    48 /   793 Train loss: 0.02289421\r\n",
      "Epoch:  97 Step:    49 /   793 Train loss: 0.02547491\r\n",
      "Epoch:  97 Step:    50 /   793 Train loss: 0.02931339\r\n",
      "Epoch:  97 Step:    51 /   793 Train loss: 0.03599102\r\n",
      "Epoch:  97 Step:    52 /   793 Train loss: 0.02943872\r\n",
      "Epoch:  97 Step:    53 /   793 Train loss: 0.02163909\r\n",
      "Epoch:  97 Step:    54 /   793 Train loss: 0.02482639\r\n",
      "Epoch:  97 Step:    55 /   793 Train loss: 0.02135551\r\n",
      "Epoch:  97 Step:    56 /   793 Train loss: 0.01944656\r\n",
      "Epoch:  97 Step:    57 /   793 Train loss: 0.00949570\r\n",
      "Epoch:  97 Step:    58 /   793 Train loss: 0.03329491\r\n",
      "Epoch:  97 Step:    59 /   793 Train loss: 0.01703643\r\n",
      "Epoch:  97 Step:    60 /   793 Train loss: 0.02668562\r\n",
      "Epoch:  97 Step:    61 /   793 Train loss: 0.02079974\r\n",
      "Epoch:  97 Step:    62 /   793 Train loss: 0.01913592\r\n",
      "Epoch:  97 Step:    63 /   793 Train loss: 0.03081905\r\n",
      "Epoch:  97 Step:    64 /   793 Train loss: 0.02717807\r\n",
      "Epoch:  97 Step:    65 /   793 Train loss: 0.03226438\r\n",
      "Epoch:  97 Step:    66 /   793 Train loss: 0.02193300\r\n",
      "Epoch:  97 Step:    67 /   793 Train loss: 0.01537828\r\n",
      "Epoch:  97 Step:    68 /   793 Train loss: 0.01278882\r\n",
      "Epoch:  97 Step:    69 /   793 Train loss: 0.02512697\r\n",
      "Epoch:  97 Step:    70 /   793 Train loss: 0.02085470\r\n",
      "Epoch:  97 Step:    71 /   793 Train loss: 0.01074796\r\n",
      "Epoch:  97 Step:    72 /   793 Train loss: 0.01920783\r\n",
      "Epoch:  97 Step:    73 /   793 Train loss: 0.02069149\r\n",
      "Epoch:  97 Step:    74 /   793 Train loss: 0.01898481\r\n",
      "Epoch:  97 Step:    75 /   793 Train loss: 0.03181503\r\n",
      "Epoch:  97 Step:    76 /   793 Train loss: 0.01956471\r\n",
      "Epoch:  97 Step:    77 /   793 Train loss: 0.01875884\r\n",
      "Epoch:  97 Step:    78 /   793 Train loss: 0.01615712\r\n",
      "Epoch:  97 Step:    79 /   793 Train loss: 0.01931828\r\n",
      "Epoch:  97 Step:    80 /   793 Train loss: 0.02631896\r\n",
      "Epoch:  97 Step:    81 /   793 Train loss: 0.03476848\r\n",
      "Epoch:  97 Step:    82 /   793 Train loss: 0.02001397\r\n",
      "Epoch:  97 Step:    83 /   793 Train loss: 0.02512905\r\n",
      "Epoch:  97 Step:    84 /   793 Train loss: 0.02758501\r\n",
      "Epoch:  97 Step:    85 /   793 Train loss: 0.03804795\r\n",
      "Epoch:  97 Step:    86 /   793 Train loss: 0.02306166\r\n",
      "Epoch:  97 Step:    87 /   793 Train loss: 0.02625200\r\n",
      "Epoch:  97 Step:    88 /   793 Train loss: 0.02378535\r\n",
      "Epoch:  97 Step:    89 /   793 Train loss: 0.01679702\r\n",
      "Epoch:  97 Step:    90 /   793 Train loss: 0.01943897\r\n",
      "Epoch:  97 Step:    91 /   793 Train loss: 0.03371628\r\n",
      "Epoch:  97 Step:    92 /   793 Train loss: 0.02062545\r\n",
      "Epoch:  97 Step:    93 /   793 Train loss: 0.02968625\r\n",
      "Epoch:  97 Step:    94 /   793 Train loss: 0.03142732\r\n",
      "Epoch:  97 Step:    95 /   793 Train loss: 0.02639934\r\n",
      "Epoch:  97 Step:    96 /   793 Train loss: 0.01613059\r\n",
      "Epoch:  97 Step:    97 /   793 Train loss: 0.02827229\r\n",
      "Epoch:  97 Step:    98 /   793 Train loss: 0.02337989\r\n",
      "Epoch:  97 Step:    99 /   793 Train loss: 0.03666974\r\n",
      "Epoch:  97 Step:   100 /   793 Train loss: 0.02538951\r\n",
      "Epoch:  97 Step:   101 /   793 Train loss: 0.02505775\r\n",
      "Epoch:  97 Step:   102 /   793 Train loss: 0.03228734\r\n",
      "Epoch:  97 Step:   103 /   793 Train loss: 0.02848509\r\n",
      "Epoch:  97 Step:   104 /   793 Train loss: 0.01686676\r\n",
      "Epoch:  97 Step:   105 /   793 Train loss: 0.01684557\r\n",
      "Epoch:  97 Step:   106 /   793 Train loss: 0.02588815\r\n",
      "Epoch:  97 Step:   107 /   793 Train loss: 0.02628731\r\n",
      "Epoch:  97 Step:   108 /   793 Train loss: 0.01383569\r\n",
      "Epoch:  97 Step:   109 /   793 Train loss: 0.03005584\r\n",
      "Epoch:  97 Step:   110 /   793 Train loss: 0.01744454\r\n",
      "Epoch:  97 Step:   111 /   793 Train loss: 0.02676629\r\n",
      "Epoch:  97 Step:   112 /   793 Train loss: 0.01565712\r\n",
      "Epoch:  97 Step:   113 /   793 Train loss: 0.02109228\r\n",
      "Epoch:  97 Step:   114 /   793 Train loss: 0.02282411\r\n",
      "Epoch:  97 Step:   115 /   793 Train loss: 0.02507140\r\n",
      "Epoch:  97 Step:   116 /   793 Train loss: 0.01645878\r\n",
      "Epoch:  97 Step:   117 /   793 Train loss: 0.02401214\r\n",
      "Epoch:  97 Step:   118 /   793 Train loss: 0.02510816\r\n",
      "Epoch:  97 Step:   119 /   793 Train loss: 0.01963304\r\n",
      "Epoch:  97 Step:   120 /   793 Train loss: 0.02067178\r\n",
      "Epoch:  97 Step:   121 /   793 Train loss: 0.03181222\r\n",
      "Epoch:  97 Step:   122 /   793 Train loss: 0.03103620\r\n",
      "Epoch:  97 Step:   123 /   793 Train loss: 0.02841711\r\n",
      "Epoch:  97 Step:   124 /   793 Train loss: 0.02654070\r\n",
      "Epoch:  97 Step:   125 /   793 Train loss: 0.03464186\r\n",
      "Epoch:  97 Step:   126 /   793 Train loss: 0.02708834\r\n",
      "Epoch:  97 Step:   127 /   793 Train loss: 0.03624892\r\n",
      "Epoch:  97 Step:   128 /   793 Train loss: 0.02145262\r\n",
      "Epoch:  97 Step:   129 /   793 Train loss: 0.02953160\r\n",
      "Epoch:  97 Step:   130 /   793 Train loss: 0.01471500\r\n",
      "Epoch:  97 Step:   131 /   793 Train loss: 0.03263869\r\n",
      "Epoch:  97 Step:   132 /   793 Train loss: 0.01723320\r\n",
      "Epoch:  97 Step:   133 /   793 Train loss: 0.01477049\r\n",
      "Epoch:  97 Step:   134 /   793 Train loss: 0.02274439\r\n",
      "Epoch:  97 Step:   135 /   793 Train loss: 0.02592034\r\n",
      "Epoch:  97 Step:   136 /   793 Train loss: 0.01480253\r\n",
      "Epoch:  97 Step:   137 /   793 Train loss: 0.03060789\r\n",
      "Epoch:  97 Step:   138 /   793 Train loss: 0.01912649\r\n",
      "Epoch:  97 Step:   139 /   793 Train loss: 0.02182548\r\n",
      "Epoch:  97 Step:   140 /   793 Train loss: 0.02451753\r\n",
      "Epoch:  97 Step:   141 /   793 Train loss: 0.03022087\r\n",
      "Epoch:  97 Step:   142 /   793 Train loss: 0.02842201\r\n",
      "Epoch:  97 Step:   143 /   793 Train loss: 0.02284210\r\n",
      "Epoch:  97 Step:   144 /   793 Train loss: 0.01772617\r\n",
      "Epoch:  97 Step:   145 /   793 Train loss: 0.01843956\r\n",
      "Epoch:  97 Step:   146 /   793 Train loss: 0.02211461\r\n",
      "Epoch:  97 Step:   147 /   793 Train loss: 0.03035549\r\n",
      "Epoch:  97 Step:   148 /   793 Train loss: 0.01903751\r\n",
      "Epoch:  97 Step:   149 /   793 Train loss: 0.02291380\r\n",
      "Epoch:  97 Step:   150 /   793 Train loss: 0.01846245\r\n",
      "Epoch:  97 Step:   151 /   793 Train loss: 0.02110509\r\n",
      "Epoch:  97 Step:   152 /   793 Train loss: 0.03876851\r\n",
      "Epoch:  97 Step:   153 /   793 Train loss: 0.02515227\r\n",
      "Epoch:  97 Step:   154 /   793 Train loss: 0.01097018\r\n",
      "Epoch:  97 Step:   155 /   793 Train loss: 0.02311468\r\n",
      "Epoch:  97 Step:   156 /   793 Train loss: 0.02690075\r\n",
      "Epoch:  97 Step:   157 /   793 Train loss: 0.02235472\r\n",
      "Epoch:  97 Step:   158 /   793 Train loss: 0.01779366\r\n",
      "Epoch:  97 Step:   159 /   793 Train loss: 0.01685976\r\n",
      "Epoch:  97 Step:   160 /   793 Train loss: 0.01331097\r\n",
      "Epoch:  97 Step:   161 /   793 Train loss: 0.01934195\r\n",
      "Epoch:  97 Step:   162 /   793 Train loss: 0.02143911\r\n",
      "Epoch:  97 Step:   163 /   793 Train loss: 0.02114611\r\n",
      "Epoch:  97 Step:   164 /   793 Train loss: 0.03719023\r\n",
      "Epoch:  97 Step:   165 /   793 Train loss: 0.02528108\r\n",
      "Epoch:  97 Step:   166 /   793 Train loss: 0.02888330\r\n",
      "Epoch:  97 Step:   167 /   793 Train loss: 0.01122432\r\n",
      "Epoch:  97 Step:   168 /   793 Train loss: 0.03968903\r\n",
      "Epoch:  97 Step:   169 /   793 Train loss: 0.02516555\r\n",
      "Epoch:  97 Step:   170 /   793 Train loss: 0.02503197\r\n",
      "Epoch:  97 Step:   171 /   793 Train loss: 0.01278255\r\n",
      "Epoch:  97 Step:   172 /   793 Train loss: 0.02757916\r\n",
      "Epoch:  97 Step:   173 /   793 Train loss: 0.02439760\r\n",
      "Epoch:  97 Step:   174 /   793 Train loss: 0.01335933\r\n",
      "Epoch:  97 Step:   175 /   793 Train loss: 0.02295498\r\n",
      "Epoch:  97 Step:   176 /   793 Train loss: 0.01760651\r\n",
      "Epoch:  97 Step:   177 /   793 Train loss: 0.01804745\r\n",
      "Epoch:  97 Step:   178 /   793 Train loss: 0.02280848\r\n",
      "Epoch:  97 Step:   179 /   793 Train loss: 0.01471864\r\n",
      "Epoch:  97 Step:   180 /   793 Train loss: 0.02308057\r\n",
      "Epoch:  97 Step:   181 /   793 Train loss: 0.01903940\r\n",
      "Epoch:  97 Step:   182 /   793 Train loss: 0.02973651\r\n",
      "Epoch:  97 Step:   183 /   793 Train loss: 0.02368026\r\n",
      "Epoch:  97 Step:   184 /   793 Train loss: 0.02064266\r\n",
      "Epoch:  97 Step:   185 /   793 Train loss: 0.01665248\r\n",
      "Epoch:  97 Step:   186 /   793 Train loss: 0.02717989\r\n",
      "Epoch:  97 Step:   187 /   793 Train loss: 0.02470268\r\n",
      "Epoch:  97 Step:   188 /   793 Train loss: 0.02156384\r\n",
      "Epoch:  97 Step:   189 /   793 Train loss: 0.01944660\r\n",
      "Epoch:  97 Step:   190 /   793 Train loss: 0.02758876\r\n",
      "Epoch:  97 Step:   191 /   793 Train loss: 0.01571394\r\n",
      "Epoch:  97 Step:   192 /   793 Train loss: 0.02721735\r\n",
      "Epoch:  97 Step:   193 /   793 Train loss: 0.03331607\r\n",
      "Epoch:  97 Step:   194 /   793 Train loss: 0.02103909\r\n",
      "Epoch:  97 Step:   195 /   793 Train loss: 0.02600392\r\n",
      "Epoch:  97 Step:   196 /   793 Train loss: 0.03377944\r\n",
      "Epoch:  97 Step:   197 /   793 Train loss: 0.01140552\r\n",
      "Epoch:  97 Step:   198 /   793 Train loss: 0.01976704\r\n",
      "Epoch:  97 Step:   199 /   793 Train loss: 0.01804693\r\n",
      "Epoch:  97 Step:   200 /   793 Train loss: 0.02079695\r\n",
      "Epoch:  97 Step:   201 /   793 Train loss: 0.01395747\r\n",
      "Epoch:  97 Step:   202 /   793 Train loss: 0.03082368\r\n",
      "Epoch:  97 Step:   203 /   793 Train loss: 0.02764971\r\n",
      "Epoch:  97 Step:   204 /   793 Train loss: 0.02079355\r\n",
      "Epoch:  97 Step:   205 /   793 Train loss: 0.02954509\r\n",
      "Epoch:  97 Step:   206 /   793 Train loss: 0.01514025\r\n",
      "Epoch:  97 Step:   207 /   793 Train loss: 0.03350298\r\n",
      "Epoch:  97 Step:   208 /   793 Train loss: 0.01472884\r\n",
      "Epoch:  97 Step:   209 /   793 Train loss: 0.02651578\r\n",
      "Epoch:  97 Step:   210 /   793 Train loss: 0.01833534\r\n",
      "Epoch:  97 Step:   211 /   793 Train loss: 0.01476339\r\n",
      "Epoch:  97 Step:   212 /   793 Train loss: 0.03817976\r\n",
      "Epoch:  97 Step:   213 /   793 Train loss: 0.02814759\r\n",
      "Epoch:  97 Step:   214 /   793 Train loss: 0.01892913\r\n",
      "Epoch:  97 Step:   215 /   793 Train loss: 0.02256532\r\n",
      "Epoch:  97 Step:   216 /   793 Train loss: 0.03614789\r\n",
      "Epoch:  97 Step:   217 /   793 Train loss: 0.02263354\r\n",
      "Epoch:  97 Step:   218 /   793 Train loss: 0.03059690\r\n",
      "Epoch:  97 Step:   219 /   793 Train loss: 0.01499092\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  97 Step:   220 /   793 Train loss: 0.01708608\r\n",
      "Epoch:  97 Step:   221 /   793 Train loss: 0.01781963\r\n",
      "Epoch:  97 Step:   222 /   793 Train loss: 0.04684637\r\n",
      "Epoch:  97 Step:   223 /   793 Train loss: 0.03318256\r\n",
      "Epoch:  97 Step:   224 /   793 Train loss: 0.03516324\r\n",
      "Epoch:  97 Step:   225 /   793 Train loss: 0.02502260\r\n",
      "Epoch:  97 Step:   226 /   793 Train loss: 0.03149763\r\n",
      "Epoch:  97 Step:   227 /   793 Train loss: 0.03626688\r\n",
      "Epoch:  97 Step:   228 /   793 Train loss: 0.02498737\r\n",
      "Epoch:  97 Step:   229 /   793 Train loss: 0.01796418\r\n",
      "Epoch:  97 Step:   230 /   793 Train loss: 0.02209440\r\n",
      "Epoch:  97 Step:   231 /   793 Train loss: 0.02493698\r\n",
      "Epoch:  97 Step:   232 /   793 Train loss: 0.03555214\r\n",
      "Epoch:  97 Step:   233 /   793 Train loss: 0.03051818\r\n",
      "Epoch:  97 Step:   234 /   793 Train loss: 0.01291744\r\n",
      "Epoch:  97 Step:   235 /   793 Train loss: 0.02399740\r\n",
      "Epoch:  97 Step:   236 /   793 Train loss: 0.03602898\r\n",
      "Epoch:  97 Step:   237 /   793 Train loss: 0.03070796\r\n",
      "Epoch:  97 Step:   238 /   793 Train loss: 0.03127178\r\n",
      "Epoch:  97 Step:   239 /   793 Train loss: 0.02183493\r\n",
      "Epoch:  97 Step:   240 /   793 Train loss: 0.03473963\r\n",
      "Epoch:  97 Step:   241 /   793 Train loss: 0.02236552\r\n",
      "Epoch:  97 Step:   242 /   793 Train loss: 0.02404465\r\n",
      "Epoch:  97 Step:   243 /   793 Train loss: 0.02369834\r\n",
      "Epoch:  97 Step:   244 /   793 Train loss: 0.02834887\r\n",
      "Epoch:  97 Step:   245 /   793 Train loss: 0.03882879\r\n",
      "Epoch:  97 Step:   246 /   793 Train loss: 0.02784859\r\n",
      "Epoch:  97 Step:   247 /   793 Train loss: 0.02041365\r\n",
      "Epoch:  97 Step:   248 /   793 Train loss: 0.02173663\r\n",
      "Epoch:  97 Step:   249 /   793 Train loss: 0.02577925\r\n",
      "Epoch:  97 Step:   250 /   793 Train loss: 0.02718016\r\n",
      "Epoch:  97 Step:   251 /   793 Train loss: 0.02385503\r\n",
      "Epoch:  97 Step:   252 /   793 Train loss: 0.02216475\r\n",
      "Epoch:  97 Step:   253 /   793 Train loss: 0.01832448\r\n",
      "Epoch:  97 Step:   254 /   793 Train loss: 0.02197743\r\n",
      "Epoch:  97 Step:   255 /   793 Train loss: 0.03179429\r\n",
      "Epoch:  97 Step:   256 /   793 Train loss: 0.02659263\r\n",
      "Epoch:  97 Step:   257 /   793 Train loss: 0.03498176\r\n",
      "Epoch:  97 Step:   258 /   793 Train loss: 0.01929263\r\n",
      "Epoch:  97 Step:   259 /   793 Train loss: 0.02251316\r\n",
      "Epoch:  97 Step:   260 /   793 Train loss: 0.02309096\r\n",
      "Epoch:  97 Step:   261 /   793 Train loss: 0.02463201\r\n",
      "Epoch:  97 Step:   262 /   793 Train loss: 0.01916685\r\n",
      "Epoch:  97 Step:   263 /   793 Train loss: 0.02187660\r\n",
      "Epoch:  97 Step:   264 /   793 Train loss: 0.01406167\r\n",
      "Epoch:  97 Step:   265 /   793 Train loss: 0.02780630\r\n",
      "Epoch:  97 Step:   266 /   793 Train loss: 0.01930190\r\n",
      "Epoch:  97 Step:   267 /   793 Train loss: 0.02731765\r\n",
      "Epoch:  97 Step:   268 /   793 Train loss: 0.02009840\r\n",
      "Epoch:  97 Step:   269 /   793 Train loss: 0.01750201\r\n",
      "Epoch:  97 Step:   270 /   793 Train loss: 0.02615469\r\n",
      "Epoch:  97 Step:   271 /   793 Train loss: 0.02474980\r\n",
      "Epoch:  97 Step:   272 /   793 Train loss: 0.03042664\r\n",
      "Epoch:  97 Step:   273 /   793 Train loss: 0.02566358\r\n",
      "Epoch:  97 Step:   274 /   793 Train loss: 0.03703791\r\n",
      "Epoch:  97 Step:   275 /   793 Train loss: 0.02479148\r\n",
      "Epoch:  97 Step:   276 /   793 Train loss: 0.02174030\r\n",
      "Epoch:  97 Step:   277 /   793 Train loss: 0.02240643\r\n",
      "Epoch:  97 Step:   278 /   793 Train loss: 0.03238855\r\n",
      "Epoch:  97 Step:   279 /   793 Train loss: 0.02679781\r\n",
      "Epoch:  97 Step:   280 /   793 Train loss: 0.02551826\r\n",
      "Epoch:  97 Step:   281 /   793 Train loss: 0.01792505\r\n",
      "Epoch:  97 Step:   282 /   793 Train loss: 0.02833781\r\n",
      "Epoch:  97 Step:   283 /   793 Train loss: 0.01880538\r\n",
      "Epoch:  97 Step:   284 /   793 Train loss: 0.02683486\r\n",
      "Epoch:  97 Step:   285 /   793 Train loss: 0.02448482\r\n",
      "Epoch:  97 Step:   286 /   793 Train loss: 0.01653823\r\n",
      "Epoch:  97 Step:   287 /   793 Train loss: 0.01823330\r\n",
      "Epoch:  97 Step:   288 /   793 Train loss: 0.02400530\r\n",
      "Epoch:  97 Step:   289 /   793 Train loss: 0.02494765\r\n",
      "Epoch:  97 Step:   290 /   793 Train loss: 0.02856258\r\n",
      "Epoch:  97 Step:   291 /   793 Train loss: 0.02903466\r\n",
      "Epoch:  97 Step:   292 /   793 Train loss: 0.01689889\r\n",
      "Epoch:  97 Step:   293 /   793 Train loss: 0.01498237\r\n",
      "Epoch:  97 Step:   294 /   793 Train loss: 0.03112279\r\n",
      "Epoch:  97 Step:   295 /   793 Train loss: 0.03335056\r\n",
      "Epoch:  97 Step:   296 /   793 Train loss: 0.01437853\r\n",
      "Epoch:  97 Step:   297 /   793 Train loss: 0.04336020\r\n",
      "Epoch:  97 Step:   298 /   793 Train loss: 0.03798079\r\n",
      "Epoch:  97 Step:   299 /   793 Train loss: 0.03373129\r\n",
      "Epoch:  97 Step:   300 /   793 Train loss: 0.02380293\r\n",
      "Epoch:  97 Step:   301 /   793 Train loss: 0.02604940\r\n",
      "Epoch:  97 Step:   302 /   793 Train loss: 0.03389952\r\n",
      "Epoch:  97 Step:   303 /   793 Train loss: 0.02710586\r\n",
      "Epoch:  97 Step:   304 /   793 Train loss: 0.01357224\r\n",
      "Epoch:  97 Step:   305 /   793 Train loss: 0.02686975\r\n",
      "Epoch:  97 Step:   306 /   793 Train loss: 0.03710906\r\n",
      "Epoch:  97 Step:   307 /   793 Train loss: 0.02987270\r\n",
      "Epoch:  97 Step:   308 /   793 Train loss: 0.01681799\r\n",
      "Epoch:  97 Step:   309 /   793 Train loss: 0.02818281\r\n",
      "Epoch:  97 Step:   310 /   793 Train loss: 0.02455068\r\n",
      "Epoch:  97 Step:   311 /   793 Train loss: 0.01775310\r\n",
      "Epoch:  97 Step:   312 /   793 Train loss: 0.03288159\r\n",
      "Epoch:  97 Step:   313 /   793 Train loss: 0.02128420\r\n",
      "Epoch:  97 Step:   314 /   793 Train loss: 0.02087303\r\n",
      "Epoch:  97 Step:   315 /   793 Train loss: 0.02195250\r\n",
      "Epoch:  97 Step:   316 /   793 Train loss: 0.02552272\r\n",
      "Epoch:  97 Step:   317 /   793 Train loss: 0.01740237\r\n",
      "Epoch:  97 Step:   318 /   793 Train loss: 0.02269364\r\n",
      "Epoch:  97 Step:   319 /   793 Train loss: 0.01909110\r\n",
      "Epoch:  97 Step:   320 /   793 Train loss: 0.02246654\r\n",
      "Epoch:  97 Step:   321 /   793 Train loss: 0.02396308\r\n",
      "Epoch:  97 Step:   322 /   793 Train loss: 0.02095562\r\n",
      "Epoch:  97 Step:   323 /   793 Train loss: 0.02372302\r\n",
      "Epoch:  97 Step:   324 /   793 Train loss: 0.02216160\r\n",
      "Epoch:  97 Step:   325 /   793 Train loss: 0.03381991\r\n",
      "Epoch:  97 Step:   326 /   793 Train loss: 0.01954906\r\n",
      "Epoch:  97 Step:   327 /   793 Train loss: 0.01977894\r\n",
      "Epoch:  97 Step:   328 /   793 Train loss: 0.03010765\r\n",
      "Epoch:  97 Step:   329 /   793 Train loss: 0.03024693\r\n",
      "Epoch:  97 Step:   330 /   793 Train loss: 0.03441643\r\n",
      "Epoch:  97 Step:   331 /   793 Train loss: 0.03078784\r\n",
      "Epoch:  97 Step:   332 /   793 Train loss: 0.02959677\r\n",
      "Epoch:  97 Step:   333 /   793 Train loss: 0.03630548\r\n",
      "Epoch:  97 Step:   334 /   793 Train loss: 0.02052115\r\n",
      "Epoch:  97 Step:   335 /   793 Train loss: 0.03022621\r\n",
      "Epoch:  97 Step:   336 /   793 Train loss: 0.02127600\r\n",
      "Epoch:  97 Step:   337 /   793 Train loss: 0.01797185\r\n",
      "Epoch:  97 Step:   338 /   793 Train loss: 0.03538679\r\n",
      "Epoch:  97 Step:   339 /   793 Train loss: 0.02111922\r\n",
      "Epoch:  97 Step:   340 /   793 Train loss: 0.01990859\r\n",
      "Epoch:  97 Step:   341 /   793 Train loss: 0.02994042\r\n",
      "Epoch:  97 Step:   342 /   793 Train loss: 0.02523846\r\n",
      "Epoch:  97 Step:   343 /   793 Train loss: 0.01936959\r\n",
      "Epoch:  97 Step:   344 /   793 Train loss: 0.02204327\r\n",
      "Epoch:  97 Step:   345 /   793 Train loss: 0.03543998\r\n",
      "Epoch:  97 Step:   346 /   793 Train loss: 0.03970616\r\n",
      "Epoch:  97 Step:   347 /   793 Train loss: 0.02593300\r\n",
      "Epoch:  97 Step:   348 /   793 Train loss: 0.03768718\r\n",
      "Epoch:  97 Step:   349 /   793 Train loss: 0.01304637\r\n",
      "Epoch:  97 Step:   350 /   793 Train loss: 0.03525943\r\n",
      "Epoch:  97 Step:   351 /   793 Train loss: 0.03069891\r\n",
      "Epoch:  97 Step:   352 /   793 Train loss: 0.02028835\r\n",
      "Epoch:  97 Step:   353 /   793 Train loss: 0.02746426\r\n",
      "Epoch:  97 Step:   354 /   793 Train loss: 0.03712912\r\n",
      "Epoch:  97 Step:   355 /   793 Train loss: 0.02055543\r\n",
      "Epoch:  97 Step:   356 /   793 Train loss: 0.02758742\r\n",
      "Epoch:  97 Step:   357 /   793 Train loss: 0.01872865\r\n",
      "Epoch:  97 Step:   358 /   793 Train loss: 0.01882314\r\n",
      "Epoch:  97 Step:   359 /   793 Train loss: 0.02161852\r\n",
      "Epoch:  97 Step:   360 /   793 Train loss: 0.03099222\r\n",
      "Epoch:  97 Step:   361 /   793 Train loss: 0.02180118\r\n",
      "Epoch:  97 Step:   362 /   793 Train loss: 0.03498888\r\n",
      "Epoch:  97 Step:   363 /   793 Train loss: 0.01501850\r\n",
      "Epoch:  97 Step:   364 /   793 Train loss: 0.01599786\r\n",
      "Epoch:  97 Step:   365 /   793 Train loss: 0.02993264\r\n",
      "Epoch:  97 Step:   366 /   793 Train loss: 0.01513911\r\n",
      "Epoch:  97 Step:   367 /   793 Train loss: 0.02628526\r\n",
      "Epoch:  97 Step:   368 /   793 Train loss: 0.02369122\r\n",
      "Epoch:  97 Step:   369 /   793 Train loss: 0.03147411\r\n",
      "Epoch:  97 Step:   370 /   793 Train loss: 0.02741865\r\n",
      "Epoch:  97 Step:   371 /   793 Train loss: 0.01526071\r\n",
      "Epoch:  97 Step:   372 /   793 Train loss: 0.01189466\r\n",
      "Epoch:  97 Step:   373 /   793 Train loss: 0.01578491\r\n",
      "Epoch:  97 Step:   374 /   793 Train loss: 0.01639690\r\n",
      "Epoch:  97 Step:   375 /   793 Train loss: 0.02826659\r\n",
      "Epoch:  97 Step:   376 /   793 Train loss: 0.02115681\r\n",
      "Epoch:  97 Step:   377 /   793 Train loss: 0.01462612\r\n",
      "Epoch:  97 Step:   378 /   793 Train loss: 0.02957705\r\n",
      "Epoch:  97 Step:   379 /   793 Train loss: 0.01745358\r\n",
      "Epoch:  97 Step:   380 /   793 Train loss: 0.02839289\r\n",
      "Epoch:  97 Step:   381 /   793 Train loss: 0.02779531\r\n",
      "Epoch:  97 Step:   382 /   793 Train loss: 0.03053932\r\n",
      "Epoch:  97 Step:   383 /   793 Train loss: 0.03025625\r\n",
      "Epoch:  97 Step:   384 /   793 Train loss: 0.01669153\r\n",
      "Epoch:  97 Step:   385 /   793 Train loss: 0.02298182\r\n",
      "Epoch:  97 Step:   386 /   793 Train loss: 0.02274221\r\n",
      "Epoch:  97 Step:   387 /   793 Train loss: 0.03249242\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  97 Step:   388 /   793 Train loss: 0.01434010\r\n",
      "Epoch:  97 Step:   389 /   793 Train loss: 0.03868831\r\n",
      "Epoch:  97 Step:   390 /   793 Train loss: 0.01981159\r\n",
      "Epoch:  97 Step:   391 /   793 Train loss: 0.03776208\r\n",
      "Epoch:  97 Step:   392 /   793 Train loss: 0.02612701\r\n",
      "Epoch:  97 Step:   393 /   793 Train loss: 0.02003646\r\n",
      "Epoch:  97 Step:   394 /   793 Train loss: 0.02468315\r\n",
      "Epoch:  97 Step:   395 /   793 Train loss: 0.02307718\r\n",
      "Epoch:  97 Step:   396 /   793 Train loss: 0.01277867\r\n",
      "Epoch:  97 Step:   397 /   793 Train loss: 0.03326745\r\n",
      "Epoch:  97 Step:   398 /   793 Train loss: 0.03918026\r\n",
      "Epoch:  97 Step:   399 /   793 Train loss: 0.01956380\r\n",
      "Epoch:  97 Step:   400 /   793 Train loss: 0.02282412\r\n",
      "Epoch:  97 Step:   401 /   793 Train loss: 0.03308370\r\n",
      "Epoch:  97 Step:   402 /   793 Train loss: 0.02928392\r\n",
      "Epoch:  97 Step:   403 /   793 Train loss: 0.02148683\r\n",
      "Epoch:  97 Step:   404 /   793 Train loss: 0.01591126\r\n",
      "Epoch:  97 Step:   405 /   793 Train loss: 0.01963435\r\n",
      "Epoch:  97 Step:   406 /   793 Train loss: 0.01648610\r\n",
      "Epoch:  97 Step:   407 /   793 Train loss: 0.02304798\r\n",
      "Epoch:  97 Step:   408 /   793 Train loss: 0.01465233\r\n",
      "Epoch:  97 Step:   409 /   793 Train loss: 0.03456515\r\n",
      "Epoch:  97 Step:   410 /   793 Train loss: 0.01608508\r\n",
      "Epoch:  97 Step:   411 /   793 Train loss: 0.01869022\r\n",
      "Epoch:  97 Step:   412 /   793 Train loss: 0.03481911\r\n",
      "Epoch:  97 Step:   413 /   793 Train loss: 0.01683609\r\n",
      "Epoch:  97 Step:   414 /   793 Train loss: 0.02140466\r\n",
      "Epoch:  97 Step:   415 /   793 Train loss: 0.01273932\r\n",
      "Epoch:  97 Step:   416 /   793 Train loss: 0.01366874\r\n",
      "Epoch:  97 Step:   417 /   793 Train loss: 0.02425346\r\n",
      "Epoch:  97 Step:   418 /   793 Train loss: 0.02139599\r\n",
      "Epoch:  97 Step:   419 /   793 Train loss: 0.00969064\r\n",
      "Epoch:  97 Step:   420 /   793 Train loss: 0.01972991\r\n",
      "Epoch:  97 Step:   421 /   793 Train loss: 0.02304324\r\n",
      "Epoch:  97 Step:   422 /   793 Train loss: 0.01669016\r\n",
      "Epoch:  97 Step:   423 /   793 Train loss: 0.01444848\r\n",
      "Epoch:  97 Step:   424 /   793 Train loss: 0.03627130\r\n",
      "Epoch:  97 Step:   425 /   793 Train loss: 0.03190326\r\n",
      "Epoch:  97 Step:   426 /   793 Train loss: 0.02324261\r\n",
      "Epoch:  97 Step:   427 /   793 Train loss: 0.03177252\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  97 Step:   428 /   793 Train loss: 0.01996766\r\n",
      "Epoch:  97 Step:   429 /   793 Train loss: 0.01802602\r\n",
      "Epoch:  97 Step:   430 /   793 Train loss: 0.01983432\r\n",
      "Epoch:  97 Step:   431 /   793 Train loss: 0.02773397\r\n",
      "Epoch:  97 Step:   432 /   793 Train loss: 0.01703213\r\n",
      "Epoch:  97 Step:   433 /   793 Train loss: 0.03180414\r\n",
      "Epoch:  97 Step:   434 /   793 Train loss: 0.01835087\r\n",
      "Epoch:  97 Step:   435 /   793 Train loss: 0.02157735\r\n",
      "Epoch:  97 Step:   436 /   793 Train loss: 0.02006390\r\n",
      "Epoch:  97 Step:   437 /   793 Train loss: 0.01928926\r\n",
      "Epoch:  97 Step:   438 /   793 Train loss: 0.02477866\r\n",
      "Epoch:  97 Step:   439 /   793 Train loss: 0.02568242\r\n",
      "Epoch:  97 Step:   440 /   793 Train loss: 0.02755164\r\n",
      "Epoch:  97 Step:   441 /   793 Train loss: 0.01199242\r\n",
      "Epoch:  97 Step:   442 /   793 Train loss: 0.03416188\r\n",
      "Epoch:  97 Step:   443 /   793 Train loss: 0.02463283\r\n",
      "Epoch:  97 Step:   444 /   793 Train loss: 0.02644699\r\n",
      "Epoch:  97 Step:   445 /   793 Train loss: 0.02143513\r\n",
      "Epoch:  97 Step:   446 /   793 Train loss: 0.03606431\r\n",
      "Epoch:  97 Step:   447 /   793 Train loss: 0.02677120\r\n",
      "Epoch:  97 Step:   448 /   793 Train loss: 0.02733549\r\n",
      "Epoch:  97 Step:   449 /   793 Train loss: 0.02511830\r\n",
      "Epoch:  97 Step:   450 /   793 Train loss: 0.04113147\r\n",
      "Epoch:  97 Step:   451 /   793 Train loss: 0.02322015\r\n",
      "Epoch:  97 Step:   452 /   793 Train loss: 0.02396677\r\n",
      "Epoch:  97 Step:   453 /   793 Train loss: 0.01989187\r\n",
      "Epoch:  97 Step:   454 /   793 Train loss: 0.01261543\r\n",
      "Epoch:  97 Step:   455 /   793 Train loss: 0.02580813\r\n",
      "Epoch:  97 Step:   456 /   793 Train loss: 0.03397296\r\n",
      "Epoch:  97 Step:   457 /   793 Train loss: 0.03512687\r\n",
      "Epoch:  97 Step:   458 /   793 Train loss: 0.00985239\r\n",
      "Epoch:  97 Step:   459 /   793 Train loss: 0.02149528\r\n",
      "Epoch:  97 Step:   460 /   793 Train loss: 0.01635985\r\n",
      "Epoch:  97 Step:   461 /   793 Train loss: 0.03131373\r\n",
      "Epoch:  97 Step:   462 /   793 Train loss: 0.01923291\r\n",
      "Epoch:  97 Step:   463 /   793 Train loss: 0.02890783\r\n",
      "Epoch:  97 Step:   464 /   793 Train loss: 0.02675121\r\n",
      "Epoch:  97 Step:   465 /   793 Train loss: 0.02555458\r\n",
      "Epoch:  97 Step:   466 /   793 Train loss: 0.03318952\r\n",
      "Epoch:  97 Step:   467 /   793 Train loss: 0.02387163\r\n",
      "Epoch:  97 Step:   468 /   793 Train loss: 0.03419341\r\n",
      "Epoch:  97 Step:   469 /   793 Train loss: 0.03015563\r\n",
      "Epoch:  97 Step:   470 /   793 Train loss: 0.02155622\r\n",
      "Epoch:  97 Step:   471 /   793 Train loss: 0.02267951\r\n",
      "Epoch:  97 Step:   472 /   793 Train loss: 0.02729162\r\n",
      "Epoch:  97 Step:   473 /   793 Train loss: 0.02681699\r\n",
      "Epoch:  97 Step:   474 /   793 Train loss: 0.01719311\r\n",
      "Epoch:  97 Step:   475 /   793 Train loss: 0.02558460\r\n",
      "Epoch:  97 Step:   476 /   793 Train loss: 0.02372281\r\n",
      "Epoch:  97 Step:   477 /   793 Train loss: 0.03303924\r\n",
      "Epoch:  97 Step:   478 /   793 Train loss: 0.03979743\r\n",
      "Epoch:  97 Step:   479 /   793 Train loss: 0.01898485\r\n",
      "Epoch:  97 Step:   480 /   793 Train loss: 0.02173977\r\n",
      "Epoch:  97 Step:   481 /   793 Train loss: 0.01482428\r\n",
      "Epoch:  97 Step:   482 /   793 Train loss: 0.03697201\r\n",
      "Epoch:  97 Step:   483 /   793 Train loss: 0.03243096\r\n",
      "Epoch:  97 Step:   484 /   793 Train loss: 0.01326235\r\n",
      "Epoch:  97 Step:   485 /   793 Train loss: 0.02973523\r\n",
      "Epoch:  97 Step:   486 /   793 Train loss: 0.01852935\r\n",
      "Epoch:  97 Step:   487 /   793 Train loss: 0.02408351\r\n",
      "Epoch:  97 Step:   488 /   793 Train loss: 0.03250793\r\n",
      "Epoch:  97 Step:   489 /   793 Train loss: 0.02180827\r\n",
      "Epoch:  97 Step:   490 /   793 Train loss: 0.03584263\r\n",
      "Epoch:  97 Step:   491 /   793 Train loss: 0.02930836\r\n",
      "Epoch:  97 Step:   492 /   793 Train loss: 0.01631787\r\n",
      "Epoch:  97 Step:   493 /   793 Train loss: 0.02224392\r\n",
      "Epoch:  97 Step:   494 /   793 Train loss: 0.02682140\r\n",
      "Epoch:  97 Step:   495 /   793 Train loss: 0.03017951\r\n",
      "Epoch:  97 Step:   496 /   793 Train loss: 0.03190768\r\n",
      "Epoch:  97 Step:   497 /   793 Train loss: 0.02642139\r\n",
      "Epoch:  97 Step:   498 /   793 Train loss: 0.01859219\r\n",
      "Epoch:  97 Step:   499 /   793 Train loss: 0.02406125\r\n",
      "Epoch:  97 Step:   500 /   793 Train loss: 0.02144776\r\n",
      "Epoch:  97 Step:   501 /   793 Train loss: 0.02719198\r\n",
      "Epoch:  97 Step:   502 /   793 Train loss: 0.02092134\r\n",
      "Epoch:  97 Step:   503 /   793 Train loss: 0.03534988\r\n",
      "Epoch:  97 Step:   504 /   793 Train loss: 0.02035882\r\n",
      "Epoch:  97 Step:   505 /   793 Train loss: 0.01802676\r\n",
      "Epoch:  97 Step:   506 /   793 Train loss: 0.02356233\r\n",
      "Epoch:  97 Step:   507 /   793 Train loss: 0.02904377\r\n",
      "Epoch:  97 Step:   508 /   793 Train loss: 0.02502156\r\n",
      "Epoch:  97 Step:   509 /   793 Train loss: 0.02335655\r\n",
      "Epoch:  97 Step:   510 /   793 Train loss: 0.02209489\r\n",
      "Epoch:  97 Step:   511 /   793 Train loss: 0.01610360\r\n",
      "Epoch:  97 Step:   512 /   793 Train loss: 0.02584999\r\n",
      "Epoch:  97 Step:   513 /   793 Train loss: 0.02736796\r\n",
      "Epoch:  97 Step:   514 /   793 Train loss: 0.02023133\r\n",
      "Epoch:  97 Step:   515 /   793 Train loss: 0.02391479\r\n",
      "Epoch:  97 Step:   516 /   793 Train loss: 0.01819548\r\n",
      "Epoch:  97 Step:   517 /   793 Train loss: 0.02479804\r\n",
      "Epoch:  97 Step:   518 /   793 Train loss: 0.02724384\r\n",
      "Epoch:  97 Step:   519 /   793 Train loss: 0.01904507\r\n",
      "Epoch:  97 Step:   520 /   793 Train loss: 0.02235604\r\n",
      "Epoch:  97 Step:   521 /   793 Train loss: 0.02784482\r\n",
      "Epoch:  97 Step:   522 /   793 Train loss: 0.01125234\r\n",
      "Epoch:  97 Step:   523 /   793 Train loss: 0.02442720\r\n",
      "Epoch:  97 Step:   524 /   793 Train loss: 0.03302165\r\n",
      "Epoch:  97 Step:   525 /   793 Train loss: 0.02159387\r\n",
      "Epoch:  97 Step:   526 /   793 Train loss: 0.01952402\r\n",
      "Epoch:  97 Step:   527 /   793 Train loss: 0.01704138\r\n",
      "Epoch:  97 Step:   528 /   793 Train loss: 0.02176285\r\n",
      "Epoch:  97 Step:   529 /   793 Train loss: 0.01958547\r\n",
      "Epoch:  97 Step:   530 /   793 Train loss: 0.01510863\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  97 Step:   531 /   793 Train loss: 0.03282348\r\n",
      "Epoch:  97 Step:   532 /   793 Train loss: 0.03121379\r\n",
      "Epoch:  97 Step:   533 /   793 Train loss: 0.01606434\r\n",
      "Epoch:  97 Step:   534 /   793 Train loss: 0.01877690\r\n",
      "Epoch:  97 Step:   535 /   793 Train loss: 0.02689014\r\n",
      "Epoch:  97 Step:   536 /   793 Train loss: 0.02621915\r\n",
      "Epoch:  97 Step:   537 /   793 Train loss: 0.03194292\r\n",
      "Epoch:  97 Step:   538 /   793 Train loss: 0.02131121\r\n",
      "Epoch:  97 Step:   539 /   793 Train loss: 0.01638860\r\n",
      "Epoch:  97 Step:   540 /   793 Train loss: 0.01866728\r\n",
      "Epoch:  97 Step:   541 /   793 Train loss: 0.01479508\r\n",
      "Epoch:  97 Step:   542 /   793 Train loss: 0.02604893\r\n",
      "Epoch:  97 Step:   543 /   793 Train loss: 0.01843581\r\n",
      "Epoch:  97 Step:   544 /   793 Train loss: 0.02333265\r\n",
      "Epoch:  97 Step:   545 /   793 Train loss: 0.01635010\r\n",
      "Epoch:  97 Step:   546 /   793 Train loss: 0.02544546\r\n",
      "Epoch:  97 Step:   547 /   793 Train loss: 0.02277276\r\n",
      "Epoch:  97 Step:   548 /   793 Train loss: 0.02445747\r\n",
      "Epoch:  97 Step:   549 /   793 Train loss: 0.03279966\r\n",
      "Epoch:  97 Step:   550 /   793 Train loss: 0.02497432\r\n",
      "Epoch:  97 Step:   551 /   793 Train loss: 0.02464997\r\n",
      "Epoch:  97 Step:   552 /   793 Train loss: 0.02843356\r\n",
      "Epoch:  97 Step:   553 /   793 Train loss: 0.01277435\r\n",
      "Epoch:  97 Step:   554 /   793 Train loss: 0.02345302\r\n",
      "Epoch:  97 Step:   555 /   793 Train loss: 0.02573416\r\n",
      "Epoch:  97 Step:   556 /   793 Train loss: 0.02656672\r\n",
      "Epoch:  97 Step:   557 /   793 Train loss: 0.01995020\r\n",
      "Epoch:  97 Step:   558 /   793 Train loss: 0.01066073\r\n",
      "Epoch:  97 Step:   559 /   793 Train loss: 0.02250496\r\n",
      "Epoch:  97 Step:   560 /   793 Train loss: 0.02815141\r\n",
      "Epoch:  97 Step:   561 /   793 Train loss: 0.01271957\r\n",
      "Epoch:  97 Step:   562 /   793 Train loss: 0.03850671\r\n",
      "Epoch:  97 Step:   563 /   793 Train loss: 0.02838873\r\n",
      "Epoch:  97 Step:   564 /   793 Train loss: 0.03132070\r\n",
      "Epoch:  97 Step:   565 /   793 Train loss: 0.01853345\r\n",
      "Epoch:  97 Step:   566 /   793 Train loss: 0.02071929\r\n",
      "Epoch:  97 Step:   567 /   793 Train loss: 0.02212914\r\n",
      "Epoch:  97 Step:   568 /   793 Train loss: 0.02418375\r\n",
      "Epoch:  97 Step:   569 /   793 Train loss: 0.01928486\r\n",
      "Epoch:  97 Step:   570 /   793 Train loss: 0.02163089\r\n",
      "Epoch:  97 Step:   571 /   793 Train loss: 0.02423624\r\n",
      "Epoch:  97 Step:   572 /   793 Train loss: 0.01565167\r\n",
      "Epoch:  97 Step:   573 /   793 Train loss: 0.03104963\r\n",
      "Epoch:  97 Step:   574 /   793 Train loss: 0.01235061\r\n",
      "Epoch:  97 Step:   575 /   793 Train loss: 0.02630607\r\n",
      "Epoch:  97 Step:   576 /   793 Train loss: 0.03103493\r\n",
      "Epoch:  97 Step:   577 /   793 Train loss: 0.02224890\r\n",
      "Epoch:  97 Step:   578 /   793 Train loss: 0.04194880\r\n",
      "Epoch:  97 Step:   579 /   793 Train loss: 0.02740485\r\n",
      "Epoch:  97 Step:   580 /   793 Train loss: 0.03280357\r\n",
      "Epoch:  97 Step:   581 /   793 Train loss: 0.02444276\r\n",
      "Epoch:  97 Step:   582 /   793 Train loss: 0.01491313\r\n",
      "Epoch:  97 Step:   583 /   793 Train loss: 0.01513958\r\n",
      "Epoch:  97 Step:   584 /   793 Train loss: 0.02223078\r\n",
      "Epoch:  97 Step:   585 /   793 Train loss: 0.02098272\r\n",
      "Epoch:  97 Step:   586 /   793 Train loss: 0.01189565\r\n",
      "Epoch:  97 Step:   587 /   793 Train loss: 0.02862734\r\n",
      "Epoch:  97 Step:   588 /   793 Train loss: 0.03470899\r\n",
      "Epoch:  97 Step:   589 /   793 Train loss: 0.03690055\r\n",
      "Epoch:  97 Step:   590 /   793 Train loss: 0.03128643\r\n",
      "Epoch:  97 Step:   591 /   793 Train loss: 0.01207551\r\n",
      "Epoch:  97 Step:   592 /   793 Train loss: 0.02416009\r\n",
      "Epoch:  97 Step:   593 /   793 Train loss: 0.02596744\r\n",
      "Epoch:  97 Step:   594 /   793 Train loss: 0.03446029\r\n",
      "Epoch:  97 Step:   595 /   793 Train loss: 0.01591941\r\n",
      "Epoch:  97 Step:   596 /   793 Train loss: 0.02955731\r\n",
      "Epoch:  97 Step:   597 /   793 Train loss: 0.01979833\r\n",
      "Epoch:  97 Step:   598 /   793 Train loss: 0.02127556\r\n",
      "Epoch:  97 Step:   599 /   793 Train loss: 0.02778517\r\n",
      "Epoch:  97 Step:   600 /   793 Train loss: 0.02176985\r\n",
      "Epoch:  97 Step:   601 /   793 Train loss: 0.01132257\r\n",
      "Epoch:  97 Step:   602 /   793 Train loss: 0.02073551\r\n",
      "Epoch:  97 Step:   603 /   793 Train loss: 0.01805838\r\n",
      "Epoch:  97 Step:   604 /   793 Train loss: 0.03239839\r\n",
      "Epoch:  97 Step:   605 /   793 Train loss: 0.01694268\r\n",
      "Epoch:  97 Step:   606 /   793 Train loss: 0.03496745\r\n",
      "Epoch:  97 Step:   607 /   793 Train loss: 0.02498972\r\n",
      "Epoch:  97 Step:   608 /   793 Train loss: 0.02825409\r\n",
      "Epoch:  97 Step:   609 /   793 Train loss: 0.02611197\r\n",
      "Epoch:  97 Step:   610 /   793 Train loss: 0.02591694\r\n",
      "Epoch:  97 Step:   611 /   793 Train loss: 0.01617432\r\n",
      "Epoch:  97 Step:   612 /   793 Train loss: 0.03495804\r\n",
      "Epoch:  97 Step:   613 /   793 Train loss: 0.02361590\r\n",
      "Epoch:  97 Step:   614 /   793 Train loss: 0.02780934\r\n",
      "Epoch:  97 Step:   615 /   793 Train loss: 0.01530455\r\n",
      "Epoch:  97 Step:   616 /   793 Train loss: 0.01642580\r\n",
      "Epoch:  97 Step:   617 /   793 Train loss: 0.02845152\r\n",
      "Epoch:  97 Step:   618 /   793 Train loss: 0.02153176\r\n",
      "Epoch:  97 Step:   619 /   793 Train loss: 0.02339540\r\n",
      "Epoch:  97 Step:   620 /   793 Train loss: 0.02688124\r\n",
      "Epoch:  97 Step:   621 /   793 Train loss: 0.02499850\r\n",
      "Epoch:  97 Step:   622 /   793 Train loss: 0.02176742\r\n",
      "Epoch:  97 Step:   623 /   793 Train loss: 0.03007470\r\n",
      "Epoch:  97 Step:   624 /   793 Train loss: 0.02783601\r\n",
      "Epoch:  97 Step:   625 /   793 Train loss: 0.03369347\r\n",
      "Epoch:  97 Step:   626 /   793 Train loss: 0.02271501\r\n",
      "Epoch:  97 Step:   627 /   793 Train loss: 0.02001818\r\n",
      "Epoch:  97 Step:   628 /   793 Train loss: 0.03344365\r\n",
      "Epoch:  97 Step:   629 /   793 Train loss: 0.02583937\r\n",
      "Epoch:  97 Step:   630 /   793 Train loss: 0.02759665\r\n",
      "Epoch:  97 Step:   631 /   793 Train loss: 0.01468823\r\n",
      "Epoch:  97 Step:   632 /   793 Train loss: 0.02160987\r\n",
      "Epoch:  97 Step:   633 /   793 Train loss: 0.03284524\r\n",
      "Epoch:  97 Step:   634 /   793 Train loss: 0.01513852\r\n",
      "Epoch:  97 Step:   635 /   793 Train loss: 0.02275553\r\n",
      "Epoch:  97 Step:   636 /   793 Train loss: 0.02862460\r\n",
      "Epoch:  97 Step:   637 /   793 Train loss: 0.02097545\r\n",
      "Epoch:  97 Step:   638 /   793 Train loss: 0.03407340\r\n",
      "Epoch:  97 Step:   639 /   793 Train loss: 0.03259541\r\n",
      "Epoch:  97 Step:   640 /   793 Train loss: 0.02060203\r\n",
      "Epoch:  97 Step:   641 /   793 Train loss: 0.01824298\r\n",
      "Epoch:  97 Step:   642 /   793 Train loss: 0.03274938\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  97 Step:   643 /   793 Train loss: 0.01784525\r\n",
      "Epoch:  97 Step:   644 /   793 Train loss: 0.03337453\r\n",
      "Epoch:  97 Step:   645 /   793 Train loss: 0.02239914\r\n",
      "Epoch:  97 Step:   646 /   793 Train loss: 0.01020723\r\n",
      "Epoch:  97 Step:   647 /   793 Train loss: 0.02135134\r\n",
      "Epoch:  97 Step:   648 /   793 Train loss: 0.02726444\r\n",
      "Epoch:  97 Step:   649 /   793 Train loss: 0.03608885\r\n",
      "Epoch:  97 Step:   650 /   793 Train loss: 0.02866083\r\n",
      "Epoch:  97 Step:   651 /   793 Train loss: 0.01921753\r\n",
      "Epoch:  97 Step:   652 /   793 Train loss: 0.02755055\r\n",
      "Epoch:  97 Step:   653 /   793 Train loss: 0.03449588\r\n",
      "Epoch:  97 Step:   654 /   793 Train loss: 0.02019348\r\n",
      "Epoch:  97 Step:   655 /   793 Train loss: 0.03477712\r\n",
      "Epoch:  97 Step:   656 /   793 Train loss: 0.03014288\r\n",
      "Epoch:  97 Step:   657 /   793 Train loss: 0.01233590\r\n",
      "Epoch:  97 Step:   658 /   793 Train loss: 0.01682434\r\n",
      "Epoch:  97 Step:   659 /   793 Train loss: 0.02820852\r\n",
      "Epoch:  97 Step:   660 /   793 Train loss: 0.02779345\r\n",
      "Epoch:  97 Step:   661 /   793 Train loss: 0.01352192\r\n",
      "Epoch:  97 Step:   662 /   793 Train loss: 0.03754378\r\n",
      "Epoch:  97 Step:   663 /   793 Train loss: 0.02681170\r\n",
      "Epoch:  97 Step:   664 /   793 Train loss: 0.01462427\r\n",
      "Epoch:  97 Step:   665 /   793 Train loss: 0.03531081\r\n",
      "Epoch:  97 Step:   666 /   793 Train loss: 0.02458252\r\n",
      "Epoch:  97 Step:   667 /   793 Train loss: 0.01930580\r\n",
      "Epoch:  97 Step:   668 /   793 Train loss: 0.01918949\r\n",
      "Epoch:  97 Step:   669 /   793 Train loss: 0.02391052\r\n",
      "Epoch:  97 Step:   670 /   793 Train loss: 0.03029289\r\n",
      "Epoch:  97 Step:   671 /   793 Train loss: 0.03159279\r\n",
      "Epoch:  97 Step:   672 /   793 Train loss: 0.01653887\r\n",
      "Epoch:  97 Step:   673 /   793 Train loss: 0.02869399\r\n",
      "Epoch:  97 Step:   674 /   793 Train loss: 0.02878072\r\n",
      "Epoch:  97 Step:   675 /   793 Train loss: 0.01807955\r\n",
      "Epoch:  97 Step:   676 /   793 Train loss: 0.03384355\r\n",
      "Epoch:  97 Step:   677 /   793 Train loss: 0.02999747\r\n",
      "Epoch:  97 Step:   678 /   793 Train loss: 0.03512479\r\n",
      "Epoch:  97 Step:   679 /   793 Train loss: 0.01250175\r\n",
      "Epoch:  97 Step:   680 /   793 Train loss: 0.01889338\r\n",
      "Epoch:  97 Step:   681 /   793 Train loss: 0.03021460\r\n",
      "Epoch:  97 Step:   682 /   793 Train loss: 0.02118920\r\n",
      "Epoch:  97 Step:   683 /   793 Train loss: 0.02283229\r\n",
      "Epoch:  97 Step:   684 /   793 Train loss: 0.01914555\r\n",
      "Epoch:  97 Step:   685 /   793 Train loss: 0.02123205\r\n",
      "Epoch:  97 Step:   686 /   793 Train loss: 0.02713198\r\n",
      "Epoch:  97 Step:   687 /   793 Train loss: 0.01960652\r\n",
      "Epoch:  97 Step:   688 /   793 Train loss: 0.01727824\r\n",
      "Epoch:  97 Step:   689 /   793 Train loss: 0.01634257\r\n",
      "Epoch:  97 Step:   690 /   793 Train loss: 0.01977199\r\n",
      "Epoch:  97 Step:   691 /   793 Train loss: 0.02879706\r\n",
      "Epoch:  97 Step:   692 /   793 Train loss: 0.01984359\r\n",
      "Epoch:  97 Step:   693 /   793 Train loss: 0.01952774\r\n",
      "Epoch:  97 Step:   694 /   793 Train loss: 0.01787214\r\n",
      "Epoch:  97 Step:   695 /   793 Train loss: 0.03974643\r\n",
      "Epoch:  97 Step:   696 /   793 Train loss: 0.03430333\r\n",
      "Epoch:  97 Step:   697 /   793 Train loss: 0.04067821\r\n",
      "Epoch:  97 Step:   698 /   793 Train loss: 0.02351919\r\n",
      "Epoch:  97 Step:   699 /   793 Train loss: 0.02342491\r\n",
      "Epoch:  97 Step:   700 /   793 Train loss: 0.02491155\r\n",
      "Epoch:  97 Step:   701 /   793 Train loss: 0.01767582\r\n",
      "Epoch:  97 Step:   702 /   793 Train loss: 0.01403043\r\n",
      "Epoch:  97 Step:   703 /   793 Train loss: 0.01717950\r\n",
      "Epoch:  97 Step:   704 /   793 Train loss: 0.02397771\r\n",
      "Epoch:  97 Step:   705 /   793 Train loss: 0.01830555\r\n",
      "Epoch:  97 Step:   706 /   793 Train loss: 0.02437950\r\n",
      "Epoch:  97 Step:   707 /   793 Train loss: 0.01992781\r\n",
      "Epoch:  97 Step:   708 /   793 Train loss: 0.01534294\r\n",
      "Epoch:  97 Step:   709 /   793 Train loss: 0.03038676\r\n",
      "Epoch:  97 Step:   710 /   793 Train loss: 0.03236681\r\n",
      "Epoch:  97 Step:   711 /   793 Train loss: 0.02985513\r\n",
      "Epoch:  97 Step:   712 /   793 Train loss: 0.03185748\r\n",
      "Epoch:  97 Step:   713 /   793 Train loss: 0.02953016\r\n",
      "Epoch:  97 Step:   714 /   793 Train loss: 0.03235401\r\n",
      "Epoch:  97 Step:   715 /   793 Train loss: 0.02528101\r\n",
      "Epoch:  97 Step:   716 /   793 Train loss: 0.03791410\r\n",
      "Epoch:  97 Step:   717 /   793 Train loss: 0.03035841\r\n",
      "Epoch:  97 Step:   718 /   793 Train loss: 0.02492743\r\n",
      "Epoch:  97 Step:   719 /   793 Train loss: 0.02882855\r\n",
      "Epoch:  97 Step:   720 /   793 Train loss: 0.02718465\r\n",
      "Epoch:  97 Step:   721 /   793 Train loss: 0.02515683\r\n",
      "Epoch:  97 Step:   722 /   793 Train loss: 0.02639573\r\n",
      "Epoch:  97 Step:   723 /   793 Train loss: 0.02912592\r\n",
      "Epoch:  97 Step:   724 /   793 Train loss: 0.02243389\r\n",
      "Epoch:  97 Step:   725 /   793 Train loss: 0.01811605\r\n",
      "Epoch:  97 Step:   726 /   793 Train loss: 0.01258240\r\n",
      "Epoch:  97 Step:   727 /   793 Train loss: 0.01592050\r\n",
      "Epoch:  97 Step:   728 /   793 Train loss: 0.01211466\r\n",
      "Epoch:  97 Step:   729 /   793 Train loss: 0.01920480\r\n",
      "Epoch:  97 Step:   730 /   793 Train loss: 0.02951434\r\n",
      "Epoch:  97 Step:   731 /   793 Train loss: 0.03633504\r\n",
      "Epoch:  97 Step:   732 /   793 Train loss: 0.02908935\r\n",
      "Epoch:  97 Step:   733 /   793 Train loss: 0.02852069\r\n",
      "Epoch:  97 Step:   734 /   793 Train loss: 0.01706921\r\n",
      "Epoch:  97 Step:   735 /   793 Train loss: 0.02458833\r\n",
      "Epoch:  97 Step:   736 /   793 Train loss: 0.02108542\r\n",
      "Epoch:  97 Step:   737 /   793 Train loss: 0.02985837\r\n",
      "Epoch:  97 Step:   738 /   793 Train loss: 0.02945673\r\n",
      "Epoch:  97 Step:   739 /   793 Train loss: 0.03040288\r\n",
      "Epoch:  97 Step:   740 /   793 Train loss: 0.01715067\r\n",
      "Epoch:  97 Step:   741 /   793 Train loss: 0.02717685\r\n",
      "Epoch:  97 Step:   742 /   793 Train loss: 0.01009668\r\n",
      "Epoch:  97 Step:   743 /   793 Train loss: 0.02277735\r\n",
      "Epoch:  97 Step:   744 /   793 Train loss: 0.01558960\r\n",
      "Epoch:  97 Step:   745 /   793 Train loss: 0.01689505\r\n",
      "Epoch:  97 Step:   746 /   793 Train loss: 0.01954409\r\n",
      "Epoch:  97 Step:   747 /   793 Train loss: 0.02140201\r\n",
      "Epoch:  97 Step:   748 /   793 Train loss: 0.02053078\r\n",
      "Epoch:  97 Step:   749 /   793 Train loss: 0.03436764\r\n",
      "Epoch:  97 Step:   750 /   793 Train loss: 0.01923903\r\n",
      "Epoch:  97 Step:   751 /   793 Train loss: 0.02139566\r\n",
      "Epoch:  97 Step:   752 /   793 Train loss: 0.01875770\r\n",
      "Epoch:  97 Step:   753 /   793 Train loss: 0.02334641\r\n",
      "Epoch:  97 Step:   754 /   793 Train loss: 0.02898932\r\n",
      "Epoch:  97 Step:   755 /   793 Train loss: 0.02908372\r\n",
      "Epoch:  97 Step:   756 /   793 Train loss: 0.01256872\r\n",
      "Epoch:  97 Step:   757 /   793 Train loss: 0.03196013\r\n",
      "Epoch:  97 Step:   758 /   793 Train loss: 0.02208274\r\n",
      "Epoch:  97 Step:   759 /   793 Train loss: 0.02353339\r\n",
      "Epoch:  97 Step:   760 /   793 Train loss: 0.01754579\r\n",
      "Epoch:  97 Step:   761 /   793 Train loss: 0.02927616\r\n",
      "Epoch:  97 Step:   762 /   793 Train loss: 0.03185318\r\n",
      "Epoch:  97 Step:   763 /   793 Train loss: 0.01561711\r\n",
      "Epoch:  97 Step:   764 /   793 Train loss: 0.01588412\r\n",
      "Epoch:  97 Step:   765 /   793 Train loss: 0.02517454\r\n",
      "Epoch:  97 Step:   766 /   793 Train loss: 0.03352656\r\n",
      "Epoch:  97 Step:   767 /   793 Train loss: 0.01798091\r\n",
      "Epoch:  97 Step:   768 /   793 Train loss: 0.01629138\r\n",
      "Epoch:  97 Step:   769 /   793 Train loss: 0.02691929\r\n",
      "Epoch:  97 Step:   770 /   793 Train loss: 0.02176710\r\n",
      "Epoch:  97 Step:   771 /   793 Train loss: 0.02488765\r\n",
      "Epoch:  97 Step:   772 /   793 Train loss: 0.01676715\r\n",
      "Epoch:  97 Step:   773 /   793 Train loss: 0.03187658\r\n",
      "Epoch:  97 Step:   774 /   793 Train loss: 0.02555692\r\n",
      "Epoch:  97 Step:   775 /   793 Train loss: 0.02945143\r\n",
      "Epoch:  97 Step:   776 /   793 Train loss: 0.01620352\r\n",
      "Epoch:  97 Step:   777 /   793 Train loss: 0.01848586\r\n",
      "Epoch:  97 Step:   778 /   793 Train loss: 0.01019573\r\n",
      "Epoch:  97 Step:   779 /   793 Train loss: 0.02770190\r\n",
      "Epoch:  97 Step:   780 /   793 Train loss: 0.02684784\r\n",
      "Epoch:  97 Step:   781 /   793 Train loss: 0.03041054\r\n",
      "Epoch:  97 Step:   782 /   793 Train loss: 0.03032415\r\n",
      "Epoch:  97 Step:   783 /   793 Train loss: 0.02695450\r\n",
      "Epoch:  97 Step:   784 /   793 Train loss: 0.02401271\r\n",
      "Epoch:  97 Step:   785 /   793 Train loss: 0.01473083\r\n",
      "Epoch:  97 Step:   786 /   793 Train loss: 0.03073033\r\n",
      "Epoch:  97 Step:   787 /   793 Train loss: 0.01609926\r\n",
      "Epoch:  97 Step:   788 /   793 Train loss: 0.04135927\r\n",
      "Epoch:  97 Step:   789 /   793 Train loss: 0.01795434\r\n",
      "Epoch:  97 Step:   790 /   793 Train loss: 0.01231973\r\n",
      "Epoch:  97 Step:   791 /   793 Train loss: 0.03450165\r\n",
      "Epoch:  97 Step:   792 /   793 Train loss: 0.02543916\r\n",
      "Epoch:  97 Validation loss: 0.01423439\r\n",
      "Epoch:  98 Step:     0 /   793 Train loss: 0.02559431\r\n",
      "Epoch:  98 Step:     1 /   793 Train loss: 0.02327028\r\n",
      "Epoch:  98 Step:     2 /   793 Train loss: 0.01795840\r\n",
      "Epoch:  98 Step:     3 /   793 Train loss: 0.02048718\r\n",
      "Epoch:  98 Step:     4 /   793 Train loss: 0.02305285\r\n",
      "Epoch:  98 Step:     5 /   793 Train loss: 0.02713905\r\n",
      "Epoch:  98 Step:     6 /   793 Train loss: 0.02273519\r\n",
      "Epoch:  98 Step:     7 /   793 Train loss: 0.02448536\r\n",
      "Epoch:  98 Step:     8 /   793 Train loss: 0.03204579\r\n",
      "Epoch:  98 Step:     9 /   793 Train loss: 0.02071790\r\n",
      "Epoch:  98 Step:    10 /   793 Train loss: 0.01741774\r\n",
      "Epoch:  98 Step:    11 /   793 Train loss: 0.01989328\r\n",
      "Epoch:  98 Step:    12 /   793 Train loss: 0.02800063\r\n",
      "Epoch:  98 Step:    13 /   793 Train loss: 0.03630438\r\n",
      "Epoch:  98 Step:    14 /   793 Train loss: 0.02057193\r\n",
      "Epoch:  98 Step:    15 /   793 Train loss: 0.02747463\r\n",
      "Epoch:  98 Step:    16 /   793 Train loss: 0.01890308\r\n",
      "Epoch:  98 Step:    17 /   793 Train loss: 0.02032616\r\n",
      "Epoch:  98 Step:    18 /   793 Train loss: 0.01910758\r\n",
      "Epoch:  98 Step:    19 /   793 Train loss: 0.02257125\r\n",
      "Epoch:  98 Step:    20 /   793 Train loss: 0.02553206\r\n",
      "Epoch:  98 Step:    21 /   793 Train loss: 0.02095110\r\n",
      "Epoch:  98 Step:    22 /   793 Train loss: 0.03392204\r\n",
      "Epoch:  98 Step:    23 /   793 Train loss: 0.02828687\r\n",
      "Epoch:  98 Step:    24 /   793 Train loss: 0.04027577\r\n",
      "Epoch:  98 Step:    25 /   793 Train loss: 0.02302936\r\n",
      "Epoch:  98 Step:    26 /   793 Train loss: 0.01922152\r\n",
      "Epoch:  98 Step:    27 /   793 Train loss: 0.03829425\r\n",
      "Epoch:  98 Step:    28 /   793 Train loss: 0.01363694\r\n",
      "Epoch:  98 Step:    29 /   793 Train loss: 0.01220449\r\n",
      "Epoch:  98 Step:    30 /   793 Train loss: 0.02868067\r\n",
      "Epoch:  98 Step:    31 /   793 Train loss: 0.03324234\r\n",
      "Epoch:  98 Step:    32 /   793 Train loss: 0.02333691\r\n",
      "Epoch:  98 Step:    33 /   793 Train loss: 0.01941366\r\n",
      "Epoch:  98 Step:    34 /   793 Train loss: 0.00687694\r\n",
      "Epoch:  98 Step:    35 /   793 Train loss: 0.02167620\r\n",
      "Epoch:  98 Step:    36 /   793 Train loss: 0.02671427\r\n",
      "Epoch:  98 Step:    37 /   793 Train loss: 0.01988365\r\n",
      "Epoch:  98 Step:    38 /   793 Train loss: 0.01488238\r\n",
      "Epoch:  98 Step:    39 /   793 Train loss: 0.01513311\r\n",
      "Epoch:  98 Step:    40 /   793 Train loss: 0.02780319\r\n",
      "Epoch:  98 Step:    41 /   793 Train loss: 0.03068976\r\n",
      "Epoch:  98 Step:    42 /   793 Train loss: 0.01570596\r\n",
      "Epoch:  98 Step:    43 /   793 Train loss: 0.01847422\r\n",
      "Epoch:  98 Step:    44 /   793 Train loss: 0.03615532\r\n",
      "Epoch:  98 Step:    45 /   793 Train loss: 0.02932206\r\n",
      "Epoch:  98 Step:    46 /   793 Train loss: 0.02382650\r\n",
      "Epoch:  98 Step:    47 /   793 Train loss: 0.03620631\r\n",
      "Epoch:  98 Step:    48 /   793 Train loss: 0.03120570\r\n",
      "Epoch:  98 Step:    49 /   793 Train loss: 0.02120154\r\n",
      "Epoch:  98 Step:    50 /   793 Train loss: 0.02606048\r\n",
      "Epoch:  98 Step:    51 /   793 Train loss: 0.02751163\r\n",
      "Epoch:  98 Step:    52 /   793 Train loss: 0.03105289\r\n",
      "Epoch:  98 Step:    53 /   793 Train loss: 0.02620851\r\n",
      "Epoch:  98 Step:    54 /   793 Train loss: 0.02468764\r\n",
      "Epoch:  98 Step:    55 /   793 Train loss: 0.02856366\r\n",
      "Epoch:  98 Step:    56 /   793 Train loss: 0.02334110\r\n",
      "Epoch:  98 Step:    57 /   793 Train loss: 0.01882504\r\n",
      "Epoch:  98 Step:    58 /   793 Train loss: 0.02072184\r\n",
      "Epoch:  98 Step:    59 /   793 Train loss: 0.04705958\r\n",
      "Epoch:  98 Step:    60 /   793 Train loss: 0.03024573\r\n",
      "Epoch:  98 Step:    61 /   793 Train loss: 0.03222866\r\n",
      "Epoch:  98 Step:    62 /   793 Train loss: 0.02308125\r\n",
      "Epoch:  98 Step:    63 /   793 Train loss: 0.02298230\r\n",
      "Epoch:  98 Step:    64 /   793 Train loss: 0.03330887\r\n",
      "Epoch:  98 Step:    65 /   793 Train loss: 0.02195158\r\n",
      "Epoch:  98 Step:    66 /   793 Train loss: 0.01667007\r\n",
      "Epoch:  98 Step:    67 /   793 Train loss: 0.02844181\r\n",
      "Epoch:  98 Step:    68 /   793 Train loss: 0.00885998\r\n",
      "Epoch:  98 Step:    69 /   793 Train loss: 0.01997348\r\n",
      "Epoch:  98 Step:    70 /   793 Train loss: 0.02697055\r\n",
      "Epoch:  98 Step:    71 /   793 Train loss: 0.01762191\r\n",
      "Epoch:  98 Step:    72 /   793 Train loss: 0.02407542\r\n",
      "Epoch:  98 Step:    73 /   793 Train loss: 0.03450228\r\n",
      "Epoch:  98 Step:    74 /   793 Train loss: 0.02248166\r\n",
      "Epoch:  98 Step:    75 /   793 Train loss: 0.02409620\r\n",
      "Epoch:  98 Step:    76 /   793 Train loss: 0.01425582\r\n",
      "Epoch:  98 Step:    77 /   793 Train loss: 0.01596847\r\n",
      "Epoch:  98 Step:    78 /   793 Train loss: 0.02253905\r\n",
      "Epoch:  98 Step:    79 /   793 Train loss: 0.01873064\r\n",
      "Epoch:  98 Step:    80 /   793 Train loss: 0.02677558\r\n",
      "Epoch:  98 Step:    81 /   793 Train loss: 0.01801599\r\n",
      "Epoch:  98 Step:    82 /   793 Train loss: 0.02528002\r\n",
      "Epoch:  98 Step:    83 /   793 Train loss: 0.02910248\r\n",
      "Epoch:  98 Step:    84 /   793 Train loss: 0.02401440\r\n",
      "Epoch:  98 Step:    85 /   793 Train loss: 0.02568148\r\n",
      "Epoch:  98 Step:    86 /   793 Train loss: 0.03667606\r\n",
      "Epoch:  98 Step:    87 /   793 Train loss: 0.03623474\r\n",
      "Epoch:  98 Step:    88 /   793 Train loss: 0.01270378\r\n",
      "Epoch:  98 Step:    89 /   793 Train loss: 0.03830197\r\n",
      "Epoch:  98 Step:    90 /   793 Train loss: 0.03298398\r\n",
      "Epoch:  98 Step:    91 /   793 Train loss: 0.02265997\r\n",
      "Epoch:  98 Step:    92 /   793 Train loss: 0.00854984\r\n",
      "Epoch:  98 Step:    93 /   793 Train loss: 0.02056227\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  98 Step:    94 /   793 Train loss: 0.01992020\r\n",
      "Epoch:  98 Step:    95 /   793 Train loss: 0.02691190\r\n",
      "Epoch:  98 Step:    96 /   793 Train loss: 0.01663704\r\n",
      "Epoch:  98 Step:    97 /   793 Train loss: 0.03334890\r\n",
      "Epoch:  98 Step:    98 /   793 Train loss: 0.01666199\r\n",
      "Epoch:  98 Step:    99 /   793 Train loss: 0.01757738\r\n",
      "Epoch:  98 Step:   100 /   793 Train loss: 0.02144486\r\n",
      "Epoch:  98 Step:   101 /   793 Train loss: 0.02026824\r\n",
      "Epoch:  98 Step:   102 /   793 Train loss: 0.02793577\r\n",
      "Epoch:  98 Step:   103 /   793 Train loss: 0.01701222\r\n",
      "Epoch:  98 Step:   104 /   793 Train loss: 0.01978514\r\n",
      "Epoch:  98 Step:   105 /   793 Train loss: 0.02583754\r\n",
      "Epoch:  98 Step:   106 /   793 Train loss: 0.02932191\r\n",
      "Epoch:  98 Step:   107 /   793 Train loss: 0.02954326\r\n",
      "Epoch:  98 Step:   108 /   793 Train loss: 0.02740986\r\n",
      "Epoch:  98 Step:   109 /   793 Train loss: 0.02742898\r\n",
      "Epoch:  98 Step:   110 /   793 Train loss: 0.01878285\r\n",
      "Epoch:  98 Step:   111 /   793 Train loss: 0.02852062\r\n",
      "Epoch:  98 Step:   112 /   793 Train loss: 0.02419760\r\n",
      "Epoch:  98 Step:   113 /   793 Train loss: 0.02018975\r\n",
      "Epoch:  98 Step:   114 /   793 Train loss: 0.01790113\r\n",
      "Epoch:  98 Step:   115 /   793 Train loss: 0.01834463\r\n",
      "Epoch:  98 Step:   116 /   793 Train loss: 0.02937800\r\n",
      "Epoch:  98 Step:   117 /   793 Train loss: 0.03021295\r\n",
      "Epoch:  98 Step:   118 /   793 Train loss: 0.02266146\r\n",
      "Epoch:  98 Step:   119 /   793 Train loss: 0.02386904\r\n",
      "Epoch:  98 Step:   120 /   793 Train loss: 0.02813124\r\n",
      "Epoch:  98 Step:   121 /   793 Train loss: 0.01578564\r\n",
      "Epoch:  98 Step:   122 /   793 Train loss: 0.02831422\r\n",
      "Epoch:  98 Step:   123 /   793 Train loss: 0.02109097\r\n",
      "Epoch:  98 Step:   124 /   793 Train loss: 0.02495824\r\n",
      "Epoch:  98 Step:   125 /   793 Train loss: 0.01864280\r\n",
      "Epoch:  98 Step:   126 /   793 Train loss: 0.03348467\r\n",
      "Epoch:  98 Step:   127 /   793 Train loss: 0.02850778\r\n",
      "Epoch:  98 Step:   128 /   793 Train loss: 0.02680256\r\n",
      "Epoch:  98 Step:   129 /   793 Train loss: 0.02273824\r\n",
      "Epoch:  98 Step:   130 /   793 Train loss: 0.03483230\r\n",
      "Epoch:  98 Step:   131 /   793 Train loss: 0.02444232\r\n",
      "Epoch:  98 Step:   132 /   793 Train loss: 0.04371636\r\n",
      "Epoch:  98 Step:   133 /   793 Train loss: 0.02644640\r\n",
      "Epoch:  98 Step:   134 /   793 Train loss: 0.02985506\r\n",
      "Epoch:  98 Step:   135 /   793 Train loss: 0.03050400\r\n",
      "Epoch:  98 Step:   136 /   793 Train loss: 0.01772183\r\n",
      "Epoch:  98 Step:   137 /   793 Train loss: 0.01583857\r\n",
      "Epoch:  98 Step:   138 /   793 Train loss: 0.02317753\r\n",
      "Epoch:  98 Step:   139 /   793 Train loss: 0.02636514\r\n",
      "Epoch:  98 Step:   140 /   793 Train loss: 0.03072258\r\n",
      "Epoch:  98 Step:   141 /   793 Train loss: 0.02004844\r\n",
      "Epoch:  98 Step:   142 /   793 Train loss: 0.02704139\r\n",
      "Epoch:  98 Step:   143 /   793 Train loss: 0.02975679\r\n",
      "Epoch:  98 Step:   144 /   793 Train loss: 0.01866537\r\n",
      "Epoch:  98 Step:   145 /   793 Train loss: 0.01976257\r\n",
      "Epoch:  98 Step:   146 /   793 Train loss: 0.03009244\r\n",
      "Epoch:  98 Step:   147 /   793 Train loss: 0.02273046\r\n",
      "Epoch:  98 Step:   148 /   793 Train loss: 0.02378659\r\n",
      "Epoch:  98 Step:   149 /   793 Train loss: 0.01350502\r\n",
      "Epoch:  98 Step:   150 /   793 Train loss: 0.02629166\r\n",
      "Epoch:  98 Step:   151 /   793 Train loss: 0.01368446\r\n",
      "Epoch:  98 Step:   152 /   793 Train loss: 0.02328576\r\n",
      "Epoch:  98 Step:   153 /   793 Train loss: 0.01856912\r\n",
      "Epoch:  98 Step:   154 /   793 Train loss: 0.02761331\r\n",
      "Epoch:  98 Step:   155 /   793 Train loss: 0.02523541\r\n",
      "Epoch:  98 Step:   156 /   793 Train loss: 0.02545277\r\n",
      "Epoch:  98 Step:   157 /   793 Train loss: 0.02604846\r\n",
      "Epoch:  98 Step:   158 /   793 Train loss: 0.02124106\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  98 Step:   159 /   793 Train loss: 0.03168998\r\n",
      "Epoch:  98 Step:   160 /   793 Train loss: 0.03486776\r\n",
      "Epoch:  98 Step:   161 /   793 Train loss: 0.03018448\r\n",
      "Epoch:  98 Step:   162 /   793 Train loss: 0.01901200\r\n",
      "Epoch:  98 Step:   163 /   793 Train loss: 0.01724231\r\n",
      "Epoch:  98 Step:   164 /   793 Train loss: 0.03246380\r\n",
      "Epoch:  98 Step:   165 /   793 Train loss: 0.02447593\r\n",
      "Epoch:  98 Step:   166 /   793 Train loss: 0.02972795\r\n",
      "Epoch:  98 Step:   167 /   793 Train loss: 0.03447410\r\n",
      "Epoch:  98 Step:   168 /   793 Train loss: 0.01809468\r\n",
      "Epoch:  98 Step:   169 /   793 Train loss: 0.02916947\r\n",
      "Epoch:  98 Step:   170 /   793 Train loss: 0.02505578\r\n",
      "Epoch:  98 Step:   171 /   793 Train loss: 0.01975130\r\n",
      "Epoch:  98 Step:   172 /   793 Train loss: 0.02848486\r\n",
      "Epoch:  98 Step:   173 /   793 Train loss: 0.02351438\r\n",
      "Epoch:  98 Step:   174 /   793 Train loss: 0.02115023\r\n",
      "Epoch:  98 Step:   175 /   793 Train loss: 0.01928033\r\n",
      "Epoch:  98 Step:   176 /   793 Train loss: 0.02026363\r\n",
      "Epoch:  98 Step:   177 /   793 Train loss: 0.04422211\r\n",
      "Epoch:  98 Step:   178 /   793 Train loss: 0.02586443\r\n",
      "Epoch:  98 Step:   179 /   793 Train loss: 0.02535016\r\n",
      "Epoch:  98 Step:   180 /   793 Train loss: 0.01966253\r\n",
      "Epoch:  98 Step:   181 /   793 Train loss: 0.02609757\r\n",
      "Epoch:  98 Step:   182 /   793 Train loss: 0.02052630\r\n",
      "Epoch:  98 Step:   183 /   793 Train loss: 0.01582006\r\n",
      "Epoch:  98 Step:   184 /   793 Train loss: 0.01953521\r\n",
      "Epoch:  98 Step:   185 /   793 Train loss: 0.02963801\r\n",
      "Epoch:  98 Step:   186 /   793 Train loss: 0.01722537\r\n",
      "Epoch:  98 Step:   187 /   793 Train loss: 0.01439280\r\n",
      "Epoch:  98 Step:   188 /   793 Train loss: 0.02181630\r\n",
      "Epoch:  98 Step:   189 /   793 Train loss: 0.02472131\r\n",
      "Epoch:  98 Step:   190 /   793 Train loss: 0.01790199\r\n",
      "Epoch:  98 Step:   191 /   793 Train loss: 0.03844513\r\n",
      "Epoch:  98 Step:   192 /   793 Train loss: 0.02959588\r\n",
      "Epoch:  98 Step:   193 /   793 Train loss: 0.03419891\r\n",
      "Epoch:  98 Step:   194 /   793 Train loss: 0.01710635\r\n",
      "Epoch:  98 Step:   195 /   793 Train loss: 0.02728936\r\n",
      "Epoch:  98 Step:   196 /   793 Train loss: 0.02424272\r\n",
      "Epoch:  98 Step:   197 /   793 Train loss: 0.03049760\r\n",
      "Epoch:  98 Step:   198 /   793 Train loss: 0.02385748\r\n",
      "Epoch:  98 Step:   199 /   793 Train loss: 0.01329094\r\n",
      "Epoch:  98 Step:   200 /   793 Train loss: 0.02779686\r\n",
      "Epoch:  98 Step:   201 /   793 Train loss: 0.02516744\r\n",
      "Epoch:  98 Step:   202 /   793 Train loss: 0.03100170\r\n",
      "Epoch:  98 Step:   203 /   793 Train loss: 0.02110053\r\n",
      "Epoch:  98 Step:   204 /   793 Train loss: 0.01820502\r\n",
      "Epoch:  98 Step:   205 /   793 Train loss: 0.02242320\r\n",
      "Epoch:  98 Step:   206 /   793 Train loss: 0.01858358\r\n",
      "Epoch:  98 Step:   207 /   793 Train loss: 0.01129339\r\n",
      "Epoch:  98 Step:   208 /   793 Train loss: 0.02179230\r\n",
      "Epoch:  98 Step:   209 /   793 Train loss: 0.02453323\r\n",
      "Epoch:  98 Step:   210 /   793 Train loss: 0.01596254\r\n",
      "Epoch:  98 Step:   211 /   793 Train loss: 0.02168805\r\n",
      "Epoch:  98 Step:   212 /   793 Train loss: 0.02118398\r\n",
      "Epoch:  98 Step:   213 /   793 Train loss: 0.02818586\r\n",
      "Epoch:  98 Step:   214 /   793 Train loss: 0.02607711\r\n",
      "Epoch:  98 Step:   215 /   793 Train loss: 0.03162564\r\n",
      "Epoch:  98 Step:   216 /   793 Train loss: 0.02528382\r\n",
      "Epoch:  98 Step:   217 /   793 Train loss: 0.01866980\r\n",
      "Epoch:  98 Step:   218 /   793 Train loss: 0.01679088\r\n",
      "Epoch:  98 Step:   219 /   793 Train loss: 0.02899491\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  98 Step:   220 /   793 Train loss: 0.01776130\r\n",
      "Epoch:  98 Step:   221 /   793 Train loss: 0.02056897\r\n",
      "Epoch:  98 Step:   222 /   793 Train loss: 0.02139411\r\n",
      "Epoch:  98 Step:   223 /   793 Train loss: 0.01570433\r\n",
      "Epoch:  98 Step:   224 /   793 Train loss: 0.02603688\r\n",
      "Epoch:  98 Step:   225 /   793 Train loss: 0.03417299\r\n",
      "Epoch:  98 Step:   226 /   793 Train loss: 0.03179070\r\n",
      "Epoch:  98 Step:   227 /   793 Train loss: 0.02092898\r\n",
      "Epoch:  98 Step:   228 /   793 Train loss: 0.01111096\r\n",
      "Epoch:  98 Step:   229 /   793 Train loss: 0.02362281\r\n",
      "Epoch:  98 Step:   230 /   793 Train loss: 0.02541091\r\n",
      "Epoch:  98 Step:   231 /   793 Train loss: 0.02881864\r\n",
      "Epoch:  98 Step:   232 /   793 Train loss: 0.03495349\r\n",
      "Epoch:  98 Step:   233 /   793 Train loss: 0.02548688\r\n",
      "Epoch:  98 Step:   234 /   793 Train loss: 0.02867661\r\n",
      "Epoch:  98 Step:   235 /   793 Train loss: 0.01903520\r\n",
      "Epoch:  98 Step:   236 /   793 Train loss: 0.02127368\r\n",
      "Epoch:  98 Step:   237 /   793 Train loss: 0.03774584\r\n",
      "Epoch:  98 Step:   238 /   793 Train loss: 0.01294413\r\n",
      "Epoch:  98 Step:   239 /   793 Train loss: 0.02895229\r\n",
      "Epoch:  98 Step:   240 /   793 Train loss: 0.02249965\r\n",
      "Epoch:  98 Step:   241 /   793 Train loss: 0.02296710\r\n",
      "Epoch:  98 Step:   242 /   793 Train loss: 0.03206602\r\n",
      "Epoch:  98 Step:   243 /   793 Train loss: 0.02762931\r\n",
      "Epoch:  98 Step:   244 /   793 Train loss: 0.02195425\r\n",
      "Epoch:  98 Step:   245 /   793 Train loss: 0.01738095\r\n",
      "Epoch:  98 Step:   246 /   793 Train loss: 0.02713928\r\n",
      "Epoch:  98 Step:   247 /   793 Train loss: 0.03405030\r\n",
      "Epoch:  98 Step:   248 /   793 Train loss: 0.02435476\r\n",
      "Epoch:  98 Step:   249 /   793 Train loss: 0.02008308\r\n",
      "Epoch:  98 Step:   250 /   793 Train loss: 0.01933634\r\n",
      "Epoch:  98 Step:   251 /   793 Train loss: 0.01526866\r\n",
      "Epoch:  98 Step:   252 /   793 Train loss: 0.02737305\r\n",
      "Epoch:  98 Step:   253 /   793 Train loss: 0.02248007\r\n",
      "Epoch:  98 Step:   254 /   793 Train loss: 0.01764069\r\n",
      "Epoch:  98 Step:   255 /   793 Train loss: 0.02373083\r\n",
      "Epoch:  98 Step:   256 /   793 Train loss: 0.03147167\r\n",
      "Epoch:  98 Step:   257 /   793 Train loss: 0.02373474\r\n",
      "Epoch:  98 Step:   258 /   793 Train loss: 0.02163160\r\n",
      "Epoch:  98 Step:   259 /   793 Train loss: 0.01400708\r\n",
      "Epoch:  98 Step:   260 /   793 Train loss: 0.03289461\r\n",
      "Epoch:  98 Step:   261 /   793 Train loss: 0.01942207\r\n",
      "Epoch:  98 Step:   262 /   793 Train loss: 0.02138310\r\n",
      "Epoch:  98 Step:   263 /   793 Train loss: 0.03114747\r\n",
      "Epoch:  98 Step:   264 /   793 Train loss: 0.02207142\r\n",
      "Epoch:  98 Step:   265 /   793 Train loss: 0.03256261\r\n",
      "Epoch:  98 Step:   266 /   793 Train loss: 0.03146169\r\n",
      "Epoch:  98 Step:   267 /   793 Train loss: 0.01267410\r\n",
      "Epoch:  98 Step:   268 /   793 Train loss: 0.02500650\r\n",
      "Epoch:  98 Step:   269 /   793 Train loss: 0.02494252\r\n",
      "Epoch:  98 Step:   270 /   793 Train loss: 0.02893198\r\n",
      "Epoch:  98 Step:   271 /   793 Train loss: 0.03240544\r\n",
      "Epoch:  98 Step:   272 /   793 Train loss: 0.02223967\r\n",
      "Epoch:  98 Step:   273 /   793 Train loss: 0.02657664\r\n",
      "Epoch:  98 Step:   274 /   793 Train loss: 0.01945046\r\n",
      "Epoch:  98 Step:   275 /   793 Train loss: 0.02744294\r\n",
      "Epoch:  98 Step:   276 /   793 Train loss: 0.01592399\r\n",
      "Epoch:  98 Step:   277 /   793 Train loss: 0.01794840\r\n",
      "Epoch:  98 Step:   278 /   793 Train loss: 0.02449015\r\n",
      "Epoch:  98 Step:   279 /   793 Train loss: 0.01634695\r\n",
      "Epoch:  98 Step:   280 /   793 Train loss: 0.02562175\r\n",
      "Epoch:  98 Step:   281 /   793 Train loss: 0.02458030\r\n",
      "Epoch:  98 Step:   282 /   793 Train loss: 0.03225561\r\n",
      "Epoch:  98 Step:   283 /   793 Train loss: 0.02419718\r\n",
      "Epoch:  98 Step:   284 /   793 Train loss: 0.01821399\r\n",
      "Epoch:  98 Step:   285 /   793 Train loss: 0.02204493\r\n",
      "Epoch:  98 Step:   286 /   793 Train loss: 0.02816758\r\n",
      "Epoch:  98 Step:   287 /   793 Train loss: 0.01891731\r\n",
      "Epoch:  98 Step:   288 /   793 Train loss: 0.02483171\r\n",
      "Epoch:  98 Step:   289 /   793 Train loss: 0.02075788\r\n",
      "Epoch:  98 Step:   290 /   793 Train loss: 0.01577182\r\n",
      "Epoch:  98 Step:   291 /   793 Train loss: 0.02877062\r\n",
      "Epoch:  98 Step:   292 /   793 Train loss: 0.02731142\r\n",
      "Epoch:  98 Step:   293 /   793 Train loss: 0.02254778\r\n",
      "Epoch:  98 Step:   294 /   793 Train loss: 0.02427241\r\n",
      "Epoch:  98 Step:   295 /   793 Train loss: 0.01355375\r\n",
      "Epoch:  98 Step:   296 /   793 Train loss: 0.02281958\r\n",
      "Epoch:  98 Step:   297 /   793 Train loss: 0.03950392\r\n",
      "Epoch:  98 Step:   298 /   793 Train loss: 0.02862506\r\n",
      "Epoch:  98 Step:   299 /   793 Train loss: 0.01730879\r\n",
      "Epoch:  98 Step:   300 /   793 Train loss: 0.01194508\r\n",
      "Epoch:  98 Step:   301 /   793 Train loss: 0.02966553\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  98 Step:   302 /   793 Train loss: 0.03078577\r\n",
      "Epoch:  98 Step:   303 /   793 Train loss: 0.02072046\r\n",
      "Epoch:  98 Step:   304 /   793 Train loss: 0.02703000\r\n",
      "Epoch:  98 Step:   305 /   793 Train loss: 0.02181618\r\n",
      "Epoch:  98 Step:   306 /   793 Train loss: 0.02806743\r\n",
      "Epoch:  98 Step:   307 /   793 Train loss: 0.02555179\r\n",
      "Epoch:  98 Step:   308 /   793 Train loss: 0.01239449\r\n",
      "Epoch:  98 Step:   309 /   793 Train loss: 0.02031667\r\n",
      "Epoch:  98 Step:   310 /   793 Train loss: 0.01779490\r\n",
      "Epoch:  98 Step:   311 /   793 Train loss: 0.02169142\r\n",
      "Epoch:  98 Step:   312 /   793 Train loss: 0.03133805\r\n",
      "Epoch:  98 Step:   313 /   793 Train loss: 0.03375034\r\n",
      "Epoch:  98 Step:   314 /   793 Train loss: 0.03094021\r\n",
      "Epoch:  98 Step:   315 /   793 Train loss: 0.03386467\r\n",
      "Epoch:  98 Step:   316 /   793 Train loss: 0.01577221\r\n",
      "Epoch:  98 Step:   317 /   793 Train loss: 0.03055291\r\n",
      "Epoch:  98 Step:   318 /   793 Train loss: 0.02573075\r\n",
      "Epoch:  98 Step:   319 /   793 Train loss: 0.02967605\r\n",
      "Epoch:  98 Step:   320 /   793 Train loss: 0.02652265\r\n",
      "Epoch:  98 Step:   321 /   793 Train loss: 0.02209912\r\n",
      "Epoch:  98 Step:   322 /   793 Train loss: 0.01811618\r\n",
      "Epoch:  98 Step:   323 /   793 Train loss: 0.02656613\r\n",
      "Epoch:  98 Step:   324 /   793 Train loss: 0.03584955\r\n",
      "Epoch:  98 Step:   325 /   793 Train loss: 0.02284901\r\n",
      "Epoch:  98 Step:   326 /   793 Train loss: 0.01575691\r\n",
      "Epoch:  98 Step:   327 /   793 Train loss: 0.02290032\r\n",
      "Epoch:  98 Step:   328 /   793 Train loss: 0.02989507\r\n",
      "Epoch:  98 Step:   329 /   793 Train loss: 0.03024104\r\n",
      "Epoch:  98 Step:   330 /   793 Train loss: 0.02785320\r\n",
      "Epoch:  98 Step:   331 /   793 Train loss: 0.03043269\r\n",
      "Epoch:  98 Step:   332 /   793 Train loss: 0.02301197\r\n",
      "Epoch:  98 Step:   333 /   793 Train loss: 0.02246404\r\n",
      "Epoch:  98 Step:   334 /   793 Train loss: 0.03594033\r\n",
      "Epoch:  98 Step:   335 /   793 Train loss: 0.01395278\r\n",
      "Epoch:  98 Step:   336 /   793 Train loss: 0.01679323\r\n",
      "Epoch:  98 Step:   337 /   793 Train loss: 0.02544855\r\n",
      "Epoch:  98 Step:   338 /   793 Train loss: 0.02478204\r\n",
      "Epoch:  98 Step:   339 /   793 Train loss: 0.02213097\r\n",
      "Epoch:  98 Step:   340 /   793 Train loss: 0.02182277\r\n",
      "Epoch:  98 Step:   341 /   793 Train loss: 0.03164409\r\n",
      "Epoch:  98 Step:   342 /   793 Train loss: 0.02175075\r\n",
      "Epoch:  98 Step:   343 /   793 Train loss: 0.03786612\r\n",
      "Epoch:  98 Step:   344 /   793 Train loss: 0.02181392\r\n",
      "Epoch:  98 Step:   345 /   793 Train loss: 0.02176381\r\n",
      "Epoch:  98 Step:   346 /   793 Train loss: 0.03239037\r\n",
      "Epoch:  98 Step:   347 /   793 Train loss: 0.02734848\r\n",
      "Epoch:  98 Step:   348 /   793 Train loss: 0.01945640\r\n",
      "Epoch:  98 Step:   349 /   793 Train loss: 0.03110909\r\n",
      "Epoch:  98 Step:   350 /   793 Train loss: 0.01536786\r\n",
      "Epoch:  98 Step:   351 /   793 Train loss: 0.01809759\r\n",
      "Epoch:  98 Step:   352 /   793 Train loss: 0.02117589\r\n",
      "Epoch:  98 Step:   353 /   793 Train loss: 0.01814641\r\n",
      "Epoch:  98 Step:   354 /   793 Train loss: 0.02995095\r\n",
      "Epoch:  98 Step:   355 /   793 Train loss: 0.03762781\r\n",
      "Epoch:  98 Step:   356 /   793 Train loss: 0.01513114\r\n",
      "Epoch:  98 Step:   357 /   793 Train loss: 0.02083951\r\n",
      "Epoch:  98 Step:   358 /   793 Train loss: 0.02935185\r\n",
      "Epoch:  98 Step:   359 /   793 Train loss: 0.01952593\r\n",
      "Epoch:  98 Step:   360 /   793 Train loss: 0.02447284\r\n",
      "Epoch:  98 Step:   361 /   793 Train loss: 0.02796539\r\n",
      "Epoch:  98 Step:   362 /   793 Train loss: 0.01596438\r\n",
      "Epoch:  98 Step:   363 /   793 Train loss: 0.02757528\r\n",
      "Epoch:  98 Step:   364 /   793 Train loss: 0.02569069\r\n",
      "Epoch:  98 Step:   365 /   793 Train loss: 0.02789304\r\n",
      "Epoch:  98 Step:   366 /   793 Train loss: 0.02424332\r\n",
      "Epoch:  98 Step:   367 /   793 Train loss: 0.02095004\r\n",
      "Epoch:  98 Step:   368 /   793 Train loss: 0.03446838\r\n",
      "Epoch:  98 Step:   369 /   793 Train loss: 0.02046335\r\n",
      "Epoch:  98 Step:   370 /   793 Train loss: 0.02501459\r\n",
      "Epoch:  98 Step:   371 /   793 Train loss: 0.01850309\r\n",
      "Epoch:  98 Step:   372 /   793 Train loss: 0.02046937\r\n",
      "Epoch:  98 Step:   373 /   793 Train loss: 0.02399130\r\n",
      "Epoch:  98 Step:   374 /   793 Train loss: 0.03808663\r\n",
      "Epoch:  98 Step:   375 /   793 Train loss: 0.02008422\r\n",
      "Epoch:  98 Step:   376 /   793 Train loss: 0.02943189\r\n",
      "Epoch:  98 Step:   377 /   793 Train loss: 0.02931930\r\n",
      "Epoch:  98 Step:   378 /   793 Train loss: 0.02712606\r\n",
      "Epoch:  98 Step:   379 /   793 Train loss: 0.02226558\r\n",
      "Epoch:  98 Step:   380 /   793 Train loss: 0.02816430\r\n",
      "Epoch:  98 Step:   381 /   793 Train loss: 0.02821952\r\n",
      "Epoch:  98 Step:   382 /   793 Train loss: 0.03435794\r\n",
      "Epoch:  98 Step:   383 /   793 Train loss: 0.02061808\r\n",
      "Epoch:  98 Step:   384 /   793 Train loss: 0.02054910\r\n",
      "Epoch:  98 Step:   385 /   793 Train loss: 0.02136591\r\n",
      "Epoch:  98 Step:   386 /   793 Train loss: 0.02258566\r\n",
      "Epoch:  98 Step:   387 /   793 Train loss: 0.02436564\r\n",
      "Epoch:  98 Step:   388 /   793 Train loss: 0.01591801\r\n",
      "Epoch:  98 Step:   389 /   793 Train loss: 0.01894980\r\n",
      "Epoch:  98 Step:   390 /   793 Train loss: 0.02737292\r\n",
      "Epoch:  98 Step:   391 /   793 Train loss: 0.03206692\r\n",
      "Epoch:  98 Step:   392 /   793 Train loss: 0.04060706\r\n",
      "Epoch:  98 Step:   393 /   793 Train loss: 0.01557331\r\n",
      "Epoch:  98 Step:   394 /   793 Train loss: 0.02966643\r\n",
      "Epoch:  98 Step:   395 /   793 Train loss: 0.02268581\r\n",
      "Epoch:  98 Step:   396 /   793 Train loss: 0.02264815\r\n",
      "Epoch:  98 Step:   397 /   793 Train loss: 0.01597232\r\n",
      "Epoch:  98 Step:   398 /   793 Train loss: 0.02737020\r\n",
      "Epoch:  98 Step:   399 /   793 Train loss: 0.02735819\r\n",
      "Epoch:  98 Step:   400 /   793 Train loss: 0.02497727\r\n",
      "Epoch:  98 Step:   401 /   793 Train loss: 0.02049802\r\n",
      "Epoch:  98 Step:   402 /   793 Train loss: 0.02956123\r\n",
      "Epoch:  98 Step:   403 /   793 Train loss: 0.03472808\r\n",
      "Epoch:  98 Step:   404 /   793 Train loss: 0.02557713\r\n",
      "Epoch:  98 Step:   405 /   793 Train loss: 0.03039562\r\n",
      "Epoch:  98 Step:   406 /   793 Train loss: 0.02117239\r\n",
      "Epoch:  98 Step:   407 /   793 Train loss: 0.03574927\r\n",
      "Epoch:  98 Step:   408 /   793 Train loss: 0.02629806\r\n",
      "Epoch:  98 Step:   409 /   793 Train loss: 0.01680107\r\n",
      "Epoch:  98 Step:   410 /   793 Train loss: 0.02273317\r\n",
      "Epoch:  98 Step:   411 /   793 Train loss: 0.02539970\r\n",
      "Epoch:  98 Step:   412 /   793 Train loss: 0.01972074\r\n",
      "Epoch:  98 Step:   413 /   793 Train loss: 0.02804382\r\n",
      "Epoch:  98 Step:   414 /   793 Train loss: 0.02209401\r\n",
      "Epoch:  98 Step:   415 /   793 Train loss: 0.01572437\r\n",
      "Epoch:  98 Step:   416 /   793 Train loss: 0.01755070\r\n",
      "Epoch:  98 Step:   417 /   793 Train loss: 0.02443615\r\n",
      "Epoch:  98 Step:   418 /   793 Train loss: 0.02536700\r\n",
      "Epoch:  98 Step:   419 /   793 Train loss: 0.02028687\r\n",
      "Epoch:  98 Step:   420 /   793 Train loss: 0.01787066\r\n",
      "Epoch:  98 Step:   421 /   793 Train loss: 0.02279629\r\n",
      "Epoch:  98 Step:   422 /   793 Train loss: 0.02742300\r\n",
      "Epoch:  98 Step:   423 /   793 Train loss: 0.01726152\r\n",
      "Epoch:  98 Step:   424 /   793 Train loss: 0.01874504\r\n",
      "Epoch:  98 Step:   425 /   793 Train loss: 0.02076519\r\n",
      "Epoch:  98 Step:   426 /   793 Train loss: 0.02275410\r\n",
      "Epoch:  98 Step:   427 /   793 Train loss: 0.02409417\r\n",
      "Epoch:  98 Step:   428 /   793 Train loss: 0.01113203\r\n",
      "Epoch:  98 Step:   429 /   793 Train loss: 0.02670397\r\n",
      "Epoch:  98 Step:   430 /   793 Train loss: 0.03071057\r\n",
      "Epoch:  98 Step:   431 /   793 Train loss: 0.02986547\r\n",
      "Epoch:  98 Step:   432 /   793 Train loss: 0.03268133\r\n",
      "Epoch:  98 Step:   433 /   793 Train loss: 0.01943056\r\n",
      "Epoch:  98 Step:   434 /   793 Train loss: 0.03132866\r\n",
      "Epoch:  98 Step:   435 /   793 Train loss: 0.03284740\r\n",
      "Epoch:  98 Step:   436 /   793 Train loss: 0.02775682\r\n",
      "Epoch:  98 Step:   437 /   793 Train loss: 0.01703107\r\n",
      "Epoch:  98 Step:   438 /   793 Train loss: 0.03033627\r\n",
      "Epoch:  98 Step:   439 /   793 Train loss: 0.01444015\r\n",
      "Epoch:  98 Step:   440 /   793 Train loss: 0.01887673\r\n",
      "Epoch:  98 Step:   441 /   793 Train loss: 0.03300684\r\n",
      "Epoch:  98 Step:   442 /   793 Train loss: 0.01326714\r\n",
      "Epoch:  98 Step:   443 /   793 Train loss: 0.01611095\r\n",
      "Epoch:  98 Step:   444 /   793 Train loss: 0.02170455\r\n",
      "Epoch:  98 Step:   445 /   793 Train loss: 0.03308983\r\n",
      "Epoch:  98 Step:   446 /   793 Train loss: 0.01720325\r\n",
      "Epoch:  98 Step:   447 /   793 Train loss: 0.02585875\r\n",
      "Epoch:  98 Step:   448 /   793 Train loss: 0.02725739\r\n",
      "Epoch:  98 Step:   449 /   793 Train loss: 0.01367716\r\n",
      "Epoch:  98 Step:   450 /   793 Train loss: 0.02488394\r\n",
      "Epoch:  98 Step:   451 /   793 Train loss: 0.02852298\r\n",
      "Epoch:  98 Step:   452 /   793 Train loss: 0.02193978\r\n",
      "Epoch:  98 Step:   453 /   793 Train loss: 0.02906044\r\n",
      "Epoch:  98 Step:   454 /   793 Train loss: 0.02624101\r\n",
      "Epoch:  98 Step:   455 /   793 Train loss: 0.02678410\r\n",
      "Epoch:  98 Step:   456 /   793 Train loss: 0.02657044\r\n",
      "Epoch:  98 Step:   457 /   793 Train loss: 0.02264260\r\n",
      "Epoch:  98 Step:   458 /   793 Train loss: 0.02502857\r\n",
      "Epoch:  98 Step:   459 /   793 Train loss: 0.02342838\r\n",
      "Epoch:  98 Step:   460 /   793 Train loss: 0.02874281\r\n",
      "Epoch:  98 Step:   461 /   793 Train loss: 0.02864205\r\n",
      "Epoch:  98 Step:   462 /   793 Train loss: 0.01638802\r\n",
      "Epoch:  98 Step:   463 /   793 Train loss: 0.03963965\r\n",
      "Epoch:  98 Step:   464 /   793 Train loss: 0.02764075\r\n",
      "Epoch:  98 Step:   465 /   793 Train loss: 0.02624231\r\n",
      "Epoch:  98 Step:   466 /   793 Train loss: 0.01870856\r\n",
      "Epoch:  98 Step:   467 /   793 Train loss: 0.01830335\r\n",
      "Epoch:  98 Step:   468 /   793 Train loss: 0.01886768\r\n",
      "Epoch:  98 Step:   469 /   793 Train loss: 0.02310727\r\n",
      "Epoch:  98 Step:   470 /   793 Train loss: 0.01494078\r\n",
      "Epoch:  98 Step:   471 /   793 Train loss: 0.01884976\r\n",
      "Epoch:  98 Step:   472 /   793 Train loss: 0.02800628\r\n",
      "Epoch:  98 Step:   473 /   793 Train loss: 0.02061062\r\n",
      "Epoch:  98 Step:   474 /   793 Train loss: 0.01433664\r\n",
      "Epoch:  98 Step:   475 /   793 Train loss: 0.01193975\r\n",
      "Epoch:  98 Step:   476 /   793 Train loss: 0.01488131\r\n",
      "Epoch:  98 Step:   477 /   793 Train loss: 0.02630877\r\n",
      "Epoch:  98 Step:   478 /   793 Train loss: 0.02593753\r\n",
      "Epoch:  98 Step:   479 /   793 Train loss: 0.01625048\r\n",
      "Epoch:  98 Step:   480 /   793 Train loss: 0.02721991\r\n",
      "Epoch:  98 Step:   481 /   793 Train loss: 0.01955097\r\n",
      "Epoch:  98 Step:   482 /   793 Train loss: 0.03261963\r\n",
      "Epoch:  98 Step:   483 /   793 Train loss: 0.02575652\r\n",
      "Epoch:  98 Step:   484 /   793 Train loss: 0.01882516\r\n",
      "Epoch:  98 Step:   485 /   793 Train loss: 0.02386759\r\n",
      "Epoch:  98 Step:   486 /   793 Train loss: 0.02386504\r\n",
      "Epoch:  98 Step:   487 /   793 Train loss: 0.01121545\r\n",
      "Epoch:  98 Step:   488 /   793 Train loss: 0.03933147\r\n",
      "Epoch:  98 Step:   489 /   793 Train loss: 0.02546644\r\n",
      "Epoch:  98 Step:   490 /   793 Train loss: 0.01074497\r\n",
      "Epoch:  98 Step:   491 /   793 Train loss: 0.02776302\r\n",
      "Epoch:  98 Step:   492 /   793 Train loss: 0.02226078\r\n",
      "Epoch:  98 Step:   493 /   793 Train loss: 0.02414613\r\n",
      "Epoch:  98 Step:   494 /   793 Train loss: 0.03713289\r\n",
      "Epoch:  98 Step:   495 /   793 Train loss: 0.02006494\r\n",
      "Epoch:  98 Step:   496 /   793 Train loss: 0.01549415\r\n",
      "Epoch:  98 Step:   497 /   793 Train loss: 0.01759398\r\n",
      "Epoch:  98 Step:   498 /   793 Train loss: 0.04642456\r\n",
      "Epoch:  98 Step:   499 /   793 Train loss: 0.02739051\r\n",
      "Epoch:  98 Step:   500 /   793 Train loss: 0.01912709\r\n",
      "Epoch:  98 Step:   501 /   793 Train loss: 0.02906367\r\n",
      "Epoch:  98 Step:   502 /   793 Train loss: 0.02599494\r\n",
      "Epoch:  98 Step:   503 /   793 Train loss: 0.02500710\r\n",
      "Epoch:  98 Step:   504 /   793 Train loss: 0.01457014\r\n",
      "Epoch:  98 Step:   505 /   793 Train loss: 0.02605676\r\n",
      "Epoch:  98 Step:   506 /   793 Train loss: 0.03137796\r\n",
      "Epoch:  98 Step:   507 /   793 Train loss: 0.01715395\r\n",
      "Epoch:  98 Step:   508 /   793 Train loss: 0.03622019\r\n",
      "Epoch:  98 Step:   509 /   793 Train loss: 0.02465997\r\n",
      "Epoch:  98 Step:   510 /   793 Train loss: 0.02773416\r\n",
      "Epoch:  98 Step:   511 /   793 Train loss: 0.02342396\r\n",
      "Epoch:  98 Step:   512 /   793 Train loss: 0.02522730\r\n",
      "Epoch:  98 Step:   513 /   793 Train loss: 0.02003621\r\n",
      "Epoch:  98 Step:   514 /   793 Train loss: 0.02699018\r\n",
      "Epoch:  98 Step:   515 /   793 Train loss: 0.01612525\r\n",
      "Epoch:  98 Step:   516 /   793 Train loss: 0.02583766\r\n",
      "Epoch:  98 Step:   517 /   793 Train loss: 0.03015406\r\n",
      "Epoch:  98 Step:   518 /   793 Train loss: 0.02120085\r\n",
      "Epoch:  98 Step:   519 /   793 Train loss: 0.02982889\r\n",
      "Epoch:  98 Step:   520 /   793 Train loss: 0.03415263\r\n",
      "Epoch:  98 Step:   521 /   793 Train loss: 0.02063799\r\n",
      "Epoch:  98 Step:   522 /   793 Train loss: 0.03472182\r\n",
      "Epoch:  98 Step:   523 /   793 Train loss: 0.03360969\r\n",
      "Epoch:  98 Step:   524 /   793 Train loss: 0.03192856\r\n",
      "Epoch:  98 Step:   525 /   793 Train loss: 0.02103247\r\n",
      "Epoch:  98 Step:   526 /   793 Train loss: 0.02385550\r\n",
      "Epoch:  98 Step:   527 /   793 Train loss: 0.02533486\r\n",
      "Epoch:  98 Step:   528 /   793 Train loss: 0.02740592\r\n",
      "Epoch:  98 Step:   529 /   793 Train loss: 0.01647937\r\n",
      "Epoch:  98 Step:   530 /   793 Train loss: 0.01753423\r\n",
      "Epoch:  98 Step:   531 /   793 Train loss: 0.02775588\r\n",
      "Epoch:  98 Step:   532 /   793 Train loss: 0.01570700\r\n",
      "Epoch:  98 Step:   533 /   793 Train loss: 0.02275848\r\n",
      "Epoch:  98 Step:   534 /   793 Train loss: 0.00858529\r\n",
      "Epoch:  98 Step:   535 /   793 Train loss: 0.00947327\r\n",
      "Epoch:  98 Step:   536 /   793 Train loss: 0.03301361\r\n",
      "Epoch:  98 Step:   537 /   793 Train loss: 0.03047794\r\n",
      "Epoch:  98 Step:   538 /   793 Train loss: 0.03121321\r\n",
      "Epoch:  98 Step:   539 /   793 Train loss: 0.01987894\r\n",
      "Epoch:  98 Step:   540 /   793 Train loss: 0.01304812\r\n",
      "Epoch:  98 Step:   541 /   793 Train loss: 0.02401161\r\n",
      "Epoch:  98 Step:   542 /   793 Train loss: 0.03074577\r\n",
      "Epoch:  98 Step:   543 /   793 Train loss: 0.02583064\r\n",
      "Epoch:  98 Step:   544 /   793 Train loss: 0.02668895\r\n",
      "Epoch:  98 Step:   545 /   793 Train loss: 0.02547515\r\n",
      "Epoch:  98 Step:   546 /   793 Train loss: 0.02936108\r\n",
      "Epoch:  98 Step:   547 /   793 Train loss: 0.01784188\r\n",
      "Epoch:  98 Step:   548 /   793 Train loss: 0.02482480\r\n",
      "Epoch:  98 Step:   549 /   793 Train loss: 0.02124199\r\n",
      "Epoch:  98 Step:   550 /   793 Train loss: 0.01932530\r\n",
      "Epoch:  98 Step:   551 /   793 Train loss: 0.01367498\r\n",
      "Epoch:  98 Step:   552 /   793 Train loss: 0.03507840\r\n",
      "Epoch:  98 Step:   553 /   793 Train loss: 0.02309173\r\n",
      "Epoch:  98 Step:   554 /   793 Train loss: 0.02758230\r\n",
      "Epoch:  98 Step:   555 /   793 Train loss: 0.02308243\r\n",
      "Epoch:  98 Step:   556 /   793 Train loss: 0.03163550\r\n",
      "Epoch:  98 Step:   557 /   793 Train loss: 0.01915880\r\n",
      "Epoch:  98 Step:   558 /   793 Train loss: 0.02424520\r\n",
      "Epoch:  98 Step:   559 /   793 Train loss: 0.02360442\r\n",
      "Epoch:  98 Step:   560 /   793 Train loss: 0.02868014\r\n",
      "Epoch:  98 Step:   561 /   793 Train loss: 0.02368509\r\n",
      "Epoch:  98 Step:   562 /   793 Train loss: 0.01402373\r\n",
      "Epoch:  98 Step:   563 /   793 Train loss: 0.01501718\r\n",
      "Epoch:  98 Step:   564 /   793 Train loss: 0.02888678\r\n",
      "Epoch:  98 Step:   565 /   793 Train loss: 0.02313273\r\n",
      "Epoch:  98 Step:   566 /   793 Train loss: 0.02657716\r\n",
      "Epoch:  98 Step:   567 /   793 Train loss: 0.03747655\r\n",
      "Epoch:  98 Step:   568 /   793 Train loss: 0.01975758\r\n",
      "Epoch:  98 Step:   569 /   793 Train loss: 0.02617950\r\n",
      "Epoch:  98 Step:   570 /   793 Train loss: 0.02471472\r\n",
      "Epoch:  98 Step:   571 /   793 Train loss: 0.03189147\r\n",
      "Epoch:  98 Step:   572 /   793 Train loss: 0.02350696\r\n",
      "Epoch:  98 Step:   573 /   793 Train loss: 0.01342931\r\n",
      "Epoch:  98 Step:   574 /   793 Train loss: 0.02627691\r\n",
      "Epoch:  98 Step:   575 /   793 Train loss: 0.04205168\r\n",
      "Epoch:  98 Step:   576 /   793 Train loss: 0.02932632\r\n",
      "Epoch:  98 Step:   577 /   793 Train loss: 0.02648209\r\n",
      "Epoch:  98 Step:   578 /   793 Train loss: 0.01864264\r\n",
      "Epoch:  98 Step:   579 /   793 Train loss: 0.03107548\r\n",
      "Epoch:  98 Step:   580 /   793 Train loss: 0.01777324\r\n",
      "Epoch:  98 Step:   581 /   793 Train loss: 0.02304236\r\n",
      "Epoch:  98 Step:   582 /   793 Train loss: 0.01859163\r\n",
      "Epoch:  98 Step:   583 /   793 Train loss: 0.03536236\r\n",
      "Epoch:  98 Step:   584 /   793 Train loss: 0.01534415\r\n",
      "Epoch:  98 Step:   585 /   793 Train loss: 0.01635265\r\n",
      "Epoch:  98 Step:   586 /   793 Train loss: 0.02059734\r\n",
      "Epoch:  98 Step:   587 /   793 Train loss: 0.03988848\r\n",
      "Epoch:  98 Step:   588 /   793 Train loss: 0.02273476\r\n",
      "Epoch:  98 Step:   589 /   793 Train loss: 0.01727723\r\n",
      "Epoch:  98 Step:   590 /   793 Train loss: 0.02704142\r\n",
      "Epoch:  98 Step:   591 /   793 Train loss: 0.01339435\r\n",
      "Epoch:  98 Step:   592 /   793 Train loss: 0.01863662\r\n",
      "Epoch:  98 Step:   593 /   793 Train loss: 0.02659715\r\n",
      "Epoch:  98 Step:   594 /   793 Train loss: 0.02405639\r\n",
      "Epoch:  98 Step:   595 /   793 Train loss: 0.01317055\r\n",
      "Epoch:  98 Step:   596 /   793 Train loss: 0.02405135\r\n",
      "Epoch:  98 Step:   597 /   793 Train loss: 0.01172143\r\n",
      "Epoch:  98 Step:   598 /   793 Train loss: 0.01546144\r\n",
      "Epoch:  98 Step:   599 /   793 Train loss: 0.02397696\r\n",
      "Epoch:  98 Step:   600 /   793 Train loss: 0.03730506\r\n",
      "Epoch:  98 Step:   601 /   793 Train loss: 0.02335903\r\n",
      "Epoch:  98 Step:   602 /   793 Train loss: 0.02820308\r\n",
      "Epoch:  98 Step:   603 /   793 Train loss: 0.01712733\r\n",
      "Epoch:  98 Step:   604 /   793 Train loss: 0.03731221\r\n",
      "Epoch:  98 Step:   605 /   793 Train loss: 0.01101873\r\n",
      "Epoch:  98 Step:   606 /   793 Train loss: 0.02748369\r\n",
      "Epoch:  98 Step:   607 /   793 Train loss: 0.03544084\r\n",
      "Epoch:  98 Step:   608 /   793 Train loss: 0.03568444\r\n",
      "Epoch:  98 Step:   609 /   793 Train loss: 0.02322723\r\n",
      "Epoch:  98 Step:   610 /   793 Train loss: 0.01976295\r\n",
      "Epoch:  98 Step:   611 /   793 Train loss: 0.02262675\r\n",
      "Epoch:  98 Step:   612 /   793 Train loss: 0.02755133\r\n",
      "Epoch:  98 Step:   613 /   793 Train loss: 0.02027882\r\n",
      "Epoch:  98 Step:   614 /   793 Train loss: 0.01961111\r\n",
      "Epoch:  98 Step:   615 /   793 Train loss: 0.02736954\r\n",
      "Epoch:  98 Step:   616 /   793 Train loss: 0.02005525\r\n",
      "Epoch:  98 Step:   617 /   793 Train loss: 0.02893474\r\n",
      "Epoch:  98 Step:   618 /   793 Train loss: 0.03561318\r\n",
      "Epoch:  98 Step:   619 /   793 Train loss: 0.02714466\r\n",
      "Epoch:  98 Step:   620 /   793 Train loss: 0.01902041\r\n",
      "Epoch:  98 Step:   621 /   793 Train loss: 0.02259854\r\n",
      "Epoch:  98 Step:   622 /   793 Train loss: 0.01667265\r\n",
      "Epoch:  98 Step:   623 /   793 Train loss: 0.02279252\r\n",
      "Epoch:  98 Step:   624 /   793 Train loss: 0.02154605\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  98 Step:   625 /   793 Train loss: 0.02644304\r\n",
      "Epoch:  98 Step:   626 /   793 Train loss: 0.02662714\r\n",
      "Epoch:  98 Step:   627 /   793 Train loss: 0.02684264\r\n",
      "Epoch:  98 Step:   628 /   793 Train loss: 0.02470654\r\n",
      "Epoch:  98 Step:   629 /   793 Train loss: 0.02039060\r\n",
      "Epoch:  98 Step:   630 /   793 Train loss: 0.02598905\r\n",
      "Epoch:  98 Step:   631 /   793 Train loss: 0.01268139\r\n",
      "Epoch:  98 Step:   632 /   793 Train loss: 0.02755878\r\n",
      "Epoch:  98 Step:   633 /   793 Train loss: 0.01425915\r\n",
      "Epoch:  98 Step:   634 /   793 Train loss: 0.02210102\r\n",
      "Epoch:  98 Step:   635 /   793 Train loss: 0.02172400\r\n",
      "Epoch:  98 Step:   636 /   793 Train loss: 0.03350718\r\n",
      "Epoch:  98 Step:   637 /   793 Train loss: 0.01232028\r\n",
      "Epoch:  98 Step:   638 /   793 Train loss: 0.01752503\r\n",
      "Epoch:  98 Step:   639 /   793 Train loss: 0.02469464\r\n",
      "Epoch:  98 Step:   640 /   793 Train loss: 0.02438933\r\n",
      "Epoch:  98 Step:   641 /   793 Train loss: 0.01399507\r\n",
      "Epoch:  98 Step:   642 /   793 Train loss: 0.03158662\r\n",
      "Epoch:  98 Step:   643 /   793 Train loss: 0.02414528\r\n",
      "Epoch:  98 Step:   644 /   793 Train loss: 0.02798915\r\n",
      "Epoch:  98 Step:   645 /   793 Train loss: 0.02185918\r\n",
      "Epoch:  98 Step:   646 /   793 Train loss: 0.03156002\r\n",
      "Epoch:  98 Step:   647 /   793 Train loss: 0.02598688\r\n",
      "Epoch:  98 Step:   648 /   793 Train loss: 0.02069486\r\n",
      "Epoch:  98 Step:   649 /   793 Train loss: 0.01970781\r\n",
      "Epoch:  98 Step:   650 /   793 Train loss: 0.02624128\r\n",
      "Epoch:  98 Step:   651 /   793 Train loss: 0.02763899\r\n",
      "Epoch:  98 Step:   652 /   793 Train loss: 0.02077500\r\n",
      "Epoch:  98 Step:   653 /   793 Train loss: 0.02415986\r\n",
      "Epoch:  98 Step:   654 /   793 Train loss: 0.03135594\r\n",
      "Epoch:  98 Step:   655 /   793 Train loss: 0.01782214\r\n",
      "Epoch:  98 Step:   656 /   793 Train loss: 0.03672663\r\n",
      "Epoch:  98 Step:   657 /   793 Train loss: 0.01925510\r\n",
      "Epoch:  98 Step:   658 /   793 Train loss: 0.03412476\r\n",
      "Epoch:  98 Step:   659 /   793 Train loss: 0.02504978\r\n",
      "Epoch:  98 Step:   660 /   793 Train loss: 0.02511573\r\n",
      "Epoch:  98 Step:   661 /   793 Train loss: 0.01280385\r\n",
      "Epoch:  98 Step:   662 /   793 Train loss: 0.02655571\r\n",
      "Epoch:  98 Step:   663 /   793 Train loss: 0.02902654\r\n",
      "Epoch:  98 Step:   664 /   793 Train loss: 0.03849992\r\n",
      "Epoch:  98 Step:   665 /   793 Train loss: 0.01372715\r\n",
      "Epoch:  98 Step:   666 /   793 Train loss: 0.02091184\r\n",
      "Epoch:  98 Step:   667 /   793 Train loss: 0.02759999\r\n",
      "Epoch:  98 Step:   668 /   793 Train loss: 0.02279101\r\n",
      "Epoch:  98 Step:   669 /   793 Train loss: 0.01454187\r\n",
      "Epoch:  98 Step:   670 /   793 Train loss: 0.02540448\r\n",
      "Epoch:  98 Step:   671 /   793 Train loss: 0.02310891\r\n",
      "Epoch:  98 Step:   672 /   793 Train loss: 0.02891450\r\n",
      "Epoch:  98 Step:   673 /   793 Train loss: 0.01919584\r\n",
      "Epoch:  98 Step:   674 /   793 Train loss: 0.01487492\r\n",
      "Epoch:  98 Step:   675 /   793 Train loss: 0.02813525\r\n",
      "Epoch:  98 Step:   676 /   793 Train loss: 0.02246246\r\n",
      "Epoch:  98 Step:   677 /   793 Train loss: 0.03578913\r\n",
      "Epoch:  98 Step:   678 /   793 Train loss: 0.04382958\r\n",
      "Epoch:  98 Step:   679 /   793 Train loss: 0.02469814\r\n",
      "Epoch:  98 Step:   680 /   793 Train loss: 0.02085119\r\n",
      "Epoch:  98 Step:   681 /   793 Train loss: 0.02444622\r\n",
      "Epoch:  98 Step:   682 /   793 Train loss: 0.02287297\r\n",
      "Epoch:  98 Step:   683 /   793 Train loss: 0.01259577\r\n",
      "Epoch:  98 Step:   684 /   793 Train loss: 0.02155137\r\n",
      "Epoch:  98 Step:   685 /   793 Train loss: 0.03264723\r\n",
      "Epoch:  98 Step:   686 /   793 Train loss: 0.02476609\r\n",
      "Epoch:  98 Step:   687 /   793 Train loss: 0.02509965\r\n",
      "Epoch:  98 Step:   688 /   793 Train loss: 0.02807480\r\n",
      "Epoch:  98 Step:   689 /   793 Train loss: 0.02118996\r\n",
      "Epoch:  98 Step:   690 /   793 Train loss: 0.02326469\r\n",
      "Epoch:  98 Step:   691 /   793 Train loss: 0.01204087\r\n",
      "Epoch:  98 Step:   692 /   793 Train loss: 0.02205890\r\n",
      "Epoch:  98 Step:   693 /   793 Train loss: 0.02622654\r\n",
      "Epoch:  98 Step:   694 /   793 Train loss: 0.02995360\r\n",
      "Epoch:  98 Step:   695 /   793 Train loss: 0.02494320\r\n",
      "Epoch:  98 Step:   696 /   793 Train loss: 0.02650101\r\n",
      "Epoch:  98 Step:   697 /   793 Train loss: 0.02997148\r\n",
      "Epoch:  98 Step:   698 /   793 Train loss: 0.02690381\r\n",
      "Epoch:  98 Step:   699 /   793 Train loss: 0.02426772\r\n",
      "Epoch:  98 Step:   700 /   793 Train loss: 0.01719309\r\n",
      "Epoch:  98 Step:   701 /   793 Train loss: 0.01746494\r\n",
      "Epoch:  98 Step:   702 /   793 Train loss: 0.02248752\r\n",
      "Epoch:  98 Step:   703 /   793 Train loss: 0.01936925\r\n",
      "Epoch:  98 Step:   704 /   793 Train loss: 0.01834356\r\n",
      "Epoch:  98 Step:   705 /   793 Train loss: 0.03117098\r\n",
      "Epoch:  98 Step:   706 /   793 Train loss: 0.01414198\r\n",
      "Epoch:  98 Step:   707 /   793 Train loss: 0.01557020\r\n",
      "Epoch:  98 Step:   708 /   793 Train loss: 0.01850822\r\n",
      "Epoch:  98 Step:   709 /   793 Train loss: 0.02639157\r\n",
      "Epoch:  98 Step:   710 /   793 Train loss: 0.03049851\r\n",
      "Epoch:  98 Step:   711 /   793 Train loss: 0.02014268\r\n",
      "Epoch:  98 Step:   712 /   793 Train loss: 0.01342684\r\n",
      "Epoch:  98 Step:   713 /   793 Train loss: 0.03541526\r\n",
      "Epoch:  98 Step:   714 /   793 Train loss: 0.01748348\r\n",
      "Epoch:  98 Step:   715 /   793 Train loss: 0.02203846\r\n",
      "Epoch:  98 Step:   716 /   793 Train loss: 0.02572673\r\n",
      "Epoch:  98 Step:   717 /   793 Train loss: 0.02335968\r\n",
      "Epoch:  98 Step:   718 /   793 Train loss: 0.03027332\r\n",
      "Epoch:  98 Step:   719 /   793 Train loss: 0.03572851\r\n",
      "Epoch:  98 Step:   720 /   793 Train loss: 0.02861793\r\n",
      "Epoch:  98 Step:   721 /   793 Train loss: 0.03032000\r\n",
      "Epoch:  98 Step:   722 /   793 Train loss: 0.02719384\r\n",
      "Epoch:  98 Step:   723 /   793 Train loss: 0.02522694\r\n",
      "Epoch:  98 Step:   724 /   793 Train loss: 0.03435372\r\n",
      "Epoch:  98 Step:   725 /   793 Train loss: 0.01949724\r\n",
      "Epoch:  98 Step:   726 /   793 Train loss: 0.03070257\r\n",
      "Epoch:  98 Step:   727 /   793 Train loss: 0.02902028\r\n",
      "Epoch:  98 Step:   728 /   793 Train loss: 0.03053780\r\n",
      "Epoch:  98 Step:   729 /   793 Train loss: 0.02428489\r\n",
      "Epoch:  98 Step:   730 /   793 Train loss: 0.03013669\r\n",
      "Epoch:  98 Step:   731 /   793 Train loss: 0.01418389\r\n",
      "Epoch:  98 Step:   732 /   793 Train loss: 0.02343707\r\n",
      "Epoch:  98 Step:   733 /   793 Train loss: 0.03069748\r\n",
      "Epoch:  98 Step:   734 /   793 Train loss: 0.02029002\r\n",
      "Epoch:  98 Step:   735 /   793 Train loss: 0.03082886\r\n",
      "Epoch:  98 Step:   736 /   793 Train loss: 0.01394288\r\n",
      "Epoch:  98 Step:   737 /   793 Train loss: 0.03026468\r\n",
      "Epoch:  98 Step:   738 /   793 Train loss: 0.01516383\r\n",
      "Epoch:  98 Step:   739 /   793 Train loss: 0.01613562\r\n",
      "Epoch:  98 Step:   740 /   793 Train loss: 0.03008008\r\n",
      "Epoch:  98 Step:   741 /   793 Train loss: 0.02453172\r\n",
      "Epoch:  98 Step:   742 /   793 Train loss: 0.02192432\r\n",
      "Epoch:  98 Step:   743 /   793 Train loss: 0.02867967\r\n",
      "Epoch:  98 Step:   744 /   793 Train loss: 0.01278473\r\n",
      "Epoch:  98 Step:   745 /   793 Train loss: 0.02330867\r\n",
      "Epoch:  98 Step:   746 /   793 Train loss: 0.02809054\r\n",
      "Epoch:  98 Step:   747 /   793 Train loss: 0.01978816\r\n",
      "Epoch:  98 Step:   748 /   793 Train loss: 0.01387419\r\n",
      "Epoch:  98 Step:   749 /   793 Train loss: 0.01965646\r\n",
      "Epoch:  98 Step:   750 /   793 Train loss: 0.01720362\r\n",
      "Epoch:  98 Step:   751 /   793 Train loss: 0.02312759\r\n",
      "Epoch:  98 Step:   752 /   793 Train loss: 0.01891485\r\n",
      "Epoch:  98 Step:   753 /   793 Train loss: 0.01888703\r\n",
      "Epoch:  98 Step:   754 /   793 Train loss: 0.01720543\r\n",
      "Epoch:  98 Step:   755 /   793 Train loss: 0.03089741\r\n",
      "Epoch:  98 Step:   756 /   793 Train loss: 0.02463711\r\n",
      "Epoch:  98 Step:   757 /   793 Train loss: 0.03665938\r\n",
      "Epoch:  98 Step:   758 /   793 Train loss: 0.03758215\r\n",
      "Epoch:  98 Step:   759 /   793 Train loss: 0.01729340\r\n",
      "Epoch:  98 Step:   760 /   793 Train loss: 0.02266470\r\n",
      "Epoch:  98 Step:   761 /   793 Train loss: 0.03076960\r\n",
      "Epoch:  98 Step:   762 /   793 Train loss: 0.01689514\r\n",
      "Epoch:  98 Step:   763 /   793 Train loss: 0.02532707\r\n",
      "Epoch:  98 Step:   764 /   793 Train loss: 0.02847902\r\n",
      "Epoch:  98 Step:   765 /   793 Train loss: 0.01889753\r\n",
      "Epoch:  98 Step:   766 /   793 Train loss: 0.01692297\r\n",
      "Epoch:  98 Step:   767 /   793 Train loss: 0.01880672\r\n",
      "Epoch:  98 Step:   768 /   793 Train loss: 0.01919688\r\n",
      "Epoch:  98 Step:   769 /   793 Train loss: 0.01739574\r\n",
      "Epoch:  98 Step:   770 /   793 Train loss: 0.02262066\r\n",
      "Epoch:  98 Step:   771 /   793 Train loss: 0.02345302\r\n",
      "Epoch:  98 Step:   772 /   793 Train loss: 0.02077387\r\n",
      "Epoch:  98 Step:   773 /   793 Train loss: 0.02141605\r\n",
      "Epoch:  98 Step:   774 /   793 Train loss: 0.01502751\r\n",
      "Epoch:  98 Step:   775 /   793 Train loss: 0.02864879\r\n",
      "Epoch:  98 Step:   776 /   793 Train loss: 0.02733632\r\n",
      "Epoch:  98 Step:   777 /   793 Train loss: 0.01846848\r\n",
      "Epoch:  98 Step:   778 /   793 Train loss: 0.02116304\r\n",
      "Epoch:  98 Step:   779 /   793 Train loss: 0.00910412\r\n",
      "Epoch:  98 Step:   780 /   793 Train loss: 0.02985635\r\n",
      "Epoch:  98 Step:   781 /   793 Train loss: 0.02399525\r\n",
      "Epoch:  98 Step:   782 /   793 Train loss: 0.03052821\r\n",
      "Epoch:  98 Step:   783 /   793 Train loss: 0.03250101\r\n",
      "Epoch:  98 Step:   784 /   793 Train loss: 0.01829855\r\n",
      "Epoch:  98 Step:   785 /   793 Train loss: 0.02830800\r\n",
      "Epoch:  98 Step:   786 /   793 Train loss: 0.02544856\r\n",
      "Epoch:  98 Step:   787 /   793 Train loss: 0.02603031\r\n",
      "Epoch:  98 Step:   788 /   793 Train loss: 0.02584363\r\n",
      "Epoch:  98 Step:   789 /   793 Train loss: 0.04075417\r\n",
      "Epoch:  98 Step:   790 /   793 Train loss: 0.01627894\r\n",
      "Epoch:  98 Step:   791 /   793 Train loss: 0.03178900\r\n",
      "Epoch:  98 Step:   792 /   793 Train loss: 0.02865485\r\n",
      "Epoch:  99 Step:     0 /   793 Train loss: 0.02208043\r\n",
      "Epoch:  99 Step:     1 /   793 Train loss: 0.02754338\r\n",
      "Epoch:  99 Step:     2 /   793 Train loss: 0.03249349\r\n",
      "Epoch:  99 Step:     3 /   793 Train loss: 0.01862189\r\n",
      "Epoch:  99 Step:     4 /   793 Train loss: 0.03451571\r\n",
      "Epoch:  99 Step:     5 /   793 Train loss: 0.02153792\r\n",
      "Epoch:  99 Step:     6 /   793 Train loss: 0.02261772\r\n",
      "Epoch:  99 Step:     7 /   793 Train loss: 0.02826525\r\n",
      "Epoch:  99 Step:     8 /   793 Train loss: 0.03033566\r\n",
      "Epoch:  99 Step:     9 /   793 Train loss: 0.02386456\r\n",
      "Epoch:  99 Step:    10 /   793 Train loss: 0.02645063\r\n",
      "Epoch:  99 Step:    11 /   793 Train loss: 0.02047661\r\n",
      "Epoch:  99 Step:    12 /   793 Train loss: 0.01845516\r\n",
      "Epoch:  99 Step:    13 /   793 Train loss: 0.01723224\r\n",
      "Epoch:  99 Step:    14 /   793 Train loss: 0.03787591\r\n",
      "Epoch:  99 Step:    15 /   793 Train loss: 0.03218983\r\n",
      "Epoch:  99 Step:    16 /   793 Train loss: 0.02477160\r\n",
      "Epoch:  99 Step:    17 /   793 Train loss: 0.02721888\r\n",
      "Epoch:  99 Step:    18 /   793 Train loss: 0.02768727\r\n",
      "Epoch:  99 Step:    19 /   793 Train loss: 0.01942599\r\n",
      "Epoch:  99 Step:    20 /   793 Train loss: 0.01150054\r\n",
      "Epoch:  99 Step:    21 /   793 Train loss: 0.01152376\r\n",
      "Epoch:  99 Step:    22 /   793 Train loss: 0.02407161\r\n",
      "Epoch:  99 Step:    23 /   793 Train loss: 0.02198114\r\n",
      "Epoch:  99 Step:    24 /   793 Train loss: 0.01639396\r\n",
      "Epoch:  99 Step:    25 /   793 Train loss: 0.03453544\r\n",
      "Epoch:  99 Step:    26 /   793 Train loss: 0.01764768\r\n",
      "Epoch:  99 Step:    27 /   793 Train loss: 0.00919421\r\n",
      "Epoch:  99 Step:    28 /   793 Train loss: 0.01798899\r\n",
      "Epoch:  99 Step:    29 /   793 Train loss: 0.03258589\r\n",
      "Epoch:  99 Step:    30 /   793 Train loss: 0.01868577\r\n",
      "Epoch:  99 Step:    31 /   793 Train loss: 0.02395832\r\n",
      "Epoch:  99 Step:    32 /   793 Train loss: 0.02214466\r\n",
      "Epoch:  99 Step:    33 /   793 Train loss: 0.04223530\r\n",
      "Epoch:  99 Step:    34 /   793 Train loss: 0.03828034\r\n",
      "Epoch:  99 Step:    35 /   793 Train loss: 0.02595039\r\n",
      "Epoch:  99 Step:    36 /   793 Train loss: 0.02959478\r\n",
      "Epoch:  99 Step:    37 /   793 Train loss: 0.01861991\r\n",
      "Epoch:  99 Step:    38 /   793 Train loss: 0.02705308\r\n",
      "Epoch:  99 Step:    39 /   793 Train loss: 0.02837165\r\n",
      "Epoch:  99 Step:    40 /   793 Train loss: 0.01890172\r\n",
      "Epoch:  99 Step:    41 /   793 Train loss: 0.01708396\r\n",
      "Epoch:  99 Step:    42 /   793 Train loss: 0.01420736\r\n",
      "Epoch:  99 Step:    43 /   793 Train loss: 0.02567410\r\n",
      "Epoch:  99 Step:    44 /   793 Train loss: 0.02931144\r\n",
      "Epoch:  99 Step:    45 /   793 Train loss: 0.03163277\r\n",
      "Epoch:  99 Step:    46 /   793 Train loss: 0.04111910\r\n",
      "Epoch:  99 Step:    47 /   793 Train loss: 0.03349299\r\n",
      "Epoch:  99 Step:    48 /   793 Train loss: 0.01608235\r\n",
      "Epoch:  99 Step:    49 /   793 Train loss: 0.02761438\r\n",
      "Epoch:  99 Step:    50 /   793 Train loss: 0.02770702\r\n",
      "Epoch:  99 Step:    51 /   793 Train loss: 0.02529950\r\n",
      "Epoch:  99 Step:    52 /   793 Train loss: 0.02140700\r\n",
      "Epoch:  99 Step:    53 /   793 Train loss: 0.03052982\r\n",
      "Epoch:  99 Step:    54 /   793 Train loss: 0.02438722\r\n",
      "Epoch:  99 Step:    55 /   793 Train loss: 0.03053864\r\n",
      "Epoch:  99 Step:    56 /   793 Train loss: 0.02396506\r\n",
      "Epoch:  99 Step:    57 /   793 Train loss: 0.01767530\r\n",
      "Epoch:  99 Step:    58 /   793 Train loss: 0.02718381\r\n",
      "Epoch:  99 Step:    59 /   793 Train loss: 0.02773827\r\n",
      "Epoch:  99 Step:    60 /   793 Train loss: 0.01612242\r\n",
      "Epoch:  99 Step:    61 /   793 Train loss: 0.02504513\r\n",
      "Epoch:  99 Step:    62 /   793 Train loss: 0.02745747\r\n",
      "Epoch:  99 Step:    63 /   793 Train loss: 0.01768737\r\n",
      "Epoch:  99 Step:    64 /   793 Train loss: 0.03594632\r\n",
      "Epoch:  99 Step:    65 /   793 Train loss: 0.01902937\r\n",
      "Epoch:  99 Step:    66 /   793 Train loss: 0.02182704\r\n",
      "Epoch:  99 Step:    67 /   793 Train loss: 0.02808692\r\n",
      "Epoch:  99 Step:    68 /   793 Train loss: 0.01196301\r\n",
      "Epoch:  99 Step:    69 /   793 Train loss: 0.04292494\r\n",
      "Epoch:  99 Step:    70 /   793 Train loss: 0.01937293\r\n",
      "Epoch:  99 Step:    71 /   793 Train loss: 0.02321489\r\n",
      "Epoch:  99 Step:    72 /   793 Train loss: 0.02790977\r\n",
      "Epoch:  99 Step:    73 /   793 Train loss: 0.02305458\r\n",
      "Epoch:  99 Step:    74 /   793 Train loss: 0.02116391\r\n",
      "Epoch:  99 Step:    75 /   793 Train loss: 0.02899975\r\n",
      "Epoch:  99 Step:    76 /   793 Train loss: 0.03084018\r\n",
      "Epoch:  99 Step:    77 /   793 Train loss: 0.02049107\r\n",
      "Epoch:  99 Step:    78 /   793 Train loss: 0.01999714\r\n",
      "Epoch:  99 Step:    79 /   793 Train loss: 0.03287840\r\n",
      "Epoch:  99 Step:    80 /   793 Train loss: 0.03066692\r\n",
      "Epoch:  99 Step:    81 /   793 Train loss: 0.01723997\r\n",
      "Epoch:  99 Step:    82 /   793 Train loss: 0.01896271\r\n",
      "Epoch:  99 Step:    83 /   793 Train loss: 0.03341627\r\n",
      "Epoch:  99 Step:    84 /   793 Train loss: 0.01687631\r\n",
      "Epoch:  99 Step:    85 /   793 Train loss: 0.02825246\r\n",
      "Epoch:  99 Step:    86 /   793 Train loss: 0.02516815\r\n",
      "Epoch:  99 Step:    87 /   793 Train loss: 0.02203901\r\n",
      "Epoch:  99 Step:    88 /   793 Train loss: 0.02637087\r\n",
      "Epoch:  99 Step:    89 /   793 Train loss: 0.02516324\r\n",
      "Epoch:  99 Step:    90 /   793 Train loss: 0.02241271\r\n",
      "Epoch:  99 Step:    91 /   793 Train loss: 0.02153689\r\n",
      "Epoch:  99 Step:    92 /   793 Train loss: 0.02711545\r\n",
      "Epoch:  99 Step:    93 /   793 Train loss: 0.03050590\r\n",
      "Epoch:  99 Step:    94 /   793 Train loss: 0.02130209\r\n",
      "Epoch:  99 Step:    95 /   793 Train loss: 0.03082245\r\n",
      "Epoch:  99 Step:    96 /   793 Train loss: 0.01752720\r\n",
      "Epoch:  99 Step:    97 /   793 Train loss: 0.03111095\r\n",
      "Epoch:  99 Step:    98 /   793 Train loss: 0.02091245\r\n",
      "Epoch:  99 Step:    99 /   793 Train loss: 0.01801074\r\n",
      "Epoch:  99 Step:   100 /   793 Train loss: 0.02435751\r\n",
      "Epoch:  99 Step:   101 /   793 Train loss: 0.02463681\r\n",
      "Epoch:  99 Step:   102 /   793 Train loss: 0.02776206\r\n",
      "Epoch:  99 Step:   103 /   793 Train loss: 0.02289134\r\n",
      "Epoch:  99 Step:   104 /   793 Train loss: 0.02666662\r\n",
      "Epoch:  99 Step:   105 /   793 Train loss: 0.02113482\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  99 Step:   106 /   793 Train loss: 0.01456625\r\n",
      "Epoch:  99 Step:   107 /   793 Train loss: 0.03090351\r\n",
      "Epoch:  99 Step:   108 /   793 Train loss: 0.01770921\r\n",
      "Epoch:  99 Step:   109 /   793 Train loss: 0.02400579\r\n",
      "Epoch:  99 Step:   110 /   793 Train loss: 0.02316801\r\n",
      "Epoch:  99 Step:   111 /   793 Train loss: 0.04724628\r\n",
      "Epoch:  99 Step:   112 /   793 Train loss: 0.02593794\r\n",
      "Epoch:  99 Step:   113 /   793 Train loss: 0.02907773\r\n",
      "Epoch:  99 Step:   114 /   793 Train loss: 0.04214231\r\n",
      "Epoch:  99 Step:   115 /   793 Train loss: 0.01760288\r\n",
      "Epoch:  99 Step:   116 /   793 Train loss: 0.01824207\r\n",
      "Epoch:  99 Step:   117 /   793 Train loss: 0.01875531\r\n",
      "Epoch:  99 Step:   118 /   793 Train loss: 0.02025847\r\n",
      "Epoch:  99 Step:   119 /   793 Train loss: 0.03841040\r\n",
      "Epoch:  99 Step:   120 /   793 Train loss: 0.02601211\r\n",
      "Epoch:  99 Step:   121 /   793 Train loss: 0.02141331\r\n",
      "Epoch:  99 Step:   122 /   793 Train loss: 0.02016989\r\n",
      "Epoch:  99 Step:   123 /   793 Train loss: 0.02065132\r\n",
      "Epoch:  99 Step:   124 /   793 Train loss: 0.01570945\r\n",
      "Epoch:  99 Step:   125 /   793 Train loss: 0.02503877\r\n",
      "Epoch:  99 Step:   126 /   793 Train loss: 0.03330924\r\n",
      "Epoch:  99 Step:   127 /   793 Train loss: 0.02627727\r\n",
      "Epoch:  99 Step:   128 /   793 Train loss: 0.02463900\r\n",
      "Epoch:  99 Step:   129 /   793 Train loss: 0.04069262\r\n",
      "Epoch:  99 Step:   130 /   793 Train loss: 0.02461053\r\n",
      "Epoch:  99 Step:   131 /   793 Train loss: 0.03170725\r\n",
      "Epoch:  99 Step:   132 /   793 Train loss: 0.01281755\r\n",
      "Epoch:  99 Step:   133 /   793 Train loss: 0.03497700\r\n",
      "Epoch:  99 Step:   134 /   793 Train loss: 0.02482435\r\n",
      "Epoch:  99 Step:   135 /   793 Train loss: 0.02190137\r\n",
      "Epoch:  99 Step:   136 /   793 Train loss: 0.02104062\r\n",
      "Epoch:  99 Step:   137 /   793 Train loss: 0.02353988\r\n",
      "Epoch:  99 Step:   138 /   793 Train loss: 0.01954659\r\n",
      "Epoch:  99 Step:   139 /   793 Train loss: 0.01419363\r\n",
      "Epoch:  99 Step:   140 /   793 Train loss: 0.02555738\r\n",
      "Epoch:  99 Step:   141 /   793 Train loss: 0.02429854\r\n",
      "Epoch:  99 Step:   142 /   793 Train loss: 0.03512290\r\n",
      "Epoch:  99 Step:   143 /   793 Train loss: 0.01828883\r\n",
      "Epoch:  99 Step:   144 /   793 Train loss: 0.01648008\r\n",
      "Epoch:  99 Step:   145 /   793 Train loss: 0.02988288\r\n",
      "Epoch:  99 Step:   146 /   793 Train loss: 0.03223420\r\n",
      "Epoch:  99 Step:   147 /   793 Train loss: 0.02512014\r\n",
      "Epoch:  99 Step:   148 /   793 Train loss: 0.02004219\r\n",
      "Epoch:  99 Step:   149 /   793 Train loss: 0.03093037\r\n",
      "Epoch:  99 Step:   150 /   793 Train loss: 0.02593937\r\n",
      "Epoch:  99 Step:   151 /   793 Train loss: 0.02943122\r\n",
      "Epoch:  99 Step:   152 /   793 Train loss: 0.03314997\r\n",
      "Epoch:  99 Step:   153 /   793 Train loss: 0.03311002\r\n",
      "Epoch:  99 Step:   154 /   793 Train loss: 0.02749681\r\n",
      "Epoch:  99 Step:   155 /   793 Train loss: 0.01566079\r\n",
      "Epoch:  99 Step:   156 /   793 Train loss: 0.01535067\r\n",
      "Epoch:  99 Step:   157 /   793 Train loss: 0.02461607\r\n",
      "Epoch:  99 Step:   158 /   793 Train loss: 0.02243613\r\n",
      "Epoch:  99 Step:   159 /   793 Train loss: 0.01650190\r\n",
      "Epoch:  99 Step:   160 /   793 Train loss: 0.01738103\r\n",
      "Epoch:  99 Step:   161 /   793 Train loss: 0.02708331\r\n",
      "Epoch:  99 Step:   162 /   793 Train loss: 0.01700054\r\n",
      "Epoch:  99 Step:   163 /   793 Train loss: 0.02440276\r\n",
      "Epoch:  99 Step:   164 /   793 Train loss: 0.00888610\r\n",
      "Epoch:  99 Step:   165 /   793 Train loss: 0.01825281\r\n",
      "Epoch:  99 Step:   166 /   793 Train loss: 0.02051974\r\n",
      "Epoch:  99 Step:   167 /   793 Train loss: 0.01082462\r\n",
      "Epoch:  99 Step:   168 /   793 Train loss: 0.01694238\r\n",
      "Epoch:  99 Step:   169 /   793 Train loss: 0.03842467\r\n",
      "Epoch:  99 Step:   170 /   793 Train loss: 0.02228029\r\n",
      "Epoch:  99 Step:   171 /   793 Train loss: 0.02468052\r\n",
      "Epoch:  99 Step:   172 /   793 Train loss: 0.03529884\r\n",
      "Epoch:  99 Step:   173 /   793 Train loss: 0.02577699\r\n",
      "Epoch:  99 Step:   174 /   793 Train loss: 0.03203739\r\n",
      "Epoch:  99 Step:   175 /   793 Train loss: 0.02805939\r\n",
      "Epoch:  99 Step:   176 /   793 Train loss: 0.01650584\r\n",
      "Epoch:  99 Step:   177 /   793 Train loss: 0.02278280\r\n",
      "Epoch:  99 Step:   178 /   793 Train loss: 0.02052153\r\n",
      "Epoch:  99 Step:   179 /   793 Train loss: 0.01682411\r\n",
      "Epoch:  99 Step:   180 /   793 Train loss: 0.02240463\r\n",
      "Epoch:  99 Step:   181 /   793 Train loss: 0.01817297\r\n",
      "Epoch:  99 Step:   182 /   793 Train loss: 0.02172196\r\n",
      "Epoch:  99 Step:   183 /   793 Train loss: 0.02861518\r\n",
      "Epoch:  99 Step:   184 /   793 Train loss: 0.02802557\r\n",
      "Epoch:  99 Step:   185 /   793 Train loss: 0.02022193\r\n",
      "Epoch:  99 Step:   186 /   793 Train loss: 0.02150789\r\n",
      "Epoch:  99 Step:   187 /   793 Train loss: 0.01831213\r\n",
      "Epoch:  99 Step:   188 /   793 Train loss: 0.02341113\r\n",
      "Epoch:  99 Step:   189 /   793 Train loss: 0.02828968\r\n",
      "Epoch:  99 Step:   190 /   793 Train loss: 0.02333052\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  99 Step:   191 /   793 Train loss: 0.02839007\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  99 Step:   192 /   793 Train loss: 0.01717998\r\n",
      "Epoch:  99 Step:   193 /   793 Train loss: 0.02433801\r\n",
      "Epoch:  99 Step:   194 /   793 Train loss: 0.02874528\r\n",
      "Epoch:  99 Step:   195 /   793 Train loss: 0.02208966\r\n",
      "Epoch:  99 Step:   196 /   793 Train loss: 0.02855279\r\n",
      "Epoch:  99 Step:   197 /   793 Train loss: 0.01709979\r\n",
      "Epoch:  99 Step:   198 /   793 Train loss: 0.02717864\r\n",
      "Epoch:  99 Step:   199 /   793 Train loss: 0.03358339\r\n",
      "Epoch:  99 Step:   200 /   793 Train loss: 0.03263203\r\n",
      "Epoch:  99 Step:   201 /   793 Train loss: 0.02365191\r\n",
      "Epoch:  99 Step:   202 /   793 Train loss: 0.01471508\r\n",
      "Epoch:  99 Step:   203 /   793 Train loss: 0.02610431\r\n",
      "Epoch:  99 Step:   204 /   793 Train loss: 0.01901160\r\n",
      "Epoch:  99 Step:   205 /   793 Train loss: 0.01096860\r\n",
      "Epoch:  99 Step:   206 /   793 Train loss: 0.02295888\r\n",
      "Epoch:  99 Step:   207 /   793 Train loss: 0.02279806\r\n",
      "Epoch:  99 Step:   208 /   793 Train loss: 0.02939916\r\n",
      "Epoch:  99 Step:   209 /   793 Train loss: 0.02199167\r\n",
      "Epoch:  99 Step:   210 /   793 Train loss: 0.03387344\r\n",
      "Epoch:  99 Step:   211 /   793 Train loss: 0.02533685\r\n",
      "Epoch:  99 Step:   212 /   793 Train loss: 0.01691870\r\n",
      "Epoch:  99 Step:   213 /   793 Train loss: 0.01582528\r\n",
      "Epoch:  99 Step:   214 /   793 Train loss: 0.02583116\r\n",
      "Epoch:  99 Step:   215 /   793 Train loss: 0.02573157\r\n",
      "Epoch:  99 Step:   216 /   793 Train loss: 0.01713812\r\n",
      "Epoch:  99 Step:   217 /   793 Train loss: 0.02276658\r\n",
      "Epoch:  99 Step:   218 /   793 Train loss: 0.01764514\r\n",
      "Epoch:  99 Step:   219 /   793 Train loss: 0.02593619\r\n",
      "Epoch:  99 Step:   220 /   793 Train loss: 0.02436250\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  99 Step:   221 /   793 Train loss: 0.02475546\r\n",
      "Epoch:  99 Step:   222 /   793 Train loss: 0.01209054\r\n",
      "Epoch:  99 Step:   223 /   793 Train loss: 0.03199460\r\n",
      "Epoch:  99 Step:   224 /   793 Train loss: 0.02685380\r\n",
      "Epoch:  99 Step:   225 /   793 Train loss: 0.01741565\r\n",
      "Epoch:  99 Step:   226 /   793 Train loss: 0.02231808\r\n",
      "Epoch:  99 Step:   227 /   793 Train loss: 0.01615581\r\n",
      "Epoch:  99 Step:   228 /   793 Train loss: 0.02012056\r\n",
      "Epoch:  99 Step:   229 /   793 Train loss: 0.01798691\r\n",
      "Epoch:  99 Step:   230 /   793 Train loss: 0.02598554\r\n",
      "Epoch:  99 Step:   231 /   793 Train loss: 0.03351207\r\n",
      "Epoch:  99 Step:   232 /   793 Train loss: 0.02911847\r\n",
      "Epoch:  99 Step:   233 /   793 Train loss: 0.02027528\r\n",
      "Epoch:  99 Step:   234 /   793 Train loss: 0.02527738\r\n",
      "Epoch:  99 Step:   235 /   793 Train loss: 0.02594380\r\n",
      "Epoch:  99 Step:   236 /   793 Train loss: 0.01427009\r\n",
      "Epoch:  99 Step:   237 /   793 Train loss: 0.02904626\r\n",
      "Epoch:  99 Step:   238 /   793 Train loss: 0.01577308\r\n",
      "Epoch:  99 Step:   239 /   793 Train loss: 0.03019849\r\n",
      "Epoch:  99 Step:   240 /   793 Train loss: 0.01290311\r\n",
      "Epoch:  99 Step:   241 /   793 Train loss: 0.02384241\r\n",
      "Epoch:  99 Step:   242 /   793 Train loss: 0.03605063\r\n",
      "Epoch:  99 Step:   243 /   793 Train loss: 0.03009415\r\n",
      "Epoch:  99 Step:   244 /   793 Train loss: 0.02723022\r\n",
      "Epoch:  99 Step:   245 /   793 Train loss: 0.02503036\r\n",
      "Epoch:  99 Step:   246 /   793 Train loss: 0.03287743\r\n",
      "Epoch:  99 Step:   247 /   793 Train loss: 0.02768700\r\n",
      "Epoch:  99 Step:   248 /   793 Train loss: 0.01261891\r\n",
      "Epoch:  99 Step:   249 /   793 Train loss: 0.02807440\r\n",
      "Epoch:  99 Step:   250 /   793 Train loss: 0.01844607\r\n",
      "Epoch:  99 Step:   251 /   793 Train loss: 0.02021320\r\n",
      "Epoch:  99 Step:   252 /   793 Train loss: 0.04237254\r\n",
      "Epoch:  99 Step:   253 /   793 Train loss: 0.01243739\r\n",
      "Epoch:  99 Step:   254 /   793 Train loss: 0.01512192\r\n",
      "Epoch:  99 Step:   255 /   793 Train loss: 0.02152835\r\n",
      "Epoch:  99 Step:   256 /   793 Train loss: 0.03772969\r\n",
      "Epoch:  99 Step:   257 /   793 Train loss: 0.01564261\r\n",
      "Epoch:  99 Step:   258 /   793 Train loss: 0.02164584\r\n",
      "Epoch:  99 Step:   259 /   793 Train loss: 0.01277571\r\n",
      "Epoch:  99 Step:   260 /   793 Train loss: 0.01815442\r\n",
      "Epoch:  99 Step:   261 /   793 Train loss: 0.01553735\r\n",
      "Epoch:  99 Step:   262 /   793 Train loss: 0.01844754\r\n",
      "Epoch:  99 Step:   263 /   793 Train loss: 0.01892916\r\n",
      "Epoch:  99 Step:   264 /   793 Train loss: 0.02742365\r\n",
      "Epoch:  99 Step:   265 /   793 Train loss: 0.01259777\r\n",
      "Epoch:  99 Step:   266 /   793 Train loss: 0.01625165\r\n",
      "Epoch:  99 Step:   267 /   793 Train loss: 0.04045640\r\n",
      "Epoch:  99 Step:   268 /   793 Train loss: 0.02383640\r\n",
      "Epoch:  99 Step:   269 /   793 Train loss: 0.03080857\r\n",
      "Epoch:  99 Step:   270 /   793 Train loss: 0.02431536\r\n",
      "Epoch:  99 Step:   271 /   793 Train loss: 0.02050559\r\n",
      "Epoch:  99 Step:   272 /   793 Train loss: 0.02942338\r\n",
      "Epoch:  99 Step:   273 /   793 Train loss: 0.01675979\r\n",
      "Epoch:  99 Step:   274 /   793 Train loss: 0.03293556\r\n",
      "Epoch:  99 Step:   275 /   793 Train loss: 0.02674011\r\n",
      "Epoch:  99 Step:   276 /   793 Train loss: 0.00876346\r\n",
      "Epoch:  99 Step:   277 /   793 Train loss: 0.02356217\r\n",
      "Epoch:  99 Step:   278 /   793 Train loss: 0.03379666\r\n",
      "Epoch:  99 Step:   279 /   793 Train loss: 0.02356770\r\n",
      "Epoch:  99 Step:   280 /   793 Train loss: 0.02190545\r\n",
      "Epoch:  99 Step:   281 /   793 Train loss: 0.01724295\r\n",
      "Epoch:  99 Step:   282 /   793 Train loss: 0.02029309\r\n",
      "Epoch:  99 Step:   283 /   793 Train loss: 0.02665883\r\n",
      "Epoch:  99 Step:   284 /   793 Train loss: 0.01555519\r\n",
      "Epoch:  99 Step:   285 /   793 Train loss: 0.04543407\r\n",
      "Epoch:  99 Step:   286 /   793 Train loss: 0.01730939\r\n",
      "Epoch:  99 Step:   287 /   793 Train loss: 0.01678249\r\n",
      "Epoch:  99 Step:   288 /   793 Train loss: 0.01275900\r\n",
      "Epoch:  99 Step:   289 /   793 Train loss: 0.02372822\r\n",
      "Epoch:  99 Step:   290 /   793 Train loss: 0.02112190\r\n",
      "Epoch:  99 Step:   291 /   793 Train loss: 0.02247731\r\n",
      "Epoch:  99 Step:   292 /   793 Train loss: 0.02974863\r\n",
      "Epoch:  99 Step:   293 /   793 Train loss: 0.02051580\r\n",
      "Epoch:  99 Step:   294 /   793 Train loss: 0.03270797\r\n",
      "Epoch:  99 Step:   295 /   793 Train loss: 0.02787999\r\n",
      "Epoch:  99 Step:   296 /   793 Train loss: 0.02553100\r\n",
      "Epoch:  99 Step:   297 /   793 Train loss: 0.02515817\r\n",
      "Epoch:  99 Step:   298 /   793 Train loss: 0.02521520\r\n",
      "Epoch:  99 Step:   299 /   793 Train loss: 0.01186014\r\n",
      "Epoch:  99 Step:   300 /   793 Train loss: 0.02989078\r\n",
      "Epoch:  99 Step:   301 /   793 Train loss: 0.02368411\r\n",
      "Epoch:  99 Step:   302 /   793 Train loss: 0.01699575\r\n",
      "Epoch:  99 Step:   303 /   793 Train loss: 0.02649708\r\n",
      "Epoch:  99 Step:   304 /   793 Train loss: 0.02845438\r\n",
      "Epoch:  99 Step:   305 /   793 Train loss: 0.02522472\r\n",
      "Epoch:  99 Step:   306 /   793 Train loss: 0.02987560\r\n",
      "Epoch:  99 Step:   307 /   793 Train loss: 0.02563945\r\n",
      "Epoch:  99 Step:   308 /   793 Train loss: 0.02517171\r\n",
      "Epoch:  99 Step:   309 /   793 Train loss: 0.03219540\r\n",
      "Epoch:  99 Step:   310 /   793 Train loss: 0.01652026\r\n",
      "Epoch:  99 Step:   311 /   793 Train loss: 0.02459540\r\n",
      "Epoch:  99 Step:   312 /   793 Train loss: 0.01665138\r\n",
      "Epoch:  99 Step:   313 /   793 Train loss: 0.02894356\r\n",
      "Epoch:  99 Step:   314 /   793 Train loss: 0.02422307\r\n",
      "Epoch:  99 Step:   315 /   793 Train loss: 0.04714292\r\n",
      "Epoch:  99 Step:   316 /   793 Train loss: 0.02507540\r\n",
      "Epoch:  99 Step:   317 /   793 Train loss: 0.03473116\r\n",
      "Epoch:  99 Step:   318 /   793 Train loss: 0.01999092\r\n",
      "Epoch:  99 Step:   319 /   793 Train loss: 0.01431483\r\n",
      "Epoch:  99 Step:   320 /   793 Train loss: 0.02412794\r\n",
      "Epoch:  99 Step:   321 /   793 Train loss: 0.02764241\r\n",
      "Epoch:  99 Step:   322 /   793 Train loss: 0.03246126\r\n",
      "Epoch:  99 Step:   323 /   793 Train loss: 0.01920174\r\n",
      "Epoch:  99 Step:   324 /   793 Train loss: 0.02228896\r\n",
      "Epoch:  99 Step:   325 /   793 Train loss: 0.01239184\r\n",
      "Epoch:  99 Step:   326 /   793 Train loss: 0.02234672\r\n",
      "Epoch:  99 Step:   327 /   793 Train loss: 0.02158761\r\n",
      "Epoch:  99 Step:   328 /   793 Train loss: 0.03790466\r\n",
      "Epoch:  99 Step:   329 /   793 Train loss: 0.01615178\r\n",
      "Epoch:  99 Step:   330 /   793 Train loss: 0.02360834\r\n",
      "Epoch:  99 Step:   331 /   793 Train loss: 0.01631052\r\n",
      "Epoch:  99 Step:   332 /   793 Train loss: 0.03129584\r\n",
      "Epoch:  99 Step:   333 /   793 Train loss: 0.02418001\r\n",
      "Epoch:  99 Step:   334 /   793 Train loss: 0.02831176\r\n",
      "Epoch:  99 Step:   335 /   793 Train loss: 0.02195537\r\n",
      "Epoch:  99 Step:   336 /   793 Train loss: 0.01799814\r\n",
      "Epoch:  99 Step:   337 /   793 Train loss: 0.02372838\r\n",
      "Epoch:  99 Step:   338 /   793 Train loss: 0.03035607\r\n",
      "Epoch:  99 Step:   339 /   793 Train loss: 0.03203102\r\n",
      "Epoch:  99 Step:   340 /   793 Train loss: 0.02527911\r\n",
      "Epoch:  99 Step:   341 /   793 Train loss: 0.02119669\r\n",
      "Epoch:  99 Step:   342 /   793 Train loss: 0.01624458\r\n",
      "Epoch:  99 Step:   343 /   793 Train loss: 0.03170049\r\n",
      "Epoch:  99 Step:   344 /   793 Train loss: 0.02811963\r\n",
      "Epoch:  99 Step:   345 /   793 Train loss: 0.03052173\r\n",
      "Epoch:  99 Step:   346 /   793 Train loss: 0.02690912\r\n",
      "Epoch:  99 Step:   347 /   793 Train loss: 0.01710851\r\n",
      "Epoch:  99 Step:   348 /   793 Train loss: 0.02893767\r\n",
      "Epoch:  99 Step:   349 /   793 Train loss: 0.02318821\r\n",
      "Epoch:  99 Step:   350 /   793 Train loss: 0.01553966\r\n",
      "Epoch:  99 Step:   351 /   793 Train loss: 0.01604102\r\n",
      "Epoch:  99 Step:   352 /   793 Train loss: 0.03027776\r\n",
      "Epoch:  99 Step:   353 /   793 Train loss: 0.02723170\r\n",
      "Epoch:  99 Step:   354 /   793 Train loss: 0.03739486\r\n",
      "Epoch:  99 Step:   355 /   793 Train loss: 0.03263681\r\n",
      "Epoch:  99 Step:   356 /   793 Train loss: 0.03152303\r\n",
      "Epoch:  99 Step:   357 /   793 Train loss: 0.02417539\r\n",
      "Epoch:  99 Step:   358 /   793 Train loss: 0.01369628\r\n",
      "Epoch:  99 Step:   359 /   793 Train loss: 0.01652850\r\n",
      "Epoch:  99 Step:   360 /   793 Train loss: 0.02650640\r\n",
      "Epoch:  99 Step:   361 /   793 Train loss: 0.02440000\r\n",
      "Epoch:  99 Step:   362 /   793 Train loss: 0.01971280\r\n",
      "Epoch:  99 Step:   363 /   793 Train loss: 0.01520210\r\n",
      "Epoch:  99 Step:   364 /   793 Train loss: 0.01460513\r\n",
      "Epoch:  99 Step:   365 /   793 Train loss: 0.02282023\r\n",
      "Epoch:  99 Step:   366 /   793 Train loss: 0.02535196\r\n",
      "Epoch:  99 Step:   367 /   793 Train loss: 0.03313794\r\n",
      "Epoch:  99 Step:   368 /   793 Train loss: 0.01888657\r\n",
      "Epoch:  99 Step:   369 /   793 Train loss: 0.03318637\r\n",
      "Epoch:  99 Step:   370 /   793 Train loss: 0.02705347\r\n",
      "Epoch:  99 Step:   371 /   793 Train loss: 0.02599941\r\n",
      "Epoch:  99 Step:   372 /   793 Train loss: 0.03498602\r\n",
      "Epoch:  99 Step:   373 /   793 Train loss: 0.01989550\r\n",
      "Epoch:  99 Step:   374 /   793 Train loss: 0.02200688\r\n",
      "Epoch:  99 Step:   375 /   793 Train loss: 0.02802123\r\n",
      "Epoch:  99 Step:   376 /   793 Train loss: 0.02454642\r\n",
      "Epoch:  99 Step:   377 /   793 Train loss: 0.02571582\r\n",
      "Epoch:  99 Step:   378 /   793 Train loss: 0.02696701\r\n",
      "Epoch:  99 Step:   379 /   793 Train loss: 0.02491478\r\n",
      "Epoch:  99 Step:   380 /   793 Train loss: 0.03292695\r\n",
      "Epoch:  99 Step:   381 /   793 Train loss: 0.02044774\r\n",
      "Epoch:  99 Step:   382 /   793 Train loss: 0.03994863\r\n",
      "Epoch:  99 Step:   383 /   793 Train loss: 0.02175582\r\n",
      "Epoch:  99 Step:   384 /   793 Train loss: 0.02365293\r\n",
      "Epoch:  99 Step:   385 /   793 Train loss: 0.02331344\r\n",
      "Epoch:  99 Step:   386 /   793 Train loss: 0.02758475\r\n",
      "Epoch:  99 Step:   387 /   793 Train loss: 0.03075318\r\n",
      "Epoch:  99 Step:   388 /   793 Train loss: 0.01880531\r\n",
      "Epoch:  99 Step:   389 /   793 Train loss: 0.03178657\r\n",
      "Epoch:  99 Step:   390 /   793 Train loss: 0.01590804\r\n",
      "Epoch:  99 Step:   391 /   793 Train loss: 0.02109919\r\n",
      "Epoch:  99 Step:   392 /   793 Train loss: 0.02793630\r\n",
      "Epoch:  99 Step:   393 /   793 Train loss: 0.03747335\r\n",
      "Epoch:  99 Step:   394 /   793 Train loss: 0.03260151\r\n",
      "Epoch:  99 Step:   395 /   793 Train loss: 0.02744082\r\n",
      "Epoch:  99 Step:   396 /   793 Train loss: 0.01532581\r\n",
      "Epoch:  99 Step:   397 /   793 Train loss: 0.01163066\r\n",
      "Premature end of JPEG file\r\n",
      "Epoch:  99 Step:   398 /   793 Train loss: 0.02962369\r\n",
      "Epoch:  99 Step:   399 /   793 Train loss: 0.02864441\r\n",
      "Epoch:  99 Step:   400 /   793 Train loss: 0.02322358\r\n",
      "Epoch:  99 Step:   401 /   793 Train loss: 0.04483840\r\n",
      "Epoch:  99 Step:   402 /   793 Train loss: 0.02272176\r\n",
      "Epoch:  99 Step:   403 /   793 Train loss: 0.03962820\r\n",
      "Epoch:  99 Step:   404 /   793 Train loss: 0.02549763\r\n",
      "Epoch:  99 Step:   405 /   793 Train loss: 0.01386593\r\n",
      "Epoch:  99 Step:   406 /   793 Train loss: 0.01542861\r\n",
      "Epoch:  99 Step:   407 /   793 Train loss: 0.01909987\r\n",
      "Epoch:  99 Step:   408 /   793 Train loss: 0.03229227\r\n",
      "Epoch:  99 Step:   409 /   793 Train loss: 0.02881418\r\n",
      "Epoch:  99 Step:   410 /   793 Train loss: 0.01823636\r\n",
      "Epoch:  99 Step:   411 /   793 Train loss: 0.02350323\r\n",
      "Epoch:  99 Step:   412 /   793 Train loss: 0.01574760\r\n",
      "Epoch:  99 Step:   413 /   793 Train loss: 0.02524233\r\n",
      "Epoch:  99 Step:   414 /   793 Train loss: 0.02394707\r\n",
      "Epoch:  99 Step:   415 /   793 Train loss: 0.02409359\r\n",
      "Epoch:  99 Step:   416 /   793 Train loss: 0.03233688\r\n",
      "Epoch:  99 Step:   417 /   793 Train loss: 0.01630412\r\n",
      "Epoch:  99 Step:   418 /   793 Train loss: 0.01565355\r\n",
      "Epoch:  99 Step:   419 /   793 Train loss: 0.02608037\r\n",
      "Epoch:  99 Step:   420 /   793 Train loss: 0.02586234\r\n",
      "Epoch:  99 Step:   421 /   793 Train loss: 0.02394911\r\n",
      "Epoch:  99 Step:   422 /   793 Train loss: 0.03861631\r\n",
      "Epoch:  99 Step:   423 /   793 Train loss: 0.02777476\r\n",
      "Epoch:  99 Step:   424 /   793 Train loss: 0.02145009\r\n",
      "Epoch:  99 Step:   425 /   793 Train loss: 0.01224296\r\n",
      "Epoch:  99 Step:   426 /   793 Train loss: 0.04159216\r\n",
      "Epoch:  99 Step:   427 /   793 Train loss: 0.02628293\r\n",
      "Epoch:  99 Step:   428 /   793 Train loss: 0.02302532\r\n",
      "Epoch:  99 Step:   429 /   793 Train loss: 0.01497904\r\n",
      "Epoch:  99 Step:   430 /   793 Train loss: 0.02653329\r\n",
      "Epoch:  99 Step:   431 /   793 Train loss: 0.01564023\r\n",
      "Epoch:  99 Step:   432 /   793 Train loss: 0.02798323\r\n",
      "Epoch:  99 Step:   433 /   793 Train loss: 0.02203135\r\n",
      "Epoch:  99 Step:   434 /   793 Train loss: 0.02290676\r\n",
      "Epoch:  99 Step:   435 /   793 Train loss: 0.03707780\r\n",
      "Epoch:  99 Step:   436 /   793 Train loss: 0.02730656\r\n",
      "Epoch:  99 Step:   437 /   793 Train loss: 0.02963991\r\n",
      "Epoch:  99 Step:   438 /   793 Train loss: 0.02541282\r\n",
      "Epoch:  99 Step:   439 /   793 Train loss: 0.03093758\r\n",
      "Epoch:  99 Step:   440 /   793 Train loss: 0.02691733\r\n",
      "Epoch:  99 Step:   441 /   793 Train loss: 0.02329221\r\n",
      "Epoch:  99 Step:   442 /   793 Train loss: 0.02490771\r\n",
      "Epoch:  99 Step:   443 /   793 Train loss: 0.03045053\r\n",
      "Epoch:  99 Step:   444 /   793 Train loss: 0.01749193\r\n",
      "Epoch:  99 Step:   445 /   793 Train loss: 0.03526885\r\n",
      "Epoch:  99 Step:   446 /   793 Train loss: 0.01636240\r\n",
      "Epoch:  99 Step:   447 /   793 Train loss: 0.01676546\r\n",
      "Epoch:  99 Step:   448 /   793 Train loss: 0.02316938\r\n",
      "Epoch:  99 Step:   449 /   793 Train loss: 0.01944738\r\n",
      "Epoch:  99 Step:   450 /   793 Train loss: 0.02760523\r\n",
      "Epoch:  99 Step:   451 /   793 Train loss: 0.02492985\r\n",
      "Epoch:  99 Step:   452 /   793 Train loss: 0.01641271\r\n",
      "Epoch:  99 Step:   453 /   793 Train loss: 0.02404651\r\n",
      "Epoch:  99 Step:   454 /   793 Train loss: 0.02842275\r\n",
      "Epoch:  99 Step:   455 /   793 Train loss: 0.02894839\r\n",
      "Epoch:  99 Step:   456 /   793 Train loss: 0.02142810\r\n",
      "Epoch:  99 Step:   457 /   793 Train loss: 0.03278479\r\n",
      "Epoch:  99 Step:   458 /   793 Train loss: 0.01524501\r\n",
      "Epoch:  99 Step:   459 /   793 Train loss: 0.02544749\r\n",
      "Epoch:  99 Step:   460 /   793 Train loss: 0.03659374\r\n",
      "Epoch:  99 Step:   461 /   793 Train loss: 0.02273114\r\n",
      "Epoch:  99 Step:   462 /   793 Train loss: 0.03263093\r\n",
      "Epoch:  99 Step:   463 /   793 Train loss: 0.02770899\r\n",
      "Epoch:  99 Step:   464 /   793 Train loss: 0.03097086\r\n",
      "Epoch:  99 Step:   465 /   793 Train loss: 0.01558243\r\n",
      "Epoch:  99 Step:   466 /   793 Train loss: 0.02081132\r\n",
      "Epoch:  99 Step:   467 /   793 Train loss: 0.02806420\r\n",
      "Epoch:  99 Step:   468 /   793 Train loss: 0.03140029\r\n",
      "Epoch:  99 Step:   469 /   793 Train loss: 0.02196022\r\n",
      "Epoch:  99 Step:   470 /   793 Train loss: 0.01592285\r\n",
      "Epoch:  99 Step:   471 /   793 Train loss: 0.01572415\r\n",
      "Epoch:  99 Step:   472 /   793 Train loss: 0.01741517\r\n",
      "Epoch:  99 Step:   473 /   793 Train loss: 0.01380089\r\n",
      "Epoch:  99 Step:   474 /   793 Train loss: 0.02337582\r\n",
      "Epoch:  99 Step:   475 /   793 Train loss: 0.02596843\r\n",
      "Epoch:  99 Step:   476 /   793 Train loss: 0.03307599\r\n",
      "Epoch:  99 Step:   477 /   793 Train loss: 0.01845898\r\n",
      "Epoch:  99 Step:   478 /   793 Train loss: 0.02972143\r\n",
      "Epoch:  99 Step:   479 /   793 Train loss: 0.02906815\r\n",
      "Epoch:  99 Step:   480 /   793 Train loss: 0.02196889\r\n",
      "Epoch:  99 Step:   481 /   793 Train loss: 0.01828547\r\n",
      "Epoch:  99 Step:   482 /   793 Train loss: 0.02949676\r\n",
      "Epoch:  99 Step:   483 /   793 Train loss: 0.02907458\r\n",
      "Epoch:  99 Step:   484 /   793 Train loss: 0.02747383\r\n",
      "Epoch:  99 Step:   485 /   793 Train loss: 0.02784810\r\n",
      "Epoch:  99 Step:   486 /   793 Train loss: 0.01993002\r\n",
      "Epoch:  99 Step:   487 /   793 Train loss: 0.02580700\r\n",
      "Epoch:  99 Step:   488 /   793 Train loss: 0.02486853\r\n",
      "Epoch:  99 Step:   489 /   793 Train loss: 0.02136882\r\n",
      "Epoch:  99 Step:   490 /   793 Train loss: 0.03295882\r\n",
      "Epoch:  99 Step:   491 /   793 Train loss: 0.02396926\r\n",
      "Epoch:  99 Step:   492 /   793 Train loss: 0.02481382\r\n",
      "Epoch:  99 Step:   493 /   793 Train loss: 0.02437314\r\n",
      "Epoch:  99 Step:   494 /   793 Train loss: 0.01735277\r\n",
      "Epoch:  99 Step:   495 /   793 Train loss: 0.03102559\r\n",
      "Epoch:  99 Step:   496 /   793 Train loss: 0.01374223\r\n",
      "Epoch:  99 Step:   497 /   793 Train loss: 0.02364779\r\n",
      "Epoch:  99 Step:   498 /   793 Train loss: 0.02294371\r\n",
      "Epoch:  99 Step:   499 /   793 Train loss: 0.01342407\r\n",
      "Epoch:  99 Step:   500 /   793 Train loss: 0.01904046\r\n",
      "Epoch:  99 Step:   501 /   793 Train loss: 0.02645255\r\n",
      "Epoch:  99 Step:   502 /   793 Train loss: 0.03086237\r\n",
      "Epoch:  99 Step:   503 /   793 Train loss: 0.02632822\r\n",
      "Epoch:  99 Step:   504 /   793 Train loss: 0.02399555\r\n",
      "Epoch:  99 Step:   505 /   793 Train loss: 0.03003990\r\n",
      "Epoch:  99 Step:   506 /   793 Train loss: 0.02242883\r\n",
      "Epoch:  99 Step:   507 /   793 Train loss: 0.03104473\r\n",
      "Epoch:  99 Step:   508 /   793 Train loss: 0.02028637\r\n",
      "Epoch:  99 Step:   509 /   793 Train loss: 0.01646422\r\n",
      "Epoch:  99 Step:   510 /   793 Train loss: 0.01877701\r\n",
      "Epoch:  99 Step:   511 /   793 Train loss: 0.02169817\r\n",
      "Epoch:  99 Step:   512 /   793 Train loss: 0.03246695\r\n",
      "Epoch:  99 Step:   513 /   793 Train loss: 0.01541364\r\n",
      "Epoch:  99 Step:   514 /   793 Train loss: 0.03165422\r\n",
      "Epoch:  99 Step:   515 /   793 Train loss: 0.02850324\r\n",
      "Epoch:  99 Step:   516 /   793 Train loss: 0.03493016\r\n",
      "Epoch:  99 Step:   517 /   793 Train loss: 0.02020118\r\n",
      "Epoch:  99 Step:   518 /   793 Train loss: 0.02956246\r\n",
      "Epoch:  99 Step:   519 /   793 Train loss: 0.01447993\r\n",
      "Epoch:  99 Step:   520 /   793 Train loss: 0.03144024\r\n",
      "Epoch:  99 Step:   521 /   793 Train loss: 0.03172363\r\n",
      "Epoch:  99 Step:   522 /   793 Train loss: 0.04195132\r\n",
      "Epoch:  99 Step:   523 /   793 Train loss: 0.03090810\r\n",
      "Epoch:  99 Step:   524 /   793 Train loss: 0.02122517\r\n",
      "Epoch:  99 Step:   525 /   793 Train loss: 0.02829774\r\n",
      "Epoch:  99 Step:   526 /   793 Train loss: 0.02075554\r\n",
      "Epoch:  99 Step:   527 /   793 Train loss: 0.01986269\r\n",
      "Epoch:  99 Step:   528 /   793 Train loss: 0.03159232\r\n",
      "Epoch:  99 Step:   529 /   793 Train loss: 0.02374512\r\n",
      "Epoch:  99 Step:   530 /   793 Train loss: 0.01917966\r\n",
      "Epoch:  99 Step:   531 /   793 Train loss: 0.02985399\r\n",
      "Epoch:  99 Step:   532 /   793 Train loss: 0.01762438\r\n",
      "Epoch:  99 Step:   533 /   793 Train loss: 0.01221500\r\n",
      "Epoch:  99 Step:   534 /   793 Train loss: 0.01571983\r\n",
      "Epoch:  99 Step:   535 /   793 Train loss: 0.03518157\r\n",
      "Epoch:  99 Step:   536 /   793 Train loss: 0.02110031\r\n",
      "Epoch:  99 Step:   537 /   793 Train loss: 0.03737090\r\n",
      "Epoch:  99 Step:   538 /   793 Train loss: 0.02411370\r\n",
      "Epoch:  99 Step:   539 /   793 Train loss: 0.03753006\r\n",
      "Epoch:  99 Step:   540 /   793 Train loss: 0.03916260\r\n",
      "Epoch:  99 Step:   541 /   793 Train loss: 0.03118131\r\n",
      "Epoch:  99 Step:   542 /   793 Train loss: 0.01209261\r\n",
      "Epoch:  99 Step:   543 /   793 Train loss: 0.03339510\r\n",
      "Epoch:  99 Step:   544 /   793 Train loss: 0.01944456\r\n",
      "Epoch:  99 Step:   545 /   793 Train loss: 0.01546581\r\n",
      "Epoch:  99 Step:   546 /   793 Train loss: 0.01446407\r\n",
      "Epoch:  99 Step:   547 /   793 Train loss: 0.02348527\r\n",
      "Epoch:  99 Step:   548 /   793 Train loss: 0.01680046\r\n",
      "Epoch:  99 Step:   549 /   793 Train loss: 0.01615900\r\n",
      "Epoch:  99 Step:   550 /   793 Train loss: 0.02527874\r\n",
      "Epoch:  99 Step:   551 /   793 Train loss: 0.03122066\r\n",
      "Epoch:  99 Step:   552 /   793 Train loss: 0.01544444\r\n",
      "Epoch:  99 Step:   553 /   793 Train loss: 0.02523358\r\n",
      "Epoch:  99 Step:   554 /   793 Train loss: 0.04052696\r\n",
      "Epoch:  99 Step:   555 /   793 Train loss: 0.02147606\r\n",
      "Epoch:  99 Step:   556 /   793 Train loss: 0.01948135\r\n",
      "Epoch:  99 Step:   557 /   793 Train loss: 0.01590794\r\n",
      "Epoch:  99 Step:   558 /   793 Train loss: 0.01714782\r\n",
      "Epoch:  99 Step:   559 /   793 Train loss: 0.03742869\r\n",
      "Epoch:  99 Step:   560 /   793 Train loss: 0.02320422\r\n",
      "Epoch:  99 Step:   561 /   793 Train loss: 0.02203379\r\n",
      "Epoch:  99 Step:   562 /   793 Train loss: 0.01591844\r\n",
      "Epoch:  99 Step:   563 /   793 Train loss: 0.02033391\r\n",
      "Epoch:  99 Step:   564 /   793 Train loss: 0.03709668\r\n",
      "Epoch:  99 Step:   565 /   793 Train loss: 0.03050305\r\n",
      "Epoch:  99 Step:   566 /   793 Train loss: 0.02587133\r\n",
      "Epoch:  99 Step:   567 /   793 Train loss: 0.01699353\r\n",
      "Epoch:  99 Step:   568 /   793 Train loss: 0.02652946\r\n",
      "Epoch:  99 Step:   569 /   793 Train loss: 0.02311274\r\n",
      "Epoch:  99 Step:   570 /   793 Train loss: 0.02789384\r\n",
      "Epoch:  99 Step:   571 /   793 Train loss: 0.02286804\r\n",
      "Epoch:  99 Step:   572 /   793 Train loss: 0.02627125\r\n",
      "Epoch:  99 Step:   573 /   793 Train loss: 0.02262239\r\n",
      "Epoch:  99 Step:   574 /   793 Train loss: 0.01994391\r\n",
      "Epoch:  99 Step:   575 /   793 Train loss: 0.01566848\r\n",
      "Epoch:  99 Step:   576 /   793 Train loss: 0.03181987\r\n",
      "Epoch:  99 Step:   577 /   793 Train loss: 0.02562092\r\n",
      "Epoch:  99 Step:   578 /   793 Train loss: 0.02433750\r\n",
      "Epoch:  99 Step:   579 /   793 Train loss: 0.02327961\r\n",
      "Epoch:  99 Step:   580 /   793 Train loss: 0.02222887\r\n",
      "Epoch:  99 Step:   581 /   793 Train loss: 0.02898115\r\n",
      "Epoch:  99 Step:   582 /   793 Train loss: 0.01830635\r\n",
      "Epoch:  99 Step:   583 /   793 Train loss: 0.01829670\r\n",
      "Epoch:  99 Step:   584 /   793 Train loss: 0.02509792\r\n",
      "Epoch:  99 Step:   585 /   793 Train loss: 0.04453673\r\n",
      "Epoch:  99 Step:   586 /   793 Train loss: 0.02647271\r\n",
      "Epoch:  99 Step:   587 /   793 Train loss: 0.03000900\r\n",
      "Epoch:  99 Step:   588 /   793 Train loss: 0.03220569\r\n",
      "Epoch:  99 Step:   589 /   793 Train loss: 0.02439993\r\n",
      "Epoch:  99 Step:   590 /   793 Train loss: 0.01726209\r\n",
      "Epoch:  99 Step:   591 /   793 Train loss: 0.01863575\r\n",
      "Epoch:  99 Step:   592 /   793 Train loss: 0.02661945\r\n",
      "Epoch:  99 Step:   593 /   793 Train loss: 0.02525241\r\n",
      "Epoch:  99 Step:   594 /   793 Train loss: 0.02137408\r\n",
      "Epoch:  99 Step:   595 /   793 Train loss: 0.02204736\r\n",
      "Epoch:  99 Step:   596 /   793 Train loss: 0.02050919\r\n",
      "Epoch:  99 Step:   597 /   793 Train loss: 0.01977552\r\n",
      "Epoch:  99 Step:   598 /   793 Train loss: 0.01543511\r\n",
      "Epoch:  99 Step:   599 /   793 Train loss: 0.03027201\r\n",
      "Epoch:  99 Step:   600 /   793 Train loss: 0.02401844\r\n",
      "Epoch:  99 Step:   601 /   793 Train loss: 0.02546010\r\n",
      "Epoch:  99 Step:   602 /   793 Train loss: 0.02554448\r\n",
      "Epoch:  99 Step:   603 /   793 Train loss: 0.02535970\r\n",
      "Epoch:  99 Step:   604 /   793 Train loss: 0.03777989\r\n",
      "Epoch:  99 Step:   605 /   793 Train loss: 0.02765174\r\n",
      "Epoch:  99 Step:   606 /   793 Train loss: 0.01804290\r\n",
      "Epoch:  99 Step:   607 /   793 Train loss: 0.02485687\r\n",
      "Epoch:  99 Step:   608 /   793 Train loss: 0.03042523\r\n",
      "Epoch:  99 Step:   609 /   793 Train loss: 0.02024273\r\n",
      "Epoch:  99 Step:   610 /   793 Train loss: 0.02337864\r\n",
      "Epoch:  99 Step:   611 /   793 Train loss: 0.01814135\r\n",
      "Epoch:  99 Step:   612 /   793 Train loss: 0.02741294\r\n",
      "Epoch:  99 Step:   613 /   793 Train loss: 0.01924749\r\n",
      "Epoch:  99 Step:   614 /   793 Train loss: 0.02720159\r\n",
      "Epoch:  99 Step:   615 /   793 Train loss: 0.02202812\r\n",
      "Epoch:  99 Step:   616 /   793 Train loss: 0.01231585\r\n",
      "Epoch:  99 Step:   617 /   793 Train loss: 0.01419560\r\n",
      "Epoch:  99 Step:   618 /   793 Train loss: 0.02027483\r\n",
      "Epoch:  99 Step:   619 /   793 Train loss: 0.03201149\r\n",
      "Epoch:  99 Step:   620 /   793 Train loss: 0.03570118\r\n",
      "Epoch:  99 Step:   621 /   793 Train loss: 0.01435773\r\n",
      "Epoch:  99 Step:   622 /   793 Train loss: 0.02030957\r\n",
      "Epoch:  99 Step:   623 /   793 Train loss: 0.02288146\r\n",
      "Epoch:  99 Step:   624 /   793 Train loss: 0.03250111\r\n",
      "Epoch:  99 Step:   625 /   793 Train loss: 0.03500546\r\n",
      "Epoch:  99 Step:   626 /   793 Train loss: 0.01512177\r\n",
      "Epoch:  99 Step:   627 /   793 Train loss: 0.01961656\r\n",
      "Epoch:  99 Step:   628 /   793 Train loss: 0.02791719\r\n",
      "Epoch:  99 Step:   629 /   793 Train loss: 0.02364676\r\n",
      "Epoch:  99 Step:   630 /   793 Train loss: 0.00742399\r\n",
      "Epoch:  99 Step:   631 /   793 Train loss: 0.02483118\r\n",
      "Epoch:  99 Step:   632 /   793 Train loss: 0.01213546\r\n",
      "Epoch:  99 Step:   633 /   793 Train loss: 0.03442201\r\n",
      "Epoch:  99 Step:   634 /   793 Train loss: 0.01621075\r\n",
      "Epoch:  99 Step:   635 /   793 Train loss: 0.02440009\r\n",
      "Epoch:  99 Step:   636 /   793 Train loss: 0.02092219\r\n",
      "Epoch:  99 Step:   637 /   793 Train loss: 0.03332022\r\n",
      "Epoch:  99 Step:   638 /   793 Train loss: 0.03556228\r\n",
      "Epoch:  99 Step:   639 /   793 Train loss: 0.01506343\r\n",
      "Epoch:  99 Step:   640 /   793 Train loss: 0.01471228\r\n",
      "Epoch:  99 Step:   641 /   793 Train loss: 0.02339447\r\n",
      "Epoch:  99 Step:   642 /   793 Train loss: 0.01355696\r\n",
      "Epoch:  99 Step:   643 /   793 Train loss: 0.02646895\r\n",
      "Epoch:  99 Step:   644 /   793 Train loss: 0.02856449\r\n",
      "Epoch:  99 Step:   645 /   793 Train loss: 0.01783752\r\n",
      "Epoch:  99 Step:   646 /   793 Train loss: 0.02121997\r\n",
      "Epoch:  99 Step:   647 /   793 Train loss: 0.01644363\r\n",
      "Epoch:  99 Step:   648 /   793 Train loss: 0.02136011\r\n",
      "Epoch:  99 Step:   649 /   793 Train loss: 0.02300936\r\n",
      "Epoch:  99 Step:   650 /   793 Train loss: 0.02610058\r\n",
      "Epoch:  99 Step:   651 /   793 Train loss: 0.01672624\r\n",
      "Epoch:  99 Step:   652 /   793 Train loss: 0.01738772\r\n",
      "Epoch:  99 Step:   653 /   793 Train loss: 0.03127080\r\n",
      "Epoch:  99 Step:   654 /   793 Train loss: 0.02000260\r\n",
      "Epoch:  99 Step:   655 /   793 Train loss: 0.02439057\r\n",
      "Epoch:  99 Step:   656 /   793 Train loss: 0.01473040\r\n",
      "Epoch:  99 Step:   657 /   793 Train loss: 0.01797342\r\n",
      "Epoch:  99 Step:   658 /   793 Train loss: 0.02404989\r\n",
      "Epoch:  99 Step:   659 /   793 Train loss: 0.02336629\r\n",
      "Epoch:  99 Step:   660 /   793 Train loss: 0.02892830\r\n",
      "Epoch:  99 Step:   661 /   793 Train loss: 0.02553758\r\n",
      "Epoch:  99 Step:   662 /   793 Train loss: 0.01329436\r\n",
      "Epoch:  99 Step:   663 /   793 Train loss: 0.02468627\r\n",
      "Epoch:  99 Step:   664 /   793 Train loss: 0.01730885\r\n",
      "Epoch:  99 Step:   665 /   793 Train loss: 0.02249139\r\n",
      "Epoch:  99 Step:   666 /   793 Train loss: 0.03011673\r\n",
      "Epoch:  99 Step:   667 /   793 Train loss: 0.03675830\r\n",
      "Epoch:  99 Step:   668 /   793 Train loss: 0.03931052\r\n",
      "Epoch:  99 Step:   669 /   793 Train loss: 0.02249765\r\n",
      "Epoch:  99 Step:   670 /   793 Train loss: 0.02784746\r\n",
      "Epoch:  99 Step:   671 /   793 Train loss: 0.02071554\r\n",
      "Epoch:  99 Step:   672 /   793 Train loss: 0.03051467\r\n",
      "Epoch:  99 Step:   673 /   793 Train loss: 0.02404435\r\n",
      "Epoch:  99 Step:   674 /   793 Train loss: 0.01224968\r\n",
      "Epoch:  99 Step:   675 /   793 Train loss: 0.02018760\r\n",
      "Epoch:  99 Step:   676 /   793 Train loss: 0.03255814\r\n",
      "Epoch:  99 Step:   677 /   793 Train loss: 0.02129964\r\n",
      "Epoch:  99 Step:   678 /   793 Train loss: 0.02992099\r\n",
      "Epoch:  99 Step:   679 /   793 Train loss: 0.01862628\r\n",
      "Epoch:  99 Step:   680 /   793 Train loss: 0.03019433\r\n",
      "Epoch:  99 Step:   681 /   793 Train loss: 0.02540242\r\n",
      "Epoch:  99 Step:   682 /   793 Train loss: 0.01670177\r\n",
      "Epoch:  99 Step:   683 /   793 Train loss: 0.02331664\r\n",
      "Epoch:  99 Step:   684 /   793 Train loss: 0.02187003\r\n",
      "Epoch:  99 Step:   685 /   793 Train loss: 0.03611836\r\n",
      "Epoch:  99 Step:   686 /   793 Train loss: 0.01869403\r\n",
      "Epoch:  99 Step:   687 /   793 Train loss: 0.02400112\r\n",
      "Epoch:  99 Step:   688 /   793 Train loss: 0.03146321\r\n",
      "Epoch:  99 Step:   689 /   793 Train loss: 0.01804932\r\n",
      "Epoch:  99 Step:   690 /   793 Train loss: 0.02437833\r\n",
      "Epoch:  99 Step:   691 /   793 Train loss: 0.02182038\r\n",
      "Epoch:  99 Step:   692 /   793 Train loss: 0.02246739\r\n",
      "Epoch:  99 Step:   693 /   793 Train loss: 0.02445787\r\n",
      "Epoch:  99 Step:   694 /   793 Train loss: 0.02194470\r\n",
      "Epoch:  99 Step:   695 /   793 Train loss: 0.01294092\r\n",
      "Epoch:  99 Step:   696 /   793 Train loss: 0.01891918\r\n",
      "Epoch:  99 Step:   697 /   793 Train loss: 0.02485326\r\n",
      "Epoch:  99 Step:   698 /   793 Train loss: 0.02322174\r\n",
      "Epoch:  99 Step:   699 /   793 Train loss: 0.02590942\r\n",
      "Epoch:  99 Step:   700 /   793 Train loss: 0.02272685\r\n",
      "Epoch:  99 Step:   701 /   793 Train loss: 0.01792824\r\n",
      "Epoch:  99 Step:   702 /   793 Train loss: 0.02895133\r\n",
      "Epoch:  99 Step:   703 /   793 Train loss: 0.02346582\r\n",
      "Epoch:  99 Step:   704 /   793 Train loss: 0.02812856\r\n",
      "Epoch:  99 Step:   705 /   793 Train loss: 0.02796344\r\n",
      "Epoch:  99 Step:   706 /   793 Train loss: 0.02142244\r\n",
      "Epoch:  99 Step:   707 /   793 Train loss: 0.02629081\r\n",
      "Epoch:  99 Step:   708 /   793 Train loss: 0.02612657\r\n",
      "Epoch:  99 Step:   709 /   793 Train loss: 0.02125898\r\n",
      "Epoch:  99 Step:   710 /   793 Train loss: 0.01724268\r\n",
      "Epoch:  99 Step:   711 /   793 Train loss: 0.01183714\r\n",
      "Epoch:  99 Step:   712 /   793 Train loss: 0.03798961\r\n",
      "Epoch:  99 Step:   713 /   793 Train loss: 0.02884313\r\n",
      "Epoch:  99 Step:   714 /   793 Train loss: 0.02338841\r\n",
      "Epoch:  99 Step:   715 /   793 Train loss: 0.03914988\r\n",
      "Epoch:  99 Step:   716 /   793 Train loss: 0.02000808\r\n",
      "Epoch:  99 Step:   717 /   793 Train loss: 0.02438471\r\n",
      "Epoch:  99 Step:   718 /   793 Train loss: 0.03408606\r\n",
      "Epoch:  99 Step:   719 /   793 Train loss: 0.02953338\r\n",
      "Epoch:  99 Step:   720 /   793 Train loss: 0.02979165\r\n",
      "Epoch:  99 Step:   721 /   793 Train loss: 0.01556464\r\n",
      "Epoch:  99 Step:   722 /   793 Train loss: 0.01212388\r\n",
      "Epoch:  99 Step:   723 /   793 Train loss: 0.03375480\r\n",
      "Epoch:  99 Step:   724 /   793 Train loss: 0.03093822\r\n",
      "Epoch:  99 Step:   725 /   793 Train loss: 0.01904348\r\n",
      "Epoch:  99 Step:   726 /   793 Train loss: 0.02385251\r\n",
      "Epoch:  99 Step:   727 /   793 Train loss: 0.03092230\r\n",
      "Epoch:  99 Step:   728 /   793 Train loss: 0.03541758\r\n",
      "Epoch:  99 Step:   729 /   793 Train loss: 0.01459747\r\n",
      "Epoch:  99 Step:   730 /   793 Train loss: 0.01526724\r\n",
      "Epoch:  99 Step:   731 /   793 Train loss: 0.02862824\r\n",
      "Epoch:  99 Step:   732 /   793 Train loss: 0.01794469\r\n",
      "Epoch:  99 Step:   733 /   793 Train loss: 0.03013043\r\n",
      "Epoch:  99 Step:   734 /   793 Train loss: 0.01904345\r\n",
      "Epoch:  99 Step:   735 /   793 Train loss: 0.01992249\r\n",
      "Epoch:  99 Step:   736 /   793 Train loss: 0.01826188\r\n",
      "Epoch:  99 Step:   737 /   793 Train loss: 0.02216706\r\n",
      "Epoch:  99 Step:   738 /   793 Train loss: 0.02486457\r\n",
      "Epoch:  99 Step:   739 /   793 Train loss: 0.01760187\r\n",
      "Epoch:  99 Step:   740 /   793 Train loss: 0.02037710\r\n",
      "Epoch:  99 Step:   741 /   793 Train loss: 0.01800771\r\n",
      "Epoch:  99 Step:   742 /   793 Train loss: 0.01993760\r\n",
      "Epoch:  99 Step:   743 /   793 Train loss: 0.02279250\r\n",
      "Epoch:  99 Step:   744 /   793 Train loss: 0.02157338\r\n",
      "Epoch:  99 Step:   745 /   793 Train loss: 0.01828243\r\n",
      "Epoch:  99 Step:   746 /   793 Train loss: 0.01609860\r\n",
      "Epoch:  99 Step:   747 /   793 Train loss: 0.02218289\r\n",
      "Epoch:  99 Step:   748 /   793 Train loss: 0.03094321\r\n",
      "Epoch:  99 Step:   749 /   793 Train loss: 0.01513115\r\n",
      "Epoch:  99 Step:   750 /   793 Train loss: 0.01942677\r\n",
      "Epoch:  99 Step:   751 /   793 Train loss: 0.02850756\r\n",
      "Epoch:  99 Step:   752 /   793 Train loss: 0.03193029\r\n",
      "Epoch:  99 Step:   753 /   793 Train loss: 0.01961786\r\n",
      "Epoch:  99 Step:   754 /   793 Train loss: 0.03212343\r\n",
      "Epoch:  99 Step:   755 /   793 Train loss: 0.03132487\r\n",
      "Epoch:  99 Step:   756 /   793 Train loss: 0.02710660\r\n",
      "Epoch:  99 Step:   757 /   793 Train loss: 0.01621011\r\n",
      "Epoch:  99 Step:   758 /   793 Train loss: 0.01959709\r\n",
      "Epoch:  99 Step:   759 /   793 Train loss: 0.02441195\r\n",
      "Epoch:  99 Step:   760 /   793 Train loss: 0.02458769\r\n",
      "Epoch:  99 Step:   761 /   793 Train loss: 0.01971810\r\n",
      "Epoch:  99 Step:   762 /   793 Train loss: 0.01778016\r\n",
      "Epoch:  99 Step:   763 /   793 Train loss: 0.03225509\r\n",
      "Epoch:  99 Step:   764 /   793 Train loss: 0.03247511\r\n",
      "Epoch:  99 Step:   765 /   793 Train loss: 0.00884828\r\n",
      "Epoch:  99 Step:   766 /   793 Train loss: 0.02689267\r\n",
      "Epoch:  99 Step:   767 /   793 Train loss: 0.02597914\r\n",
      "Epoch:  99 Step:   768 /   793 Train loss: 0.01765893\r\n",
      "Epoch:  99 Step:   769 /   793 Train loss: 0.02488091\r\n",
      "Epoch:  99 Step:   770 /   793 Train loss: 0.02982326\r\n",
      "Epoch:  99 Step:   771 /   793 Train loss: 0.01432916\r\n",
      "Epoch:  99 Step:   772 /   793 Train loss: 0.02418453\r\n",
      "Epoch:  99 Step:   773 /   793 Train loss: 0.02117470\r\n",
      "Epoch:  99 Step:   774 /   793 Train loss: 0.01242638\r\n",
      "Epoch:  99 Step:   775 /   793 Train loss: 0.03326432\r\n",
      "Epoch:  99 Step:   776 /   793 Train loss: 0.03716386\r\n",
      "Epoch:  99 Step:   777 /   793 Train loss: 0.03563461\r\n",
      "Epoch:  99 Step:   778 /   793 Train loss: 0.03460846\r\n",
      "Epoch:  99 Step:   779 /   793 Train loss: 0.02229134\r\n",
      "Epoch:  99 Step:   780 /   793 Train loss: 0.01581304\r\n",
      "Epoch:  99 Step:   781 /   793 Train loss: 0.01401135\r\n",
      "Epoch:  99 Step:   782 /   793 Train loss: 0.01008086\r\n",
      "Epoch:  99 Step:   783 /   793 Train loss: 0.02248658\r\n",
      "Epoch:  99 Step:   784 /   793 Train loss: 0.03199899\r\n",
      "Epoch:  99 Step:   785 /   793 Train loss: 0.02534666\r\n",
      "Epoch:  99 Step:   786 /   793 Train loss: 0.02541951\r\n",
      "Epoch:  99 Step:   787 /   793 Train loss: 0.02131497\r\n",
      "Epoch:  99 Step:   788 /   793 Train loss: 0.02833607\r\n",
      "Epoch:  99 Step:   789 /   793 Train loss: 0.03982668\r\n",
      "Epoch:  99 Step:   790 /   793 Train loss: 0.02408843\r\n",
      "Epoch:  99 Step:   791 /   793 Train loss: 0.02294028\r\n",
      "Epoch:  99 Step:   792 /   793 Train loss: 0.01688196\r\n",
      "Epoch:  99 Validation loss: 0.01431434\r\n"
     ]
    }
   ],
   "source": [
    "!cp /kaggle/input/baid-model-test/baid-model/data.py /kaggle/working\n",
    "!cp /kaggle/input/baid-model-test/baid-model/models/model.py /kaggle/working\n",
    "!cp /kaggle/input/baid-model-test/baid-model/models/layers.py /kaggle/working\n",
    "!cp /kaggle/input/baid-model-test/baid-model/test.py /kaggle/working\n",
    "!cp /kaggle/input/baid-model-test/baid-model/train.py /kaggle/working\n",
    "!cp /kaggle/input/baid-model-test/baid-model/pretraining.py /kaggle/working\n",
    "!cp /kaggle/input/baid-model-test/baid-model/common.py /kaggle/working\n",
    "\n",
    "\n",
    "# and so on for other necessary files\n",
    "\n",
    "!python /kaggle/input/baid-model-test/baid-model/train.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbacf7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-28T20:08:13.193157Z",
     "iopub.status.busy": "2024-03-28T20:08:13.192436Z",
     "iopub.status.idle": "2024-03-28T20:10:38.283564Z",
     "shell.execute_reply": "2024-03-28T20:10:38.282465Z",
     "shell.execute_reply.started": "2024-03-28T20:08:13.193122Z"
    },
    "papermill": {
     "duration": 1.522835,
     "end_time": "2024-04-07T18:08:10.897354",
     "exception": false,
     "start_time": "2024-04-07T18:08:09.374519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4629576,
     "sourceId": 7886377,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4749547,
     "sourceId": 8053356,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30664,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 23610.977663,
   "end_time": "2024-04-07T18:08:12.916709",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-07T11:34:41.939046",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
